[
  {
    "id": "arXiv:2312.00003",
    "title": "Transport Equation based Physics Informed Neural Network to predict the  Yield Strength of Architected Materials",
    "abstract": "In this research, the application of the Physics-Informed Neural Network (PINN) model is explored to solve transport equation-based Partial Differential Equations (PDEs). The primary objective is to analyze the impact of different activation functions incorporated within the PINN model on its predictive performance, specifically assessing the Mean Squared Error (MSE) and Mean Absolute Error (MAE). The dataset used in the study consists of a varied set of input parameters related to strut diameter, unit cell size, and the corresponding yield stress values. Through this investigation the aim is to understand the effectiveness of the PINN model and the significance of choosing appropriate activation functions for solving complex PDEs in real-world applications. The outcomes suggest that the choice of activation function may have minimal influence on the model's predictive accuracy for this particular problem. The PINN model showcases exceptional generalization capabilities, indicating its capacity to avoid overfitting with the provided dataset. The research underscores the importance of striking a balance between performance and computational efficiency while selecting an activation function for specific real-world applications. These valuable findings contribute to advancing the understanding and potential adoption of PINN as an effective tool for solving challenging PDEs in diverse scientific and engineering domains. ",
    "url": "https://arxiv.org/abs/2312.00003",
    "authors": [
      "Akshansh Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2312.00005",
    "title": "NumCalc: An open source BEM code for solving acoustic scattering  problems",
    "abstract": "The calculation of the acoustic field in or around objects is an important task in acoustic engineering. To numerically solve this task, the boundary element method (BEM) is a commonly used method especially for infinite domains. The open source tool Mesh2HRTF and its BEM core NumCalc provide users with a collection of free software for acoustic simulations without the need of having an in-depth knowledge into numerical methods. However, we feel that users should have a basic understanding with respect to the methods behind the software they are using. We are convinced that this basic understanding helps in avoiding common mistakes and also helps to understand the requirements to use the software. To provide this background is the first motivation for this paper. A second motivation for this paper is to demonstrate the accuracy of NumCalc when solving benchmark problems. Thus, users can get an idea about the accuracy they can expect when using NumCalc as well as the memory and CPU requirements of NumCalc. A third motivation for this paper is to give users detailed information about some parts of the actual implementation that are usually not mentioned in literature, e.g., the specific version of the fast multipole method and its clustering process or how to use frequency-dependent admittance boundary conditions. ",
    "url": "https://arxiv.org/abs/2312.00005",
    "authors": [
      "Wolfgang Kreuzer",
      "Katharina Pollack",
      "Fabian Brinkmann",
      "Piotr Majdak"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2312.00006",
    "title": "Enhancing ML-Based DoS Attack Detection Through Combinatorial Fusion  Analysis",
    "abstract": "Mitigating Denial-of-Service (DoS) attacks is vital for online service security and availability. While machine learning (ML) models are used for DoS attack detection, new strategies are needed to enhance their performance. We suggest an innovative method, combinatorial fusion, which combines multiple ML models using advanced algorithms. This includes score and rank combinations, weighted techniques, and diversity strength of scoring systems. Through rigorous evaluations, we demonstrate the effectiveness of this fusion approach, considering metrics like precision, recall, and F1-score. We address the challenge of low-profiled attack classification by fusing models to create a comprehensive solution. Our findings emphasize the potential of this approach to improve DoS attack detection and contribute to stronger defense mechanisms. ",
    "url": "https://arxiv.org/abs/2312.00006",
    "authors": [
      "Evans Owusu",
      "Mohamed Rahouti",
      "D. Frank Hsu",
      "Kaiqi Xiong",
      "Yufeng Xin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.00009",
    "title": "Risk-Aware and Explainable Framework for Ensuring Guaranteed Coverage in  Evolving Hardware Trojan Detection",
    "abstract": "As the semiconductor industry has shifted to a fabless paradigm, the risk of hardware Trojans being inserted at various stages of production has also increased. Recently, there has been a growing trend toward the use of machine learning solutions to detect hardware Trojans more effectively, with a focus on the accuracy of the model as an evaluation metric. However, in a high-risk and sensitive domain, we cannot accept even a small misclassification. Additionally, it is unrealistic to expect an ideal model, especially when Trojans evolve over time. Therefore, we need metrics to assess the trustworthiness of detected Trojans and a mechanism to simulate unseen ones. In this paper, we generate evolving hardware Trojans using our proposed novel conformalized generative adversarial networks and offer an efficient approach to detecting them based on a non-invasive algorithm-agnostic statistical inference framework that leverages the Mondrian conformal predictor. The method acts like a wrapper over any of the machine learning models and produces set predictions along with uncertainty quantification for each new detected Trojan for more robust decision-making. In the case of a NULL set, a novel method to reject the decision by providing a calibrated explainability is discussed. The proposed approach has been validated on both synthetic and real chip-level benchmarks and proven to pave the way for researchers looking to find informed machine learning solutions to hardware security problems. ",
    "url": "https://arxiv.org/abs/2312.00009",
    "authors": [
      "Rahul Vishwakarma",
      "Amin Rezaei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.00016",
    "title": "Preserving The Safety And Confidentiality Of Data Mining Information In  Health Care: A literature review",
    "abstract": "Daily, massive volume of data are produced due to the internet of things' rapid development, which has now permeated the healthcare industry. Recent advances in data mining have spawned a new field of a study dubbed privacy-preserving data mining (PPDM). PPDM technique or approach enables the extraction of actionable insight from enormous volume of data while safeguarding the privacy of individual information and benefiting the entire society Medical research has taken a new course as a result of data mining with healthcare data to detect diseases earlier and improve patient care. Data integration necessitates the sharing of sensitive patient information. However, substantial privacy issues are raised in connection with the storage and transmission of potentially sensitive information. Disclosing sensitive information infringes on patients' privacy. This paper aims to conduct a review of related work on privacy-preserving mechanisms, data protection regulations, and mitigating tactics. The review concluded that no single strategy outperforms all others. Hence, future research should focus on adequate techniques for privacy solutions in the age of massive medical data and the standardization of evaluation standards. ",
    "url": "https://arxiv.org/abs/2312.00016",
    "authors": [
      "Robinson Onyemechi Oturugbum"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.00023",
    "title": "Hypergraph Topological Features for Autoencoder-Based Intrusion  Detection for Cybersecurity Data",
    "abstract": "In this position paper, we argue that when hypergraphs are used to capture multi-way local relations of data, their resulting topological features describe global behaviour. Consequently, these features capture complex correlations that can then serve as high fidelity inputs to autoencoder-driven anomaly detection pipelines. We propose two such potential pipelines for cybersecurity data, one that uses an autoencoder directly to determine network intrusions, and one that de-noises input data for a persistent homology system, PHANTOM. We provide heuristic justification for the use of the methods described therein for an intrusion detection pipeline for cyber data. We conclude by showing a small example over synthetic cyber attack data. ",
    "url": "https://arxiv.org/abs/2312.00023",
    "authors": [
      "Bill Kay",
      "Sinan G. Aksoy",
      "Molly Baird",
      "Daniel M. Best",
      "Helen Jenne",
      "Cliff Joslyn",
      "Christopher Potvin",
      "Gregory Henselman-Petrusek",
      "Garret Seppala",
      "Stephen J. Young",
      "Emilie Purvine"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.00027",
    "title": "Stealthy and Persistent Unalignment on Large Language Models via  Backdoor Injections",
    "abstract": "Recent developments in Large Language Models (LLMs) have manifested significant advancements. To facilitate safeguards against malicious exploitation, a body of research has concentrated on aligning LLMs with human preferences and inhibiting their generation of inappropriate content. Unfortunately, such alignments are often vulnerable: fine-tuning with a minimal amount of harmful data can easily unalign the target LLM. While being effective, such fine-tuning-based unalignment approaches also have their own limitations: (1) non-stealthiness, after fine-tuning, safety audits or red-teaming can easily expose the potential weaknesses of the unaligned models, thereby precluding their release/use. (2) non-persistence, the unaligned LLMs can be easily repaired through re-alignment, i.e., fine-tuning again with aligned data points. In this work, we show that it is possible to conduct stealthy and persistent unalignment on large language models via backdoor injections. We also provide a novel understanding on the relationship between the backdoor persistence and the activation pattern and further provide guidelines for potential trigger design. Through extensive experiments, we demonstrate that our proposed stealthy and persistent unalignment can successfully pass the safety evaluation while maintaining strong persistence against re-alignment defense. ",
    "url": "https://arxiv.org/abs/2312.00027",
    "authors": [
      "Yuanpu Cao",
      "Bochuan Cao",
      "Jinghui Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.00028",
    "title": "Constructive Representation of Functions in $N$-Dimensional Sobolev  Space",
    "abstract": "We propose a new representation of functions in Sobolev spaces on an $N$-dimensional hyper-rectangle, expressing such functions in terms of their admissible derivatives, evaluated along lower-boundaries of the domain. These boundary values are either finite-dimensional or exist in the space $L_2$ of square-integrable functions -- free of the continuity constraints inherent to Sobolev space. Moreover, we show that the map from this space of boundary values to the Sobolev space is given by an integral operator with polynomial kernel, and we prove that this map is invertible. Using this result, we propose a method for polynomial approximation of functions in Sobolev space, reconstructing such an approximation from polynomial projections of the boundary values. We prove that this approximation is optimal with respect to a discrete-continuous Sobolev norm, and show through numerical examples that it exhibits better convergence behavior than direct projection of the function. Finally, we show that this approach may also be adapted to use a basis of step functions, to construct accurate piecewise polynomial approximations that do not suffer from e.g. Gibbs phenomenon. ",
    "url": "https://arxiv.org/abs/2312.00028",
    "authors": [
      "Declan S. Jagt",
      "Matthew M. Peet"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2312.00029",
    "title": "Bergeron: Combating Adversarial Attacks through a Conscience-Based  Alignment Framework",
    "abstract": "Modern Large language models (LLMs) can still generate responses that may not be aligned with human expectations or values. While many weight-based alignment methods have been proposed, many of them still leave models vulnerable to attacks when used on their own. To help mitigate this issue, we introduce Bergeron, a framework designed to improve the robustness of LLMs against adversarial attacks. Bergeron employs a two-tiered architecture. Here, a secondary LLM serves as a simulated conscience that safeguards a primary LLM. We do this by monitoring for and correcting potentially harmful text within both the prompt inputs and the generated outputs of the primary LLM. Empirical evaluation shows that Bergeron can improve the alignment and robustness of several popular LLMs without costly fine-tuning. It aids both open-source and black-box LLMs by complementing and reinforcing their existing alignment training. ",
    "url": "https://arxiv.org/abs/2312.00029",
    "authors": [
      "Matthew Pisano",
      "Peter Ly",
      "Abraham Sanders",
      "Bingsheng Yao",
      "Dakuo Wang",
      "Tomek Strzalkowski",
      "Mei Si"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.00033",
    "title": "DeFi Security: Turning The Weakest Link Into The Strongest Attraction",
    "abstract": "The primary innovation we pioneer -- focused on blockchain information security -- is called the Safe-House. The Safe-House is badly needed since there are many ongoing hacks and security concerns in the DeFi space right now. The Safe-House is a piece of engineering sophistication that utilizes existing blockchain principles to bring about greater security when customer assets are moved around. The Safe-House logic is easily implemented as smart contracts on any decentralized system. The amount of funds at risk from both internal and external parties -- and hence the maximum one time loss -- is guaranteed to stay within the specified limits based on cryptographic fundamentals. To improve the safety of the Safe-House even further, we adapt the one time password (OPT) concept to operate using blockchain technology. Well suited to blockchain cryptographic nuances, our secondary advancement can be termed the one time next time password (OTNTP) mechanism. The OTNTP is designed to complement the Safe-House making it even more safe. We provide a detailed threat assessment model -- discussing the risks faced by DeFi protocols and the specific risks that apply to blockchain fund management -- and give technical arguments regarding how these threats can be overcome in a robust manner. We discuss how the Safe-House can participate with other external yield generation protocols in a secure way. We provide reasons for why the Safe-House increases safety without sacrificing the efficiency of operation. We start with a high level intuitive description of the landscape, the corresponding problems and our solutions. We then supplement this overview with detailed discussions including the corresponding mathematical formulations and pointers for technological implementation. This approach ensures that the article is accessible to a broad audience. ",
    "url": "https://arxiv.org/abs/2312.00033",
    "authors": [
      "Ravi Kashyap"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computers and Society (cs.CY)",
      "Portfolio Management (q-fin.PM)",
      "Risk Management (q-fin.RM)"
    ]
  },
  {
    "id": "arXiv:2312.00034",
    "title": "Enhancing IoT Security via Automatic Network Traffic Analysis: The  Transition from Machine Learning to Deep Learning",
    "abstract": "This work provides a comparative analysis illustrating how Deep Learning (DL) surpasses Machine Learning (ML) in addressing tasks within Internet of Things (IoT), such as attack classification and device-type identification. Our approach involves training and evaluating a DL model using a range of diverse IoT-related datasets, allowing us to gain valuable insights into how adaptable and practical these models can be when confronted with various IoT configurations. We initially convert the unstructured network traffic data from IoT networks, stored in PCAP files, into images by processing the packet data. This conversion process adapts the data to meet the criteria of DL classification methods. The experiments showcase the ability of DL to surpass the constraints tied to manually engineered features, achieving superior results in attack detection and maintaining comparable outcomes in device-type identification. Additionally, a notable feature extraction time difference becomes evident in the experiments: traditional methods require around 29 milliseconds per data packet, while DL accomplishes the same task in just 2.9 milliseconds. The significant time gap, DL's superior performance, and the recognized limitations of manually engineered features, presents a compelling call to action within the IoT community. This encourages us to shift from exploring new IoT features for each dataset to addressing the challenges of integrating DL into IoT, making it a more efficient solution for real-world IoT scenarios. ",
    "url": "https://arxiv.org/abs/2312.00034",
    "authors": [
      "Mounia Hamidouche",
      "Eugeny Popko",
      "Bassem Ouni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2312.00040",
    "title": "Presentation Attack detection using Wavelet Transform and Deep Residual  Neural Net",
    "abstract": "Biometric authentication is becoming more prevalent for secured authentication systems. However, the biometric substances can be deceived by the imposters in several ways. Among other imposter attacks, print attacks, mask attacks, and replay attacks fall under the presentation attack category. The bio-metric images, especially the iris and face, are vulnerable to different presentation attacks. This research applies deep learning approaches to mitigate presentation attacks in a biometric access control system. Our contribution in this paper is two-fold: First, we applied the wavelet transform to extract the features from the biometric images. Second, we modified the deep residual neural net and applied it to the spoof datasets in an attempt to detect the presentation attacks. This research applied the proposed approach to biometric spoof datasets, namely ATVS, CASIA two class, and CASIA cropped image sets. The datasets used in this research contain images that are captured in both a controlled and uncontrolled environment along with different resolutions and sizes. We obtained the best accuracy of 93% on the ATVS Iris datasets. For CASIA two class and CASIA cropped datasets, we achieved test accuracies of 91% and 82%, respectively. ",
    "url": "https://arxiv.org/abs/2312.00040",
    "authors": [
      "Prosenjit Chatterjee",
      "Alex Yalchin",
      "Joseph Shelton",
      "Kaushik Roy",
      "Xiaohong Yuan",
      "Kossi D. Edoh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00041",
    "title": "Presentation Attack Detection using Convolutional Neural Networks and  Local Binary Patterns",
    "abstract": "The use of biometrics to authenticate users and control access to secure areas has become extremely popular in recent years, and biometric access control systems are frequently used by both governments and private corporations. However, these systems may represent risks to security when deployed without considering the possibility of biometric presentation attacks (also known as spoofing). Presentation attacks are a serious threat because they do not require significant time, expense, or skill to carry out while remaining effective against many biometric systems in use today. This research compares three different software-based methods for facial and iris presentation attack detection in images. The first method uses Inception-v3, a pre-trained deep Convolutional Neural Network (CNN) made by Google for the ImageNet challenge, which is retrained for this problem. The second uses a shallow CNN based on a modified Spoofnet architecture, which is trained normally. The third is a texture-based method using Local Binary Patterns (LBP). The datasets used are the ATVS-FIr dataset, which contains real and fake iris images, and the CASIA Face Anti-Spoofing Dataset, which contains real images as well as warped photos, cut photos, and video replay presentation attacks. We also present a third set of results, based on cropped versions of the CASIA images. ",
    "url": "https://arxiv.org/abs/2312.00041",
    "authors": [
      "Justin Spencer",
      "Deborah Lawrence",
      "Prosenjit Chatterjee",
      "Kaushik Roy",
      "Albert Esterline",
      "Jung-Hee Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00051",
    "title": "MIA-BAD: An Approach for Enhancing Membership Inference Attack and its  Mitigation with Federated Learning",
    "abstract": "The membership inference attack (MIA) is a popular paradigm for compromising the privacy of a machine learning (ML) model. MIA exploits the natural inclination of ML models to overfit upon the training data. MIAs are trained to distinguish between training and testing prediction confidence to infer membership information. Federated Learning (FL) is a privacy-preserving ML paradigm that enables multiple clients to train a unified model without disclosing their private data. In this paper, we propose an enhanced Membership Inference Attack with the Batch-wise generated Attack Dataset (MIA-BAD), a modification to the MIA approach. We investigate that the MIA is more accurate when the attack dataset is generated batch-wise. This quantitatively decreases the attack dataset while qualitatively improving it. We show how training an ML model through FL, has some distinct advantages and investigate how the threat introduced with the proposed MIA-BAD approach can be mitigated with FL approaches. Finally, we demonstrate the qualitative effects of the proposed MIA-BAD methodology by conducting extensive experiments with various target datasets, variable numbers of federated clients, and training batch sizes. ",
    "url": "https://arxiv.org/abs/2312.00051",
    "authors": [
      "Soumya Banerjee",
      "Sandip Roy",
      "Sayyed Farid Ahamed",
      "Devin Quinn",
      "Marc Vucovich",
      "Dhruv Nandakumar",
      "Kevin Choi",
      "Abdul Rahman",
      "Edward Bowen",
      "Sachin Shetty"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00053",
    "title": "Anti-Sexism Alert System: Identification of Sexist Comments on Social  Media Using AI Techniques",
    "abstract": "Social relationships in the digital sphere are becoming more usual and frequent, and they constitute a very important aspect for all of us. {Violent interactions in this sphere are very frequent, and have serious effects on the victims}. Within this global scenario, there is one kind of digital violence that is becoming really worrying: sexism against women. Sexist comments that are publicly posted in social media (newspaper comments, social networks, etc.), usually obtain a lot of attention and become viral, with consequent damage to the persons involved. In this paper, we introduce an anti-sexism alert system, based on natural language processing (NLP) and artificial intelligence (AI), that analyzes any public post, and decides if it could be considered a sexist comment or not. Additionally, this system also works on analyzing all the public comments linked to any multimedia content (piece of news, video, tweet, etc.) and decides, using a color-based system similar to traffic lights, if there is sexism in the global set of posts. We have created a labeled data set in Spanish, since the majority of studies focus on English, to train our system, which offers a very good performance after the validation experiments. ",
    "url": "https://arxiv.org/abs/2312.00053",
    "authors": [
      "Rebeca P. D\u00edaz Redondo",
      "Ana Fern\u00e1ndez Vilas",
      "Mateo Ramos Merino",
      "Sonia Valladares",
      "Soledad Torres Guijarro",
      "Manar Mohamed Hafez"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00068",
    "title": "GLiDR: Topologically Regularized Graph Generative Network for Sparse  LiDAR Point Clouds",
    "abstract": "Sparse LiDAR point clouds cause severe loss of detail of static structures and reduce the density of static points available for navigation. Reduced density can be detrimental to navigation under several scenarios. We observe that despite high sparsity, in most cases, the global topology of LiDAR outlining the static structures can be inferred. We utilize this property to obtain a backbone skeleton of a static LiDAR scan in the form of a single connected component that is a proxy to its global topology. We utilize the backbone to augment new points along static structures to overcome sparsity. Newly introduced points could correspond to existing static structures or to static points that were earlier obstructed by dynamic objects. To the best of our knowledge, we are the first to use this strategy for sparse LiDAR point clouds. Existing solutions close to our approach fail to identify and preserve the global static LiDAR topology and generate sub-optimal points. We propose GLiDR, a Graph Generative network that is topologically regularized using 0-dimensional Persistent Homology (PH) constraints. This enables GLiDR to introduce newer static points along a topologically consistent global static LiDAR backbone. GLiDR generates precise static points using 32x sparser dynamic scans and performs better than the baselines across three datasets. The newly introduced static points allow GLiDR to outperform LiDAR-based navigation using SLAM in several settings. GLiDR generates a valuable byproduct - an accurate binary segmentation mask of static and dynamic objects that is helpful for navigation planning and safety in constrained environments. ",
    "url": "https://arxiv.org/abs/2312.00068",
    "authors": [
      "Prashant Kumar",
      "Kshitij Madhav Bhat",
      "Vedang Bhupesh Shenvi Nadkarni",
      "Prem Kalra"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00075",
    "title": "Accelerating Neural Field Training via Soft Mining",
    "abstract": "We present an approach to accelerate Neural Field training by efficiently selecting sampling locations. While Neural Fields have recently become popular, it is often trained by uniformly sampling the training domain, or through handcrafted heuristics. We show that improved convergence and final training quality can be achieved by a soft mining technique based on importance sampling: rather than either considering or ignoring a pixel completely, we weigh the corresponding loss by a scalar. To implement our idea we use Langevin Monte-Carlo sampling. We show that by doing so, regions with higher error are being selected more frequently, leading to more than 2x improvement in convergence speed. The code and related resources for this study are publicly available at https://ubc-vision.github.io/nf-soft-mining/. ",
    "url": "https://arxiv.org/abs/2312.00075",
    "authors": [
      "Shakiba Kheradmand",
      "Daniel Rebain",
      "Gopal Sharma",
      "Hossam Isack",
      "Abhishek Kar",
      "Andrea Tagliasacchi",
      "Kwang Moo Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00078",
    "title": "Enhancing Cross-domain Click-Through Rate Prediction via Explicit  Feature Augmentation",
    "abstract": "Cross-domain CTR (CDCTR) prediction is an important research topic that studies how to leverage meaningful data from a related domain to help CTR prediction in target domain. Most existing CDCTR works design implicit ways to transfer knowledge across domains such as parameter-sharing that regularizes the model training in target domain. More effectively, recent researchers propose explicit techniques to extract user interest knowledge and transfer this knowledge to target domain. However, the proposed method mainly faces two issues: 1) it usually requires a super domain, i.e. an extremely large source domain, to cover most users or items of target domain, and 2) the extracted user interest knowledge is static no matter what the context is in target domain. These limitations motivate us to develop a more flexible and efficient technique to explicitly transfer knowledge. In this work, we propose a cross-domain augmentation network (CDAnet) being able to perform explicit knowledge transfer between two domains. Specifically, CDAnet contains a designed translation network and an augmentation network which are trained sequentially. The translation network computes latent features from two domains and learns meaningful cross-domain knowledge of each input in target domain by using a designed cross-supervised feature translator. Later the augmentation network employs the explicit cross-domain knowledge as augmented information to boost the target domain CTR prediction. Through extensive experiments on two public benchmarks and one industrial production dataset, we show CDAnet can learn meaningful translated features and largely improve the performance of CTR prediction. CDAnet has been conducted online A/B test in image2product retrieval at Taobao app, bringing an absolute 0.11 point CTR improvement, a relative 0.64% deal growth and a relative 1.26% GMV increase. ",
    "url": "https://arxiv.org/abs/2312.00078",
    "authors": [
      "Xu Chen",
      "Zida Cheng",
      "Jiangchao Yao",
      "Chen Ju",
      "Weilin Huang",
      "Jinsong Lan",
      "Xiaoyi Zeng",
      "Shuai Xiao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2312.00083",
    "title": "BAM-DETR: Boundary-Aligned Moment Detection Transformer for Temporal  Sentence Grounding in Videos",
    "abstract": "Temporal sentence grounding aims to localize moments relevant to a language description. Recently, DETR-like approaches have shown notable progress by decoding the center and length of a target moment from learnable queries. However, they suffer from the issue of center misalignment raised by the inherent ambiguity of moment centers, leading to inaccurate predictions. To remedy this problem, we introduce a novel boundary-oriented moment formulation. In our paradigm, the model no longer needs to find the precise center but instead suffices to predict any anchor point within the interval, from which the onset and offset are directly estimated. Based on this idea, we design a Boundary-Aligned Moment Detection Transformer (BAM-DETR), equipped with a dual-pathway decoding process. Specifically, it refines the anchor and boundaries within parallel pathways using global and boundary-focused attention, respectively. This separate design allows the model to focus on desirable regions, enabling precise refinement of moment predictions. Further, we propose a quality-based ranking method, ensuring that proposals with high localization qualities are prioritized over incomplete ones. Extensive experiments verify the advantages of our methods, where our model records new state-of-the-art results on three benchmarks. Code is at https://github.com/Pilhyeon/BAM-DETR. ",
    "url": "https://arxiv.org/abs/2312.00083",
    "authors": [
      "Pilhyeon Lee",
      "Hyeran Byun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00088",
    "title": "Anomaly Detection via Learning-Based Sequential Controlled Sensing",
    "abstract": "In this paper, we address the problem of detecting anomalies among a given set of binary processes via learning-based controlled sensing. Each process is parameterized by a binary random variable indicating whether the process is anomalous. To identify the anomalies, the decision-making agent is allowed to observe a subset of the processes at each time instant. Also, probing each process has an associated cost. Our objective is to design a sequential selection policy that dynamically determines which processes to observe at each time with the goal to minimize the delay in making the decision and the total sensing cost. We cast this problem as a sequential hypothesis testing problem within the framework of Markov decision processes. This formulation utilizes both a Bayesian log-likelihood ratio-based reward and an entropy-based reward. The problem is then solved using two approaches: 1) a deep reinforcement learning-based approach where we design both deep Q-learning and policy gradient actor-critic algorithms; and 2) a deep active inference-based approach. Using numerical experiments, we demonstrate the efficacy of our algorithms and show that our algorithms adapt to any unknown statistical dependence pattern of the processes. ",
    "url": "https://arxiv.org/abs/2312.00088",
    "authors": [
      "Geethu Joseph",
      "Chen Zhong",
      "M. Cenk Gursoy",
      "Senem Velipasalar",
      "Pramod K. Varshney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.00093",
    "title": "GraphDreamer: Compositional 3D Scene Synthesis from Scene Graphs",
    "abstract": "As pretrained text-to-image diffusion models become increasingly powerful, recent efforts have been made to distill knowledge from these text-to-image pretrained models for optimizing a text-guided 3D model. Most of the existing methods generate a holistic 3D model from a plain text input. This can be problematic when the text describes a complex scene with multiple objects, because the vectorized text embeddings are inherently unable to capture a complex description with multiple entities and relationships. Holistic 3D modeling of the entire scene further prevents accurate grounding of text entities and concepts. To address this limitation, we propose GraphDreamer, a novel framework to generate compositional 3D scenes from scene graphs, where objects are represented as nodes and their interactions as edges. By exploiting node and edge information in scene graphs, our method makes better use of the pretrained text-to-image diffusion model and is able to fully disentangle different objects without image-level supervision. To facilitate modeling of object-wise relationships, we use signed distance fields as representation and impose a constraint to avoid inter-penetration of objects. To avoid manual scene graph creation, we design a text prompt for ChatGPT to generate scene graphs based on text inputs. We conduct both qualitative and quantitative experiments to validate the effectiveness of GraphDreamer in generating high-fidelity compositional 3D scenes with disentangled object entities. ",
    "url": "https://arxiv.org/abs/2312.00093",
    "authors": [
      "Gege Gao",
      "Weiyang Liu",
      "Anpei Chen",
      "Andreas Geiger",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00101",
    "title": "Towards Unsupervised Representation Learning: Learning, Evaluating and  Transferring Visual Representations",
    "abstract": "Unsupervised representation learning aims at finding methods that learn representations from data without annotation-based signals. Abstaining from annotations not only leads to economic benefits but may - and to some extent already does - result in advantages regarding the representation's structure, robustness, and generalizability to different tasks. In the long run, unsupervised methods are expected to surpass their supervised counterparts due to the reduction of human intervention and the inherently more general setup that does not bias the optimization towards an objective originating from specific annotation-based signals. While major advantages of unsupervised representation learning have been recently observed in natural language processing, supervised methods still dominate in vision domains for most tasks. In this dissertation, we contribute to the field of unsupervised (visual) representation learning from three perspectives: (i) Learning representations: We design unsupervised, backpropagation-free Convolutional Self-Organizing Neural Networks (CSNNs) that utilize self-organization- and Hebbian-based learning rules to learn convolutional kernels and masks to achieve deeper backpropagation-free models. (ii) Evaluating representations: We build upon the widely used (non-)linear evaluation protocol to define pretext- and target-objective-independent metrics for measuring and investigating the objective function mismatch between various unsupervised pretext tasks and target tasks. (iii) Transferring representations: We contribute CARLANE, the first 3-way sim-to-real domain adaptation benchmark for 2D lane detection, and a method based on prototypical self-supervised learning. Finally, we contribute a content-consistent unpaired image-to-image translation method that utilizes masks, global and local discriminators, and similarity sampling to mitigate content inconsistencies. ",
    "url": "https://arxiv.org/abs/2312.00101",
    "authors": [
      "Bonifaz Stuhr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00102",
    "title": "FedEmb: A Vertical and Hybrid Federated Learning Algorithm using Network  And Feature Embedding Aggregation",
    "abstract": "Federated learning (FL) is an emerging paradigm for decentralized training of machine learning models on distributed clients, without revealing the data to the central server. The learning scheme may be horizontal, vertical or hybrid (both vertical and horizontal). Most existing research work with deep neural network (DNN) modelling is focused on horizontal data distributions, while vertical and hybrid schemes are much less studied. In this paper, we propose a generalized algorithm FedEmb, for modelling vertical and hybrid DNN-based learning. The idea of our algorithm is characterised by higher inference accuracy, stronger privacy-preserving properties, and lower client-server communication bandwidth demands as compared with existing work. The experimental results show that FedEmb is an effective method to tackle both split feature & subject space decentralized problems, shows 0.3% to 4.2% inference accuracy improvement with limited privacy revealing for datasets stored in local clients, and reduces 88.9 % time complexity over vertical baseline method. ",
    "url": "https://arxiv.org/abs/2312.00102",
    "authors": [
      "Fanfei Meng",
      "Lele Zhang",
      "Yu Chen",
      "Yuxin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.00105",
    "title": "Improving the Robustness of Quantized Deep Neural Networks to White-Box  Attacks using Stochastic Quantization and Information-Theoretic Ensemble  Training",
    "abstract": "Most real-world applications that employ deep neural networks (DNNs) quantize them to low precision to reduce the compute needs. We present a method to improve the robustness of quantized DNNs to white-box adversarial attacks. We first tackle the limitation of deterministic quantization to fixed ``bins'' by introducing a differentiable Stochastic Quantizer (SQ). We explore the hypothesis that different quantizations may collectively be more robust than each quantized DNN. We formulate a training objective to encourage different quantized DNNs to learn different representations of the input image. The training objective captures diversity and accuracy via mutual information between ensemble members. Through experimentation, we demonstrate substantial improvement in robustness against $L_\\infty$ attacks even if the attacker is allowed to backpropagate through SQ (e.g., > 50\\% accuracy to PGD(5/255) on CIFAR10 without adversarial training), compared to vanilla DNNs as well as existing ensembles of quantized DNNs. We extend the method to detect attacks and generate robustness profiles in the adversarial information plane (AIP), towards a unified analysis of different threat models by correlating the MI and accuracy. ",
    "url": "https://arxiv.org/abs/2312.00105",
    "authors": [
      "Saurabh Farkya",
      "Aswin Raghavan",
      "Avi Ziskind"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00112",
    "title": "DynMF: Neural Motion Factorization for Real-time Dynamic View Synthesis  with 3D Gaussian Splatting",
    "abstract": "Accurately and efficiently modeling dynamic scenes and motions is considered so challenging a task due to temporal dynamics and motion complexity. To address these challenges, we propose DynMF, a compact and efficient representation that decomposes a dynamic scene into a few neural trajectories. We argue that the per-point motions of a dynamic scene can be decomposed into a small set of explicit or learned trajectories. Our carefully designed neural framework consisting of a tiny set of learned basis queried only in time allows for rendering speed similar to 3D Gaussian Splatting, surpassing 120 FPS, while at the same time, requiring only double the storage compared to static scenes. Our neural representation adequately constrains the inherently underconstrained motion field of a dynamic scene leading to effective and fast optimization. This is done by biding each point to motion coefficients that enforce the per-point sharing of basis trajectories. By carefully applying a sparsity loss to the motion coefficients, we are able to disentangle the motions that comprise the scene, independently control them, and generate novel motion combinations that have never been seen before. We can reach state-of-the-art render quality within just 5 minutes of training and in less than half an hour, we can synthesize novel views of dynamic scenes with superior photorealistic quality. Our representation is interpretable, efficient, and expressive enough to offer real-time view synthesis of complex dynamic scene motions, in monocular and multi-view scenarios. ",
    "url": "https://arxiv.org/abs/2312.00112",
    "authors": [
      "Agelos Kratimenos",
      "Jiahui Lei",
      "Kostas Daniilidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2312.00157",
    "title": "Universal Backdoor Attacks",
    "abstract": "Web-scraped datasets are vulnerable to data poisoning, which can be used for backdooring deep image classifiers during training. Since training on large datasets is expensive, a model is trained once and re-used many times. Unlike adversarial examples, backdoor attacks often target specific classes rather than any class learned by the model. One might expect that targeting many classes through a naive composition of attacks vastly increases the number of poison samples. We show this is not necessarily true and more efficient, universal data poisoning attacks exist that allow controlling misclassifications from any source class into any target class with a small increase in poison samples. Our idea is to generate triggers with salient characteristics that the model can learn. The triggers we craft exploit a phenomenon we call inter-class poison transferability, where learning a trigger from one class makes the model more vulnerable to learning triggers for other classes. We demonstrate the effectiveness and robustness of our universal backdoor attacks by controlling models with up to 6,000 classes while poisoning only 0.15% of the training dataset. ",
    "url": "https://arxiv.org/abs/2312.00157",
    "authors": [
      "Benjamin Schneider",
      "Nils Lukas",
      "Florian Kerschbaum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00173",
    "title": "Fool the Hydra: Adversarial Attacks against Multi-view Object Detection  Systems",
    "abstract": "Adversarial patches exemplify the tangible manifestation of the threat posed by adversarial attacks on Machine Learning (ML) models in real-world scenarios. Robustness against these attacks is of the utmost importance when designing computer vision applications, especially for safety-critical domains such as CCTV systems. In most practical situations, monitoring open spaces requires multi-view systems to overcome acquisition challenges such as occlusion handling. Multiview object systems are able to combine data from multiple views, and reach reliable detection results even in difficult environments. Despite its importance in real-world vision applications, the vulnerability of multiview systems to adversarial patches is not sufficiently investigated. In this paper, we raise the following question: Does the increased performance and information sharing across views offer as a by-product robustness to adversarial patches? We first conduct a preliminary analysis showing promising robustness against off-the-shelf adversarial patches, even in an extreme setting where we consider patches applied to all views by all persons in Wildtrack benchmark. However, we challenged this observation by proposing two new attacks: (i) In the first attack, targeting a multiview CNN, we maximize the global loss by proposing gradient projection to the different views and aggregating the obtained local gradients. (ii) In the second attack, we focus on a Transformer-based multiview framework. In addition to the focal loss, we also maximize the transformer-specific loss by dissipating its attention blocks. Our results show a large degradation in the detection performance of victim multiview systems with our first patch attack reaching an attack success rate of 73% , while our second proposed attack reduced the performance of its target detector by 62% ",
    "url": "https://arxiv.org/abs/2312.00173",
    "authors": [
      "Bilel Tarchoun",
      "Quazi Mishkatul Alam",
      "Nael Abu-Ghazaleh",
      "Ihsen Alouani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.00183",
    "title": "RNA-KG: An ontology-based knowledge graph for representing interactions  involving RNA molecules",
    "abstract": "The \"RNA world\" represents a novel frontier for the study of fundamental biological processes and human diseases and is paving the way for the development of new drugs tailored to the patient's biomolecular characteristics. Although scientific data about coding and non-coding RNA molecules are continuously produced and available from public repositories, they are scattered across different databases and a centralized, uniform, and semantically consistent representation of the \"RNA world\" is still lacking. We propose RNA-KG, a knowledge graph encompassing biological knowledge about RNAs gathered from more than 50 public databases, integrating functional relationships with genes, proteins, and chemicals and ontologically grounded biomedical concepts. To develop RNA-KG, we first identified, pre-processed, and characterized each data source; next, we built a meta-graph that provides an ontological description of the KG by representing all the bio-molecular entities and medical concepts of interest in this domain, as well as the types of interactions connecting them. Finally, we leveraged an instance-based semantically abstracted knowledge model to specify the ontological alignment according to which RNA-KG was generated. RNA-KG can be downloaded in different formats and also queried by a SPARQL endpoint. A thorough topological analysis of the resulting heterogeneous graph provides further insights into the characteristics of the \"RNA world\". RNA-KG can be both directly explored and visualized, and/or analyzed by applying computational methods to infer bio-medical knowledge from its heterogeneous nodes and edges. The resource can be easily updated with new experimental data, and specific views of the overall KG can be extracted according to the bio-medical problem to be studied. ",
    "url": "https://arxiv.org/abs/2312.00183",
    "authors": [
      "Emanuele Cavalleri",
      "Alberto Cabri",
      "Mauricio Soto-Gomez",
      "Sara Bonfitto",
      "Paolo Perlasca",
      "Jessica Gliozzo",
      "Tiffany J. Callahan",
      "Justin Reese",
      "Peter N Robinson",
      "Elena Casiraghi",
      "Giorgio Valentini",
      "Marco Mesiti"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.00189",
    "title": "HeTriNet: Heterogeneous Graph Triplet Attention Network for  Drug-Target-Disease Interaction",
    "abstract": "Modeling the interactions between drugs, targets, and diseases is paramount in drug discovery and has significant implications for precision medicine and personalized treatments. Current approaches frequently consider drug-target or drug-disease interactions individually, ignoring the interdependencies among all three entities. Within human metabolic systems, drugs interact with protein targets in cells, influencing target activities and subsequently impacting biological pathways to promote healthy functions and treat diseases. Moving beyond binary relationships and exploring tighter triple relationships is essential to understanding drugs' mechanism of action (MoAs). Moreover, identifying the heterogeneity of drugs, targets, and diseases, along with their distinct characteristics, is critical to model these complex interactions appropriately. To address these challenges, we effectively model the interconnectedness of all entities in a heterogeneous graph and develop a novel Heterogeneous Graph Triplet Attention Network (\\texttt{HeTriNet}). \\texttt{HeTriNet} introduces a novel triplet attention mechanism within this heterogeneous graph structure. Beyond pairwise attention as the importance of an entity for the other one, we define triplet attention to model the importance of pairs for entities in the drug-target-disease triplet prediction problem. Experimental results on real-world datasets show that \\texttt{HeTriNet} outperforms several baselines, demonstrating its remarkable proficiency in uncovering novel drug-target-disease relationships. ",
    "url": "https://arxiv.org/abs/2312.00189",
    "authors": [
      "Farhan Tanvir",
      "Khaled Mohammed Saifuddin",
      "Tanvir Hossain",
      "Arunkumar Bagavathi",
      "Esra Akbas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2312.00194",
    "title": "Robust Concept Erasure via Kernelized Rate-Distortion Maximization",
    "abstract": "Distributed representations provide a vector space that captures meaningful relationships between data instances. The distributed nature of these representations, however, entangles together multiple attributes or concepts of data instances (e.g., the topic or sentiment of a text, characteristics of the author (age, gender, etc), etc). Recent work has proposed the task of concept erasure, in which rather than making a concept predictable, the goal is to remove an attribute from distributed representations while retaining other information from the original representation space as much as possible. In this paper, we propose a new distance metric learning-based objective, the Kernelized Rate-Distortion Maximizer (KRaM), for performing concept erasure. KRaM fits a transformation of representations to match a specified distance measure (defined by a labeled concept to erase) using a modified rate-distortion function. Specifically, KRaM's objective function aims to make instances with similar concept labels dissimilar in the learned representation space while retaining other information. We find that optimizing KRaM effectively erases various types of concepts: categorical, continuous, and vector-valued variables from data representations across diverse domains. We also provide a theoretical analysis of several properties of KRaM's objective. To assess the quality of the learned representations, we propose an alignment score to evaluate their similarity with the original representation space. Additionally, we conduct experiments to showcase KRaM's efficacy in various settings, from erasing binary gender variables in word embeddings to vector-valued variables in GPT-3 representations. ",
    "url": "https://arxiv.org/abs/2312.00194",
    "authors": [
      "Somnath Basu Roy Chowdhury",
      "Nicholas Monath",
      "Avinava Dubey",
      "Amr Ahmed",
      "Snigdha Chaturvedi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.00195",
    "title": "Raising the Bar of AI-generated Image Detection with CLIP",
    "abstract": "Aim of this work is to explore the potential of pre-trained vision-language models (VLMs) for universal detection of AI-generated images. We develop a lightweight detection strategy based on CLIP features and study its performance in a wide variety of challenging scenarios. We find that, unlike previous belief, it is neither necessary nor convenient to use a large domain-specific dataset for training. On the contrary, by using only a handful of example images from a single generative model, a CLIP-based detector exhibits a surprising generalization ability and high robustness across several different architectures, including recent commercial tools such as Dalle-3, Midjourney v5, and Firefly. We match the SoTA on in-distribution data, and improve largely above it in terms of generalization to out-of-distribution data (+6% in terms of AUC) and robustness to impaired/laundered data (+13%). Our project is available at https://grip-unina.github.io/ClipBased-SyntheticImageDetection/ ",
    "url": "https://arxiv.org/abs/2312.00195",
    "authors": [
      "Davide Cozzolino",
      "Giovanni Poggi",
      "Riccardo Corvi",
      "Matthias Nie\u00dfner",
      "Luisa Verdoliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00198",
    "title": "Optimal Attack and Defense for Reinforcement Learning",
    "abstract": "To ensure the usefulness of Reinforcement Learning (RL) in real systems, it is crucial to ensure they are robust to noise and adversarial attacks. In adversarial RL, an external attacker has the power to manipulate the victim agent's interaction with the environment. We study the full class of online manipulation attacks, which include (i) state attacks, (ii) observation attacks (which are a generalization of perceived-state attacks), (iii) action attacks, and (iv) reward attacks. We show the attacker's problem of designing a stealthy attack that maximizes its own expected reward, which often corresponds to minimizing the victim's value, is captured by a Markov Decision Process (MDP) that we call a meta-MDP since it is not the true environment but a higher level environment induced by the attacked interaction. We show that the attacker can derive optimal attacks by planning in polynomial time or learning with polynomial sample complexity using standard RL techniques. We argue that the optimal defense policy for the victim can be computed as the solution to a stochastic Stackelberg game, which can be further simplified into a partially-observable turn-based stochastic game (POTBSG). Neither the attacker nor the victim would benefit from deviating from their respective optimal policies, thus such solutions are truly robust. Although the defense problem is NP-hard, we show that optimal Markovian defenses can be computed (learned) in polynomial time (sample complexity) in many scenarios. ",
    "url": "https://arxiv.org/abs/2312.00198",
    "authors": [
      "Jeremy McMahan",
      "Young Wu",
      "Xiaojin Zhu",
      "Qiaomin Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2312.00204",
    "title": "DNS SLAM: Dense Neural Semantic-Informed SLAM",
    "abstract": "In recent years, coordinate-based neural implicit representations have shown promising results for the task of Simultaneous Localization and Mapping (SLAM). While achieving impressive performance on small synthetic scenes, these methods often suffer from oversmoothed reconstructions, especially for complex real-world scenes. In this work, we introduce DNS SLAM, a novel neural RGB-D semantic SLAM approach featuring a hybrid representation. Relying only on 2D semantic priors, we propose the first semantic neural SLAM method that trains class-wise scene representations while providing stable camera tracking at the same time. Our method integrates multi-view geometry constraints with image-based feature extraction to improve appearance details and to output color, density, and semantic class information, enabling many downstream applications. To further enable real-time tracking, we introduce a lightweight coarse scene representation which is trained in a self-supervised manner in latent space. Our experimental results achieve state-of-the-art performance on both synthetic data and real-world data tracking while maintaining a commendable operational speed on off-the-shelf hardware. Further, our method outputs class-wise decomposed reconstructions with better texture capturing appearance and geometric details. ",
    "url": "https://arxiv.org/abs/2312.00204",
    "authors": [
      "Kunyi Li",
      "Michael Niemeyer",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00214",
    "title": "Relevance-guided Neural Machine Translation",
    "abstract": "With the advent of the Transformer architecture, Neural Machine Translation (NMT) results have shown great improvement lately. However, results in low-resource conditions still lag behind in both bilingual and multilingual setups, due to the limited amount of available monolingual and/or parallel data; hence, the need for methods addressing data scarcity in an efficient, and explainable way, is eminent. We propose an explainability-based training approach for NMT, applied in Unsupervised and Supervised model training, for translation of three languages of varying resources, French, Gujarati, Kazakh, to and from English. Our results show our method can be promising, particularly when training in low-resource conditions, outperforming simple training baselines; though the improvement is marginal, it sets the ground for further exploration of the approach and the parameters, and its extension to other languages. ",
    "url": "https://arxiv.org/abs/2312.00214",
    "authors": [
      "Isidora Chara Tourni",
      "Derry Wijaya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.00224",
    "title": "Unsupervised textile defect detection using convolutional neural  networks",
    "abstract": "In this study, we propose a novel motif-based approach for unsupervised textile anomaly detection that combines the benefits of traditional convolutional neural networks with those of an unsupervised learning paradigm. It consists of five main steps: preprocessing, automatic pattern period extraction, patch extraction, features selection and anomaly detection. This proposed approach uses a new dynamic and heuristic method for feature selection which avoids the drawbacks of initialization of the number of filters (neurons) and their weights, and those of the backpropagation mechanism such as the vanishing gradients, which are common practice in the state-of-the-art methods. The design and training of the network are performed in a dynamic and input domain-based manner and, thus, no ad-hoc configurations are required. Before building the model, only the number of layers and the stride are defined. We do not initialize the weights randomly nor do we define the filter size or number of filters as conventionally done in CNN-based approaches. This reduces effort and time spent on hyperparameter initialization and fine-tuning. Only one defect-free sample is required for training and no further labeled data is needed. The trained network is then used to detect anomalies on defective fabric samples. We demonstrate the effectiveness of our approach on the Patterned Fabrics benchmark dataset. Our algorithm yields reliable and competitive results (on recall, precision, accuracy and f1- measure) compared to state-of-the-art unsupervised approaches, in less time, with efficient training in a single epoch and a lower computational cost. ",
    "url": "https://arxiv.org/abs/2312.00224",
    "authors": [
      "Imane Koulali",
      "M. Taner Eskil"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.00228",
    "title": "Multi-Axis and Multi-Vector Gradient Estimations: Using Multi-Sampled  Complex Unit Vectors to Estimate Gradients of Real Functions",
    "abstract": "In this preliminary study, we provide two methods for estimating the gradients of functions of real value. Both methods are built on derivative estimations that are calculated using the standard method or the Squire-Trapp method for any given direction. Gradients are computed as the average of derivatives in uniformly sampled directions. The first method uses a uniformly distributed set of axes that consists of orthogonal unit vectors that span the space. The second method only uses a uniformly distributed set of unit vectors. Both methods essentially minimize the error through an average of estimations to cancel error terms. Both methods are essentially a conceptual generalization of the method used to estimate normal fractal surfaces. ",
    "url": "https://arxiv.org/abs/2312.00228",
    "authors": [
      "Ergun Akleman",
      "Alan Freed"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2312.00232",
    "title": "Uncertainty in Graph Contrastive Learning with Bayesian Neural Networks",
    "abstract": "Graph contrastive learning has shown great promise when labeled data is scarce, but large unlabeled datasets are available. However, it often does not take uncertainty estimation into account. We show that a variational Bayesian neural network approach can be used to improve not only the uncertainty estimates but also the downstream performance on semi-supervised node-classification tasks. Moreover, we propose a new measure of uncertainty for contrastive learning, that is based on the disagreement in likelihood due to different positive samples. ",
    "url": "https://arxiv.org/abs/2312.00232",
    "authors": [
      "Alexander M\u00f6llers",
      "Alexander Immer",
      "Elvin Isufi",
      "Vincent Fortuin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.00234",
    "title": "Deep Equilibrium Based Neural Operators for Steady-State PDEs",
    "abstract": "Data-driven machine learning approaches are being increasingly used to solve partial differential equations (PDEs). They have shown particularly striking successes when training an operator, which takes as input a PDE in some family, and outputs its solution. However, the architectural design space, especially given structural knowledge of the PDE family of interest, is still poorly understood. We seek to remedy this gap by studying the benefits of weight-tied neural network architectures for steady-state PDEs. To achieve this, we first demonstrate that the solution of most steady-state PDEs can be expressed as a fixed point of a non-linear operator. Motivated by this observation, we propose FNO-DEQ, a deep equilibrium variant of the FNO architecture that directly solves for the solution of a steady-state PDE as the infinite-depth fixed point of an implicit operator layer using a black-box root solver and differentiates analytically through this fixed point resulting in $\\mathcal{O}(1)$ training memory. Our experiments indicate that FNO-DEQ-based architectures outperform FNO-based baselines with $4\\times$ the number of parameters in predicting the solution to steady-state PDEs such as Darcy Flow and steady-state incompressible Navier-Stokes. Finally, we show FNO-DEQ is more robust when trained with datasets with more noisy observations than the FNO-based baselines, demonstrating the benefits of using appropriate inductive biases in architectural design for different neural network based PDE solvers. Further, we show a universal approximation result that demonstrates that FNO-DEQ can approximate the solution to any steady-state PDE that can be written as a fixed point equation. ",
    "url": "https://arxiv.org/abs/2312.00234",
    "authors": [
      "Tanya Marwah",
      "Ashwini Pokle",
      "J. Zico Kolter",
      "Zachary C. Lipton",
      "Jianfeng Lu",
      "Andrej Risteski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.00252",
    "title": "PyNeRF: Pyramidal Neural Radiance Fields",
    "abstract": "Neural Radiance Fields (NeRFs) can be dramatically accelerated by spatial grid representations. However, they do not explicitly reason about scale and so introduce aliasing artifacts when reconstructing scenes captured at different camera distances. Mip-NeRF and its extensions propose scale-aware renderers that project volumetric frustums rather than point samples but such approaches rely on positional encodings that are not readily compatible with grid methods. We propose a simple modification to grid-based models by training model heads at different spatial grid resolutions. At render time, we simply use coarser grids to render samples that cover larger volumes. Our method can be easily applied to existing accelerated NeRF methods and significantly improves rendering quality (reducing error rates by 20-90% across synthetic and unbounded real-world scenes) while incurring minimal performance overhead (as each model head is quick to evaluate). Compared to Mip-NeRF, we reduce error rates by 20% while training over 60x faster. ",
    "url": "https://arxiv.org/abs/2312.00252",
    "authors": [
      "Haithem Turki",
      "Michael Zollh\u00f6fer",
      "Christian Richardt",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00259",
    "title": "Scalable Cellular V2X Solutions: Large-Scale Deployment Challenges of  Connected Vehicle Safety Networks",
    "abstract": "Vehicle-to-Everything (V2X) communication is expected to accomplish a long-standing goal of the Connected and Autonomous Vehicle (CAV) community to bring connected vehicles to roads on a large scale. A major challenge, and perhaps the biggest hurdle on the path towards this goal is the scalability issues associated with it, especially when vehicular safety is concerned. As a major stakeholder, 3rd Generation Partnership Project (3GPP) based Cellular V2X (C-V2X) community has long been trying to research on whether vehicular networks are able to support the safety-critical applications in high-density vehicular scenarios. This paper attempts to answer this by first presenting an overview on the scalability challenges faced by 3GPP Release 14 Long Term Evolution C-V2X (LTE-V2X) using the PC5 sidelink interface for low and heavy-density traffic scenarios. Next, it demonstrates a series of solutions that address network congestion, packet losses and other scalability issues associated with LTE-V2X to enable this communication technology for commercial deployment. In addition, a brief survey is provided into 3GPP Release 16 5G New Radio V2X (NR-V2X) that utilizes the NR sidelink interface and works as an evolution of C-V2X towards better performance for V2X communications including new enhanced V2X (eV2X) scenarios that possess ultra-low-latency and high-reliability requirements. ",
    "url": "https://arxiv.org/abs/2312.00259",
    "authors": [
      "Ghayoor Shah",
      "Mahdi Zaman",
      "Md Saifuddin",
      "Behrad Toghi",
      "Yaser Fallah"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2312.00265",
    "title": "RoboSync: OS for Social Robots with Customizable Behaviour",
    "abstract": "Traditional robotic systems require complex implementations that are not always accessible or easy to use for Human-Robot Interaction (HRI) application developers. With the aim of simplifying the implementation of HRI applications, this paper introduces a novel real-time operating system (RTOS) designed for customizable HRI - RoboSync. By creating multi-level abstraction layers, the system enables users to define complex emotional and behavioral models without needing deep technical expertise. The system's modular architecture comprises a behavior modeling layer, a machine learning plugin configuration layer, a sensor checks customization layer, a scheduler that fits the need of HRI, and a communication and synchronization layer. This approach not only promotes ease of use without highly specialized skills but also ensures real-time responsiveness and adaptability. The primary functionality of the RTOS has been implemented for proof of concept and was tested on a CortexM4 microcontroller, demonstrating its potential for a wide range of lightweight simple-to-implement social robotics applications. ",
    "url": "https://arxiv.org/abs/2312.00265",
    "authors": [
      "Cheng Tang",
      "Yijing Feng",
      "Yue Hu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.00271",
    "title": "Towards Clinical Prediction with Transparency: An Explainable AI  Approach to Survival Modelling in Residential Aged Care",
    "abstract": "Background: Accurate survival time estimates aid end-of-life medical decision-making. Objectives: Develop an interpretable survival model for elderly residential aged care residents using advanced machine learning. Setting: A major Australasian residential aged care provider. Participants: Residents aged 65+ admitted for long-term care from July 2017 to August 2023. Sample size: 11,944 residents across 40 facilities. Predictors: Factors include age, gender, health status, co-morbidities, cognitive function, mood, nutrition, mobility, smoking, sleep, skin integrity, and continence. Outcome: Probability of survival post-admission, specifically calibrated for 6-month survival estimates. Statistical Analysis: Tested CoxPH, EN, RR, Lasso, GB, XGB, and RF models in 20 experiments with a 90/10 train/test split. Evaluated accuracy using C-index, Harrell's C-index, dynamic AUROC, IBS, and calibrated ROC. Chose XGB for its performance and calibrated it for 1, 3, 6, and 12-month predictions using Platt scaling. Employed SHAP values to analyze predictor impacts. Results: GB, XGB, and RF models showed the highest C-Index values (0.714, 0.712, 0.712). The optimal XGB model demonstrated a 6-month survival prediction AUROC of 0.746 (95% CI 0.744-0.749). Key mortality predictors include age, male gender, mobility, health status, pressure ulcer risk, and appetite. Conclusions: The study successfully applies machine learning to create a survival model for aged care, aligning with clinical insights on mortality risk factors and enhancing model interpretability and clinical utility through explainable AI. ",
    "url": "https://arxiv.org/abs/2312.00271",
    "authors": [
      "Teo Susnjak",
      "Elise Griffin",
      "Mitchell McCutcheon",
      "Kathleen Potter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00289",
    "title": "Robust Generalized Proportional Integral Control for Trajectory Tracking  of Soft Actuators in a Pediatric Wearable Assistive Device",
    "abstract": "Soft robotics hold promise in the development of safe yet powered assistive wearable devices for infants. Key to this is the development of closed-loop controllers that can help regulate pneumatic pressure in the device's actuators in an effort to induce controlled motion at the user's limbs and be able to track different types of trajectories. This work develops a controller for soft pneumatic actuators aimed to power a pediatric soft wearable robotic device prototype for upper extremity motion assistance. The controller tracks desired trajectories for a system of soft pneumatic actuators supporting two-degree-of-freedom shoulder joint motion on an infant-sized engineered mannequin. The degrees of freedom assisted by the actuators are equivalent to shoulder motion (abduction/adduction and flexion/extension). Embedded inertial measurement unit sensors provide real-time joint feedback. Experimental data from performing reaching tasks using the engineered mannequin are obtained and compared against ground truth to evaluate the performance of the developed controller. Results reveal the proposed controller leads to accurate trajectory tracking performance across a variety of shoulder joint motions. ",
    "url": "https://arxiv.org/abs/2312.00289",
    "authors": [
      "Caio Mucchiani",
      "Zhichao Liu",
      "Ipsita Sahin",
      "Elena Kokkoni",
      "Konstantinos Karydis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.00290",
    "title": "Learning to forecast diagnostic parameters using pre-trained weather  embedding",
    "abstract": "Data-driven weather prediction (DDWP) models are increasingly becoming popular for weather forecasting. However, while operational weather forecasts predict a wide variety of weather variables, DDWPs currently forecast a specific set of key prognostic variables. Non-prognostic (\"diagnostic\") variables are sometimes modeled separately as dependent variables of the prognostic variables (c.f. FourCastNet), or by including the diagnostic variable as a target in the DDWP. However, the cost of training and deploying bespoke models for each diagnostic variable can increase dramatically with more diagnostic variables, and limit the operational use of such models. Likewise, retraining an entire DDWP each time a new diagnostic variable is added is also cost-prohibitive. We present an two-stage approach that allows new diagnostic variables to be added to an end-to-end DDWP model without the expensive retraining. In the first stage, we train an autoencoder that learns to embed prognostic variables into a latent space. In the second stage, the autoencoder is frozen and \"downstream\" models are trained to predict diagnostic variables using only the latent representations of prognostic variables as input. Our experiments indicate that models trained using the two-stage approach offer accuracy comparable to training bespoke models, while leading to significant reduction in resource utilization during training and inference. This approach allows for new \"downstream\" models to be developed as needed, without affecting existing models and thus reducing the friction in operationalizing new models. ",
    "url": "https://arxiv.org/abs/2312.00290",
    "authors": [
      "Peetak P. Mitra",
      "Vivek Ramavajjala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00292",
    "title": "SEPSIS: I Can Catch Your Lies -- A New Paradigm for Deception Detection",
    "abstract": "Deception is the intentional practice of twisting information. It is a nuanced societal practice deeply intertwined with human societal evolution, characterized by a multitude of facets. This research explores the problem of deception through the lens of psychology, employing a framework that categorizes deception into three forms: lies of omission, lies of commission, and lies of influence. The primary focus of this study is specifically on investigating only lies of omission. We propose a novel framework for deception detection leveraging NLP techniques. We curated an annotated dataset of 876,784 samples by amalgamating a popular large-scale fake news dataset and scraped news headlines from the Twitter handle of Times of India, a well-known Indian news media house. Each sample has been labeled with four layers, namely: (i) the type of omission (speculation, bias, distortion, sounds factual, and opinion), (ii) colors of lies(black, white, etc), and (iii) the intention of such lies (to influence, etc) (iv) topic of lies (political, educational, religious, etc). We present a novel multi-task learning pipeline that leverages the dataless merging of fine-tuned language models to address the deception detection task mentioned earlier. Our proposed model achieved an F1 score of 0.87, demonstrating strong performance across all layers including the type, color, intent, and topic aspects of deceptive content. Finally, our research explores the relationship between lies of omission and propaganda techniques. To accomplish this, we conducted an in-depth analysis, uncovering compelling findings. For instance, our analysis revealed a significant correlation between loaded language and opinion, shedding light on their interconnectedness. To encourage further research in this field, we will be making the models and dataset available with the MIT License, making it favorable for open-source research. ",
    "url": "https://arxiv.org/abs/2312.00292",
    "authors": [
      "Anku Rani",
      "Dwip Dalal",
      "Shreya Gautam",
      "Pankaj Gupta",
      "Vinija Jain",
      "Aman Chadha",
      "Amit Sheth",
      "Amitava Das"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.00293",
    "title": "PsyAttention: Psychological Attention Model for Personality Detection",
    "abstract": "Work on personality detection has tended to incorporate psychological features from different personality models, such as BigFive and MBTI. There are more than 900 psychological features, each of which is helpful for personality detection. However, when used in combination, the application of different calculation standards among these features may result in interference between features calculated using distinct systems, thereby introducing noise and reducing performance. This paper adapts different psychological models in the proposed PsyAttention for personality detection, which can effectively encode psychological features, reducing their number by 85%. In experiments on the BigFive and MBTI models, PysAttention achieved average accuracy of 65.66% and 86.30%, respectively, outperforming state-of-the-art methods, indicating that it is effective at encoding psychological features. ",
    "url": "https://arxiv.org/abs/2312.00293",
    "authors": [
      "Baohua Zhang",
      "Yongyi Huang",
      "Wenyao Cui",
      "Huaping Zhang",
      "Jianyun Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.00304",
    "title": "Developmental Pretraining (DPT) for Image Classification Networks",
    "abstract": "In the backdrop of increasing data requirements of Deep Neural Networks for object recognition that is growing more untenable by the day, we present Developmental PreTraining (DPT) as a possible solution. DPT is designed as a curriculum-based pre-training approach designed to rival traditional pre-training techniques that are data-hungry. These training approaches also introduce unnecessary features that could be misleading when the network is employed in a downstream classification task where the data is sufficiently different from the pre-training data and is scarce. We design the curriculum for DPT by drawing inspiration from human infant visual development. DPT employs a phased approach where carefully-selected primitive and universal features like edges and shapes are taught to the network participating in our pre-training regime. A model that underwent the DPT regime is tested against models with randomised weights to evaluate the viability of DPT. ",
    "url": "https://arxiv.org/abs/2312.00304",
    "authors": [
      "Niranjan Rajesh",
      "Debayan Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00312",
    "title": "Segment Anything Model-guided Collaborative Learning Network for  Scribble-supervised Polyp Segmentation",
    "abstract": "Polyp segmentation plays a vital role in accurately locating polyps at an early stage, which holds significant clinical importance for the prevention of colorectal cancer. Various polyp segmentation methods have been developed using fully-supervised deep learning techniques. However, pixel-wise annotation for polyp images by physicians during the diagnosis is both time-consuming and expensive. Moreover, visual foundation models such as the Segment Anything Model (SAM) have shown remarkable performance. Nevertheless, directly applying SAM to medical segmentation may not produce satisfactory results due to the inherent absence of medical knowledge. In this paper, we propose a novel SAM-guided Collaborative Learning Network (SAM-CLNet) for scribble-supervised polyp segmentation, enabling a collaborative learning process between our segmentation network and SAM to boost the model performance. Specifically, we first propose a Cross-level Enhancement and Aggregation Network (CEA-Net) for weakly-supervised polyp segmentation. Within CEA-Net, we propose a Cross-level Enhancement Module (CEM) that integrates the adjacent features to enhance the representation capabilities of different resolution features. Additionally, a Feature Aggregation Module (FAM) is employed to capture richer features across multiple levels. Moreover, we present a box-augmentation strategy that combines the segmentation maps generated by CEA-Net with scribble annotations to create more precise prompts. These prompts are then fed into SAM, generating segmentation SAM-guided masks, which can provide additional supervision to train CEA-Net effectively. Furthermore, we present an Image-level Filtering Mechanism to filter out unreliable SAM-guided masks. Extensive experimental results show that our SAM-CLNet outperforms state-of-the-art weakly-supervised segmentation methods. ",
    "url": "https://arxiv.org/abs/2312.00312",
    "authors": [
      "Yiming Zhao",
      "Tao Zhou",
      "Yunqi Gu",
      "Yi Zhou",
      "Yizhe Zhang",
      "Ye Wu",
      "Huazhu Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00334",
    "title": "UAV-Aided Lifelong Learning for AoI and Energy Optimization in  Non-Stationary IoT Networks",
    "abstract": "In this paper, a novel joint energy and age of information (AoI) optimization framework for IoT devices in a non-stationary environment is presented. In particular, IoT devices that are distributed in the real-world are required to efficiently utilize their computing resources so as to balance the freshness of their data and their energy consumption. To optimize the performance of IoT devices in such a dynamic setting, a novel lifelong reinforcement learning (RL) solution that enables IoT devices to continuously adapt their policies to each newly encountered environment is proposed. Given that IoT devices have limited energy and computing resources, an unmanned aerial vehicle (UAV) is leveraged to visit the IoT devices and update the policy of each device sequentially. As such, the UAV is exploited as a mobile learning agent that can learn a shared knowledge base with a feature base in its training phase, and feature sets of a zero-shot learning method in its testing phase, to generalize between the environments. To optimize the trajectory and flying velocity of the UAV, an actor-critic network is leveraged so as to minimize the UAV energy consumption. Simulation results show that the proposed lifelong RL solution can outperform the state-of-art benchmarks by enhancing the balanced cost of IoT devices by $8.3\\%$ when incorporating warm-start policies for unseen environments. In addition, our solution achieves up to $49.38\\%$ reduction in terms of energy consumption by the UAV in comparison to the random flying strategy. ",
    "url": "https://arxiv.org/abs/2312.00334",
    "authors": [
      "Zhenzhen Gong",
      "Omar Hashash",
      "Yingze Wang",
      "Qimei Cui",
      "Wei Ni",
      "Walid Saad",
      "Kei Sakaguchi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.00335",
    "title": "Learning Anatomically Consistent Embedding for Chest Radiography",
    "abstract": "Self-supervised learning (SSL) approaches have recently shown substantial success in learning visual representations from unannotated images. Compared with photographic images, medical images acquired with the same imaging protocol exhibit high consistency in anatomy. To exploit this anatomical consistency, this paper introduces a novel SSL approach, called PEAC (patch embedding of anatomical consistency), for medical image analysis. Specifically, in this paper, we propose to learn global and local consistencies via stable grid-based matching, transfer pre-trained PEAC models to diverse downstream tasks, and extensively demonstrate that (1) PEAC achieves significantly better performance than the existing state-of-the-art fully/self-supervised methods, and (2) PEAC captures the anatomical structure consistency across views of the same patient and across patients of different genders, weights, and healthy statuses, which enhances the interpretability of our method for medical image analysis. ",
    "url": "https://arxiv.org/abs/2312.00335",
    "authors": [
      "Ziyu Zhou",
      "Haozhe Luo",
      "Jiaxuan Pang",
      "Xiaowei Ding",
      "Michael Gotway",
      "Jianming Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00336",
    "title": "Hypergraph Node Representation Learning with One-Stage Message Passing",
    "abstract": "Hypergraphs as an expressive and general structure have attracted considerable attention from various research domains. Most existing hypergraph node representation learning techniques are based on graph neural networks, and thus adopt the two-stage message passing paradigm (i.e. node -> hyperedge -> node). This paradigm only focuses on local information propagation and does not effectively take into account global information, resulting in less optimal representations. Our theoretical analysis of representative two-stage message passing methods shows that, mathematically, they model different ways of local message passing through hyperedges, and can be unified into one-stage message passing (i.e. node -> node). However, they still only model local information. Motivated by this theoretical analysis, we propose a novel one-stage message passing paradigm to model both global and local information propagation for hypergraphs. We integrate this paradigm into HGraphormer, a Transformer-based framework for hypergraph node representation learning. HGraphormer injects the hypergraph structure information (local information) into Transformers (global information) by combining the attention matrix and hypergraph Laplacian. Extensive experiments demonstrate that HGraphormer outperforms recent hypergraph learning methods on five representative benchmark datasets on the semi-supervised hypernode classification task, setting new state-of-the-art performance, with accuracy improvements between 2.52% and 6.70%. Our code and datasets are available. ",
    "url": "https://arxiv.org/abs/2312.00336",
    "authors": [
      "Shilin Qu",
      "Weiqing Wang",
      "Yuan-Fang Li",
      "Xin Zhou",
      "Fajie Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2312.00345",
    "title": "IEEE 802.11be Network Throughput Optimization with Multi-Link Operation  and AP Coordination",
    "abstract": "IEEE 802.11be (Wi-Fi 7) introduces a new concept called multi-link operation (MLO) which allows multiple Wi-Fi interfaces in different bands (2.4, 5, and 6 GHz) to work together to increase network throughput, reduce latency, and improve spectrum reuse efficiency in dense overlapping networks. To make the most of MLO, a new intelligent resource allocation is needed. This paper proposes a model to align MLO and access point (AP) coordination in 11be. To maximize network throughput, a network topology optimization problem is formulated for MLO with AP coordination, which is solved by exploiting the totally unimodular property of the bipartite graph formed by the connection between AP and station (STA) in Wi-Fi networks. Subsequently, a proportional fairness algorithm is applied for radio link allocation, network throughput optimization considering the channel condition, and the fairness of the multi-link device (MLD) data rate. The performance of the proposed algorithm on two main MLO implementations - multi-mink multi-radio (MLMR) with simultaneous transmission and reception (STR), and the interplay between multiple nodes employing them are evaluated through cross-layer (PHY-MAC) data rate simulation with PHY abstraction. ",
    "url": "https://arxiv.org/abs/2312.00345",
    "authors": [
      "Lyutianyang Zhang",
      "Hao Yin",
      "Sumit Roy",
      "Liu Cao",
      "Xiangyu Gao",
      "Vanlin Sathya"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2312.00353",
    "title": "On Exploring the Reasoning Capability of Large Language Models with  Knowledge Graphs",
    "abstract": "This paper examines the capacity of LLMs to reason with knowledge graphs using their internal knowledge graph, i.e., the knowledge graph they learned during pre-training. Two research questions are formulated to investigate the accuracy of LLMs in recalling information from pre-training knowledge graphs and their ability to infer knowledge graph relations from context. To address these questions, we employ LLMs to perform four distinct knowledge graph reasoning tasks. Furthermore, we identify two types of hallucinations that may occur during knowledge reasoning with LLMs: content and ontology hallucination. Our experimental results demonstrate that LLMs can successfully tackle both simple and complex knowledge graph reasoning tasks from their own memory, as well as infer from input context. ",
    "url": "https://arxiv.org/abs/2312.00353",
    "authors": [
      "Pei-Chi Lo",
      "Yi-Hang Tsai",
      "Ee-Peng Lim",
      "San-Yih Hwang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.00359",
    "title": "Temperature Balancing, Layer-wise Weight Analysis, and Neural Network  Training",
    "abstract": "Regularization in modern machine learning is crucial, and it can take various forms in algorithmic design: training set, model family, error function, regularization terms, and optimizations. In particular, the learning rate, which can be interpreted as a temperature-like parameter within the statistical mechanics of learning, plays a crucial role in neural network training. Indeed, many widely adopted training strategies basically just define the decay of the learning rate over time. This process can be interpreted as decreasing a temperature, using either a global learning rate (for the entire model) or a learning rate that varies for each parameter. This paper proposes TempBalance, a straightforward yet effective layer-wise learning rate method. TempBalance is based on Heavy-Tailed Self-Regularization (HT-SR) Theory, an approach which characterizes the implicit self-regularization of different layers in trained models. We demonstrate the efficacy of using HT-SR-motivated metrics to guide the scheduling and balancing of temperature across all network layers during model training, resulting in improved performance during testing. We implement TempBalance on CIFAR10, CIFAR100, SVHN, and TinyImageNet datasets using ResNets, VGGs, and WideResNets with various depths and widths. Our results show that TempBalance significantly outperforms ordinary SGD and carefully-tuned spectral norm regularization. We also show that TempBalance outperforms a number of state-of-the-art optimizers and learning rate schedulers. ",
    "url": "https://arxiv.org/abs/2312.00359",
    "authors": [
      "Yefan Zhou",
      "Tianyu Pang",
      "Keqin Liu",
      "Charles H. Martin",
      "Michael W. Mahoney",
      "Yaoqing Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.00396",
    "title": "GFN-SR: Symbolic Regression with Generative Flow Networks",
    "abstract": "Symbolic regression (SR) is an area of interpretable machine learning that aims to identify mathematical expressions, often composed of simple functions, that best fit in a given set of covariates $X$ and response $y$. In recent years, deep symbolic regression (DSR) has emerged as a popular method in the field by leveraging deep reinforcement learning to solve the complicated combinatorial search problem. In this work, we propose an alternative framework (GFN-SR) to approach SR with deep learning. We model the construction of an expression tree as traversing through a directed acyclic graph (DAG) so that GFlowNet can learn a stochastic policy to generate such trees sequentially. Enhanced with an adaptive reward baseline, our method is capable of generating a diverse set of best-fitting expressions. Notably, we observe that GFN-SR outperforms other SR algorithms in noisy data regimes, owing to its ability to learn a distribution of rewards over a space of candidate solutions. ",
    "url": "https://arxiv.org/abs/2312.00396",
    "authors": [
      "Sida Li",
      "Ioana Marinescu",
      "Sebastian Musslick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.00398",
    "title": "Learning to Estimate Critical Gait Parameters from Single-View RGB  Videos with Transformer-Based Attention Network",
    "abstract": "Musculoskeletal diseases and cognitive impairments in patients lead to difficulties in movement as well as negative effects on their psychological health. Clinical gait analysis, a vital tool for early diagnosis and treatment, traditionally relies on expensive optical motion capture systems. Recent advances in computer vision and deep learning have opened the door to more accessible and cost-effective alternatives. This paper introduces a novel spatio-temporal Transformer network to estimate critical gait parameters from RGB videos captured by a single-view camera. Empirical evaluations on a public dataset of cerebral palsy patients indicate that the proposed framework surpasses current state-of-the-art approaches and show significant improvements in predicting general gait parameters (including Walking Speed, Gait Deviation Index - GDI, and Knee Flexion Angle at Maximum Extension), while utilizing fewer parameters and alleviating the need for manual feature extraction. ",
    "url": "https://arxiv.org/abs/2312.00398",
    "authors": [
      "Quoc Hung T. Le",
      "Hieu H. Pham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00404",
    "title": "A Causality-Aware Pattern Mining Scheme for Group Activity Recognition  in a Pervasive Sensor Space",
    "abstract": "Human activity recognition (HAR) is a key challenge in pervasive computing and its solutions have been presented based on various disciplines. Specifically, for HAR in a smart space without privacy and accessibility issues, data streams generated by deployed pervasive sensors are leveraged. In this paper, we focus on a group activity by which a group of users perform a collaborative task without user identification and propose an efficient group activity recognition scheme which extracts causality patterns from pervasive sensor event sequences generated by a group of users to support as good recognition accuracy as the state-of-the-art graphical model. To filter out irrelevant noise events from a given data stream, a set of rules is leveraged to highlight causally related events. Then, a pattern-tree algorithm extracts frequent causal patterns by means of a growing tree structure. Based on the extracted patterns, a weighted sum-based pattern matching algorithm computes the likelihoods of stored group activities to the given test event sequence by means of matched event pattern counts for group activity recognition. We evaluate the proposed scheme using the data collected from our testbed and CASAS datasets where users perform their tasks on a daily basis and validate its effectiveness in a real environment. Experiment results show that the proposed scheme performs higher recognition accuracy and with a small amount of runtime overhead than the existing schemes. ",
    "url": "https://arxiv.org/abs/2312.00404",
    "authors": [
      "Hyunju Kim",
      "Heesuk Son",
      "Dongman Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2312.00411",
    "title": "A framework for mining lifestyle profiles through multi-dimensional and  high-order mobility feature clustering",
    "abstract": "Human mobility demonstrates a high degree of regularity, which facilitates the discovery of lifestyle profiles. Existing research has yet to fully utilize the regularities embedded in high-order features extracted from human mobility records in such profiling. This study proposes a progressive feature extraction strategy that mines high-order mobility features from users' moving trajectory records from the spatial, temporal, and semantic dimensions. Specific features are extracted such as travel motifs, rhythms decomposed by discrete Fourier transform (DFT) of mobility time series, and vectorized place semantics by word2vec, respectively to the three dimensions, and they are further clustered to reveal the users' lifestyle characteristics. An experiment using a trajectory dataset of over 500k users in Shenzhen, China yields seven user clusters with different lifestyle profiles that can be well interpreted by common sense. The results suggest the possibility of fine-grained user profiling through cross-order trajectory feature engineering and clustering. ",
    "url": "https://arxiv.org/abs/2312.00411",
    "authors": [
      "Yeshuo Shu",
      "Gangcheng Zhang",
      "Keyi Liu",
      "Jintong Tang",
      "Liyan Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00416",
    "title": "Towards Explaining Satellite Based Poverty Predictions with  Convolutional Neural Networks",
    "abstract": "Deep convolutional neural networks (CNNs) have been shown to predict poverty and development indicators from satellite images with surprising accuracy. This paper presents a first attempt at analyzing the CNNs responses in detail and explaining the basis for the predictions. The CNN model, while trained on relatively low resolution day- and night-time satellite images, is able to outperform human subjects who look at high-resolution images in ranking the Wealth Index categories. Multiple explainability experiments performed on the model indicate the importance of the sizes of the objects, pixel colors in the image, and provide a visualization of the importance of different structures in input images. A visualization is also provided of type images that maximize the network prediction of Wealth Index, which provides clues on what the CNN prediction is based on. ",
    "url": "https://arxiv.org/abs/2312.00416",
    "authors": [
      "Hamid Sarmadi",
      "Thorsteinn R\u00f6gnvaldsson",
      "Nils Roger Carlsson",
      "Mattias Ohlsson",
      "Ibrahim Wahab",
      "Ola Hall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00435",
    "title": "Enhancing Image Captioning with Neural Models",
    "abstract": "This research explores the realm of neural image captioning using deep learning models. The study investigates the performance of different neural architecture configurations, focusing on the inject architecture, and proposes a novel quality metric for evaluating caption generation. Through extensive experimentation and analysis, this work sheds light on the challenges and opportunities in image captioning, providing insights into model behavior and overfitting. The results reveal that while the merge models exhibit a larger vocabulary and higher ROUGE scores, the inject architecture generates relevant and concise image captions. The study also highlights the importance of refining training data and optimizing hyperparameters for improved model performance. This research contributes to the growing body of knowledge in neural image captioning and encourages further exploration in the field, emphasizing the democratization of artificial intelligence. ",
    "url": "https://arxiv.org/abs/2312.00435",
    "authors": [
      "Pooja Bhatnagar",
      "Sai Mrunaal",
      "Sachin Kamnure"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.00455",
    "title": "Meta-Diversity Search in Complex Systems, A Recipe for Artificial  Open-Endedness ?",
    "abstract": "Can we build an artificial system that would be able to generate endless surprises if ran \"forever\" in Minecraft? While there is not a single path toward solving that grand challenge, this article presents what we believe to be some working ingredients for the endless generation of novel increasingly complex artifacts in Minecraft. Our framework for an open-ended system includes two components: a complex system used to recursively grow and complexify artifacts over time, and a discovery algorithm that leverages the concept of meta-diversity search. Since complex systems have shown to enable the emergence of considerable complexity from set of simple rules, we believe them to be great candidates to generate all sort of artifacts in Minecraft. Yet, the space of possible artifacts that can be generated by these systems is often unknown, challenging to characterize and explore. Therefore automating the long-term discovery of novel and increasingly complex artifacts in these systems is an exciting research field. To approach these challenges, we formulate the problem of meta-diversity search where an artificial \"discovery assistant\" incrementally learns a diverse set of representations to characterize behaviors and searches to discover diverse patterns within each of them. A successful discovery assistant should continuously seek for novel sources of diversities while being able to quickly specialize the search toward a new unknown type of diversity. To implement those ideas in the Minecraft environment, we simulate an artificial \"chemistry\" system based on Lenia continuous cellular automaton for generating artifacts, as well as an artificial \"discovery assistant\" (called Holmes) for the artifact-discovery process. Holmes incrementally learns a hierarchy of modular representations to characterize divergent sources of diversity and uses a goal-based intrinsically-motivated exploration as the diversity search strategy. ",
    "url": "https://arxiv.org/abs/2312.00455",
    "authors": [
      "Mayalen Etcheverry",
      "Bert Wang-Chak Chan",
      "Cl\u00e9ment Moulin-Frier",
      "Pierre-Yves Oudeyer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Cellular Automata and Lattice Gases (nlin.CG)"
    ]
  },
  {
    "id": "arXiv:2312.00476",
    "title": "Self-Supervised Learning of Spatial Acoustic Representation with  Cross-Channel Signal Reconstruction and Multi-Channel Conformer",
    "abstract": "Supervised learning methods have shown effectiveness in estimating spatial acoustic parameters such as time difference of arrival, direct-to-reverberant ratio and reverberation time. However, they still suffer from the simulation-to-reality generalization problem due to the mismatch between simulated and real-world acoustic characteristics and the deficiency of annotated real-world data. To this end, this work proposes a self-supervised method that takes full advantage of unlabeled data for spatial acoustic parameter estimation. First, a new pretext task, i.e. cross-channel signal reconstruction (CCSR), is designed to learn a universal spatial acoustic representation from unlabeled multi-channel microphone signals. We mask partial signals of one channel and ask the model to reconstruct them, which makes it possible to learn spatial acoustic information from unmasked signals and extract source information from the other microphone channel. An encoder-decoder structure is used to disentangle the two kinds of information. By fine-tuning the pre-trained spatial encoder with a small annotated dataset, this encoder can be used to estimate spatial acoustic parameters. Second, a novel multi-channel audio Conformer (MC-Conformer) is adopted as the encoder model architecture, which is suitable for both the pretext and downstream tasks. It is carefully designed to be able to capture the local and global characteristics of spatial acoustics exhibited in the time-frequency domain. Experimental results of five acoustic parameter estimation tasks on both simulated and real-world data show the effectiveness of the proposed method. To the best of our knowledge, this is the first self-supervised learning method in the field of spatial acoustic representation learning and multi-channel audio signal processing. ",
    "url": "https://arxiv.org/abs/2312.00476",
    "authors": [
      "Bing Yang",
      "Xiaofei Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2312.00480",
    "title": "Japanese Tort-case Dataset for Rationale-supported Legal Judgment  Prediction",
    "abstract": "This paper presents the first dataset for Japanese Legal Judgment Prediction (LJP), the Japanese Tort-case Dataset (JTD), which features two tasks: tort prediction and its rationale extraction. The rationale extraction task identifies the court's accepting arguments from alleged arguments by plaintiffs and defendants, which is a novel task in the field. JTD is constructed based on annotated 3,477 Japanese Civil Code judgments by 41 legal experts, resulting in 7,978 instances with 59,697 of their alleged arguments from the involved parties. Our baseline experiments show the feasibility of the proposed two tasks, and our error analysis by legal experts identifies sources of errors and suggests future directions of the LJP research. ",
    "url": "https://arxiv.org/abs/2312.00480",
    "authors": [
      "Hiroaki Yamada",
      "Takenobu Tokunaga",
      "Ryutaro Ohara",
      "Akira Tokutsu",
      "Keisuke Takeshita",
      "Mihoko Sumida"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.00485",
    "title": "Backbone-based Dynamic Graph Spatio-Temporal Network for Epidemic  Forecasting",
    "abstract": "Accurate epidemic forecasting is a critical task in controlling disease transmission. Many deep learning-based models focus only on static or dynamic graphs when constructing spatial information, ignoring their relationship. Additionally, these models often rely on recurrent structures, which can lead to error accumulation and computational time consumption. To address the aforementioned problems, we propose a novel model called Backbone-based Dynamic Graph Spatio-Temporal Network (BDGSTN). Intuitively, the continuous and smooth changes in graph structure, make adjacent graph structures share a basic pattern. To capture this property, we use adaptive methods to generate static backbone graphs containing the primary information and temporal models to generate dynamic temporal graphs of epidemic data, fusing them to generate a backbone-based dynamic graph. To overcome potential limitations associated with recurrent structures, we introduce a linear model DLinear to handle temporal dependencies and combine it with dynamic graph convolution for epidemic forecasting. Extensive experiments on two datasets demonstrate that BDGSTN outperforms baseline models and ablation comparison further verifies the effectiveness of model components. Furthermore, we analyze and measure the significance of backbone and temporal graphs by using information metrics from different aspects. Finally, we compare model parameter volume and training time to confirm the superior complexity and efficiency of BDGSTN. ",
    "url": "https://arxiv.org/abs/2312.00485",
    "authors": [
      "Junkai Mao",
      "Yuexing Han",
      "Gouhei Tanaka",
      "Bing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2312.00486",
    "title": "REDUCR: Robust Data Downsampling Using Class Priority Reweighting",
    "abstract": "Modern machine learning models are becoming increasingly expensive to train for real-world image and text classification tasks, where massive web-scale data is collected in a streaming fashion. To reduce the training cost, online batch selection techniques have been developed to choose the most informative datapoints. However, these techniques can suffer from poor worst-class generalization performance due to class imbalance and distributional shifts. This work introduces REDUCR, a robust and efficient data downsampling method that uses class priority reweighting. REDUCR reduces the training data while preserving worst-class generalization performance. REDUCR assigns priority weights to datapoints in a class-aware manner using an online learning algorithm. We demonstrate the data efficiency and robust performance of REDUCR on vision and text classification tasks. On web-scraped datasets with imbalanced class distributions, REDUCR significantly improves worst-class test accuracy (and average accuracy), surpassing state-of-the-art methods by around 15%. ",
    "url": "https://arxiv.org/abs/2312.00486",
    "authors": [
      "William Bankes",
      "George Hughes",
      "Ilija Bogunovic",
      "Zi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00502",
    "title": "On the Out-Of-Distribution Robustness of Self-Supervised Representation  Learning for Phonocardiogram Signals",
    "abstract": "Objective: Despite the recent increase in research activity, deep-learning models have not yet been widely accepted in medicine. The shortage of high-quality annotated data often hinders the development of robust and generalizable models, which do not suffer from degraded effectiveness when presented with newly-collected, out-of-distribution (OOD) datasets. Methods: Contrastive Self-Supervised Learning (SSL) offers a potential solution to the scarcity of labeled data as it takes advantage of unlabeled data to increase model effectiveness and robustness. In this research, we propose applying contrastive SSL for detecting abnormalities in phonocardiogram (PCG) samples by learning a generalized representation of the signal. Specifically, we perform an extensive comparative evaluation of a wide range of audio-based augmentations and evaluate trained classifiers on multiple datasets across different downstream tasks. Results: We experimentally demonstrate that, depending on its training distribution, the effectiveness of a fully-supervised model can degrade up to 32% when evaluated on unseen data, while SSL models only lose up to 10% or even improve in some cases. Conclusions: Contrastive SSL pretraining can assist in providing robust classifiers which can generalize to unseen, OOD data, without relying on time- and labor-intensive annotation processes by medical experts. Furthermore, the proposed extensive evaluation protocol sheds light on the most promising and appropriate augmentations for robust PCG signal processing. Significance: We provide researchers and practitioners with a roadmap towards producing robust models for PCG classification, in addition to an open-source codebase for developing novel approaches. ",
    "url": "https://arxiv.org/abs/2312.00502",
    "authors": [
      "Aristotelis Ballas",
      "Vasileios Papapanagiotou",
      "Christos Diou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2312.00507",
    "title": "VEXIR2Vec: An Architecture-Neutral Embedding Framework for Binary  Similarity",
    "abstract": "We propose VEXIR2Vec, a code embedding framework for finding similar functions in binaries. Our representations rely on VEX IR, the intermediate representation used by binary analysis tools like Valgrind and angr. Our proposed embeddings encode both syntactic and semantic information to represent a function, and is both application and architecture independent. We also propose POV, a custom Peephole Optimization engine that normalizes the VEX IR for effective similarity analysis. We design several optimizations like copy/constant propagation, constant folding, common subexpression elimination and load-store elimination in POV. We evaluate our framework on two experiments -- diffing and searching -- involving binaries targeting different architectures, compiled using different compilers and versions, optimization sequences, and obfuscations. We show results on several standard projects and on real-world vulnerabilities. Our results show that VEXIR2Vec achieves superior precision and recall values compared to the state-of-the-art works. Our framework is highly scalable and is built as a multi-threaded, parallel library by only using open-source tools. VEXIR2Vec achieves about $3.2 \\times$ speedup on the closest competitor, and orders-of-magnitude speedup on other tools. ",
    "url": "https://arxiv.org/abs/2312.00507",
    "authors": [
      "S. VenkataKeerthy",
      "Yashas Andaluri",
      "Sayan Dey",
      "Soumya Banerjee",
      "Ramakrishna Upadrasta"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00508",
    "title": "PyraTrans: Learning Attention-Enriched Multi-Scale Pyramid Network from  Pre-Trained Transformers for Effective Malicious URL Detection",
    "abstract": "Detecting malicious URLs is a crucial aspect of web search and mining, significantly impacting internet security. Though advancements in machine learning have improved the effectiveness of detection methods, these methods still face significant challenges in their capacity to generalize and their resilience against evolving threats. In this paper, we propose PyraTrans, an approach that combines the strengths of pretrained Transformers and pyramid feature learning for improving malicious URL detection. We implement PyraTrans by leveraging a pretrained CharBERT as the base and augmenting it with 3 connected feature modules: 1) The Encoder Feature Extraction module, which extracts representations from each encoder layer of CharBERT to obtain multi-order features; 2) The Multi-Scale Feature Learning Module, which captures multi-scale local contextual insights and aggregate information across different layer-levels; and 3) The Pyramid Spatial Attention Module, which learns hierarchical and spatial feature attentions, highlighting critical classification signals while reducing noise. The proposed approach addresses the limitations of the Transformer in local feature learning and spatial awareness, and enabling us to extract multi-order, multi-scale URL feature representations with enhanced attentional focus. PyraTrans is evaluated using 4 benchmark datasets, where it demonstrated significant advancements over prior baseline methods. Particularly, on the imbalanced dataset, our method, with just 10% of the data for training, the TPR is 3.3-6.5 times and the F1-score is 2.9-4.5 times that of the baseline. Our approach also demonstrates robustness against adversarial attacks. Codes and data are available at https://github.com/Alixyvtte/PyraTrans. ",
    "url": "https://arxiv.org/abs/2312.00508",
    "authors": [
      "Ruitong Liu",
      "Yanbin Wang",
      "Zhenhao Guo",
      "Haitao Xu",
      "Zhan Qin",
      "Wenrui Ma",
      "Fan Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.00512",
    "title": "Attack Detection Using Item Vector Shift in Matrix Factorisation  Recommenders",
    "abstract": "This paper proposes a novel method for detecting shilling attacks in Matrix Factorization (MF)-based Recommender Systems (RS), in which attackers use false user-item feedback to promote a specific item. Unlike existing methods that use either use supervised learning to distinguish between attack and genuine profiles or analyse target item rating distributions to detect false ratings, our method uses an unsupervised technique to detect false ratings by examining shifts in item preference vectors that exploit rating deviations and user characteristics, making it a promising new direction. The experimental results demonstrate the effectiveness of our approach in various attack scenarios, including those involving obfuscation techniques. ",
    "url": "https://arxiv.org/abs/2312.00512",
    "authors": [
      "Sulthana Shams",
      "Douglas Leith"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2312.00513",
    "title": "Summarization-based Data Augmentation for Document Classification",
    "abstract": "Despite the prevalence of pretrained language models in natural language understanding tasks, understanding lengthy text such as document is still challenging due to the data sparseness problem. Inspired by that humans develop their ability of understanding lengthy text from reading shorter text, we propose a simple yet effective summarization-based data augmentation, SUMMaug, for document classification. We first obtain easy-to-learn examples for the target document classification task by summarizing the input of the original training examples, while optionally merging the original labels to conform to the summarized input. We then use the generated pseudo examples to perform curriculum learning. Experimental results on two datasets confirmed the advantage of our method compared to existing baseline methods in terms of robustness and accuracy. We release our code and data at https://github.com/etsurin/summaug. ",
    "url": "https://arxiv.org/abs/2312.00513",
    "authors": [
      "Yueguan Wang",
      "Naoki Yoshinaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.00519",
    "title": "The Impact of Privacy and Security Attitudes and Concerns of Travellers  on Their Willingness to Use Mobility-as-a-Service Systems",
    "abstract": "This paper reports results from an online survey on the impact of travellers' privacy and security attitudes and concerns on their willingness to use mobility-as-a-service (MaaS) systems. This study is part of a larger project that aims at investigating barriers to potential MaaS uptake. The online survey was designed to cover data privacy and security attitudes and concerns as well as a variety of socio-psychological and socio-demographic variables associated with travellers' intentions to use MaaS systems. The study involved $n=320$ UK participants recruited via the Prolific survey platform. Overall, correlation analysis and a multiple regression model indicated that, neither attitudes nor concerns of participants over the privacy and security of personal data would significantly impact their decisions to use MaaS systems, which was an unexpected result, however, their trust in (commercial and governmental) websites would. Another surprising result is that, having been a victim of improper invasion of privacy did not appear to affect individuals' intentions to use MaaS systems, whereas frequency with which one heard about misuse of personal data did. Implications of the results and future directions are also discussed, e.g., MaaS providers are encouraged to work on improving the trustworthiness of their corporate image. ",
    "url": "https://arxiv.org/abs/2312.00519",
    "authors": [
      "Maria Sophia Heering",
      "Haiyue Yuan",
      "Shujun Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2312.00534",
    "title": "LiDAR-based curb detection for ground truth annotation in automated  driving validation",
    "abstract": "Curb detection is essential for environmental awareness in Automated Driving (AD), as it typically limits drivable and non-drivable areas. Annotated data are necessary for developing and validating an AD function. However, the number of public datasets with annotated point cloud curbs is scarce. This paper presents a method for detecting 3D curbs in a sequence of point clouds captured from a LiDAR sensor, which consists of two main steps. First, our approach detects the curbs at each scan using a segmentation deep neural network. Then, a sequence-level processing step estimates the 3D curbs in the reconstructed point cloud using the odometry of the vehicle. From these 3D points of the curb, we obtain polylines structured following ASAM OpenLABEL standard. These detections can be used as pre-annotations in labelling pipelines to efficiently generate curb-related ground truth data. We validate our approach through an experiment in which different human annotators were required to annotate curbs in a group of LiDAR-based sequences with and without our automatically generated pre-annotations. The results show that the manual annotation time is reduced by 50.99% thanks to our detections, keeping the data quality level. ",
    "url": "https://arxiv.org/abs/2312.00534",
    "authors": [
      "Jose Luis Apell\u00e1niz",
      "Mikel Garc\u00eda",
      "Nerea Aranjuelo",
      "Javier Barandiar\u00e1n",
      "Marcos Nieto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00553",
    "title": "A Spatio-Temporal Graph Convolutional Network for Gesture Recognition  from High-Density Electromyography",
    "abstract": "Accurate hand gesture prediction is crucial for effective upper-limb prosthetic limbs control. As the high flexibility and multiple degrees of freedom exhibited by human hands, there has been a growing interest in integrating deep networks with high-density surface electromyography (HD-sEMG) grids to enhance gesture recognition capabilities. However, many existing methods fall short in fully exploit the specific spatial topology and temporal dependencies present in HD-sEMG data. Additionally, these studies are often limited number of gestures and lack generality. Hence, this study introduces a novel gesture recognition method, named STGCN-GR, which leverages spatio-temporal graph convolution networks for HD-sEMG-based human-machine interfaces. Firstly, we construct muscle networks based on functional connectivity between channels, creating a graph representation of HD-sEMG recordings. Subsequently, a temporal convolution module is applied to capture the temporal dependences in the HD-sEMG series and a spatial graph convolution module is employed to effectively learn the intrinsic spatial topology information among distinct HD-sEMG channels. We evaluate our proposed model on a public HD-sEMG dataset comprising a substantial number of gestures (i.e., 65). Our results demonstrate the remarkable capability of the STGCN-GR method, achieving an impressive accuracy of 91.07% in predicting gestures, which surpasses state-of-the-art deep learning methods applied to the same dataset. ",
    "url": "https://arxiv.org/abs/2312.00553",
    "authors": [
      "Wenjuan Zhong",
      "Yuyang Zhang",
      "Peiwen Fu",
      "Wenxuan Xiong",
      "Mingming Zhang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.00570",
    "title": "Generative models for visualising abstract social processes: Guiding  streetview image synthesis of StyleGAN2 with indices of deprivation",
    "abstract": "This paper presents a novel application of Generative Adverserial Networks (GANs) to study visual aspects of social processes. I train a a StyleGAN2-model on a custom dataset of 14,564 images of London, sourced from Google Streetview taken in London. After training, I invert the images in the training set, finding points in the model's latent space that correspond to them, and compare results from three inversion techniques. I connect each data point with metadata from the Indices of Multiple Deprivation, describing income, health and environmental quality in the area where the photographs were taken. It is then possible to map which parts of the model's latent space encode visual features that are distinctive for health, income and environmental quality, and condition the synthesis of new images based on these factors. The synthetic images created reflect visual features of social processes that were previously unknown and difficult to study, describing recurring visual differences between deprived and privileged areas in London. GANs are known for their capability to produce a continuous range of images that exhibit visual differences. The paper tests how to exploit this ability through visual comparisons in still images as well as through an interactive website where users can guide image synthesis with sliders. Though conditioned synthesis has its limitations and the results are difficult to validate, the paper points to the potential for generative models to be repurposed to be parts of social scientific methods. ",
    "url": "https://arxiv.org/abs/2312.00570",
    "authors": [
      "Aleksi Knuutila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00586",
    "title": "Explainable Fraud Detection with Deep Symbolic Classification",
    "abstract": "There is a growing demand for explainable, transparent, and data-driven models within the domain of fraud detection. Decisions made by fraud detection models need to be explainable in the event of a customer dispute. Additionally, the decision-making process in the model must be transparent to win the trust of regulators and business stakeholders. At the same time, fraud detection solutions can benefit from data due to the noisy, dynamic nature of fraud and the availability of large historical data sets. Finally, fraud detection is notorious for its class imbalance: there are typically several orders of magnitude more legitimate transactions than fraudulent ones. In this paper, we present Deep Symbolic Classification (DSC), an extension of the Deep Symbolic Regression framework to classification problems. DSC casts classification as a search problem in the space of all analytic functions composed of a vocabulary of variables, constants, and operations and optimizes for an arbitrary evaluation metric directly. The search is guided by a deep neural network trained with reinforcement learning. Because the functions are mathematical expressions that are in closed-form and concise, the model is inherently explainable both at the level of a single classification decision and the model's decision process. Furthermore, the class imbalance problem is successfully addressed by optimizing for metrics that are robust to class imbalance such as the F1 score. This eliminates the need for oversampling and undersampling techniques that plague traditional approaches. Finally, the model allows to explicitly balance between the prediction accuracy and the explainability. An evaluation on the PaySim data set demonstrates competitive predictive performance with state-of-the-art models, while surpassing them in terms of explainability. This establishes DSC as a promising model for fraud detection systems. ",
    "url": "https://arxiv.org/abs/2312.00586",
    "authors": [
      "Samantha Visbeek",
      "Erman Acar",
      "Floris den Hengst"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.00592",
    "title": "Tracking Object Positions in Reinforcement Learning: A Metric for  Keypoint Detection (extended version)",
    "abstract": "Reinforcement learning (RL) for robot control typically requires a detailed representation of the environment state, including information about task-relevant objects not directly measurable. Keypoint detectors, such as spatial autoencoders (SAEs), are a common approach to extracting a low-dimensional representation from high-dimensional image data. SAEs aim at spatial features such as object positions, which are often useful representations in robotic RL. However, whether an SAE is actually able to track objects in the scene and thus yields a spatial state representation well suited for RL tasks has rarely been examined due to a lack of established metrics. In this paper, we propose to assess the performance of an SAE instance by measuring how well keypoints track ground truth objects in images. We present a computationally lightweight metric and use it to evaluate common baseline SAE architectures on image data from a simulated robot task. We find that common SAEs differ substantially in their spatial extraction capability. Furthermore, we validate that SAEs that perform well in our metric achieve superior performance when used in downstream RL. Thus, our metric is an effective and lightweight indicator of RL performance before executing expensive RL training. Building on these insights, we identify three key modifications of SAE architectures to improve tracking performance. We make our code available at anonymous.4open.science/r/sae-rl. ",
    "url": "https://arxiv.org/abs/2312.00592",
    "authors": [
      "Emma Cramer",
      "Jonas Reiher",
      "Sebastian Trimpe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.00601",
    "title": "Online Graph Coloring with Predictions",
    "abstract": "We introduce learning augmented algorithms to the online graph coloring problem. Although the simple greedy algorithm FirstFit is known to perform poorly in the worst case, we are able to establish a relationship between the structure of any input graph $G$ that is revealed online and the number of colors that FirstFit uses for $G$. Based on this relationship, we propose an online coloring algorithm FirstFitPredictions that extends FirstFit while making use of machine learned predictions. We show that FirstFitPredictions is both \\emph{consistent} and \\emph{smooth}. Moreover, we develop a novel framework for combining online algorithms at runtime specifically for the online graph coloring problem. Finally, we show how this framework can be used to robustify by combining it with any classical online coloring algorithm (that disregards the predictions). ",
    "url": "https://arxiv.org/abs/2312.00601",
    "authors": [
      "Antonios Antoniadis",
      "Hajo Broersma",
      "Yang Meng"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2312.00633",
    "title": "Towards Efficient 3D Object Detection in Bird's-Eye-View Space for  Autonomous Driving: A Convolutional-Only Approach",
    "abstract": "3D object detection in Bird's-Eye-View (BEV) space has recently emerged as a prevalent approach in the field of autonomous driving. Despite the demonstrated improvements in accuracy and velocity estimation compared to perspective view methods, the deployment of BEV-based techniques in real-world autonomous vehicles remains challenging. This is primarily due to their reliance on vision-transformer (ViT) based architectures, which introduce quadratic complexity with respect to the input resolution. To address this issue, we propose an efficient BEV-based 3D detection framework called BEVENet, which leverages a convolutional-only architectural design to circumvent the limitations of ViT models while maintaining the effectiveness of BEV-based methods. Our experiments show that BEVENet is 3$\\times$ faster than contemporary state-of-the-art (SOTA) approaches on the NuScenes challenge, achieving a mean average precision (mAP) of 0.456 and a nuScenes detection score (NDS) of 0.555 on the NuScenes validation dataset, with an inference speed of 47.6 frames per second. To the best of our knowledge, this study stands as the first to achieve such significant efficiency improvements for BEV-based methods, highlighting their enhanced feasibility for real-world autonomous driving applications. ",
    "url": "https://arxiv.org/abs/2312.00633",
    "authors": [
      "Yuxin Li",
      "Qiang Han",
      "Mengying Yu",
      "Yuxin Jiang",
      "Chaikiat Yeo",
      "Yiheng Li",
      "Zihang Huang",
      "Nini Liu",
      "Hsuanhan Chen",
      "Xiaojun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.00644",
    "title": "Neural networks for the approximation of Euler's elastica",
    "abstract": "Euler's elastica is a classical model of flexible slender structures, relevant in many industrial applications. Static equilibrium equations can be derived via a variational principle. The accurate approximation of solutions of this problem can be challenging due to nonlinearity and constraints. We here present two neural network based approaches for the simulation of this Euler's elastica. Starting from a data set of solutions of the discretised static equilibria, we train the neural networks to produce solutions for unseen boundary conditions. We present a $\\textit{discrete}$ approach learning discrete solutions from the discrete data. We then consider a $\\textit{continuous}$ approach using the same training data set, but learning continuous solutions to the problem. We present numerical evidence that the proposed neural networks can effectively approximate configurations of the planar Euler's elastica for a range of different boundary conditions. ",
    "url": "https://arxiv.org/abs/2312.00644",
    "authors": [
      "Elena Celledoni",
      "Ergys \u00c7okaj",
      "Andrea Leone",
      "Sigrid Leyendecker",
      "Davide Murari",
      "Brynjulf Owren",
      "Rodrigo T. Sato Mart\u00edn de Almagro",
      "Martina Stavole"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2312.00671",
    "title": "CellMixer: Annotation-free Semantic Cell Segmentation of Heterogeneous  Cell Populations",
    "abstract": "In recent years, several unsupervised cell segmentation methods have been presented, trying to omit the requirement of laborious pixel-level annotations for the training of a cell segmentation model. Most if not all of these methods handle the instance segmentation task by focusing on the detection of different cell instances ignoring their type. While such models prove adequate for certain tasks, like cell counting, other applications require the identification of each cell's type. In this paper, we present CellMixer, an innovative annotation-free approach for the semantic segmentation of heterogeneous cell populations. Our augmentation-based method enables the training of a segmentation model from image-level labels of homogeneous cell populations. Our results show that CellMixer can achieve competitive segmentation performance across multiple cell types and imaging modalities, demonstrating the method's scalability and potential for broader applications in medical imaging, cellular biology, and diagnostics. ",
    "url": "https://arxiv.org/abs/2312.00671",
    "authors": [
      "Mehdi Naouar",
      "Gabriel Kalweit",
      "Anusha Klett",
      "Yannick Vogt",
      "Paula Silvestrini",
      "Diana Laura Infante Ramirez",
      "Roland Mertelsmann",
      "Joschka Boedecker",
      "Maria Kalweit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00686",
    "title": "Classification of cyber attacks on IoT and ubiquitous computing devices",
    "abstract": "As the Internet of Things (IoT) has become truly ubiquitous, so has the surrounding threat landscape. However, while the security of classical computing systems has significantly matured in the last decades, IoT cybersecurity is still typically low or fully neglected. This paper provides a classification of IoT malware. Major targets and used exploits for attacks are identified and referred to the specific malware. The lack of standard definitions of IoT devices and, therefore, security goals has been identified during this research as a profound barrier in advancing IoT cybersecurity. Furthermore, standardized reporting of IoT malware by trustworthy sources is required in the field. The majority of current IoT attacks continue to be of comparably low effort and level of sophistication and could be mitigated by existing technical measures. ",
    "url": "https://arxiv.org/abs/2312.00686",
    "authors": [
      "Monika Freunek",
      "Alexandra Rombos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.00699",
    "title": "Rethinking Detection Based Table Structure Recognition for Visually Rich  Documents",
    "abstract": "Table Structure Recognition (TSR) aims at transforming unstructured table images into structured formats, such as HTML sequences. One type of popular solution is using detection models to detect components of a table, such as columns and rows, then applying a rule-based post-processing method to convert detection results into HTML sequences. However, existing detection-based studies often have the following limitations. First, these studies usually pay more attention to improving the detection performance, which does not necessarily lead to better performance regarding cell-level metrics, such as TEDS. Second, some solutions over-simplify the problem and can miss some critical information. Lastly, even though some studies defined the problem to detect more components to provide as much information as other types of solutions, these studies ignore the fact this problem definition is a multi-label detection because row, projected row header and column header can share identical bounding boxes. Besides, there is often a performance gap between two-stage and transformer-based detection models regarding the structure-only TEDS, even though they have similar performance regarding the COCO metrics. Therefore, we revisit the limitations of existing detection-based solutions, compare two-stage and transformer-based detection models, and identify the key design aspects for the success of a two-stage detection model for the TSR task, including the multi-class problem definition, the aspect ratio for anchor box generation, and the feature generation of the backbone network. We applied simple methods to improve these aspects of the Cascade R-CNN model, achieved state-of-the-art performance, and improved the baseline Cascade R-CNN model by 19.32%, 11.56% and 14.77% regarding the structure-only TEDS on SciTSR, FinTabNet, and PubTables1M datasets. ",
    "url": "https://arxiv.org/abs/2312.00699",
    "authors": [
      "Bin Xiao",
      "Murat Simsek",
      "Burak Kantarci",
      "Ala Abu Alkheir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2312.00739",
    "title": "Adversarial Score Distillation: When score distillation meets GAN",
    "abstract": "Existing score distillation methods are sensitive to classifier-free guidance (CFG) scale: manifested as over-smoothness or instability at small CFG scales, while over-saturation at large ones. To explain and analyze these issues, we revisit the derivation of Score Distillation Sampling (SDS) and decipher existing score distillation with the Wasserstein Generative Adversarial Network (WGAN) paradigm. With the WGAN paradigm, we find that existing score distillation either employs a fixed sub-optimal discriminator or conducts incomplete discriminator optimization, resulting in the scale-sensitive issue. We propose the Adversarial Score Distillation (ASD), which maintains an optimizable discriminator and updates it using the complete optimization objective. Experiments show that the proposed ASD performs favorably in 2D distillation and text-to-3D tasks against existing methods. Furthermore, to explore the generalization ability of our WGAN paradigm, we extend ASD to the image editing task, which achieves competitive results. The project page and code are at https://github.com/2y7c3/ASD. ",
    "url": "https://arxiv.org/abs/2312.00739",
    "authors": [
      "Min Wei",
      "Jingkai Zhou",
      "Junyao Sun",
      "Xuesong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00740",
    "title": "Computing Networks Enabled Semantic Communications",
    "abstract": "Semantic communication has shown great potential in boosting the effectiveness and reliability of communications. However, its systems to date are mostly enabled by deep learning, which requires demanding computing resources. This article proposes a framework for the computing networks enabled semantic communication system, aiming to offer sufficient computing resources for semantic processing and transmission. Key techniques including semantic sampling and reconstruction, semantic-channel coding, semantic-aware resource allocation and optimization are introduced based on the cloud-edge-end computing coordination. Two use cases are demonstrated to show advantages of the proposed framework. The article concludes with several future research directions. ",
    "url": "https://arxiv.org/abs/2312.00740",
    "authors": [
      "Zhijin Qin",
      "Jingkai Ying",
      "Dingxi Yang",
      "Hengjiang Wang",
      "Xiaoming Tao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2312.00741",
    "title": "Crystal: Enhancing Blockchain Mining Transparency with Quorum  Certificate",
    "abstract": "Researchers have discovered a series of theoretical attacks against Bitcoin's Nakamoto consensus; the most damaging ones are selfish mining, double-spending, and consistency delay attacks. These attacks have one common cause: block withholding. This paper proposes Crystal, which leverages quorum certificates to resist block withholding misbehavior. Crystal continuously elects committees from miners and requires each block to have a quorum certificate, i.e., a set of signatures issued by members of its committee. Consequently, an attacker has to publish its blocks to obtain quorum certificates, rendering block withholding impossible. To build Crystal, we design a novel two-round committee election in a Sybil-resistant, unpredictable and non-interactive way, and a reward mechanism to incentivize miners to follow the protocol. Our analysis and evaluations show that Crystal can significantly mitigate selfish mining and double-spending attacks. For example, in Bitcoin, an attacker with 30% of the total computation power will succeed in double-spending attacks with a probability of 15.6% to break the 6-confirmation rule; however, in Crystal, the success probability for the same attacker falls to 0.62%. We provide formal end-to-end safety proofs for Crystal, ensuring no unknown attacks will be introduced. To the best of our knowledge, Crystal is the first protocol that prevents selfish mining and double-spending attacks while providing safety proof. ",
    "url": "https://arxiv.org/abs/2312.00741",
    "authors": [
      "Jianyu Niu",
      "Fangyu Gai",
      "Runchao Han",
      "Ren Zhang",
      "Yinqian Zhang",
      "Chen Feng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2312.00747",
    "title": "Reduction from sparse LPN to LPN, Dual Attack 3.0",
    "abstract": "The security of code-based cryptography relies primarily on the hardness of decoding generic linear codes. Until very recently, all the best algorithms for solving the decoding problem were information set decoders (ISD). However, recently a new algorithm called RLPN-decoding which relies on a completely different approach was introduced and it has been shown that RLPN outperforms significantly ISD decoders for a rather large range of rates. This RLPN decoder relies on two ingredients, first reducing decoding to some underlying LPN problem, and then computing efficiently many parity-checks of small weight when restricted to some positions. We revisit RLPN-decoding by noticing that, in this algorithm, decoding is in fact reduced to a sparse-LPN problem, namely with a secret whose Hamming weight is small. Our new approach consists this time in making an additional reduction from sparse-LPN to plain-LPN with a coding approach inspired by coded-BKW. It outperforms significantly the ISD's and RLPN for code rates smaller than 0.42. This algorithm can be viewed as the code-based cryptography cousin of recent dual attacks in lattice-based cryptography. We depart completely from the traditional analysis of this kind of algorithm which uses a certain number of independence assumptions that have been strongly questioned recently in the latter domain. We give instead a formula for the LPNs noise relying on duality which allows to analyze the behavior of the algorithm by relying only on the analysis of a certain weight distribution. By using only a minimal assumption whose validity has been verified experimentally we are able to justify the correctness of our algorithm. This key tool, namely the duality formula, can be readily adapted to the lattice setting and is shown to give a simple explanation for some phenomena observed on dual attacks in lattices in [DP23]. ",
    "url": "https://arxiv.org/abs/2312.00747",
    "authors": [
      "K\u00e9vin Carrier",
      "Thomas Debris-Alazard",
      "Charles Meyer-Hilfiger",
      "Jean-Pierre Tillich"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.00778",
    "title": "MorpheuS: Neural Dynamic 360\u00b0 Surface Reconstruction from Monocular  RGB-D Video",
    "abstract": "Neural rendering has demonstrated remarkable success in dynamic scene reconstruction. Thanks to the expressiveness of neural representations, prior works can accurately capture the motion and achieve high-fidelity reconstruction of the target object. Despite this, real-world video scenarios often feature large unobserved regions where neural representations struggle to achieve realistic completion. To tackle this challenge, we introduce MorpheuS, a framework for dynamic 360{\\deg} surface reconstruction from a casually captured RGB-D video. Our approach models the target scene as a canonical field that encodes its geometry and appearance, in conjunction with a deformation field that warps points from the current frame to the canonical space. We leverage a view-dependent diffusion prior and distill knowledge from it to achieve realistic completion of unobserved regions. Experimental results on various real-world and synthetic datasets show that our method can achieve high-fidelity 360{\\deg} surface reconstruction of a deformable object from a monocular RGB-D video. ",
    "url": "https://arxiv.org/abs/2312.00778",
    "authors": [
      "Hengyi Wang",
      "Jingwen Wang",
      "Lourdes Agapito"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00781",
    "title": "Modeling False Data Injection Attacks on Integrated Electricity-Gas  Systems",
    "abstract": "This work studies the modeling of false data injection attacks (FDIAs) on IEGSs. First, we introduce a static state estimation model and bad data detection method for IEGSs. Then, we develop FDIAs on IEGSs with complete network topology and parameter information. Next, we develop FDIAs on IEGSs when intruders have only local network topology and parameter information of an IEGS. Lastly, we explore FDIAs on IEGSs when intruders have only local network topology information of an IEGS. ",
    "url": "https://arxiv.org/abs/2312.00781",
    "authors": [
      "Rong-Peng Liu",
      "Xiaozhe Wang",
      "Zuyi Li",
      "Rawad Zgheib"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.00037",
    "title": "Photonic Neural Networks and Optics-informed Deep Learning Fundamentals",
    "abstract": "The recent explosive compute growth, mainly fueled by the boost of AI and DNNs, is currently instigating the demand for a novel computing paradigm that can overcome the insurmountable barriers imposed by conventional electronic computing architectures. PNNs implemented on silicon integration platforms stand out as a promising candidate to endow NN hardware, offering the potential for energy efficient and ultra-fast computations through the utilization of the unique primitives of photonics i.e. energy efficiency, THz bandwidth and low-latency. Thus far, several demonstrations have revealed the huge potential of PNNs in performing both linear and non-linear NN operations at unparalleled speed and energy consumption metrics. Transforming this potential into a tangible reality for DL applications requires, however, a deep understanding of the basic PNN principles, requirements and challenges across all constituent architectural, technological and training aspects. In this tutorial, we, initially, review the principles of DNNs along with their fundamental building blocks, analyzing also the key mathematical operations needed for their computation in a photonic hardware. Then, we investigate, through an intuitive mathematical analysis, the interdependence of bit precision and energy efficiency in analog photonic circuitry, discussing the opportunities and challenges of PNNs. Followingly, a performance overview of PNN architectures, weight technologies and activation functions is presented, summarizing their impact in speed, scalability and power consumption. Finally, we provide an holistic overview of the optics-informed NN training framework that incorporates the physical properties of photonic building blocks into the training process in order to improve the NN classification accuracy and effectively elevate neuromorphic photonic hardware into high-performance DL computational settings. ",
    "url": "https://arxiv.org/abs/2312.00037",
    "authors": [
      "A. Tsakyridis",
      "M. Moralis-Pegios",
      "G. Giamougiannis",
      "M. Kirtas",
      "N. Passalis",
      "A. Tefas",
      "N. Pleros"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2312.00038",
    "title": "A Physics-Constrained NeuralODE Approach for Robust Learning of Stiff  Chemical Kinetics",
    "abstract": "The high computational cost associated with solving for detailed chemistry poses a significant challenge for predictive computational fluid dynamics (CFD) simulations of turbulent reacting flows. These models often require solving a system of coupled stiff ordinary differential equations (ODEs). While deep learning techniques have been experimented with to develop faster surrogate models, they often fail to integrate reliably with CFD solvers. This instability arises because deep learning methods optimize for training error without ensuring compatibility with ODE solvers, leading to accumulation of errors over time. Recently, NeuralODE-based techniques have offered a promising solution by effectively modeling chemical kinetics. In this study, we extend the NeuralODE framework for stiff chemical kinetics by incorporating mass conservation constraints directly into the loss function during training. This ensures that the total mass and the elemental mass are conserved, a critical requirement for reliable downstream integration with CFD solvers. Our results demonstrate that this enhancement not only improves the physical consistency with respect to mass conservation criteria but also ensures better robustness and makes the training process more computationally efficient. ",
    "url": "https://arxiv.org/abs/2312.00038",
    "authors": [
      "Tadbhagya Kumar",
      "Anuj Kumar",
      "Pinaki Pal"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2312.00067",
    "title": "Predicting breast cancer with AI for individual risk-adjusted MRI  screening and early detection",
    "abstract": "Women with an increased life-time risk of breast cancer undergo supplemental annual screening MRI. We propose to predict the risk of developing breast cancer within one year based on the current MRI, with the objective of reducing screening burden and facilitating early detection. An AI algorithm was developed on 53,858 breasts from 12,694 patients who underwent screening or diagnostic MRI and accrued over 12 years, with 2,331 confirmed cancers. A first U-Net was trained to segment lesions and identify regions of concern. A second convolutional network was trained to detect malignant cancer using features extracted by the U-Net. This network was then fine-tuned to estimate the risk of developing cancer within a year in cases that radiologists considered normal or likely benign. Risk predictions from this AI were evaluated with a retrospective analysis of 9,183 breasts from a high-risk screening cohort, which were not used for training. Statistical analysis focused on the tradeoff between number of omitted exams versus negative predictive value, and number of potential early detections versus positive predictive value. The AI algorithm identified regions of concern that coincided with future tumors in 52% of screen-detected cancers. Upon directed review, a radiologist found that 71.3% of cancers had a visible correlate on the MRI prior to diagnosis, 65% of these correlates were identified by the AI model. Reevaluating these regions in 10% of all cases with higher AI-predicted risk could have resulted in up to 33% early detections by a radiologist. Additionally, screening burden could have been reduced in 16% of lower-risk cases by recommending a later follow-up without compromising current interval cancer rate. With increasing datasets and improving image quality we expect this new AI-aided, adaptive screening to meaningfully reduce screening burden and improve early detection. ",
    "url": "https://arxiv.org/abs/2312.00067",
    "authors": [
      "Lukas Hirsch",
      "Yu Huang",
      "Hernan A. Makse",
      "Danny F. Martinez",
      "Mary Hughes",
      "Sarah Eskreis-Winkler",
      "Katja Pinker",
      "Elizabeth Morris",
      "Lucas C. Parra",
      "Elizabeth J. Sutton"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2312.00082",
    "title": "A Compact Implicit Neural Representation for Efficient Storage of  Massive 4D Functional Magnetic Resonance Imaging",
    "abstract": "Functional Magnetic Resonance Imaging (fMRI) data is a kind of widely used four-dimensional biomedical data, demanding effective compression but presenting unique challenges for compression due to its intricate temporal dynamics, low signal-to-noise ratio, and complicated underlying redundancies. This paper reports a novel compression paradigm specifically tailored for fMRI data based on Implicit Neural Representation (INR). The proposed approach focuses on removing the various redundancies among the time series, including (i) conducting spatial correlation modeling for intra-region dynamics, (ii) decomposing reusable neuronal activation patterns, and using proper initialization together with nonlinear fusion to describe the inter-region similarity. The above scheme properly incorporates the unique features of fMRI data, and experimental results on publicly available datasets demonstrate the effectiveness of the proposed method, surpassing state-of-the-art algorithms in both conventional image quality evaluation metrics and fMRI downstream tasks. This work in this paper paves the way for sharing massive fMRI data at low bandwidth and high fidelity. ",
    "url": "https://arxiv.org/abs/2312.00082",
    "authors": [
      "Ruoran Li",
      "Runzhao Yang",
      "Wenxin Xiang",
      "Yuxiao Cheng",
      "Tingxiong Xiao",
      "Jinli Suo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00086",
    "title": "Star colouring and locally constrained graph homomorphisms",
    "abstract": "Dvo\\v{r}\\'ak, Mohar and \\v{S}\\'amal (J. Graph Theory, 2013) proved that for every 3-regular graph $G$, the line graph of $G$ is 4-star colourable if and only if $G$ admits a locally bijective homomorphism to the cube $Q_3$. We generalise this result as follows: for $p\\geq 2$, a $K_{1,p+1}$-free $2p$-regular graph $G$ admits a $(p + 2)$-star colouring if and only if $G$ admits a locally bijective homomorphism to a fixed $2p$-regular graph named $G_{2p}$. We also prove the following: (i) for $p\\geq 2$, a $2p$-regular graph $G$ admits a $(p + 2)$-star colouring if and only if $G$ has an orientation $\\vec{G}$ that admits an out-neighbourhood bijective homomorphism to a fixed orientation $\\vec{G_{2p}}$ of $G2p$; (ii) for every 3-regular graph $G$, the line graph of $G$ is 4-star colourable if and only if $G$ is bipartite and distance-two 4-colourable; and (iii) it is NP-complete to check whether a planar 4-regular 3-connected graph is 4-star colourable. ",
    "url": "https://arxiv.org/abs/2312.00086",
    "authors": [
      "Shalu M. A.",
      "Cyriac Antony"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2312.00223",
    "title": "Convolutional Neural Networks for Segmentation of Malignant Pleural  Mesothelioma: Analysis of Probability Map Thresholds (CALGB 30901, Alliance)",
    "abstract": "Malignant pleural mesothelioma (MPM) is the most common form of mesothelioma. To assess response to treatment, tumor measurements are acquired and evaluated based on a patient's longitudinal computed tomography (CT) scans. Tumor volume, however, is the more accurate metric for assessing tumor burden and response. Automated segmentation methods using deep learning can be employed to acquire volume, which otherwise is a tedious task performed manually. The deep learning-based tumor volume and contours can then be compared with a standard reference to assess the robustness of the automated segmentations. The purpose of this study was to evaluate the impact of probability map threshold on MPM tumor delineations generated using a convolutional neural network (CNN). Eighty-eight CT scans from 21 MPM patients were segmented by a VGG16/U-Net CNN. A radiologist modified the contours generated at a 0.5 probability threshold. Percent difference of tumor volume and overlap using the Dice Similarity Coefficient (DSC) were compared between the standard reference provided by the radiologist and CNN outputs for thresholds ranging from 0.001 to 0.9. CNN annotations consistently yielded smaller tumor volumes than radiologist contours. Reducing the probability threshold from 0.5 to 0.1 decreased the absolute percent volume difference, on average, from 43.96% to 24.18%. Median and mean DSC ranged from 0.58 to 0.60, with a peak at a threshold of 0.5; no distinct threshold was found for percent volume difference. No single output threshold in the CNN probability maps was optimal for both tumor volume and DSC. This work underscores the need to assess tumor volume and spatial overlap when evaluating CNN performance. While automated segmentations may yield comparable tumor volumes to that of the reference standard, the spatial region delineated by the CNN at a specific threshold is equally important. ",
    "url": "https://arxiv.org/abs/2312.00223",
    "authors": [
      "Mena Shenouda",
      "Eyj\u00f3lfur Gudmundsson",
      "Feng Li",
      "Christopher M. Straus",
      "Hedy L. Kindler",
      "Arkadiusz Z. Dudek",
      "Thomas Stinchcombe",
      "Xiaofei Wang",
      "Adam Starkey",
      "Samuel G. Armato III"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2312.00299",
    "title": "QIENet: Quantitative irradiance estimation network using recurrent  neural network based on satellite remote sensing data",
    "abstract": "Global horizontal irradiance (GHI) plays a vital role in estimating solar energy resources, which are used to generate sustainable green energy. In order to estimate GHI with high spatial resolution, a quantitative irradiance estimation network, named QIENet, is proposed. Specifically, the temporal and spatial characteristics of remote sensing data of the satellite Himawari-8 are extracted and fused by recurrent neural network (RNN) and convolution operation, respectively. Not only remote sensing data, but also GHI-related time information (hour, day, and month) and geographical information (altitude, longitude, and latitude), are used as the inputs of QIENet. The satellite spectral channels B07 and B11 - B15 and time are recommended as model inputs for QIENet according to the spatial distributions of annual solar energy. Meanwhile, QIENet is able to capture the impact of various clouds on hourly GHI estimates. More importantly, QIENet does not overestimate ground observations and can also reduce RMSE by 27.51%/18.00%, increase R2 by 20.17%/9.42%, and increase r by 8.69%/3.54% compared with ERA5/NSRDB. Furthermore, QIENet is capable of providing a high-fidelity hourly GHI database with spatial resolution 0.02{\\deg} * 0.02{\\deg}(approximately 2km * 2km) for many applied energy fields. ",
    "url": "https://arxiv.org/abs/2312.00299",
    "authors": [
      "Longfeng Nie",
      "Yuntian Chen",
      "Dongxiao Zhang",
      "Xinyue Liu",
      "Wentian Yuan"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00306",
    "title": "RadioGalaxyNET: Dataset and Novel Computer Vision Algorithms for the  Detection of Extended Radio Galaxies and Infrared Hosts",
    "abstract": "Creating radio galaxy catalogues from next-generation deep surveys requires automated identification of associated components of extended sources and their corresponding infrared hosts. In this paper, we introduce RadioGalaxyNET, a multimodal dataset, and a suite of novel computer vision algorithms designed to automate the detection and localization of multi-component extended radio galaxies and their corresponding infrared hosts. The dataset comprises 4,155 instances of galaxies in 2,800 images with both radio and infrared channels. Each instance provides information about the extended radio galaxy class, its corresponding bounding box encompassing all components, the pixel-level segmentation mask, and the keypoint position of its corresponding infrared host galaxy. RadioGalaxyNET is the first dataset to include images from the highly sensitive Australian Square Kilometre Array Pathfinder (ASKAP) radio telescope, corresponding infrared images, and instance-level annotations for galaxy detection. We benchmark several object detection algorithms on the dataset and propose a novel multimodal approach to simultaneously detect radio galaxies and the positions of infrared hosts. ",
    "url": "https://arxiv.org/abs/2312.00306",
    "authors": [
      "Nikhel Gupta",
      "Zeeshan Hayder",
      "Ray P. Norris",
      "Minh Huynh",
      "Lars Petersson"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00352",
    "title": "Quantum Kernel t-Distributed Stochastic Neighbor Embedding",
    "abstract": "Data visualization is important in understanding the characteristics of data that are difficult to see directly. It is used to visualize loss landscapes and optimization trajectories to analyze optimization performance. Popular optimization analysis is performed by visualizing a loss landscape around the reached local or global minimum using principal component analysis. However, this visualization depends on the variational parameters of a quantum circuit rather than quantum states, which makes it difficult to understand the mechanism of optimization process through the property of quantum states. Here, we propose a quantum data visualization method using quantum kernels, which enables us to offer fast and highly accurate visualization of quantum states. In our numerical experiments, we visualize hand-written digits dataset and apply $k$-nearest neighbor algorithm to the low-dimensional data to quantitatively evaluate our proposed method compared with a classical kernel method. As a result, our proposed method achieves comparable accuracy to the state-of-the-art classical kernel method, meaning that the proposed visualization method based on quantum machine learning does not degrade the separability of the input higher dimensional data. Furthermore, we visualize the optimization trajectories of finding the ground states of transverse field Ising model and successfully find the trajectory characteristics. Since quantum states are higher dimensional objects that can only be seen via observables, our visualization method, which inherits the similarity of quantum data, would be useful in understanding the behavior of quantum circuits and algorithms. ",
    "url": "https://arxiv.org/abs/2312.00352",
    "authors": [
      "Yoshiaki Kawase",
      "Kosuke Mitarai",
      "Keisuke Fujii"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00358",
    "title": "Impact of Data Augmentation on QCNNs",
    "abstract": "In recent years, Classical Convolutional Neural Networks (CNNs) have been applied for image recognition successfully. Quantum Convolutional Neural Networks (QCNNs) are proposed as a novel generalization to CNNs by using quantum mechanisms. The quantum mechanisms lead to an efficient training process in QCNNs by reducing the size of input from $N$ to $log_2N$. This paper implements and compares both CNNs and QCNNs by testing losses and prediction accuracy on three commonly used datasets. The datasets include the MNIST hand-written digits, Fashion MNIST and cat/dog face images. Additionally, data augmentation (DA), a technique commonly used in CNNs to improve the performance of classification by generating similar images based on original inputs, is also implemented in QCNNs. Surprisingly, the results showed that data augmentation didn't improve QCNNs performance. The reasons and logic behind this result are discussed, hoping to expand our understanding of Quantum machine learning theory. ",
    "url": "https://arxiv.org/abs/2312.00358",
    "authors": [
      "Leting Zhouli",
      "Peiyong Wang",
      "Udaya Parampalli"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00509",
    "title": "Bayesian causal discovery from unknown general interventions",
    "abstract": "We consider the problem of learning causal Directed Acyclic Graphs (DAGs) using combinations of observational and interventional experimental data. Current methods tailored to this setting assume that interventions either destroy parent-child relations of the intervened (target) nodes or only alter such relations without modifying the parent sets, even when the intervention targets are unknown. We relax this assumption by proposing a Bayesian method for causal discovery from general interventions, which allow for modifications of the parent sets of the unknown targets. Even in this framework, DAGs and general interventions may be identifiable only up to some equivalence classes. We provide graphical characterizations of such interventional Markov equivalence and devise compatible priors for Bayesian inference that guarantee score equivalence of indistinguishable structures. We then develop a Markov Chain Monte Carlo (MCMC) scheme to approximate the posterior distribution over DAGs, intervention targets and induced parent sets. Finally, we evaluate the proposed methodology on both simulated and real protein expression data. ",
    "url": "https://arxiv.org/abs/2312.00509",
    "authors": [
      "Alessandro Mascaro",
      "Federico Castelletti"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.00529",
    "title": "Algorithm-based diagnostic application for diabetic retinopathy  detection",
    "abstract": "Diabetic retinopathy (DR) is a growing health problem worldwide and is a leading cause of visual impairment and blindness, especially among working people aged 20-65. Its incidence is increasing along with the number of diabetes cases, and it is more common in developed countries than in developing countries. Recent research in the field of diabetic retinopathy diagnosis is using advanced technologies, such as analysis of images obtained by ophthalmoscopy. Automatic methods for analyzing eye images based on neural networks, deep learning and image analysis algorithms can improve the efficiency of diagnosis. This paper describes an automatic DR diagnosis method that includes processing and analysis of ophthalmoscopic images of the eye. It uses morphological algorithms to identify the optic disc and lesions characteristic of DR, such as microaneurysms, hemorrhages and exudates. Automated DR diagnosis has the potential to improve the efficiency of early detection of this disease and contribute to reducing the number of cases of diabetes-related visual impairment. The final step was to create an application with a graphical user interface that allowed retinal images taken at cooperating ophthalmology offices to be uploaded to the server. These images were then analyzed using a developed algorithm to make a diagnosis. ",
    "url": "https://arxiv.org/abs/2312.00529",
    "authors": [
      "Agnieszka Cisek",
      "Karolina Korycinska",
      "Leszek Pyziak",
      "Marzena Malicka",
      "Tomasz Wiecek",
      "Grzegorz Gruzel",
      "Kamil Szmuc",
      "Jozef Cebulski",
      "Mariusz Spyra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Tissues and Organs (q-bio.TO)"
    ]
  },
  {
    "id": "arXiv:2312.00535",
    "title": "RIS-Based On-the-Air Semantic Communications -- a Diffractional Deep  Neural Network Approach",
    "abstract": "Semantic communication has gained significant attention recently due to its advantages in achieving higher transmission efficiency by focusing on semantic information instead of bit-level information. However, current AI-based semantic communication methods require digital hardware for implementation. With the rapid advancement on reconfigurable intelligence surfaces (RISs), a new approach called on-the-air diffractional deep neural networks (D$^2$NN) can be utilized to enable semantic communications on the wave domain. This paper proposes a new paradigm of RIS-based on-the-air semantic communications, where the computational process occurs inherently as wireless signals pass through RISs. We present the system model and discuss the data and control flows of this scheme, followed by a performance analysis using image transmission as an example. In comparison to traditional hardware-based approaches, RIS-based semantic communications offer appealing features, such as light-speed computation, low computational power requirements, and the ability to handle multiple tasks simultaneously. ",
    "url": "https://arxiv.org/abs/2312.00535",
    "authors": [
      "Shuyi Chen",
      "Yingzhe Hui",
      "Yifan Qin",
      "Yueyi Yuan",
      "Weixiao Meng",
      "Xuewen Luo",
      "Hsiao-Hwa Chen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00585",
    "title": "Adaptive Parameter-Free Robust Learning using Latent Bernoulli Variables",
    "abstract": "We present an efficient parameter-free approach for statistical learning from corrupted training sets. We identify corrupted and non-corrupted samples using latent Bernoulli variables, and therefore formulate the robust learning problem as maximization of the likelihood where latent variables are marginalized out. The resulting optimization problem is solved via variational inference using an efficient Expectation-Maximization based method. The proposed approach improves over the state-of-the-art by automatically inferring the corruption level and identifying outliers, while adding minimal computational overhead. We demonstrate our robust learning method on a wide variety of machine learning tasks including online learning and deep learning where it exhibits ability to adapt to different levels of noise and attain high prediction accuracy. ",
    "url": "https://arxiv.org/abs/2312.00585",
    "authors": [
      "Aleksandr Karakulev",
      "Dave Zachariah",
      "Prashant Singh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.00661",
    "title": "Dual-Domain Multi-Contrast MRI Reconstruction with Synthesis-based  Fusion Network",
    "abstract": "Purpose: To develop an efficient dual-domain reconstruction framework for multi-contrast MRI, with the focus on minimising cross-contrast misalignment in both the image and the frequency domains to enhance optimisation. Theory and Methods: Our proposed framework, based on deep learning, facilitates the optimisation for under-sampled target contrast using fully-sampled reference contrast that is quicker to acquire. The method consists of three key steps: 1) Learning to synthesise data resembling the target contrast from the reference contrast; 2) Registering the multi-contrast data to reduce inter-scan motion; and 3) Utilising the registered data for reconstructing the target contrast. These steps involve learning in both domains with regularisation applied to ensure their consistency. We also compare the reconstruction performance with existing deep learning-based methods using a dataset of brain MRI scans. Results: Extensive experiments demonstrate the superiority of our proposed framework, for up to an 8-fold acceleration rate, compared to state-of-the-art algorithms. Comprehensive analysis and ablation studies further present the effectiveness of the proposed components. Conclusion:Our dual-domain framework offers a promising approach to multi-contrast MRI reconstruction. It can also be integrated with existing methods to further enhance the reconstruction. ",
    "url": "https://arxiv.org/abs/2312.00661",
    "authors": [
      "Junwei Yang",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.00677",
    "title": "Unsupervised Adaptive Implicit Neural Representation Learning for  Scan-Specific MRI Reconstruction",
    "abstract": "In recent studies on MRI reconstruction, advances have shown significant promise for further accelerating the MRI acquisition. Most state-of-the-art methods require a large amount of fully-sampled data to optimise reconstruction models, which is impractical and expensive under certain clinical settings. On the other hand, for unsupervised scan-specific reconstruction methods, overfitting is likely to happen due to insufficient supervision, while restrictions on acceleration rates and under-sampling patterns further limit their applicability. To this end, we propose an unsupervised, adaptive coarse-to-fine framework that enhances reconstruction quality without being constrained by the sparsity levels or patterns in under-sampling. The framework employs an implicit neural representation for scan-specific MRI reconstruction, learning a mapping from multi-dimensional coordinates to their corresponding signal intensities. Moreover, we integrate a novel learning strategy that progressively refines the use of acquired k-space signals for self-supervision. This approach effectively adjusts the proportion of supervising signals from unevenly distributed information across different frequency bands, thus mitigating the issue of overfitting while improving the overall reconstruction. Comprehensive evaluation on a public dataset, including both 2D and 3D data, has shown that our method outperforms current state-of-the-art scan-specific MRI reconstruction techniques, for up to 8-fold under-sampling. ",
    "url": "https://arxiv.org/abs/2312.00677",
    "authors": [
      "Junwei Yang",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1911.05467",
    "title": "ChebNet: Efficient and Stable Constructions of Deep Neural Networks with  Rectified Power Units via Chebyshev Approximations",
    "abstract": " Comments: 6 figures, 3 tables, to appear on Communications in Mathematics and Statistics ",
    "url": "https://arxiv.org/abs/1911.05467",
    "authors": [
      "Shanshan Tang",
      "Bo Li",
      "Haijun Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2010.04055",
    "title": "A Unified Approach to Interpreting and Boosting Adversarial  Transferability",
    "abstract": " Title: A Unified Approach to Interpreting and Boosting Adversarial  Transferability ",
    "url": "https://arxiv.org/abs/2010.04055",
    "authors": [
      "Xin Wang",
      "Jie Ren",
      "Shuyun Lin",
      "Xiangming Zhu",
      "Yisen Wang",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2101.12276",
    "title": "A causal convolutional neural network for multi-subject motion modeling  and generation",
    "abstract": " Comments: This preprint has not undergone peer review (when applicable) or any post-submission improvements or corrections. The Version of Record of this article is published in Computational Visual Media, and is available online at this https URL ",
    "url": "https://arxiv.org/abs/2101.12276",
    "authors": [
      "Shuaiying Hou",
      "Congyi Wang",
      "Wenlin Zhuang",
      "Yu Chen",
      "Yangang Wang",
      "Hujun Bao",
      "Jinxiang Chai",
      "Weiwei Xu"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2104.13669",
    "title": "Optimal Stopping via Randomized Neural Networks",
    "abstract": " Title: Optimal Stopping via Randomized Neural Networks ",
    "url": "https://arxiv.org/abs/2104.13669",
    "authors": [
      "Calypso Herrera",
      "Florian Krach",
      "Pierre Ruyssen",
      "Josef Teichmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2205.02347",
    "title": "Rooted America: Immobility and Segregation of the Intercounty Migration  Network",
    "abstract": " Title: Rooted America: Immobility and Segregation of the Intercounty Migration  Network ",
    "url": "https://arxiv.org/abs/2205.02347",
    "authors": [
      "Peng Huang",
      "Carter T. Butts"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2206.08401",
    "title": "Is decentralized finance actually decentralized? A social network  analysis of the Aave protocol on the Ethereum blockchain",
    "abstract": " Comments: Accepted at 29th Annual Global Finance Conference featuring Professor Robert Engle, The 2003 Nobel Laureate in Economic Sciences ",
    "url": "https://arxiv.org/abs/2206.08401",
    "authors": [
      "Ziqiao Ao",
      "Lin William Cong",
      "Gergely Horvath",
      "Luyao Zhang"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Cryptography and Security (cs.CR)",
      "Statistical Finance (q-fin.ST)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2210.00379",
    "title": "NeRF: Neural Radiance Field in 3D Vision, A Comprehensive Review",
    "abstract": " Comments: Fixed some typos from previous version ",
    "url": "https://arxiv.org/abs/2210.00379",
    "authors": [
      "Kyle Gao",
      "Yina Gao",
      "Hongjie He",
      "Dening Lu",
      "Linlin Xu",
      "Jonathan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.09020",
    "title": "Defects of Convolutional Decoder Networks in Frequency Representation",
    "abstract": " Title: Defects of Convolutional Decoder Networks in Frequency Representation ",
    "url": "https://arxiv.org/abs/2210.09020",
    "authors": [
      "Ling Tang",
      "Wen Shen",
      "Zhanpeng Zhou",
      "Yuefeng Chen",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.16063",
    "title": "Defense Against Smart Invaders with Swarms of Sweeping Agents",
    "abstract": " Comments: 18 pages, 21 figures ",
    "url": "https://arxiv.org/abs/2210.16063",
    "authors": [
      "Roee M. Francos",
      "Alfred M. Bruckstein"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2211.05781",
    "title": "Demystify Transformers & Convolutions in Modern Image Deep Networks",
    "abstract": " Title: Demystify Transformers & Convolutions in Modern Image Deep Networks ",
    "url": "https://arxiv.org/abs/2211.05781",
    "authors": [
      "Xiaowei Hu",
      "Min Shi",
      "Weiyun Wang",
      "Sitong Wu",
      "Linjie Xing",
      "Wenhai Wang",
      "Xizhou Zhu",
      "Lewei Lu",
      "Jie Zhou",
      "Xiaogang Wang",
      "Yu Qiao",
      "Jifeng Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.06108",
    "title": "RaLiBEV: Radar and LiDAR BEV Fusion Learning for Anchor Box Free Object  Detection Systems",
    "abstract": " Comments: 14 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2211.06108",
    "authors": [
      "Yanlong Yang",
      "Jianan Liu",
      "Tao Huang",
      "Qing-Long Han",
      "Gang Ma",
      "Bing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.02003",
    "title": "Bayesian Learning with Information Gain Provably Bounds Risk for a  Robust Adversarial Defense",
    "abstract": " Comments: Published at ICML 2022. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2212.02003",
    "authors": [
      "Bao Gia Doan",
      "Ehsan Abbasnejad",
      "Javen Qinfeng Shi",
      "Damith C. Ranasinghe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05500",
    "title": "Security Defense of Large Scale Networks Under False Data Injection  Attacks: An Attack Detection Scheduling Approach",
    "abstract": " Comments: 14 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2212.05500",
    "authors": [
      "Yuhan Suo",
      "Senchun Chai",
      "Runqi Chai",
      "Zhong-Hua Pang",
      "Yuanqing Xia",
      "Guo-Ping Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.07099",
    "title": "Adaptive Deep Neural Network Inference Optimization with EENet",
    "abstract": " Title: Adaptive Deep Neural Network Inference Optimization with EENet ",
    "url": "https://arxiv.org/abs/2301.07099",
    "authors": [
      "Fatih Ilhan",
      "Ka-Ho Chow",
      "Sihao Hu",
      "Tiansheng Huang",
      "Selim Tekin",
      "Wenqi Wei",
      "Yanzhao Wu",
      "Myungjin Lee",
      "Ramana Kompella",
      "Hugo Latapie",
      "Gaowen Liu",
      "Ling Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.09043",
    "title": "CodeScore: Evaluating Code Generation by Learning Code Execution",
    "abstract": " Title: CodeScore: Evaluating Code Generation by Learning Code Execution ",
    "url": "https://arxiv.org/abs/2301.09043",
    "authors": [
      "Yihong Dong",
      "Jiazheng Ding",
      "Xue Jiang",
      "Ge Li",
      "Zhuo Li",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.09995",
    "title": "Selectively Providing Reliance Calibration Cues With Reliance Prediction",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2302.09995",
    "authors": [
      "Yosuke Fukuchi",
      "Seiji Yamada"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.13080",
    "title": "Does a Neural Network Really Encode Symbolic Concepts?",
    "abstract": " Title: Does a Neural Network Really Encode Symbolic Concepts? ",
    "url": "https://arxiv.org/abs/2302.13080",
    "authors": [
      "Mingjie Li",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.13095",
    "title": "Bayesian Neural Networks Avoid Encoding Complex and  Perturbation-Sensitive Concepts",
    "abstract": " Title: Bayesian Neural Networks Avoid Encoding Complex and  Perturbation-Sensitive Concepts ",
    "url": "https://arxiv.org/abs/2302.13095",
    "authors": [
      "Qihan Ren",
      "Huiqi Deng",
      "Yunuo Chen",
      "Siyu Lou",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.01261",
    "title": "ParrotTTS: Text-to-Speech synthesis by exploiting self-supervised  representations",
    "abstract": " Title: ParrotTTS: Text-to-Speech synthesis by exploiting self-supervised  representations ",
    "url": "https://arxiv.org/abs/2303.01261",
    "authors": [
      "Neil Shah",
      "Saiteja Kosgi",
      "Vishal Tambrahalli",
      "Neha Sahipjohn",
      "Anil Kumar Nelakanti",
      "Niranjan Pedanekar",
      "Vineet Gandhi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2303.06388",
    "title": "Generalized 3D Self-supervised Learning Framework via Prompted  Foreground-Aware Feature Contrast",
    "abstract": " Comments: International Journal of Computer Vision, Manuscript Info: 28 Pages, 14 Figures, and 11 Tables ",
    "url": "https://arxiv.org/abs/2303.06388",
    "authors": [
      "Kangcheng Liu",
      "Xinhu Zheng",
      "Chaoqun Wang",
      "Kai Tang",
      "Ming Liu",
      "Baoquan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.12693",
    "title": "Phylo2Vec: a vector representation for binary trees",
    "abstract": " Comments: 35 pages, 8 figures, 2 tables, 2 supplementary figures ",
    "url": "https://arxiv.org/abs/2304.12693",
    "authors": [
      "Matthew J Penn",
      "Neil Scheidwasser",
      "Mark P Khurana",
      "David A Duch\u00eane",
      "Christl A Donnelly",
      "Samir Bhatt"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2305.03977",
    "title": "An Adversarial Non-Autoregressive Model for Text Generation with  Incomplete Information",
    "abstract": " Title: An Adversarial Non-Autoregressive Model for Text Generation with  Incomplete Information ",
    "url": "https://arxiv.org/abs/2305.03977",
    "authors": [
      "Da Ren",
      "Yi Cai",
      "Qing Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.07618",
    "title": "Uncertainty Estimation and Out-of-Distribution Detection for Deep  Learning-Based Image Reconstruction using the Local Lipschitz",
    "abstract": " Title: Uncertainty Estimation and Out-of-Distribution Detection for Deep  Learning-Based Image Reconstruction using the Local Lipschitz ",
    "url": "https://arxiv.org/abs/2305.07618",
    "authors": [
      "Danyal F. Bhutto",
      "Bo Zhu",
      "Jeremiah Z. Liu",
      "Neha Koonjoo",
      "Hongwei B. Li",
      "Bruce R. Rosen",
      "Matthew S. Rosen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.13161",
    "title": "DeepJSCC-l++: Robust and Bandwidth-Adaptive Wireless Image Transmission",
    "abstract": " Comments: Accepted to IEEE Global Communications Conference 2023. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2305.13161",
    "authors": [
      "Chenghong Bian",
      "Yulin Shao",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.19103",
    "title": "Does Conceptual Representation Require Embodiment? Insights From Large  Language Models",
    "abstract": " Title: Does Conceptual Representation Require Embodiment? Insights From Large  Language Models ",
    "url": "https://arxiv.org/abs/2305.19103",
    "authors": [
      "Qihui Xu",
      "Yingying Peng",
      "Samuel A. Nastase",
      "Martin Chodorow",
      "Minghua Wu",
      "Ping Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.01213",
    "title": "Learning Causally Disentangled Representations via the Principle of  Independent Causal Mechanisms",
    "abstract": " Comments: Accepted to the NeurIPS 2023 Workshop on Causal Representation Learning ",
    "url": "https://arxiv.org/abs/2306.01213",
    "authors": [
      "Aneesh Komanduri",
      "Yongkai Wu",
      "Feng Chen",
      "Xintao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.02456",
    "title": "A fully coupled regularized mortar-type finite element approach for  embedding one-dimensional fibers into three-dimensional fluid flow",
    "abstract": " Title: A fully coupled regularized mortar-type finite element approach for  embedding one-dimensional fibers into three-dimensional fluid flow ",
    "url": "https://arxiv.org/abs/2306.02456",
    "authors": [
      "Nora Hagmeyer",
      "Matthias Mayr",
      "Alexander Popp"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.03438",
    "title": "Large Language Models of Code Fail at Completing Code with Potential  Bugs",
    "abstract": " Comments: 27 pages, accepted to NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.03438",
    "authors": [
      "Tuan Dinh",
      "Jinman Zhao",
      "Samson Tan",
      "Renato Negrinho",
      "Leonard Lausen",
      "Sheng Zha",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2306.11667",
    "title": "G-NM: A Group of Numerical Time Series Prediction Models",
    "abstract": " Comments: Not Completed Paper ",
    "url": "https://arxiv.org/abs/2306.11667",
    "authors": [
      "Juyoung Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.17670",
    "title": "Learning Delays in Spiking Neural Networks using Dilated Convolutions  with Learnable Spacings",
    "abstract": " Title: Learning Delays in Spiking Neural Networks using Dilated Convolutions  with Learnable Spacings ",
    "url": "https://arxiv.org/abs/2306.17670",
    "authors": [
      "Ilyass Hammouamri",
      "Ismail Khalfaoui-Hassani",
      "Timoth\u00e9e Masquelier"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.00309",
    "title": "Adversarial Attacks and Defenses on 3D Point Cloud Classification: A  Survey",
    "abstract": " Title: Adversarial Attacks and Defenses on 3D Point Cloud Classification: A  Survey ",
    "url": "https://arxiv.org/abs/2307.00309",
    "authors": [
      "Hanieh Naderi",
      "Ivan V. Baji\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.04962",
    "title": "Intrinsically motivated graph exploration using network theories of  human curiosity",
    "abstract": " Comments: 15 pages, 5 figures in main text, and 18 pages, 9 figures in supplement ",
    "url": "https://arxiv.org/abs/2307.04962",
    "authors": [
      "Shubhankar P. Patankar",
      "Mathieu Ouellet",
      "Juan Cervino",
      "Alejandro Ribeiro",
      "Kieran A. Murphy",
      "Dani S. Bassett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2307.07643",
    "title": "AECIF-Net: An Attention-Enhanced Co-Interactive Fusion Network for  Automated Structural Condition Assessment in Visual Inspection",
    "abstract": " Comments: Submitted to Automation in Construction ",
    "url": "https://arxiv.org/abs/2307.07643",
    "authors": [
      "Chenyu Zhang",
      "Zhaozheng Yin",
      "Ruwen Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.13494",
    "title": "Duet: efficient and scalable hybriD neUral rElation undersTanding",
    "abstract": " Title: Duet: efficient and scalable hybriD neUral rElation undersTanding ",
    "url": "https://arxiv.org/abs/2307.13494",
    "authors": [
      "Kaixin Zhang",
      "Hongzhi Wang",
      "Yabin Lu",
      "Ziqi Li",
      "Chang Shu",
      "Yu Yan",
      "Donghua Yang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15090",
    "title": "Understanding Forward Process of Convolutional Neural Network",
    "abstract": " Comments: something wrong in this paper ",
    "url": "https://arxiv.org/abs/2307.15090",
    "authors": [
      "Peixin Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.01300",
    "title": "Revisiting DETR Pre-training for Object Detection",
    "abstract": " Title: Revisiting DETR Pre-training for Object Detection ",
    "url": "https://arxiv.org/abs/2308.01300",
    "authors": [
      "Yan Ma",
      "Weicong Liang",
      "Bohan Chen",
      "Yiduo Hao",
      "Bojian Hou",
      "Xiangyu Yue",
      "Chao Zhang",
      "Yuhui Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.04170",
    "title": "DroidDissector: A Static and Dynamic Analysis Tool for Android Malware  Detection",
    "abstract": " Comments: Proceedings of the International Conference on Applied Cybersecurity (ACS) 2023 (LNNS,volume 760) ",
    "url": "https://arxiv.org/abs/2308.04170",
    "authors": [
      "Ali Muzaffar",
      "Hani Ragab Hassen",
      "Hind Zantout",
      "Michael A Lones"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.09193",
    "title": "A Comparative Study of Text Embedding Models for Semantic Text  Similarity in Bug Reports",
    "abstract": " Comments: 7 Pages ",
    "url": "https://arxiv.org/abs/2308.09193",
    "authors": [
      "Avinash Patil",
      "Kihwan Han",
      "Aryan Jadon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13490",
    "title": "TpuGraphs: A Performance Prediction Dataset on Large Tensor  Computational Graphs",
    "abstract": " Title: TpuGraphs: A Performance Prediction Dataset on Large Tensor  Computational Graphs ",
    "url": "https://arxiv.org/abs/2308.13490",
    "authors": [
      "Phitchaya Mangpo Phothilimthana",
      "Sami Abu-El-Haija",
      "Kaidi Cao",
      "Bahare Fatemi",
      "Charith Mendis",
      "Bryan Perozzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.14837",
    "title": "Breaking the VLB Barrier for Oblivious Reconfigurable Networks",
    "abstract": " Comments: 50 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2308.14837",
    "authors": [
      "Tegan Wilson",
      "Daniel Amir",
      "Nitika Saran",
      "Robert Kleinberg",
      "Vishal Shrivastav",
      "Hakim Weatherspoon"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2309.11814",
    "title": "Micromechanics-Informed Parametric Deep Material Network for Physics  Behavior Prediction of Heterogeneous Materials with a Varying Morphology",
    "abstract": " Title: Micromechanics-Informed Parametric Deep Material Network for Physics  Behavior Prediction of Heterogeneous Materials with a Varying Morphology ",
    "url": "https://arxiv.org/abs/2309.11814",
    "authors": [
      "Tianyi Li"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2309.11969",
    "title": "A survey of trends and motivations regarding Communication Service  Providers' metro area network implementations",
    "abstract": " Comments: 70 pages ",
    "url": "https://arxiv.org/abs/2309.11969",
    "authors": [
      "Etienne-Victor Depasquale",
      "Mark Tinka",
      "Saviour Zammit",
      "Franco Davoli"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.03940",
    "title": "Hard View Selection for Self-Supervised Learning",
    "abstract": " Title: Hard View Selection for Self-Supervised Learning ",
    "url": "https://arxiv.org/abs/2310.03940",
    "authors": [
      "Fabio Ferreira",
      "Ivo Rapant",
      "Frank Hutter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05920",
    "title": "SimPLR: A Simple and Plain Transformer for Object Detection and  Segmentation",
    "abstract": " Title: SimPLR: A Simple and Plain Transformer for Object Detection and  Segmentation ",
    "url": "https://arxiv.org/abs/2310.05920",
    "authors": [
      "Duy-Kien Nguyen",
      "Martin R. Oswald",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.14395",
    "title": "Universal representation by Boltzmann machines with Regularised Axons",
    "abstract": " Comments: 12 pages. Updated references ",
    "url": "https://arxiv.org/abs/2310.14395",
    "authors": [
      "Przemys\u0142aw R. Grzybowski",
      "Antoni Jankiewicz",
      "Eloy Pi\u00f1ol",
      "David Cirauqui",
      "Dorota H. Grzybowska",
      "Pawe\u0142 M. Petrykowski",
      "Miguel \u00c1ngel Garc\u00eda-March",
      "Maciej Lewenstein",
      "Gorka Mu\u00f1oz-Gil",
      "Alejandro Pozas-Kerstjens"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01356",
    "title": "Upper and lower bounds for the Lipschitz constant of random neural  networks",
    "abstract": " Title: Upper and lower bounds for the Lipschitz constant of random neural  networks ",
    "url": "https://arxiv.org/abs/2311.01356",
    "authors": [
      "Paul Geuchen",
      "Thomas Heindl",
      "Dominik St\u00f6ger",
      "Felix Voigtlaender"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2311.05723",
    "title": "Active Admission Control in a P2P Distributed Environment for Capacity  Efficient Livestreaming in Mobile Wireless Networks",
    "abstract": " Comments: 8 pages, 6 figures, 3 tables, Accepted for publication in CSCI 2023 ",
    "url": "https://arxiv.org/abs/2311.05723",
    "authors": [
      "Andrei Negulescu",
      "Weijia Shang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.15890",
    "title": "Stability-Informed Initialization of Neural Ordinary Differential  Equations",
    "abstract": " Title: Stability-Informed Initialization of Neural Ordinary Differential  Equations ",
    "url": "https://arxiv.org/abs/2311.15890",
    "authors": [
      "Theodor Westny",
      "Arman Mohammadi",
      "Daniel Jung",
      "Erik Frisk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16334",
    "title": "Robust Basket Recommendation via Noise-tolerated Graph Contrastive  Learning",
    "abstract": " Comments: CIKM 2023 ",
    "url": "https://arxiv.org/abs/2311.16334",
    "authors": [
      "Xinrui He",
      "Tianxin Wei",
      "Jingrui He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.17116",
    "title": "REF$^2$-NeRF: Reflection and Refraction aware Neural Radiance Field",
    "abstract": " Comments: 11 pages, 8 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2311.17116",
    "authors": [
      "Wooseok Kim",
      "Taiki Fukiage",
      "Takeshi Oishi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17303",
    "title": "Enhancing the Performance of Neural Networks Through Causal Discovery  and Integration of Domain Knowledge",
    "abstract": " Title: Enhancing the Performance of Neural Networks Through Causal Discovery  and Integration of Domain Knowledge ",
    "url": "https://arxiv.org/abs/2311.17303",
    "authors": [
      "Xiaoge Zhang",
      "Xiao-Lin Wang",
      "Fenglei Fan",
      "Yiu-Ming Cheung",
      "Indranil Bose"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2311.17853",
    "title": "On the Adversarial Robustness of Graph Contrastive Learning Methods",
    "abstract": " Comments: Accepted at NeurIPS 2023 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2023) ",
    "url": "https://arxiv.org/abs/2311.17853",
    "authors": [
      "Filippo Guerranti",
      "Zinuo Yi",
      "Anna Starovoit",
      "Rafiq Kamel",
      "Simon Geisler",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.18341",
    "title": "Learning Robust Precipitation Forecaster by Temporal Frame Interpolation",
    "abstract": " Comments: Previous version has text overlap with last year's paper arXiv:2212.02968 since the competition's datasets does not change. We restate the dataset description to avoid it. We also polish the overall writing ",
    "url": "https://arxiv.org/abs/2311.18341",
    "authors": [
      "Lu Han",
      "Xu-Yang Chen",
      "Han-Jia Ye",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2311.18587",
    "title": "Continuous 16-bit Training: Accelerating 32-bit Pre-Trained Neural  Networks",
    "abstract": " Comments: Not Completed Paper ",
    "url": "https://arxiv.org/abs/2311.18587",
    "authors": [
      "Juyoung Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.18599",
    "title": "Joint Detection Algorithm for Multiple Cognitive Users in Spectrum  Sensing",
    "abstract": " Comments: this https URL ",
    "url": "https://arxiv.org/abs/2311.18599",
    "authors": [
      "Fanfei Meng",
      "Yuxin Wang",
      "Lele Zhang",
      "Yingxin Zhao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.18765",
    "title": "MLLMs-Augmented Visual-Language Representation Learning",
    "abstract": " Title: MLLMs-Augmented Visual-Language Representation Learning ",
    "url": "https://arxiv.org/abs/2311.18765",
    "authors": [
      "Yanqing Liu",
      "Kai Wang",
      "Wenqi Shao",
      "Ping Luo",
      "Yu Qiao",
      "Mike Zheng Shou",
      "Kaipeng Zhang",
      "Yang You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  }
]