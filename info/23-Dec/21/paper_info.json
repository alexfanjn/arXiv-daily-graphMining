[
  {
    "id": "arXiv:2312.12444",
    "title": "What Makes Pre-Trained Visual Representations Successful for Robust  Manipulation?",
    "abstract": "Inspired by the success of transfer learning in computer vision, roboticists have investigated visual pre-training as a means to improve the learning efficiency and generalization ability of policies learned from pixels. To that end, past work has favored large object interaction datasets, such as first-person videos of humans completing diverse tasks, in pursuit of manipulation-relevant features. Although this approach improves the efficiency of policy learning, it remains unclear how reliable these representations are in the presence of distribution shifts that arise commonly in robotic applications. Surprisingly, we find that visual representations designed for manipulation and control tasks do not necessarily generalize under subtle changes in lighting and scene texture or the introduction of distractor objects. To understand what properties do lead to robust representations, we compare the performance of 15 pre-trained vision models under different visual appearances. We find that emergent segmentation ability is a strong predictor of out-of-distribution generalization among ViT models. The rank order induced by this metric is more predictive than metrics that have previously guided generalization research within computer vision and machine learning, such as downstream ImageNet accuracy, in-domain accuracy, or shape-bias as evaluated by cue-conflict performance. We test this finding extensively on a suite of distribution shifts in ten tasks across two simulated manipulation environments. On the ALOHA setup, segmentation score predicts real-world performance after offline training with 50 demonstrations. ",
    "url": "https://arxiv.org/abs/2312.12444",
    "authors": [
      "Kaylee Burns",
      "Zach Witzel",
      "Jubayer Ibn Hamid",
      "Tianhe Yu",
      "Chelsea Finn",
      "Karol Hausman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2312.12450",
    "title": "Can It Edit? Evaluating the Ability of Large Language Models to Follow  Code Editing Instructions",
    "abstract": "A significant amount of research is focused on developing and evaluating large language models for a variety of code synthesis tasks. These include synthesizing code from natural language instructions, synthesizing tests from code, and synthesizing explanations of code. In contrast, the behavior of instructional code editing with LLMs is understudied. These are tasks in which the model is instructed to update a block of code provided in a prompt. The editing instruction may ask for a feature to added or removed, describe a bug and ask for a fix, ask for a different kind of solution, or many other common code editing tasks. We introduce a carefully crafted benchmark of code editing tasks and use it evaluate several cutting edge LLMs. Our evaluation exposes a significant gap between the capabilities of state-of-the-art open and closed models. For example, even GPT-3.5-Turbo is 8.8% better than the best open model at editing code. We also introduce a new, carefully curated, permissively licensed training set of code edits coupled with natural language instructions. Using this training set, we show that we can fine-tune open Code LLMs to significantly improve their code editing capabilities. ",
    "url": "https://arxiv.org/abs/2312.12450",
    "authors": [
      "Federico Cassano",
      "Luisa Li",
      "Akul Sethi",
      "Noah Shinn",
      "Abby Brennan-Jones",
      "Anton Lozhkov",
      "Carolyn Anderson",
      "Arjun Guha"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2312.12459",
    "title": "Prediction of Crash Injury Severity in Florida's Interstate-95",
    "abstract": "Drivers can sustain serious injuries in traffic accidents. In this study, traffic crashes on Florida's Interstate-95 from 2016 to 2021 were gathered, and several classification methods were used to estimate the severity of driver injuries. In the feature selection method, logistic regression was applied. To compare model performances, various model assessment matrices such as accuracy, recall, and area under curve (AUC) were developed. The Adaboost algorithm outperformed the others in terms of recall and AUC. SHAP values were also generated to explain the classification model's results. This analytical study can be used to examine factors that contribute to the severity of driver injuries in crashes. ",
    "url": "https://arxiv.org/abs/2312.12459",
    "authors": [
      "B M Tazbiul Hassan Anik",
      "Md Mobasshir Rashid",
      "Md Jamil Ahsan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.12461",
    "title": "Bird Movement Prediction Using Long Short-Term Memory Networks to  Prevent Bird Strikes with Low Altitude Aircraft",
    "abstract": "The number of collisions between aircraft and birds in the airspace has been increasing at an alarming rate over the past decade due to increasing bird population, air traffic and usage of quieter aircraft. Bird strikes with aircraft are anticipated to increase dramatically when emerging Advanced Air Mobility aircraft start operating in the low altitude airspace where probability of bird strikes is the highest. Not only do such bird strikes can result in human and bird fatalities, but they also cost the aviation industry millions of dollars in damages to aircraft annually. To better understand the causes and effects of bird strikes, research to date has mainly focused on analyzing factors which increase the probability of bird strikes, identifying high risk birds in different locations, predicting the future number of bird strike incidents, and estimating cost of bird strike damages. However, research on bird movement prediction for use in flight planning algorithms to minimize the probability of bird strikes is very limited. To address this gap in research, we implement four different types of Long Short-Term Memory (LSTM) models to predict bird movement latitudes and longitudes. A publicly available data set on the movement of pigeons is utilized to train the models and evaluate their performances. Using the bird flight track predictions, aircraft departures from Cleveland Hopkins airport are simulated to be delayed by varying amounts to avoid potential bird strikes with aircraft during takeoff. Results demonstrate that the LSTM models can predict bird movement with high accuracy, achieving a Mean Absolute Error of less than 100 meters, outperforming linear and nonlinear regression models. Our findings indicate that incorporating bird movement prediction into flight planning can be highly beneficial. ",
    "url": "https://arxiv.org/abs/2312.12461",
    "authors": [
      "Elaheh Sabziyan Varnousfaderani",
      "Syed A. M. Shihab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.12470",
    "title": "Rotated Multi-Scale Interaction Network for Referring Remote Sensing  Image Segmentation",
    "abstract": "Referring Remote Sensing Image Segmentation (RRSIS) is a new challenge that combines computer vision and natural language processing, delineating specific regions in aerial images as described by textual queries. Traditional Referring Image Segmentation (RIS) approaches have been impeded by the complex spatial scales and orientations found in aerial imagery, leading to suboptimal segmentation results. To address these challenges, we introduce the Rotated Multi-Scale Interaction Network (RMSIN), an innovative approach designed for the unique demands of RRSIS. RMSIN incorporates an Intra-scale Interaction Module (IIM) to effectively address the fine-grained detail required at multiple scales and a Cross-scale Interaction Module (CIM) for integrating these details coherently across the network. Furthermore, RMSIN employs an Adaptive Rotated Convolution (ARC) to account for the diverse orientations of objects, a novel contribution that significantly enhances segmentation accuracy. To assess the efficacy of RMSIN, we have curated an expansive dataset comprising 17,402 image-caption-mask triplets, which is unparalleled in terms of scale and variety. This dataset not only presents the model with a wide range of spatial and rotational scenarios but also establishes a stringent benchmark for the RRSIS task, ensuring a rigorous evaluation of performance. Our experimental evaluations demonstrate the exceptional performance of RMSIN, surpassing existing state-of-the-art models by a significant margin. All datasets and code are made available at https://github.com/Lsan2401/RMSIN. ",
    "url": "https://arxiv.org/abs/2312.12470",
    "authors": [
      "Sihan Liu",
      "Yiwei Ma",
      "Xiaoqing Zhang",
      "Haowei Wang",
      "Jiayi Ji",
      "Xiaoshuai Sun",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.12473",
    "title": "A Study on Social Robot Behavior in Group Conversation",
    "abstract": "Recently, research in human-robot interaction began to consider a robot's influence at the group level. Despite the recent growth in research investigating the effects of robots within groups of people, our overall understanding of what happens when robots are placed within groups or teams of people is still limited. This paper investigates several key problems for soci robots that manage conversations in a group setting, where the number of participants is more than two. In a group setting, the conversation dynamics are a lot more complicated than the conventional one-to-one conversation, thus, there are more challenges need to be solved. ",
    "url": "https://arxiv.org/abs/2312.12473",
    "authors": [
      "Tung Nguyen",
      "Eric Nichols",
      "Randy Gomez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.12474",
    "title": "Principled Weight Initialisation for Input-Convex Neural Networks",
    "abstract": "Input-Convex Neural Networks (ICNNs) are networks that guarantee convexity in their input-output mapping. These networks have been successfully applied for energy-based modelling, optimal transport problems and learning invariances. The convexity of ICNNs is achieved by using non-decreasing convex activation functions and non-negative weights. Because of these peculiarities, previous initialisation strategies, which implicitly assume centred weights, are not effective for ICNNs. By studying signal propagation through layers with non-negative weights, we are able to derive a principled weight initialisation for ICNNs. Concretely, we generalise signal propagation theory by removing the assumption that weights are sampled from a centred distribution. In a set of experiments, we demonstrate that our principled initialisation effectively accelerates learning in ICNNs and leads to better generalisation. Moreover, we find that, in contrast to common belief, ICNNs can be trained without skip-connections when initialised correctly. Finally, we apply ICNNs to a real-world drug discovery task and show that they allow for more effective molecular latent space exploration. ",
    "url": "https://arxiv.org/abs/2312.12474",
    "authors": [
      "Pieter-Jan Hoedt",
      "G\u00fcnter Klambauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.12475",
    "title": "Learning to Reweight for Graph Neural Network",
    "abstract": "Graph Neural Networks (GNNs) show promising results for graph tasks. However, existing GNNs' generalization ability will degrade when there exist distribution shifts between testing and training graph data. The cardinal impetus underlying the severe degeneration is that the GNNs are architected predicated upon the I.I.D assumptions. In such a setting, GNNs are inclined to leverage imperceptible statistical correlations subsisting in the training set to predict, albeit it is a spurious correlation. In this paper, we study the problem of the generalization ability of GNNs in Out-Of-Distribution (OOD) settings. To solve this problem, we propose the Learning to Reweight for Generalizable Graph Neural Network (L2R-GNN) to enhance the generalization ability for achieving satisfactory performance on unseen testing graphs that have different distributions with training graphs. We propose a novel nonlinear graph decorrelation method, which can substantially improve the out-of-distribution generalization ability and compares favorably to previous methods in restraining the over-reduced sample size. The variables of the graph representation are clustered based on the stability of the correlation, and the graph decorrelation method learns weights to remove correlations between the variables of different clusters rather than any two variables. Besides, we interpose an efficacious stochastic algorithm upon bi-level optimization for the L2R-GNN framework, which facilitates simultaneously learning the optimal weights and GNN parameters, and avoids the overfitting problem. Experimental results show that L2R-GNN greatly outperforms baselines on various graph prediction benchmarks under distribution shifts. ",
    "url": "https://arxiv.org/abs/2312.12475",
    "authors": [
      "Zhengyu Chen",
      "Teng Xiao",
      "Kun Kuang",
      "Zheqi Lv",
      "Min Zhang",
      "Jinluan Yang",
      "Chengqiang Lu",
      "Hongxia Yang",
      "Fei Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.12477",
    "title": "Survey on Trustworthy Graph Neural Networks: From A Causal Perspective",
    "abstract": "Graph Neural Networks (GNNs) have emerged as powerful representation learning tools for capturing complex dependencies within diverse graph-structured data. Despite their success in a wide range of graph mining tasks, GNNs have raised serious concerns regarding their trustworthiness, including susceptibility to distribution shift, biases towards certain populations, and lack of explainability. Recently, integrating causal learning techniques into GNNs has sparked numerous ground-breaking studies since most of the trustworthiness issues can be alleviated by capturing the underlying data causality rather than superficial correlations. In this survey, we provide a comprehensive review of recent research efforts on causality-inspired GNNs. Specifically, we first present the key trustworthy risks of existing GNN models through the lens of causality. Moreover, we introduce a taxonomy of Causality-Inspired GNNs (CIGNNs) based on the type of causal learning capability they are equipped with, i.e., causal reasoning and causal representation learning. Besides, we systematically discuss typical methods within each category and demonstrate how they mitigate trustworthiness risks. Finally, we summarize useful resources and discuss several future directions, hoping to shed light on new research opportunities in this emerging field. The representative papers, along with open-source data and codes, are available in https://github.com/usail-hkust/Causality-Inspired-GNNs. ",
    "url": "https://arxiv.org/abs/2312.12477",
    "authors": [
      "Wenzhao Jiang",
      "Hao Liu",
      "Hui Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2312.12484",
    "title": "SkyMask: Attack-agnostic Robust Federated Learning with Fine-grained  Learnable Masks",
    "abstract": "Federated Learning (FL) is becoming a popular paradigm for leveraging distributed data and preserving data privacy. However, due to the distributed characteristic, FL systems are vulnerable to Byzantine attacks that compromised clients attack the global model by uploading malicious model updates. Most existing Byzantine-robust FL systems statistically analyze the weights of whole individual model updates uploaded by clients to defend against Byzantine attacks. With the development of layer-level and parameter-level fine-grained attacks, the attacks' stealthiness and effectiveness have been significantly improved. Due to unawareness or overreaction, the existing model-level defense methods degrade the training efficiency and model performance. To address this problem, we propose SkyMask, a new attack-agnostic robust FL system that leverages fine-grained learnable masks to identify malicious model updates at the parameter-level. Specifically, the FL server applies parameter-level masks to model updates uploaded by clients and trains the masks over a small clean dataset (i.e., root dataset) to learn the subtle difference between benign and malicious model updates in a high-dimension space. Our extensive experiments involve different models on three public datasets under state-of-the-art (SOTA) attacks, where the results show that SkyMask achieves up to 10% higher testing accuracy compared with SOTA defense strategies and successfully defends against attacks with malicious clients of a high fraction up to 80%. In the meantime, the experimental results demonstrate the scalability of our approach and the weak dependence on the data distribution of the root dataset. ",
    "url": "https://arxiv.org/abs/2312.12484",
    "authors": [
      "Peishen Yan",
      "Hao Wang",
      "Tao Song",
      "Yang Hua",
      "Ruhui Ma",
      "Ningxin Hu",
      "Mohammad R. Haghighat",
      "Haibing Guan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.12492",
    "title": "CodeLL: A Lifelong Learning Dataset to Support the Co-Evolution of Data  and Language Models of Code",
    "abstract": "Motivated by recent work on lifelong learning applications for language models (LMs) of code, we introduce CodeLL, a lifelong learning dataset focused on code changes. Our contribution addresses a notable research gap marked by the absence of a long-term temporal dimension in existing code change datasets, limiting their suitability in lifelong learning scenarios. In contrast, our dataset aims to comprehensively capture code changes across the entire release history of open-source software repositories. In this work, we introduce an initial version of CodeLL, comprising 71 machine-learning-based projects mined from Software Heritage. This dataset enables the extraction and in-depth analysis of code changes spanning 2,483 releases at both the method and API levels. CodeLL enables researchers studying the behaviour of LMs in lifelong fine-tuning settings for learning code changes. Additionally, the dataset can help studying data distribution shifts within software repositories and the evolution of API usages over time. ",
    "url": "https://arxiv.org/abs/2312.12492",
    "authors": [
      "Martin Weyssow",
      "Claudio Di Sipio",
      "Davide Di Ruscio",
      "Houari Sahraoui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.12556",
    "title": "Tensor Train Decomposition for Adversarial Attacks on Computer Vision  Models",
    "abstract": "Deep neural networks (DNNs) are widely used today, but they are vulnerable to adversarial attacks. To develop effective methods of defense, it is important to understand the potential weak spots of DNNs. Often attacks are organized taking into account the architecture of models (white-box approach) and based on gradient methods, but for real-world DNNs this approach in most cases is impossible. At the same time, several gradient-free optimization algorithms are used to attack black-box models. However, classical methods are often ineffective in the multidimensional case. To organize black-box attacks for computer vision models, in this work, we propose the use of an optimizer based on the low-rank tensor train (TT) format, which has gained popularity in various practical multidimensional applications in recent years. Combined with the attribution of the target image, which is built by the auxiliary (white-box) model, the TT-based optimization method makes it possible to organize an effective black-box attack by small perturbation of pixels in the target image. The superiority of the proposed approach over three popular baselines is demonstrated for five modern DNNs on the ImageNet dataset. ",
    "url": "https://arxiv.org/abs/2312.12556",
    "authors": [
      "Andrei Chertkov",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2312.12573",
    "title": "SoK: Security of Cross-chain Bridges: Attack Surfaces, Defenses, and  Open Problems",
    "abstract": "Cross-chain bridges are used to facilitate token and data exchanges across blockchains. Although bridges are becoming increasingly popular, they are still in their infancy and have been attacked multiple times recently, causing significant financial loss. Although there are numerous reports online explaining each of the incidents on cross-chain bridges, they are scattered over the Internet, and there is no work that analyzes the security landscape of cross-chain bridges in a holistic manner. To fill the gap, in this paper, we performed a systematic study of cross-chain bridge security issues. First, we summarize the characteristics of existing cross-chain bridges, including their usages, verification mechanisms, communication models, and three categorizations. Based on these characteristics, we identify 12 potential attack vectors that attackers may exploit. Next, we introduce a taxonomy that categorizes cross-chain attacks in the past two years into 10 distinct types, and then provide explanations for each vulnerability type, accompanied by Solidity code examples. We also discuss existing and potential defenses, as well as open questions and future research directions on cross-chain bridges. We believe that this systematization can shed light on designing and implementing cross-chain bridges with higher security and, more importantly, facilitating future research on building a better cross-chain bridge ecosystem. ",
    "url": "https://arxiv.org/abs/2312.12573",
    "authors": [
      "Mengya Zhang",
      "Xiaokuan Zhang",
      "Josh Barbee",
      "Yinqian Zhang",
      "Zhiqiang Lin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.12578",
    "title": "Improving the Expressive Power of Deep Neural Networks through Integral  Activation Transform",
    "abstract": "The impressive expressive power of deep neural networks (DNNs) underlies their widespread applicability. However, while the theoretical capacity of deep architectures is high, the practical expressive power achieved through successful training often falls short. Building on the insights gained from Neural ODEs, which explore the depth of DNNs as a continuous variable, in this work, we generalize the traditional fully connected DNN through the concept of continuous width. In the Generalized Deep Neural Network (GDNN), the traditional notion of neurons in each layer is replaced by a continuous state function. Using the finite rank parameterization of the weight integral kernel, we establish that GDNN can be obtained by employing the Integral Activation Transform (IAT) as activation layers within the traditional DNN framework. The IAT maps the input vector to a function space using some basis functions, followed by nonlinear activation in the function space, and then extracts information through the integration with another collection of basis functions. A specific variant, IAT-ReLU, featuring the ReLU nonlinearity, serves as a smooth generalization of the scalar ReLU activation. Notably, IAT-ReLU exhibits a continuous activation pattern when continuous basis functions are employed, making it smooth and enhancing the trainability of the DNN. Our numerical experiments demonstrate that IAT-ReLU outperforms regular ReLU in terms of trainability and better smoothness. ",
    "url": "https://arxiv.org/abs/2312.12578",
    "authors": [
      "Zezhong Zhang",
      "Feng Bao",
      "Guannan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.12585",
    "title": "BadRL: Sparse Targeted Backdoor Attack Against Reinforcement Learning",
    "abstract": "Backdoor attacks in reinforcement learning (RL) have previously employed intense attack strategies to ensure attack success. However, these methods suffer from high attack costs and increased detectability. In this work, we propose a novel approach, BadRL, which focuses on conducting highly sparse backdoor poisoning efforts during training and testing while maintaining successful attacks. Our algorithm, BadRL, strategically chooses state observations with high attack values to inject triggers during training and testing, thereby reducing the chances of detection. In contrast to the previous methods that utilize sample-agnostic trigger patterns, BadRL dynamically generates distinct trigger patterns based on targeted state observations, thereby enhancing its effectiveness. Theoretical analysis shows that the targeted backdoor attack is always viable and remains stealthy under specific assumptions. Empirical results on various classic RL tasks illustrate that BadRL can substantially degrade the performance of a victim agent with minimal poisoning efforts 0.003% of total training steps) during training and infrequent attacks during testing. ",
    "url": "https://arxiv.org/abs/2312.12585",
    "authors": [
      "Jing Cui",
      "Yufei Han",
      "Yuzhe Ma",
      "Jianbin Jiao",
      "Junge Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.12588",
    "title": "An Empirical study of Unsupervised Neural Machine Translation: analyzing  NMT output, model's behavior and sentences' contribution",
    "abstract": "Unsupervised Neural Machine Translation (UNMT) focuses on improving NMT results under the assumption there is no human translated parallel data, yet little work has been done so far in highlighting its advantages compared to supervised methods and analyzing its output in aspects other than translation accuracy. We focus on three very diverse languages, French, Gujarati, and Kazakh, and train bilingual NMT models, to and from English, with various levels of supervision, in high- and low- resource setups, measure quality of the NMT output and compare the generated sequences' word order and semantic similarity to source and reference sentences. We also use Layer-wise Relevance Propagation to evaluate the source and target sentences' contribution to the result, expanding the findings of previous works to the UNMT paradigm. ",
    "url": "https://arxiv.org/abs/2312.12588",
    "authors": [
      "Isidora Chara Tourni",
      "Derry Wijaya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.12597",
    "title": "Robust Machine Learning by Transforming and Augmenting Imperfect  Training Data",
    "abstract": "Machine Learning (ML) is an expressive framework for turning data into computer programs. Across many problem domains -- both in industry and policy settings -- the types of computer programs needed for accurate prediction or optimal control are difficult to write by hand. On the other hand, collecting instances of desired system behavior may be relatively more feasible. This makes ML broadly appealing, but also induces data sensitivities that often manifest as unexpected failure modes during deployment. In this sense, the training data available tend to be imperfect for the task at hand. This thesis explores several data sensitivities of modern machine learning and how to address them. We begin by discussing how to prevent ML from codifying prior human discrimination measured in the training data, where we take a fair representation learning approach. We then discuss the problem of learning from data containing spurious features, which provide predictive fidelity during training but are unreliable upon deployment. Here we observe that insofar as standard training methods tend to learn such features, this propensity can be leveraged to search for partitions of training data that expose this inconsistency, ultimately promoting learning algorithms invariant to spurious features. Finally, we turn our attention to reinforcement learning from data with insufficient coverage over all possible states and actions. To address the coverage issue, we discuss how causal priors can be used to model the single-step dynamics of the setting where data are collected. This enables a new type of data augmentation where observed trajectories are stitched together to produce new but plausible counterfactual trajectories. ",
    "url": "https://arxiv.org/abs/2312.12597",
    "authors": [
      "Elliot Creager"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.12606",
    "title": "Optimizing Neural Networks with Gradient Lexicase Selection",
    "abstract": "One potential drawback of using aggregated performance measurement in machine learning is that models may learn to accept higher errors on some training cases as compromises for lower errors on others, with the lower errors actually being instances of overfitting. This can lead to both stagnation at local optima and poor generalization. Lexicase selection is an uncompromising method developed in evolutionary computation, which selects models on the basis of sequences of individual training case errors instead of using aggregated metrics such as loss and accuracy. In this paper, we investigate how lexicase selection, in its general form, can be integrated into the context of deep learning to enhance generalization. We propose Gradient Lexicase Selection, an optimization framework that combines gradient descent and lexicase selection in an evolutionary fashion. Our experimental results demonstrate that the proposed method improves the generalization performance of various widely-used deep neural network architectures across three image classification benchmarks. Additionally, qualitative analysis suggests that our method assists networks in learning more diverse representations. Our source code is available on GitHub: https://github.com/ld-ing/gradient-lexicase. ",
    "url": "https://arxiv.org/abs/2312.12606",
    "authors": [
      "Li Ding",
      "Lee Spector"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.12657",
    "title": "The Convex Landscape of Neural Networks: Characterizing Global Optima  and Stationary Points via Lasso Models",
    "abstract": "Due to the non-convex nature of training Deep Neural Network (DNN) models, their effectiveness relies on the use of non-convex optimization heuristics. Traditional methods for training DNNs often require costly empirical methods to produce successful models and do not have a clear theoretical foundation. In this study, we examine the use of convex optimization theory and sparse recovery models to refine the training process of neural networks and provide a better interpretation of their optimal weights. We focus on training two-layer neural networks with piecewise linear activations and demonstrate that they can be formulated as a finite-dimensional convex program. These programs include a regularization term that promotes sparsity, which constitutes a variant of group Lasso. We first utilize semi-infinite programming theory to prove strong duality for finite width neural networks and then we express these architectures equivalently as high dimensional convex sparse recovery models. Remarkably, the worst-case complexity to solve the convex program is polynomial in the number of samples and number of neurons when the rank of the data matrix is bounded, which is the case in convolutional networks. To extend our method to training data of arbitrary rank, we develop a novel polynomial-time approximation scheme based on zonotope subsampling that comes with a guaranteed approximation ratio. We also show that all the stationary of the nonconvex training objective can be characterized as the global optimum of a subsampled convex program. Our convex models can be trained using standard convex solvers without resorting to heuristics or extensive hyper-parameter tuning unlike non-convex methods. Through extensive numerical experiments, we show that convex models can outperform traditional non-convex methods and are not sensitive to optimizer hyperparameters. ",
    "url": "https://arxiv.org/abs/2312.12657",
    "authors": [
      "Tolga Ergen",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.12664",
    "title": "UnionDet: Union-Level Detector Towards Real-Time Human-Object  Interaction Detection",
    "abstract": "Recent advances in deep neural networks have achieved significant progress in detecting individual objects from an image. However, object detection is not sufficient to fully understand a visual scene. Towards a deeper visual understanding, the interactions between objects, especially humans and objects are essential. Most prior works have obtained this information with a bottom-up approach, where the objects are first detected and the interactions are predicted sequentially by pairing the objects. This is a major bottleneck in HOI detection inference time. To tackle this problem, we propose UnionDet, a one-stage meta-architecture for HOI detection powered by a novel union-level detector that eliminates this additional inference stage by directly capturing the region of interaction. Our one-stage detector for human-object interaction shows a significant reduction in interaction prediction time 4x~14x while outperforming state-of-the-art methods on two public datasets: V-COCO and HICO-DET. ",
    "url": "https://arxiv.org/abs/2312.12664",
    "authors": [
      "Bumsoo Kim",
      "Taeho Choi",
      "Jaewoo Kang",
      "Hyunwoo J. Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.12668",
    "title": "Convolutional Channel-wise Competitive Learning for the Forward-Forward  Algorithm",
    "abstract": "The Forward-Forward (FF) Algorithm has been recently proposed to alleviate the issues of backpropagation (BP) commonly used to train deep neural networks. However, its current formulation exhibits limitations such as the generation of negative data, slower convergence, and inadequate performance on complex tasks. In this paper, we take the main ideas of FF and improve them by leveraging channel-wise competitive learning in the context of convolutional neural networks for image classification tasks. A layer-wise loss function is introduced that promotes competitive learning and eliminates the need for negative data construction. To enhance both the learning of compositional features and feature space partitioning, a channel-wise feature separator and extractor block is proposed that complements the competitive learning process. Our method outperforms recent FF-based models on image classification tasks, achieving testing errors of 0.58%, 7.69%, 21.89%, and 48.77% on MNIST, Fashion-MNIST, CIFAR-10 and CIFAR-100 respectively. Our approach bridges the performance gap between FF learning and BP methods, indicating the potential of our proposed approach to learn useful representations in a layer-wise modular fashion, enabling more efficient and flexible learning. ",
    "url": "https://arxiv.org/abs/2312.12668",
    "authors": [
      "Andreas Papachristodoulou",
      "Christos Kyrkou",
      "Stelios Timotheou",
      "Theocharis Theocharides"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.12679",
    "title": "Towards Efficient Verification of Quantized Neural Networks",
    "abstract": "Quantization replaces floating point arithmetic with integer arithmetic in deep neural network models, providing more efficient on-device inference with less power and memory. In this work, we propose a framework for formally verifying properties of quantized neural networks. Our baseline technique is based on integer linear programming which guarantees both soundness and completeness. We then show how efficiency can be improved by utilizing gradient-based heuristic search methods and also bound-propagation techniques. We evaluate our approach on perception networks quantized with PyTorch. Our results show that we can verify quantized networks with better scalability and efficiency than the previous state of the art. ",
    "url": "https://arxiv.org/abs/2312.12679",
    "authors": [
      "Pei Huang",
      "Haoze Wu",
      "Yuting Yang",
      "Ieva Daukantas",
      "Min Wu",
      "Yedi Zhang",
      "Clark Barrett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2312.12687",
    "title": "A Distributed Solution for Efficient K Shortest Paths Computation over  Dynamic Road Networks",
    "abstract": "The problem of identifying the k-shortest paths KSPs for short in a dynamic road network is essential to many location-based services. Road networks are dynamic in the sense that the weights of the edges in the corresponding graph constantly change over time, representing evolving traffic conditions. Very often such services have to process numerous KSP queries over large road networks at the same time, thus there is a pressing need to identify distributed solutions for this problem. However, most existing approaches are designed to identify KSPs on a static graph in a sequential manner, restricting their scalability and applicability in a distributed setting. We therefore propose KSP-DG, a distributed algorithm for identifying k-shortest paths in a dynamic graph. It is based on partitioning the entire graph into smaller subgraphs, and reduces the problem of determining KSPs into the computation of partial KSPs in relevant subgraphs, which can execute in parallel on a cluster of servers. A distributed two-level index called DTLP is developed to facilitate the efficient identification of relevant subgraphs. A salient feature of DTLP is that it indexes a set of virtual paths that are insensitive to varying traffic conditions in an efficient and compact fashion, leading to very low maintenance cost in dynamic road networks. This is the first treatment of the problem of processing KSP queries over dynamic road networks. Extensive experiments conducted on real road networks confirm the superiority of our proposal over baseline methods. ",
    "url": "https://arxiv.org/abs/2312.12687",
    "authors": [
      "Ziqiang Yu",
      "Xiaohui Yu",
      "Nick Koudas",
      "Yueting Chen",
      "Yang Liu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2312.12688",
    "title": "ODIN: Object Density Aware Index for CkNN Queries over Moving Objects on  Road Networks",
    "abstract": "We study the problem of processing continuous k nearest neighbor (CkNN) queries over moving objects on road networks, which is an essential operation in a variety of applications. We are particularly concerned with scenarios where the object densities in different parts of the road network evolve over time as the objects move. Existing methods on CkNN query processing are ill-suited for such scenarios as they utilize index structures with fixed granularities and are thus unable to keep up with the evolving object densities. In this paper, we directly address this problem and propose an object density aware index structure called ODIN that is an elastic tree built on a hierarchical partitioning of the road network. It is equipped with the unique capability of dynamically folding/unfolding its nodes, thereby adapting to varying object densities. We further present the ODIN-KNN-Init and ODIN-KNN-Inc algorithms for the initial identification of the kNNs and the incremental update of query result as objects move. Thorough experiments on both real and synthetic datasets confirm the superiority of our proposal over several baseline methods. ",
    "url": "https://arxiv.org/abs/2312.12688",
    "authors": [
      "Ziqiang Yu",
      "Xiaohui Yu",
      "Tao Zhou",
      "Yueting Chen",
      "Yang Liu",
      "Bohan Li"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2312.12697",
    "title": "DGCLUSTER: A Neural Framework for Attributed Graph Clustering via  Modularity Maximization",
    "abstract": "Graph clustering is a fundamental and challenging task in the field of graph mining where the objective is to group the nodes into clusters taking into consideration the topology of the graph. It has several applications in diverse domains spanning social network analysis, recommender systems, computer vision, and bioinformatics. In this work, we propose a novel method, DGCluster, which primarily optimizes the modularity objective using graph neural networks and scales linearly with the graph size. Our method does not require the number of clusters to be specified as a part of the input and can also leverage the availability of auxiliary node level information. We extensively test DGCluster on several real-world datasets of varying sizes, across multiple popular cluster quality metrics. Our approach consistently outperforms the state-of-the-art methods, demonstrating significant performance gains in almost all settings. ",
    "url": "https://arxiv.org/abs/2312.12697",
    "authors": [
      "Aritra Bhowmick",
      "Mert Kosan",
      "Zexi Huang",
      "Ambuj Singh",
      "Sourav Medya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.12717",
    "title": "DoDo-Code: a Deep Levenshtein Distance Embedding-based Code for IDS  Channel and DNA Storage",
    "abstract": "Recently, DNA storage has emerged as a promising data storage solution, offering significant advantages in storage density, maintenance cost efficiency, and parallel replication capability. Mathematically, the DNA storage pipeline can be viewed as an insertion, deletion, and substitution (IDS) channel. Because of the mathematical terra incognita of the Levenshtein distance, designing an IDS-correcting code is still a challenge. In this paper, we propose an innovative approach that utilizes deep Levenshtein distance embedding to bypass these mathematical challenges. By representing the Levenshtein distance between two sequences as a conventional distance between their corresponding embedding vectors, the inherent structural property of Levenshtein distance is revealed in the friendly embedding space. Leveraging this embedding space, we introduce the DoDo-Code, an IDS-correcting code that incorporates deep embedding of Levenshtein distance, deep embedding-based codeword search, and deep embedding-based segment correcting. To address the requirements of DNA storage, we also present a preliminary algorithm for long sequence decoding. As far as we know, the DoDo-Code is the first IDS-correcting code designed using plausible deep learning methodologies, potentially paving the way for a new direction in error-correcting code research. It is also the first IDS code that exhibits characteristics of being `optimal' in terms of redundancy, significantly outperforming the mainstream IDS-correcting codes of the Varshamov-Tenengolts code family in code rate. ",
    "url": "https://arxiv.org/abs/2312.12717",
    "authors": [
      "Alan J.X. Guo",
      "Sihan Sun",
      "Xiang Wei",
      "Mengyi Wei",
      "Xin Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.12723",
    "title": "Multi-Clue Reasoning with Memory Augmentation for Knowledge-based Visual  Question Answering",
    "abstract": "Visual Question Answering (VQA) has emerged as one of the most challenging tasks in artificial intelligence due to its multi-modal nature. However, most existing VQA methods are incapable of handling Knowledge-based Visual Question Answering (KB-VQA), which requires external knowledge beyond visible contents to answer questions about a given image. To address this issue, we propose a novel framework that endows the model with capabilities of answering more general questions, and achieves a better exploitation of external knowledge through generating Multiple Clues for Reasoning with Memory Neural Networks (MCR-MemNN). Specifically, a well-defined detector is adopted to predict image-question related relation phrases, each of which delivers two complementary clues to retrieve the supporting facts from external knowledge base (KB), which are further encoded into a continuous embedding space using a content-addressable memory. Afterwards, mutual interactions between visual-semantic representation and the supporting facts stored in memory are captured to distill the most relevant information in three modalities (i.e., image, question, and KB). Finally, the optimal answer is predicted by choosing the supporting fact with the highest score. We conduct extensive experiments on two widely-used benchmarks. The experimental results well justify the effectiveness of MCR-MemNN, as well as its superiority over other KB-VQA methods. ",
    "url": "https://arxiv.org/abs/2312.12723",
    "authors": [
      "Chengxiang Yin",
      "Zhengping Che",
      "Kun Wu",
      "Zhiyuan Xu",
      "Jian Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.12724",
    "title": "Progressive Poisoned Data Isolation for Training-time Backdoor Defense",
    "abstract": "Deep Neural Networks (DNN) are susceptible to backdoor attacks where malicious attackers manipulate the model's predictions via data poisoning. It is hence imperative to develop a strategy for training a clean model using a potentially poisoned dataset. Previous training-time defense mechanisms typically employ an one-time isolation process, often leading to suboptimal isolation outcomes. In this study, we present a novel and efficacious defense method, termed Progressive Isolation of Poisoned Data (PIPD), that progressively isolates poisoned data to enhance the isolation accuracy and mitigate the risk of benign samples being misclassified as poisoned ones. Once the poisoned portion of the dataset has been identified, we introduce a selective training process to train a clean model. Through the implementation of these techniques, we ensure that the trained model manifests a significantly diminished attack success rate against the poisoned data. Extensive experiments on multiple benchmark datasets and DNN models, assessed against nine state-of-the-art backdoor attacks, demonstrate the superior performance of our PIPD method for backdoor defense. For instance, our PIPD achieves an average True Positive Rate (TPR) of 99.95% and an average False Positive Rate (FPR) of 0.06% for diverse attacks over CIFAR-10 dataset, markedly surpassing the performance of state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2312.12724",
    "authors": [
      "Yiming Chen",
      "Haiwei Wu",
      "Jiantao Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.12731",
    "title": "Robustly Improving Bandit Algorithms with Confounded and Selection  Biased Offline Data: A Causal Approach",
    "abstract": "This paper studies bandit problems where an agent has access to offline data that might be utilized to potentially improve the estimation of each arm's reward distribution. A major obstacle in this setting is the existence of compound biases from the observational data. Ignoring these biases and blindly fitting a model with the biased data could even negatively affect the online learning phase. In this work, we formulate this problem from a causal perspective. First, we categorize the biases into confounding bias and selection bias based on the causal structure they imply. Next, we extract the causal bound for each arm that is robust towards compound biases from biased observational data. The derived bounds contain the ground truth mean reward and can effectively guide the bandit agent to learn a nearly-optimal decision policy. We also conduct regret analysis in both contextual and non-contextual bandit settings and show that prior causal bounds could help consistently reduce the asymptotic regret. ",
    "url": "https://arxiv.org/abs/2312.12731",
    "authors": [
      "Wen Huang",
      "Xintao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.12735",
    "title": "MetaSegNet: Metadata-collaborative Vision-Language Representation  Learning for Semantic Segmentation of Remote Sensing Images",
    "abstract": "Semantic segmentation of remote sensing images plays a vital role in a wide range of Earth Observation (EO) applications, such as land use land cover mapping, environment monitoring, and sustainable development. Driven by rapid developments in Artificial Intelligence (AI), deep learning (DL) has emerged as the mainstream tool for semantic segmentation and achieved many breakthroughs in the field of remote sensing. However, the existing DL-based methods mainly focus on unimodal visual data while ignoring the rich multimodal information involved in the real world, usually demonstrating weak reliability and generlization. Inspired by the success of Vision Transformers and large language models, we propose a novel metadata-collaborative multimodal segmentation network (MetaSegNet) that applies vision-language representation learning for semantic segmentation of remote sensing images. Unlike the common model structure that only uses unimodal visual data, we extract the key characteristic (i.e. the climate zone) from freely available remote sensing image metadata and transfer it into knowledge-based text prompts via the generic ChatGPT. Then, we construct an image encoder, a text encoder and a crossmodal attention fusion subnetwork to extract the image and text feature and apply image-text interaction. Benefiting from such a design, the proposed MetaSegNet demonstrates superior generalization and achieves competitive accuracy with state-of-the-art semantic segmentation methods on the large-scale OpenEarthMap dataset (68.6% mIoU) and Potsdam dataset (93.3% mean F1 score) as well as LoveDA dataset (52.2% mIoU). ",
    "url": "https://arxiv.org/abs/2312.12735",
    "authors": [
      "Libo Wang",
      "Sijun Dong",
      "Ying Chen",
      "Xiaoliang Meng",
      "Shenghui Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.12748",
    "title": "Emergence of Fairness Behavior Driven by Reputation-Based Voluntary  Participation in Evolutionary Dictator Games",
    "abstract": "Recently, reputation-based indirect reciprocity has been widely applied to the study on fairness behavior. Previous works mainly investigate indirect reciprocity by considering compulsory participation. While in reality, individuals may choose voluntary participation according to the opponent's reputation. It is still unclear how such reputation-based voluntary participation influences the evolution of fairness. To address this question, we introduce indirect reciprocity with voluntary participation into the dictator game (DG). We respectively consider good dictators or recipients can voluntarily participate in games when the opponents are assessed as bad. We theoretically calculate the fairness level under all social norms of third-order information. Our findings reveal that several social norms induce the high fairness level in both scenarios. However, more social norms lead to a high fairness level for voluntary participation of recipients, compared with the one of good dictators. The results also hold when the probability of voluntary participation is not low. Our results demonstrate that recipients' voluntary participation is more effective in promoting the emergence of fairness behavior. ",
    "url": "https://arxiv.org/abs/2312.12748",
    "authors": [
      "Yanling Zhang",
      "Yin Li",
      "Xiaojie Chen",
      "Guangming Xie"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2312.12768",
    "title": "Mutual-modality Adversarial Attack with Semantic Perturbation",
    "abstract": "Adversarial attacks constitute a notable threat to machine learning systems, given their potential to induce erroneous predictions and classifications. However, within real-world contexts, the essential specifics of the deployed model are frequently treated as a black box, consequently mitigating the vulnerability to such attacks. Thus, enhancing the transferability of the adversarial samples has become a crucial area of research, which heavily relies on selecting appropriate surrogate models. To address this challenge, we propose a novel approach that generates adversarial attacks in a mutual-modality optimization scheme. Our approach is accomplished by leveraging the pre-trained CLIP model. Firstly, we conduct a visual attack on the clean image that causes semantic perturbations on the aligned embedding space with the other textual modality. Then, we apply the corresponding defense on the textual modality by updating the prompts, which forces the re-matching on the perturbed embedding space. Finally, to enhance the attack transferability, we utilize the iterative training strategy on the visual attack and the textual defense, where the two processes optimize from each other. We evaluate our approach on several benchmark datasets and demonstrate that our mutual-modal attack strategy can effectively produce high-transferable attacks, which are stable regardless of the target networks. Our approach outperforms state-of-the-art attack methods and can be readily deployed as a plug-and-play solution. ",
    "url": "https://arxiv.org/abs/2312.12768",
    "authors": [
      "Jingwen Ye",
      "Ruonan Yu",
      "Songhua Liu",
      "Xinchao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.12781",
    "title": "DynaLay: An Introspective Approach to Dynamic Layer Selection for Deep  Networks",
    "abstract": "Deep learning models have become increasingly computationally intensive, requiring extensive computational resources and time for both training and inference. A significant contributing factor to this challenge is the uniform computational effort expended on each input example, regardless of its complexity. We introduce \\textbf{DynaLay}, an alternative architecture that features a decision-making agent to adaptively select the most suitable layers for processing each input, thereby endowing the model with a remarkable level of introspection. DynaLay reevaluates more complex inputs during inference, adjusting the computational effort to optimize both performance and efficiency. The core of the system is a main model equipped with Fixed-Point Iterative (FPI) layers, capable of accurately approximating complex functions, paired with an agent that chooses these layers or a direct action based on the introspection of the models inner state. The model invests more time in processing harder examples, while minimal computation is required for easier ones. This introspective approach is a step toward developing deep learning models that \"think\" and \"ponder\", rather than \"ballistically'' produce answers. Our experiments demonstrate that DynaLay achieves accuracy comparable to conventional deep models while significantly reducing computational demands. ",
    "url": "https://arxiv.org/abs/2312.12781",
    "authors": [
      "Mrinal Mathur",
      "Sergey Plis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.12784",
    "title": "Fast Cell Library Characterization for Design Technology Co-Optimization  Based on Graph Neural Networks",
    "abstract": "Design technology co-optimization (DTCO) plays a critical role in achieving optimal power, performance, and area (PPA) for advanced semiconductor process development. Cell library characterization is essential in DTCO flow, but traditional methods are time-consuming and costly. To overcome these challenges, we propose a graph neural network (GNN)-based machine learning model for rapid and accurate cell library characterization. Our model incorporates cell structures and demonstrates high prediction accuracy across various process-voltage-temperature (PVT) corners and technology parameters. Validation with 512 unseen technology corners and over one million test data points shows accurate predictions of delay, power, and input pin capacitance for 33 types of cells, with a mean absolute percentage error (MAPE) $\\le$ 0.95% and a speed-up of 100X compared with SPICE simulations. Additionally, we investigate system-level metrics such as worst negative slack (WNS), leakage power, and dynamic power using predictions obtained from the GNN-based model on unseen corners. Our model achieves precise predictions, with absolute error $\\le$3.0 ps for WNS, percentage errors $\\le$0.60% for leakage power, and $\\le$0.99% for dynamic power, when compared to golden reference. With the developed model, we further proposed a fine-grained drive strength interpolation methodology to enhance PPA for small-to-medium-scale designs, resulting in an approximate 1-3% improvement. ",
    "url": "https://arxiv.org/abs/2312.12784",
    "authors": [
      "Tianliang Ma",
      "Zhihui Deng",
      "Xuguang Sun",
      "Leilai Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.12791",
    "title": "Model-Based Control with Sparse Neural Dynamics",
    "abstract": "Learning predictive models from observations using deep neural networks (DNNs) is a promising new approach to many real-world planning and control problems. However, common DNNs are too unstructured for effective planning, and current control methods typically rely on extensive sampling or local gradient descent. In this paper, we propose a new framework for integrated model learning and predictive control that is amenable to efficient optimization algorithms. Specifically, we start with a ReLU neural model of the system dynamics and, with minimal losses in prediction accuracy, we gradually sparsify it by removing redundant neurons. This discrete sparsification process is approximated as a continuous problem, enabling an end-to-end optimization of both the model architecture and the weight parameters. The sparsified model is subsequently used by a mixed-integer predictive controller, which represents the neuron activations as binary variables and employs efficient branch-and-bound algorithms. Our framework is applicable to a wide variety of DNNs, from simple multilayer perceptrons to complex graph neural dynamics. It can efficiently handle tasks involving complicated contact dynamics, such as object pushing, compositional object sorting, and manipulation of deformable objects. Numerical and hardware experiments show that, despite the aggressive sparsification, our framework can deliver better closed-loop performance than existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2312.12791",
    "authors": [
      "Ziang Liu",
      "Genggeng Zhou",
      "Jeff He",
      "Tobia Marcucci",
      "Li Fei-Fei",
      "Jiajun Wu",
      "Yunzhu Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.12804",
    "title": "Multi-stages attention Breast cancer classification based on nonlinear  spiking neural P neurons with autapses",
    "abstract": "Breast cancer(BC) is a prevalent type of malignant tumor in women. Early diagnosis and treatment are vital for enhancing the patients' survival rate. Downsampling in deep networks may lead to loss of information, so for compensating the detail and edge information and allowing convolutional neural networks to pay more attention to seek the lesion region, we propose a multi-stages attention architecture based on NSNP neurons with autapses. First, unlike the single-scale attention acquisition methods of existing methods, we set up spatial attention acquisition at each feature map scale of the convolutional network to obtain an fusion global information on attention guidance. Then we introduce a new type of NSNP variants called NSNP neurons with autapses. Specifically, NSNP systems are modularized as feature encoders, recoding the features extracted from convolutional neural network as well as the fusion of attention information and preserve the key characteristic elements in feature maps. This ensures the retention of valuable data while gradually transforming high-dimensional complicated info into low-dimensional ones. The proposed method is evaluated on the public dataset BreakHis at various magnifications and classification tasks. It achieves a classification accuracy of 96.32% at all magnification cases, outperforming state-of-the-art methods. Ablation studies are also performed, verifying the proposed model's efficacy. The source code is available at XhuBobYoung/Breast-cancer-Classification. ",
    "url": "https://arxiv.org/abs/2312.12804",
    "authors": [
      "Bo Yang",
      "Hong Peng",
      "Xiaohui Luo",
      "Jun Wang",
      "Xianzhong Long"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.12813",
    "title": "Selecting Source Code Generation Tools Based on Bandit Algorithms",
    "abstract": "Background: Recently, code generation tools such as ChatGPT have drawn attention to their performance. Generally, a prior analysis of their performance is needed to select new code-generation tools from a list of candidates. Without such analysis, there is a higher risk of selecting an ineffective tool, negatively affecting software development productivity. Additionally, conducting prior analysis of new code generation tools takes time and effort. Aim: To use a new code generation tool without prior analysis but with low risk, we propose to evaluate the new tools during software development (i.e., online optimization). Method: We apply the bandit algorithm (BA) approach to help select the best code-generation tool among candidates. Developers evaluate whether the result of the tool is correct or not. When code generation and evaluation are repeated, the evaluation results are saved. We utilize the stored evaluation results to select the best tool based on the BA approach. Our preliminary analysis evaluated five code generation tools with 164 code generation cases using BA. Result: The BA approach selected ChatGPT as the best tool as the evaluation proceeded, and during the evaluation, the average accuracy by the BA approach outperformed the second-best performing tool. Our results reveal the feasibility and effectiveness of BA in assisting the selection of best-performing code generation tools. ",
    "url": "https://arxiv.org/abs/2312.12813",
    "authors": [
      "Ryoto Shima",
      "Masateru Tsunoda",
      "Yukasa Murakami",
      "Akito Monden",
      "Amjed Tahir",
      "Kwabena Ebo Bennin",
      "Koji Toda",
      "Keitaro Nakasai"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.12832",
    "title": "Turning Dust into Gold: Distilling Complex Reasoning Capabilities from  LLMs by Leveraging Negative Data",
    "abstract": "Large Language Models (LLMs) have performed well on various reasoning tasks, but their inaccessibility and numerous parameters hinder wide application in practice. One promising way is distilling the reasoning ability from LLMs to small models by the generated chain-of-thought reasoning paths. In some cases, however, LLMs may produce incorrect reasoning chains, especially when facing complex mathematical problems. Previous studies only transfer knowledge from positive samples and drop the synthesized data with wrong answers. In this work, we illustrate the merit of negative data and propose a model specialization framework to distill LLMs with negative samples besides positive ones. The framework consists of three progressive steps, covering from training to inference stages, to absorb knowledge from negative data. We conduct extensive experiments across arithmetic reasoning tasks to demonstrate the role of negative data in distillation from LLM. ",
    "url": "https://arxiv.org/abs/2312.12832",
    "authors": [
      "Yiwei Li",
      "Peiwen Yuan",
      "Shaoxiong Feng",
      "Boyuan Pan",
      "Bin Sun",
      "Xinglin Wang",
      "Heda Wang",
      "Kan Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.12838",
    "title": "FedA3I: Annotation Quality-Aware Aggregation for Federated Medical Image  Segmentation Against Heterogeneous Annotation Noise",
    "abstract": "Federated learning (FL) has emerged as a promising paradigm for training segmentation models on decentralized medical data, owing to its privacy-preserving property. However, existing research overlooks the prevalent annotation noise encountered in real-world medical datasets, which limits the performance ceilings of FL. In this paper, we, for the first time, identify and tackle this problem. For problem formulation, we propose a contour evolution for modeling non-independent and identically distributed (Non-IID) noise across pixels within each client and then extend it to the case of multi-source data to form a heterogeneous noise model (\\textit{i.e.}, Non-IID annotation noise across clients). For robust learning from annotations with such two-level Non-IID noise, we emphasize the importance of data quality in model aggregation, allowing high-quality clients to have a greater impact on FL. To achieve this, we propose \\textbf{Fed}erated learning with \\textbf{A}nnotation qu\\textbf{A}lity-aware \\textbf{A}ggregat\\textbf{I}on, named \\textbf{FedA$^3$I}, by introducing a quality factor based on client-wise noise estimation. Specifically, noise estimation at each client is accomplished through the Gaussian mixture model and then incorporated into model aggregation in a layer-wise manner to up-weight high-quality clients. Extensive experiments on two real-world medical image segmentation datasets demonstrate the superior performance of FedA$^3$I against the state-of-the-art approaches in dealing with cross-client annotation noise. The code is available at \\color{blue}{https://github.com/wnn2000/FedAAAI}. ",
    "url": "https://arxiv.org/abs/2312.12838",
    "authors": [
      "Nannan Wu",
      "Zhaobin Sun",
      "Zengqiang Yan",
      "Li Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.12844",
    "title": "Causal Discovery under Identifiable Heteroscedastic Noise Model",
    "abstract": "Capturing the underlying structural causal relations represented by Directed Acyclic Graphs (DAGs) has been a fundamental task in various AI disciplines. Causal DAG learning via the continuous optimization framework has recently achieved promising performance in terms of both accuracy and efficiency. However, most methods make strong assumptions of homoscedastic noise, i.e., exogenous noises have equal variances across variables, observations, or even both. The noises in real data usually violate both assumptions due to the biases introduced by different data collection processes. To address the issue of heteroscedastic noise, we introduce relaxed and implementable sufficient conditions, proving the identifiability of a general class of SEM subject to these conditions. Based on the identifiable general SEM, we propose a novel formulation for DAG learning that accounts for the variation in noise variance across variables and observations. We then propose an effective two-phase iterative DAG learning algorithm to address the increasing optimization difficulties and to learn a causal DAG from data with heteroscedastic variable noise under varying variance. We show significant empirical gains of the proposed approaches over state-of-the-art methods on both synthetic data and real data. ",
    "url": "https://arxiv.org/abs/2312.12844",
    "authors": [
      "Naiyu Yin",
      "Tian Gao",
      "Yue Yu",
      "Qiang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2312.12867",
    "title": "Dynamic Fairness-Aware Spectrum Auction for Enhanced Licensed Shared  Access in 6G Networks",
    "abstract": "This article introduces a new approach to address the spectrum scarcity challenge in 6G networks by implementing the enhanced licensed shared access (ELSA) framework. Our proposed auction mechanism aims to ensure fairness in spectrum allocation to mobile network operators (MNOs) through a novel weighted auction called the fair Vickery-Clarke-Groves (FVCG) mechanism. Through comparison with traditional methods, the study demonstrates that the proposed auction method improves fairness significantly. We suggest using spectrum sensing and integrating UAV-based networks to enhance efficiency of the LSA system. This research employs two methods to solve the problem. We first propose a novel greedy algorithm, named market share based weighted greedy algorithm (MSWGA) to achieve better fairness compared to the traditional auction methods and as the second approach, we exploit deep reinforcement learning (DRL) algorithms, to optimize the auction policy and demonstrate its superiority over other methods. Simulation results show that the deep deterministic policy gradient (DDPG) method performs superior to soft actor critic (SAC), MSWGA, and greedy methods. Moreover, a significant improvement is observed in fairness index compared to the traditional greedy auction methods. This improvement is as high as about 27% and 35% when deploying the MSWGA and DDPG methods, respectively. ",
    "url": "https://arxiv.org/abs/2312.12867",
    "authors": [
      "Mina Khadem",
      "Maryam Ansarifard",
      "Nader Mokari",
      "Mohammadreza Javan",
      "Hamid Saeedi",
      "Eduard A. Jorswieck"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2312.12874",
    "title": "Deep-Unfolding-Based Joint Activity and Data Detection for Grant-Free  Transmission in Cell-Free Communication Systems",
    "abstract": "Massive grant-free transmission and cell-free wireless communication systems have emerged as pivotal enablers for massive machine-type communication. This paper proposes a deep-unfolding-based joint activity and data detection (DU-JAD) algorithm for massive grant-free transmission in cell-free systems. We first formulate a joint activity and data detection optimization problem, which we solve approximately using forward-backward splitting (FBS). We then apply deep unfolding to FBS to optimize algorithm parameters using machine learning. In order to improve data detection (DD) performance, reduce algorithm complexity, and enhance active user detection (AUD), we employ a momentum strategy, an approximate posterior mean estimator, and a novel soft-output AUD module, respectively. Simulation results confirm the efficacy of DU-JAD for AUD and DD. ",
    "url": "https://arxiv.org/abs/2312.12874",
    "authors": [
      "Gangle Sun",
      "Wenjin Wang",
      "Wei Xu",
      "Christoph Studer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.12877",
    "title": "Relightable and Animatable Neural Avatars from Videos",
    "abstract": "Lightweight creation of 3D digital avatars is a highly desirable but challenging task. With only sparse videos of a person under unknown illumination, we propose a method to create relightable and animatable neural avatars, which can be used to synthesize photorealistic images of humans under novel viewpoints, body poses, and lighting. The key challenge here is to disentangle the geometry, material of the clothed body, and lighting, which becomes more difficult due to the complex geometry and shadow changes caused by body motions. To solve this ill-posed problem, we propose novel techniques to better model the geometry and shadow changes. For geometry change modeling, we propose an invertible deformation field, which helps to solve the inverse skinning problem and leads to better geometry quality. To model the spatial and temporal varying shading cues, we propose a pose-aware part-wise light visibility network to estimate light occlusion. Extensive experiments on synthetic and real datasets show that our approach reconstructs high-quality geometry and generates realistic shadows under different body poses. Code and data are available at \\url{https://wenbin-lin.github.io/RelightableAvatar-page/}. ",
    "url": "https://arxiv.org/abs/2312.12877",
    "authors": [
      "Wenbin Lin",
      "Chengwei Zheng",
      "Jun-Hai Yong",
      "Feng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.12878",
    "title": "Rule-Extraction Methods From Feedforward Neural Networks: A Systematic  Literature Review",
    "abstract": "Motivated by the interpretability question in ML models as a crucial element for the successful deployment of AI systems, this paper focuses on rule extraction as a means for neural networks interpretability. Through a systematic literature review, different approaches for extracting rules from feedforward neural networks, an important block in deep learning models, are identified and explored. The findings reveal a range of methods developed for over two decades, mostly suitable for shallow neural networks, with recent developments to meet deep learning models' challenges. Rules offer a transparent and intuitive means of explaining neural networks, making this study a comprehensive introduction for researchers interested in the field. While the study specifically addresses feedforward networks with supervised learning and crisp rules, future work can extend to other network types, machine learning methods, and fuzzy rule extraction. ",
    "url": "https://arxiv.org/abs/2312.12878",
    "authors": [
      "Sara El Mekkaoui",
      "Loubna Benabbou",
      "Abdelaziz Berrado"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.12904",
    "title": "PGN: A perturbation generation network against deep reinforcement  learning",
    "abstract": "Deep reinforcement learning has advanced greatly and applied in many areas. In this paper, we explore the vulnerability of deep reinforcement learning by proposing a novel generative model for creating effective adversarial examples to attack the agent. Our proposed model can achieve both targeted attacks and untargeted attacks. Considering the specificity of deep reinforcement learning, we propose the action consistency ratio as a measure of stealthiness, and a new measurement index of effectiveness and stealthiness. Experiment results show that our method can ensure the effectiveness and stealthiness of attack compared with other algorithms. Moreover, our methods are considerably faster and thus can achieve rapid and efficient verification of the vulnerability of deep reinforcement learning. ",
    "url": "https://arxiv.org/abs/2312.12904",
    "authors": [
      "Xiangjuan Li",
      "Feifan Li",
      "Yang Li",
      "Quan Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.12913",
    "title": "Produce Once, Utilize Twice for Anomaly Detection",
    "abstract": "Visual anomaly detection aims at classifying and locating the regions that deviate from the normal appearance. Embedding-based methods and reconstruction-based methods are two main approaches for this task. However, they are either not efficient or not precise enough for the industrial detection. To deal with this problem, we derive POUTA (Produce Once Utilize Twice for Anomaly detection), which improves both the accuracy and efficiency by reusing the discriminant information potential in the reconstructive network. We observe that the encoder and decoder representations of the reconstructive network are able to stand for the features of the original and reconstructed image respectively. And the discrepancies between the symmetric reconstructive representations provides roughly accurate anomaly information. To refine this information, a coarse-to-fine process is proposed in POUTA, which calibrates the semantics of each discriminative layer by the high-level representations and supervision loss. Equipped with the above modules, POUTA is endowed with the ability to provide a more precise anomaly location than the prior arts. Besides, the representation reusage also enables to exclude the feature extraction process in the discriminative network, which reduces the parameters and improves the efficiency. Extensive experiments show that, POUTA is superior or comparable to the prior methods with even less cost. Furthermore, POUTA also achieves better performance than the state-of-the-art few-shot anomaly detection methods without any special design, showing that POUTA has strong ability to learn representations inherent in the training data. ",
    "url": "https://arxiv.org/abs/2312.12913",
    "authors": [
      "Shuyuan Wang",
      "Qi Li",
      "Huiyuan Luo",
      "Chengkan Lv",
      "Zhengtao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.12918",
    "title": "Assaying on the Robustness of Zero-Shot Machine-Generated Text Detectors",
    "abstract": "To combat the potential misuse of Natural Language Generation (NLG) technology, a variety of algorithms have been developed for the detection of AI-generated texts. Traditionally, this task is treated as a binary classification problem. Although supervised learning has demonstrated promising results, acquiring labeled data for detection purposes poses real-world challenges and the risk of overfitting. In an effort to address these issues, we delve into the realm of zero-shot machine-generated text detection. Existing zero-shot detectors, typically designed for specific tasks or topics, often assume uniform testing scenarios, limiting their practicality. In our research, we explore various advanced Large Language Models (LLMs) and their specialized variants, contributing to this field in several ways. In empirical studies, we uncover a significant correlation between topics and detection performance. Secondly, we delve into the influence of topic shifts on zero-shot detectors. These investigations shed light on the adaptability and robustness of these detection methods across diverse topics. ",
    "url": "https://arxiv.org/abs/2312.12918",
    "authors": [
      "Yi-Fan Zhang",
      "Zhang Zhang",
      "Liang Wang",
      "Rong Jin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.12925",
    "title": "Secure Authentication Mechanism for Cluster based Vehicular Adhoc  Network (VANET): A Survey",
    "abstract": "Vehicular Ad Hoc Networks (VANETs) play a crucial role in Intelligent Transportation Systems (ITS) by facilitating communication between vehicles and infrastructure. This communication aims to enhance road safety, improve traffic efficiency, and enhance passenger comfort. The secure and reliable exchange of information is paramount to ensure the integrity and confidentiality of data, while the authentication of vehicles and messages is essential to prevent unauthorized access and malicious activities. This survey paper presents a comprehensive analysis of existing authentication mechanisms proposed for cluster-based VANETs. The strengths, weaknesses, and suitability of these mechanisms for various scenarios are carefully examined. Additionally, the integration of secure key management techniques is discussed to enhance the overall authentication process. Cluster-based VANETs are formed by dividing the network into smaller groups or clusters, with designated cluster heads comprising one or more vehicles. Furthermore, this paper identifies gaps in the existing literature through an exploration of previous surveys. Several schemes based on different methods are critically evaluated, considering factors such as throughput, detection rate, security, packet delivery ratio, and end-to-end delay. To provide optimal solutions for authentication in cluster-based VANETs, this paper highlights AI- and ML-based routing-based schemes. These approaches leverage artificial intelligence and machine learning techniques to enhance authentication within the cluster-based VANET network. Finally, this paper explores the open research challenges that exist in the realm of authentication for cluster-based Vehicular Adhoc Networks, shedding light on areas that require further investigation and development. ",
    "url": "https://arxiv.org/abs/2312.12925",
    "authors": [
      "Rabia Nasir",
      "Humaira Ashraf",
      "NZ Jhanjhi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.12934",
    "title": "Stability of Graph Convolutional Neural Networks through the lens of  small perturbation analysis",
    "abstract": "In this work, we study the problem of stability of Graph Convolutional Neural Networks (GCNs) under random small perturbations in the underlying graph topology, i.e. under a limited number of insertions or deletions of edges. We derive a novel bound on the expected difference between the outputs of unperturbed and perturbed GCNs. The proposed bound explicitly depends on the magnitude of the perturbation of the eigenpairs of the Laplacian matrix, and the perturbation explicitly depends on which edges are inserted or deleted. Then, we provide a quantitative characterization of the effect of perturbing specific edges on the stability of the network. We leverage tools from small perturbation analysis to express the bounds in closed, albeit approximate, form, in order to enhance interpretability of the results, without the need to compute any perturbed shift operator. Finally, we numerically evaluate the effectiveness of the proposed bound. ",
    "url": "https://arxiv.org/abs/2312.12934",
    "authors": [
      "Lucia Testa",
      "Claudio Battiloro",
      "Stefania Sardellitti",
      "Sergio Barbarossa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.12937",
    "title": "Robust Loss Functions for Training Decision Trees with Noisy Labels",
    "abstract": "We consider training decision trees using noisily labeled data, focusing on loss functions that can lead to robust learning algorithms. Our contributions are threefold. First, we offer novel theoretical insights on the robustness of many existing loss functions in the context of decision tree learning. We show that some of the losses belong to a class of what we call conservative losses, and the conservative losses lead to an early stopping behavior during training and noise-tolerant predictions during testing. Second, we introduce a framework for constructing robust loss functions, called distribution losses. These losses apply percentile-based penalties based on an assumed margin distribution, and they naturally allow adapting to different noise rates via a robustness parameter. In particular, we introduce a new loss called the negative exponential loss, which leads to an efficient greedy impurity-reduction learning algorithm. Lastly, our experiments on multiple datasets and noise settings validate our theoretical insight and the effectiveness of our adaptive negative exponential loss. ",
    "url": "https://arxiv.org/abs/2312.12937",
    "authors": [
      "Jonathan Wilton",
      "Nan Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.12940",
    "title": "On the Energy Consumption of UAV Edge Computing in Non-Terrestrial  Networks",
    "abstract": "During the last few years, the use of Unmanned Aerial Vehicles (UAVs) equipped with sensors and cameras has emerged as a cutting-edge technology to provide services such as surveillance, infrastructure inspections, and target acquisition. However, this approach requires UAVs to process data onboard, mainly for person/object detection and recognition, which may pose significant energy constraints as UAVs are battery-powered. A possible solution can be the support of Non-Terrestrial Networks (NTNs) for edge computing. In particular, UAVs can partially offload data (e.g., video acquisitions from onboard sensors) to more powerful upstream High Altitude Platforms (HAPs) or satellites acting as edge computing servers to increase the battery autonomy compared to local processing, even though at the expense of some data transmission delays. Accordingly, in this study we model the energy consumption of UAVs, HAPs, and satellites considering the energy for data processing, offloading, and hovering. Then, we investigate whether data offloading can improve the system performance. Simulations demonstrate that edge computing can improve both UAV autonomy and end-to-end delay compared to onboard processing in many configurations. ",
    "url": "https://arxiv.org/abs/2312.12940",
    "authors": [
      "Alessandro Traspadini",
      "Marco Giordani",
      "Giovanni Giambene",
      "Tomaso De Cola",
      "Michele Zorzi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2312.12954",
    "title": "TADAP: Trajectory-Aided Drivable area Auto-labeling with Pre-trained  self-supervised features in winter driving conditions",
    "abstract": "Detection of the drivable area in all conditions is crucial for autonomous driving and advanced driver assistance systems. However, the amount of labeled data in adverse driving conditions is limited, especially in winter, and supervised methods generalize poorly to conditions outside the training distribution. For easy adaption to all conditions, the need for human annotation should be removed from the learning process. In this paper, Trajectory-Aided Drivable area Auto-labeling with Pre-trained self-supervised features (TADAP) is presented for automated annotation of the drivable area in winter driving conditions. A sample of the drivable area is extracted based on the trajectory estimate from the global navigation satellite system. Similarity with the sample area is determined based on pre-trained self-supervised visual features. Image areas similar to the sample area are considered to be drivable. These TADAP labels were evaluated with a novel winter-driving dataset, collected in varying driving scenes. A prediction model trained with the TADAP labels achieved a +9.6 improvement in intersection over union compared to the previous state-of-the-art of self-supervised drivable area detection. ",
    "url": "https://arxiv.org/abs/2312.12954",
    "authors": [
      "Eerik Alamikkotervo",
      "Risto Ojala",
      "Alvari Sepp\u00e4nen",
      "Kari Tammi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.13010",
    "title": "AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and  Optimisation",
    "abstract": "The advancement of natural language processing (NLP) has been significantly boosted by the development of transformer-based large language models (LLMs). These models have revolutionized NLP tasks, particularly in code generation, aiding developers in creating software with enhanced efficiency. Despite their advancements, challenges in balancing code snippet generation with effective test case generation and execution persist. To address these issues, this paper introduces Multi-Agent Assistant Code Generation (AgentCoder), a novel solution comprising a multi-agent framework with specialized agents: the programmer agent, the test designer agent, and the test executor agent. During the coding procedure, the programmer agent will focus on the code generation and refinement based on the test executor agent's feedback. The test designer agent will generate test cases for the generated code, and the test executor agent will run the code with the test cases and write the feedback to the programmer. This collaborative system ensures robust code generation, surpassing the limitations of single-agent models and traditional methodologies. Our extensive experiments on 9 code generation models and 12 enhancement approaches showcase AgentCoder's superior performance over existing code generation models and prompt engineering techniques across various benchmarks. For example, AgentCoder achieves 77.4% and 89.1% pass@1 in HumanEval-ET and MBPP-ET with GPT-3.5, while SOTA baselines obtain only 69.5% and 63.0%. ",
    "url": "https://arxiv.org/abs/2312.13010",
    "authors": [
      "Dong Huang",
      "Qingwen Bu",
      "Jie M.Zhang",
      "Michael Luck",
      "Heming Cui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.13032",
    "title": "NodeMixup: Tackling Under-Reaching for Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have become mainstream methods for solving the semi-supervised node classification problem. However, due to the uneven location distribution of labeled nodes in the graph, labeled nodes are only accessible to a small portion of unlabeled nodes, leading to the \\emph{under-reaching} issue. In this study, we firstly reveal under-reaching by conducting an empirical investigation on various well-known graphs. Then, we demonstrate that under-reaching results in unsatisfactory distribution alignment between labeled and unlabeled nodes through systematic experimental analysis, significantly degrading GNNs' performance. To tackle under-reaching for GNNs, we propose an architecture-agnostic method dubbed NodeMixup. The fundamental idea is to (1) increase the reachability of labeled nodes by labeled-unlabeled pairs mixup, (2) leverage graph structures via fusing the neighbor connections of intra-class node pairs to improve performance gains of mixup, and (3) use neighbor label distribution similarity incorporating node degrees to determine sampling weights for node mixup. Extensive experiments demonstrate the efficacy of NodeMixup in assisting GNNs in handling under-reaching. The source code is available at \\url{https://github.com/WeigangLu/NodeMixup}. ",
    "url": "https://arxiv.org/abs/2312.13032",
    "authors": [
      "Weigang Lu",
      "Ziyu Guan",
      "Wei Zhao",
      "Long Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.13041",
    "title": "Advancing SQL Injection Detection for High-Speed Data Centers: A Novel  Approach Using Cascaded NLP",
    "abstract": "Detecting SQL Injection (SQLi) attacks is crucial for web-based data center security, but it is challenging to balance accuracy and computational efficiency, especially in high-speed networks. Traditional methods struggle with this balance, while NLP-based approaches, although accurate, are computationally intensive. We introduce a novel cascade SQLi detection method, blending classical and transformer-based NLP models, achieving a 99.86% detection accuracy with significantly lower computational demands-20 times faster than using transformer-based models alone. Our approach is tested in a realistic setting and compared with 35 other methods, including Machine Learning-based and transformer models like BERT, on a dataset of over 30,000 SQL sentences. Our results show that this hybrid method effectively detects SQLi in high-traffic environments, offering efficient and accurate protection against SQLi vulnerabilities with computational efficiency. The code is available at https://github.com/gdrlab/cascaded-sqli-detection . ",
    "url": "https://arxiv.org/abs/2312.13041",
    "authors": [
      "Kasim Tasdemir",
      "Rafiullah Khan",
      "Fahad Siddiqui",
      "Sakir Sezer",
      "Fatih Kurugollu",
      "Sena Busra Yengec-Tasdemir",
      "Alperen Bolat"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.13066",
    "title": "PPEA-Depth: Progressive Parameter-Efficient Adaptation for  Self-Supervised Monocular Depth Estimation",
    "abstract": "Self-supervised monocular depth estimation is of significant importance with applications spanning across autonomous driving and robotics. However, the reliance on self-supervision introduces a strong static-scene assumption, thereby posing challenges in achieving optimal performance in dynamic scenes, which are prevalent in most real-world situations. To address these issues, we propose PPEA-Depth, a Progressive Parameter-Efficient Adaptation approach to transfer a pre-trained image model for self-supervised depth estimation. The training comprises two sequential stages: an initial phase trained on a dataset primarily composed of static scenes, succeeded by an expansion to more intricate datasets involving dynamic scenes. To facilitate this process, we design compact encoder and decoder adapters to enable parameter-efficient tuning, allowing the network to adapt effectively. They not only uphold generalized patterns from pre-trained image models but also retain knowledge gained from the preceding phase into the subsequent one. Extensive experiments demonstrate that PPEA-Depth achieves state-of-the-art performance on KITTI, CityScapes and DDAD datasets. ",
    "url": "https://arxiv.org/abs/2312.13066",
    "authors": [
      "Yue-Jiang Dong",
      "Yuan-Chen Guo",
      "Ying-Tian Liu",
      "Fang-Lue Zhang",
      "Song-Hai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.13068",
    "title": "Continuous-time Graph Representation with Sequential Survival Process",
    "abstract": "Over the past two decades, there has been a tremendous increase in the growth of representation learning methods for graphs, with numerous applications across various fields, including bioinformatics, chemistry, and the social sciences. However, current dynamic network approaches focus on discrete-time networks or treat links in continuous-time networks as instantaneous events. Therefore, these approaches have limitations in capturing the persistence or absence of links that continuously emerge and disappear over time for particular durations. To address this, we propose a novel stochastic process relying on survival functions to model the durations of links and their absences over time. This forms a generic new likelihood specification explicitly accounting for intermittent edge-persistent networks, namely GraSSP: Graph Representation with Sequential Survival Process. We apply the developed framework to a recent continuous time dynamic latent distance model characterizing network dynamics in terms of a sequence of piecewise linear movements of nodes in latent space. We quantitatively assess the developed framework in various downstream tasks, such as link prediction and network completion, demonstrating that the developed modeling framework accounting for link persistence and absence well tracks the intrinsic trajectories of nodes in a latent space and captures the underlying characteristics of evolving network structure. ",
    "url": "https://arxiv.org/abs/2312.13068",
    "authors": [
      "Abdulkadir Celikkanat",
      "Nikolaos Nakis",
      "Morten M\u00f8rup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2312.13071",
    "title": "Point Deformable Network with Enhanced Normal Embedding for Point Cloud  Analysis",
    "abstract": "Recently MLP-based methods have shown strong performance in point cloud analysis. Simple MLP architectures are able to learn geometric features in local point groups yet fail to model long-range dependencies directly. In this paper, we propose Point Deformable Network (PDNet), a concise MLP-based network that can capture long-range relations with strong representation ability. Specifically, we put forward Point Deformable Aggregation Module (PDAM) to improve representation capability in both long-range dependency and adaptive aggregation among points. For each query point, PDAM aggregates information from deformable reference points rather than points in limited local areas. The deformable reference points are generated data-dependent, and we initialize them according to the input point positions. Additional offsets and modulation scalars are learned on the whole point features, which shift the deformable reference points to the regions of interest. We also suggest estimating the normal vector for point clouds and applying Enhanced Normal Embedding (ENE) to the geometric extractors to improve the representation ability of single-point. Extensive experiments and ablation studies on various benchmarks demonstrate the effectiveness and superiority of our PDNet. ",
    "url": "https://arxiv.org/abs/2312.13071",
    "authors": [
      "Xingyilang Yin",
      "Xi Yang",
      "Liangchen Liu",
      "Nannan Wang",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.13081",
    "title": "BEVSeg2TP: Surround View Camera Bird's-Eye-View Based Joint Vehicle  Segmentation and Ego Vehicle Trajectory Prediction",
    "abstract": "Trajectory prediction is, naturally, a key task for vehicle autonomy. While the number of traffic rules is limited, the combinations and uncertainties associated with each agent's behaviour in real-world scenarios are nearly impossible to encode. Consequently, there is a growing interest in learning-based trajectory prediction. The proposed method in this paper predicts trajectories by considering perception and trajectory prediction as a unified system. In considering them as unified tasks, we show that there is the potential to improve the performance of perception. To achieve these goals, we present BEVSeg2TP - a surround-view camera bird's-eye-view-based joint vehicle segmentation and ego vehicle trajectory prediction system for autonomous vehicles. The proposed system uses a network trained on multiple camera views. The images are transformed using several deep learning techniques to perform semantic segmentation of objects, including other vehicles, in the scene. The segmentation outputs are fused across the camera views to obtain a comprehensive representation of the surrounding vehicles from the bird's-eye-view perspective. The system further predicts the future trajectory of the ego vehicle using a spatiotemporal probabilistic network (STPN) to optimize trajectory prediction. This network leverages information from encoder-decoder transformers and joint vehicle segmentation. ",
    "url": "https://arxiv.org/abs/2312.13081",
    "authors": [
      "Sushil Sharma",
      "Arindam Das",
      "Ganesh Sistu",
      "Mark Halton",
      "Ciar\u00e1n Eising"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.13094",
    "title": "Automated MPI code generation for scalable finite-difference solvers",
    "abstract": "Partial differential equations (PDEs) are crucial in modelling diverse phenomena across scientific disciplines, including seismic and medical imaging, computational fluid dynamics, image processing, and neural networks. Solving these PDEs on a large scale is an intricate and time-intensive process that demands careful tuning. This paper introduces automated code-generation techniques specifically tailored for distributed memory parallelism (DMP) to solve explicit finite-difference (FD) stencils at scale, a fundamental challenge in numerous scientific applications. These techniques are implemented and integrated into the Devito DSL and compiler framework, a well-established solution for automating the generation of FD solvers based on a high-level symbolic math input. Users benefit from modelling simulations at a high-level symbolic abstraction and effortlessly harnessing HPC-ready distributed-memory parallelism without altering their source code. This results in drastic reductions both in execution time and developer effort. While the contributions of this work are implemented and integrated within the Devito framework, the DMP concepts and the techniques applied are generally applicable to any FD solvers. A comprehensive performance evaluation of Devito's DMP via MPI demonstrates highly competitive weak and strong scaling on the Archer2 supercomputer, demonstrating the effectiveness of the proposed approach in meeting the demands of large-scale scientific simulations. ",
    "url": "https://arxiv.org/abs/2312.13094",
    "authors": [
      "George Bisbas",
      "Rhodri Nelson",
      "Mathias Louboutin",
      "Paul H.J. Kelly",
      "Fabio Luporini",
      "Gerard Gorman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Mathematical Software (cs.MS)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2312.13104",
    "title": "Optimizing Ego Vehicle Trajectory Prediction: The Graph Enhancement  Approach",
    "abstract": "Predicting the trajectory of an ego vehicle is a critical component of autonomous driving systems. Current state-of-the-art methods typically rely on Deep Neural Networks (DNNs) and sequential models to process front-view images for future trajectory prediction. However, these approaches often struggle with perspective issues affecting object features in the scene. To address this, we advocate for the use of Bird's Eye View (BEV) perspectives, which offer unique advantages in capturing spatial relationships and object homogeneity. In our work, we leverage Graph Neural Networks (GNNs) and positional encoding to represent objects in a BEV, achieving competitive performance compared to traditional DNN-based methods. While the BEV-based approach loses some detailed information inherent to front-view images, we balance this by enriching the BEV data by representing it as a graph where relationships between the objects in a scene are captured effectively. ",
    "url": "https://arxiv.org/abs/2312.13104",
    "authors": [
      "Sushil Sharma",
      "Aryan Singh",
      "Ganesh Sistu",
      "Mark Halton",
      "Ciar\u00e1n Eising"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.13105",
    "title": "Exploring ChatGPT for Toxicity Detection in GitHub",
    "abstract": "Fostering a collaborative and inclusive environment is crucial for the sustained progress of open source development. However, the prevalence of negative discourse, often manifested as toxic comments, poses significant challenges to developer well-being and productivity. To identify such negativity in project communications, especially within large projects, automated toxicity detection models are necessary. To train these models effectively, we need large software engineering-specific toxicity datasets. However, such datasets are limited in availability and often exhibit imbalance (e.g., only 6 in 1000 GitHub issues are toxic), posing challenges for training effective toxicity detection models. To address this problem, we explore a zero-shot LLM (ChatGPT) that is pre-trained on massive datasets but without being fine-tuned specifically for the task of detecting toxicity in software-related text. Our preliminary evaluation indicates that ChatGPT shows promise in detecting toxicity in GitHub, and warrants further investigation. We experimented with various prompts, including those designed for justifying model outputs, thereby enhancing model interpretability and paving the way for potential integration of ChatGPT-enabled toxicity detection into developer communication channels. ",
    "url": "https://arxiv.org/abs/2312.13105",
    "authors": [
      "Shyamal Mishra",
      "Preetha Chatterjee"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.13116",
    "title": "VSR-Net: Vessel-like Structure Rehabilitation Network with Graph  Clustering",
    "abstract": "The morphologies of vessel-like structures, such as blood vessels and nerve fibres, play significant roles in disease diagnosis, e.g., Parkinson's disease. Deep network-based refinement segmentation methods have recently achieved promising vessel-like structure segmentation results. There are still two challenges: (1) existing methods have limitations in rehabilitating subsection ruptures in segmented vessel-like structures; (2) they are often overconfident in predicted segmentation results. To tackle these two challenges, this paper attempts to leverage the potential of spatial interconnection relationships among subsection ruptures from the structure rehabilitation perspective. Based on this, we propose a novel Vessel-like Structure Rehabilitation Network (VSR-Net) to rehabilitate subsection ruptures and improve the model calibration based on coarse vessel-like structure segmentation results. VSR-Net first constructs subsection rupture clusters with Curvilinear Clustering Module (CCM). Then, the well-designed Curvilinear Merging Module (CMM) is applied to rehabilitate the subsection ruptures to obtain the refined vessel-like structures. Extensive experiments on five 2D/3D medical image datasets show that VSR-Net significantly outperforms state-of-the-art (SOTA) refinement segmentation methods with lower calibration error. Additionally, we provide quantitative analysis to explain the morphological difference between the rehabilitation results of VSR-Net and ground truth (GT), which is smaller than SOTA methods and GT, demonstrating that our method better rehabilitates vessel-like structures by restoring subsection ruptures. ",
    "url": "https://arxiv.org/abs/2312.13116",
    "authors": [
      "Haili Ye",
      "Xiaoqing Zhang",
      "Yan Hu",
      "Huazhu Fu",
      "Jiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.13118",
    "title": "LRS: Enhancing Adversarial Transferability through Lipschitz Regularized  Surrogate",
    "abstract": "The transferability of adversarial examples is of central importance to transfer-based black-box adversarial attacks. Previous works for generating transferable adversarial examples focus on attacking \\emph{given} pretrained surrogate models while the connections between surrogate models and adversarial trasferability have been overlooked. In this paper, we propose {\\em Lipschitz Regularized Surrogate} (LRS) for transfer-based black-box attacks, a novel approach that transforms surrogate models towards favorable adversarial transferability. Using such transformed surrogate models, any existing transfer-based black-box attack can run without any change, yet achieving much better performance. Specifically, we impose Lipschitz regularization on the loss landscape of surrogate models to enable a smoother and more controlled optimization process for generating more transferable adversarial examples. In addition, this paper also sheds light on the connection between the inner properties of surrogate models and adversarial transferability, where three factors are identified: smaller local Lipschitz constant, smoother loss landscape, and stronger adversarial robustness. We evaluate our proposed LRS approach by attacking state-of-the-art standard deep neural networks and defense models. The results demonstrate significant improvement on the attack success rates and transferability. Our code is available at https://github.com/TrustAIoT/LRS. ",
    "url": "https://arxiv.org/abs/2312.13118",
    "authors": [
      "Tao Wu",
      "Tie Luo",
      "Donald C. Wunsch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.13119",
    "title": "Prometheus: Infrastructure Security Posture Analysis with AI-generated  Attack Graphs",
    "abstract": "The rampant occurrence of cybersecurity breaches imposes substantial limitations on the progress of network infrastructures, leading to compromised data, financial losses, potential harm to individuals, and disruptions in essential services. The current security landscape demands the urgent development of a holistic security assessment solution that encompasses vulnerability analysis and investigates the potential exploitation of these vulnerabilities as attack paths. In this paper, we propose Prometheus, an advanced system designed to provide a detailed analysis of the security posture of computing infrastructures. Using user-provided information, such as device details and software versions, Prometheus performs a comprehensive security assessment. This assessment includes identifying associated vulnerabilities and constructing potential attack graphs that adversaries can exploit. Furthermore, Prometheus evaluates the exploitability of these attack paths and quantifies the overall security posture through a scoring mechanism. The system takes a holistic approach by analyzing security layers encompassing hardware, system, network, and cryptography. Furthermore, Prometheus delves into the interconnections between these layers, exploring how vulnerabilities in one layer can be leveraged to exploit vulnerabilities in others. In this paper, we present the end-to-end pipeline implemented in Prometheus, showcasing the systematic approach adopted for conducting this thorough security analysis. ",
    "url": "https://arxiv.org/abs/2312.13119",
    "authors": [
      "Xin Jin",
      "Charalampos Katsis",
      "Fan Sang",
      "Jiahao Sun",
      "Elisa Bertino",
      "Ramana Rao Kompella",
      "Ashish Kundu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.13131",
    "title": "Scaling Compute Is Not All You Need for Adversarial Robustness",
    "abstract": "The last six years have witnessed significant progress in adversarially robust deep learning. As evidenced by the CIFAR-10 dataset category in RobustBench benchmark, the accuracy under $\\ell_\\infty$ adversarial perturbations improved from 44\\% in \\citet{Madry2018Towards} to 71\\% in \\citet{peng2023robust}. Although impressive, existing state-of-the-art is still far from satisfactory. It is further observed that best-performing models are often very large models adversarially trained by industrial labs with significant computational budgets. In this paper, we aim to understand: ``how much longer can computing power drive adversarial robustness advances?\" To answer this question, we derive \\emph{scaling laws for adversarial robustness} which can be extrapolated in the future to provide an estimate of how much cost we would need to pay to reach a desired level of robustness. We show that increasing the FLOPs needed for adversarial training does not bring as much advantage as it does for standard training in terms of performance improvements. Moreover, we find that some of the top-performing techniques are difficult to exactly reproduce, suggesting that they are not robust enough for minor changes in the training setup. Our analysis also uncovers potentially worthwhile directions to pursue in future research. Finally, we make our benchmarking framework (built on top of \\texttt{timm}~\\citep{rw2019timm}) publicly available to facilitate future analysis in efficient robust deep learning. ",
    "url": "https://arxiv.org/abs/2312.13131",
    "authors": [
      "Edoardo Debenedetti",
      "Zishen Wan",
      "Maksym Andriushchenko",
      "Vikash Sehwag",
      "Kshitij Bhardwaj",
      "Bhavya Kailkhura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.13132",
    "title": "On the complexity of sabotage games for network security",
    "abstract": "Securing dynamic networks against adversarial actions is challenging because of the need to anticipate and counter strategic disruptions by adversarial entities within complex network structures. Traditional game-theoretic models, while insightful, often fail to model the unpredictability and constraints of real-world threat assessment scenarios. We refine sabotage games to reflect the realistic limitations of the saboteur and the network operator. By transforming sabotage games into reachability problems, our approach allows applying existing computational solutions to model realistic restrictions on attackers and defenders within the game. Modifying sabotage games into dynamic network security problems successfully captures the nuanced interplay of strategy and uncertainty in dynamic network security. Theoretically, we extend sabotage games to model network security contexts and thoroughly explore if the additional restrictions raise their computational complexity, often the bottleneck of game theory in practical contexts. Practically, this research sets the stage for actionable insights for developing robust defense mechanisms by understanding what risks to mitigate in dynamically changing networks under threat. ",
    "url": "https://arxiv.org/abs/2312.13132",
    "authors": [
      "Dhananjay Raju",
      "Georgios Bakirtzis",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2312.13152",
    "title": "Neural Stochastic Differential Equations with Change Points: A  Generative Adversarial Approach",
    "abstract": "Stochastic differential equations (SDEs) have been widely used to model real world random phenomena. Existing works mainly focus on the case where the time series is modeled by a single SDE, which might be restrictive for modeling time series with distributional shift. In this work, we propose a change point detection algorithm for time series modeled as neural SDEs. Given a time series dataset, the proposed method jointly learns the unknown change points and the parameters of distinct neural SDE models corresponding to each change point. Specifically, the SDEs are learned under the framework of generative adversarial networks (GANs) and the change points are detected based on the output of the GAN discriminator in a forward pass. At each step of the proposed algorithm, the change points and the SDE model parameters are updated in an alternating fashion. Numerical results on both synthetic and real datasets are provided to validate the performance of our algorithm in comparison to classical change point detection benchmarks, standard GAN-based neural SDEs, and other state-of-the-art deep generative models for time series data. ",
    "url": "https://arxiv.org/abs/2312.13152",
    "authors": [
      "Zhongchang Sun",
      "Yousef El-Laham",
      "Svitlana Vyetrenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.13155",
    "title": "Gappy local conformal auto-encoders for heterogeneous data fusion: in  praise of rigidity",
    "abstract": "Fusing measurements from multiple, heterogeneous, partial sources, observing a common object or process, poses challenges due to the increasing availability of numbers and types of sensors. In this work we propose, implement and validate an end-to-end computational pipeline in the form of a multiple-auto-encoder neural network architecture for this task. The inputs to the pipeline are several sets of partial observations, and the result is a globally consistent latent space, harmonizing (rigidifying, fusing) all measurements. The key enabler is the availability of multiple slightly perturbed measurements of each instance:, local measurement, \"bursts\", that allows us to estimate the local distortion induced by each instrument. We demonstrate the approach in a sequence of examples, starting with simple two-dimensional data sets and proceeding to a Wi-Fi localization problem and to the solution of a \"dynamical puzzle\" arising in spatio-temporal observations of the solutions of Partial Differential Equations. ",
    "url": "https://arxiv.org/abs/2312.13155",
    "authors": [
      "Erez Peterfreund",
      "Iryna Burak",
      "Ofir Lindenbaum",
      "Jim Gimlett",
      "Felix Dietrich",
      "Ronald R. Coifman",
      "Ioannis G. Kevrekidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.13175",
    "title": "Nonlinear moving horizon estimation for robust state and parameter  estimation",
    "abstract": "We propose a moving horizon estimation scheme to estimate the states and the unknown constant parameters of general nonlinear uncertain discrete time systems. The proposed framework and analysis explicitly do not involve the a priori verification of a particular excitation condition for the parameters. Instead, we use online information about the actual excitation of the parameters at any time during operation and ensure that the regularization term in the cost function is always automatically selected appropriately. This ensures that the state and parameter estimation error is bounded for all times, even if the parameters are never (or only rarely) excited during operation. Additionally, the more often sufficient excitation is detected, the better (i.e., smaller) the bound becomes. Robust exponential stability of the state and parameter estimation error emerges under an additional uniform condition on the maximum duration of insufficient excitation. The theoretical results are illustrated by a numerical example. ",
    "url": "https://arxiv.org/abs/2312.13175",
    "authors": [
      "Julian D. Schiller",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.13179",
    "title": "Contextual Code Switching for Machine Translation using Language Models",
    "abstract": "Large language models (LLMs) have exerted a considerable impact on diverse language-related tasks in recent years. Their demonstrated state-of-the-art performance is achieved through methodologies such as zero-shot or few-shot prompting. These models undergo training on extensive datasets that encompass segments of the Internet and subsequently undergo fine-tuning tailored to specific tasks. Notably, they exhibit proficiency in tasks such as translation, summarization, question answering, and creative writing, even in the absence of explicit training for those particular tasks. While they have shown substantial improvement in the multilingual tasks their performance in the code switching, especially for machine translation remains relatively uncharted. In this paper, we present an extensive study on the code switching task specifically for the machine translation task comparing multiple LLMs. Our results indicate that despite the LLMs having promising results in the certain tasks, the models with relatively lesser complexity outperform the multilingual large language models in the machine translation task. We posit that the efficacy of multilingual large language models in contextual code switching is constrained by their training methodologies. In contrast, relatively smaller models, when trained and fine-tuned on bespoke datasets, may yield superior results in comparison to the majority of multilingual models. ",
    "url": "https://arxiv.org/abs/2312.13179",
    "authors": [
      "Arshad Kaji",
      "Manan Shah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.13218",
    "title": "FiFAR: A Fraud Detection Dataset for Learning to Defer",
    "abstract": "Public dataset limitations have significantly hindered the development and benchmarking of learning to defer (L2D) algorithms, which aim to optimally combine human and AI capabilities in hybrid decision-making systems. In such systems, human availability and domain-specific concerns introduce difficulties, while obtaining human predictions for training and evaluation is costly. Financial fraud detection is a high-stakes setting where algorithms and human experts often work in tandem; however, there are no publicly available datasets for L2D concerning this important application of human-AI teaming. To fill this gap in L2D research, we introduce the Financial Fraud Alert Review Dataset (FiFAR), a synthetic bank account fraud detection dataset, containing the predictions of a team of 50 highly complex and varied synthetic fraud analysts, with varied bias and feature dependence. We also provide a realistic definition of human work capacity constraints, an aspect of L2D systems that is often overlooked, allowing for extensive testing of assignment systems under real-world conditions. We use our dataset to develop a capacity-aware L2D method and rejection learning approach under realistic data availability conditions, and benchmark these baselines under an array of 300 distinct testing scenarios. We believe that this dataset will serve as a pivotal instrument in facilitating a systematic, rigorous, reproducible, and transparent evaluation and comparison of L2D methods, thereby fostering the development of more synergistic human-AI collaboration in decision-making systems. The public dataset and detailed synthetic expert information are available at: https://github.com/feedzai/fifar-dataset ",
    "url": "https://arxiv.org/abs/2312.13218",
    "authors": [
      "Jean V. Alves",
      "Diogo Leit\u00e3o",
      "S\u00e9rgio Jesus",
      "Marco O. P. Sampaio",
      "Pedro Saleiro",
      "M\u00e1rio A. T. Figueiredo",
      "Pedro Bizarro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.13225",
    "title": "Automated DevOps Pipeline Generation for Code Repositories using Large  Language Models",
    "abstract": "Automating software development processes through the orchestration of GitHub Action workflows has revolutionized the efficiency and agility of software delivery pipelines. This paper presents a detailed investigation into the use of Large Language Models (LLMs) specifically, GPT 3.5 and GPT 4 to generate and evaluate GitHub Action workflows for DevOps tasks. Our methodology involves data collection from public GitHub repositories, prompt engineering for LLM utilization, and evaluation metrics encompassing exact match scores, BLEU scores, and a novel DevOps Aware score. The research scrutinizes the proficiency of GPT 3.5 and GPT 4 in generating GitHub workflows, while assessing the influence of various prompt elements in constructing the most efficient pipeline. Results indicate substantial advancements in GPT 4, particularly in DevOps awareness and syntax correctness. The research introduces a GitHub App built on Probot, empowering users to automate workflow generation within GitHub ecosystem. This study contributes insights into the evolving landscape of AI-driven automation in DevOps practices. ",
    "url": "https://arxiv.org/abs/2312.13225",
    "authors": [
      "Deep Mehta",
      "Kartik Rawool",
      "Subodh Gujar",
      "Bowen Xu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2312.13247",
    "title": "Enhancing Neural Training via a Correlated Dynamics Model",
    "abstract": "As neural networks grow in scale, their training becomes both computationally demanding and rich in dynamics. Amidst the flourishing interest in these training dynamics, we present a novel observation: Parameters during training exhibit intrinsic correlations over time. Capitalizing on this, we introduce Correlation Mode Decomposition (CMD). This algorithm clusters the parameter space into groups, termed modes, that display synchronized behavior across epochs. This enables CMD to efficiently represent the training dynamics of complex networks, like ResNets and Transformers, using only a few modes. Moreover, test set generalization is enhanced. We introduce an efficient CMD variant, designed to run concurrently with training. Our experiments indicate that CMD surpasses the state-of-the-art method for compactly modeled dynamics on image classification. Our modeling can improve training efficiency and lower communication overhead, as shown by our preliminary experiments in the context of federated learning. ",
    "url": "https://arxiv.org/abs/2312.13247",
    "authors": [
      "Jonathan Brokman",
      "Roy Betser",
      "Rotem Turjeman",
      "Tom Berkov",
      "Ido Cohen",
      "Guy Gilboa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2312.13277",
    "title": "Deep Learning on 3D Neural Fields",
    "abstract": "In recent years, Neural Fields (NFs) have emerged as an effective tool for encoding diverse continuous signals such as images, videos, audio, and 3D shapes. When applied to 3D data, NFs offer a solution to the fragmentation and limitations associated with prevalent discrete representations. However, given that NFs are essentially neural networks, it remains unclear whether and how they can be seamlessly integrated into deep learning pipelines for solving downstream tasks. This paper addresses this research problem and introduces nf2vec, a framework capable of generating a compact latent representation for an input NF in a single inference pass. We demonstrate that nf2vec effectively embeds 3D objects represented by the input NFs and showcase how the resulting embeddings can be employed in deep learning pipelines to successfully address various tasks, all while processing exclusively NFs. We test this framework on several NFs used to represent 3D surfaces, such as unsigned/signed distance and occupancy fields. Moreover, we demonstrate the effectiveness of our approach with more complex NFs that encompass both geometry and appearance of 3D objects such as neural radiance fields. ",
    "url": "https://arxiv.org/abs/2312.13277",
    "authors": [
      "Pierluigi Zama Ramirez",
      "Luca De Luigi",
      "Daniele Sirocchi",
      "Adriano Cardace",
      "Riccardo Spezialetti",
      "Francesco Ballerini",
      "Samuele Salti",
      "Luigi Di Stefano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.13285",
    "title": "UniSDF: Unifying Neural Representations for High-Fidelity 3D  Reconstruction of Complex Scenes with Reflections",
    "abstract": "Neural 3D scene representations have shown great potential for 3D reconstruction from 2D images. However, reconstructing real-world captures of complex scenes still remains a challenge. Existing generic 3D reconstruction methods often struggle to represent fine geometric details and do not adequately model reflective surfaces of large-scale scenes. Techniques that explicitly focus on reflective surfaces can model complex and detailed reflections by exploiting better reflection parameterizations. However, we observe that these methods are often not robust in real unbounded scenarios where non-reflective as well as reflective components are present. In this work, we propose UniSDF, a general purpose 3D reconstruction method that can reconstruct large complex scenes with reflections. We investigate both view-based as well as reflection-based color prediction parameterization techniques and find that explicitly blending these representations in 3D space enables reconstruction of surfaces that are more geometrically accurate, especially for reflective surfaces. We further combine this representation with a multi-resolution grid backbone that is trained in a coarse-to-fine manner, enabling faster reconstructions than prior methods. Extensive experiments on object-level datasets DTU, Shiny Blender as well as unbounded datasets Mip-NeRF 360 and Ref-NeRF real demonstrate that our method is able to robustly reconstruct complex large-scale scenes with fine details and reflective surfaces. Please see our project page at https://fangjinhuawang.github.io/UniSDF. ",
    "url": "https://arxiv.org/abs/2312.13285",
    "authors": [
      "Fangjinhua Wang",
      "Marie-Julie Rakotosaona",
      "Michael Niemeyer",
      "Richard Szeliski",
      "Marc Pollefeys",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.12476",
    "title": "DSAF: A Dual-Stage Adaptive Framework for Numerical Weather Prediction  Downscaling",
    "abstract": "While widely recognized as one of the most substantial weather forecasting methodologies, Numerical Weather Prediction (NWP) usually suffers from relatively coarse resolution and inevitable bias due to tempo-spatial discretization, physical parametrization process, and computation limitation. With the roaring growth of deep learning-based techniques, we propose the Dual-Stage Adaptive Framework (DSAF), a novel framework to address regional NWP downscaling and bias correction tasks. DSAF uniquely incorporates adaptive elements in its design to ensure a flexible response to evolving weather conditions. Specifically, NWP downscaling and correction are well-decoupled in the framework and can be applied independently, which strategically guides the optimization trajectory of the model. Utilizing a multi-task learning mechanism and an uncertainty-weighted loss function, DSAF facilitates balanced training across various weather factors. Additionally, our specifically designed attention-centric learnable module effectively integrates geographic information, proficiently managing complex interrelationships. Experimental validation on the ECMWF operational forecast (HRES) and reanalysis (ERA5) archive demonstrates DSAF's superior performance over existing state-of-the-art models and shows substantial improvements when existing models are augmented using our proposed modules. Code is publicly available at https://github.com/pengwei07/DSAF. ",
    "url": "https://arxiv.org/abs/2312.12476",
    "authors": [
      "Pengwei Liu",
      "Wenwei Wang",
      "Bingqing Peng",
      "Binqing Wu",
      "Liang Sun"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.12485",
    "title": "Learning Deterministic Surrogates for Robust Convex QCQPs",
    "abstract": "Decision-focused learning is a promising development for contextual optimisation. It enables us to train prediction models that reflect the contextual sensitivity structure of the problem. However, there have been limited attempts to extend this paradigm to robust optimisation. We propose a double implicit layer model for training prediction models with respect to robust decision loss in uncertain convex quadratically constrained quadratic programs (QCQP). The first layer solves a deterministic version of the problem, the second layer evaluates the worst case realisation for an uncertainty set centred on the observation given the decisions obtained from the first layer. This enables us to learn model parameterisations that lead to robust decisions while only solving a simpler deterministic problem at test time. Additionally, instead of having to solve a robust counterpart we solve two smaller and potentially easier problems in training. The second layer (worst case problem) can be seen as a regularisation approach for predict-and-optimise by fitting to a neighbourhood of problems instead of just a point observation. We motivate relaxations of the worst-case problem in cases of uncertainty sets that would otherwise lead to trust region problems, and leverage various relaxations to deal with uncertain constraints. Both layers are typically strictly convex in this problem setting and thus have meaningful gradients almost everywhere. We demonstrate an application of this model on simulated experiments. The method is an effective regularisation tool for decision-focused learning for uncertain convex QCQPs. ",
    "url": "https://arxiv.org/abs/2312.12485",
    "authors": [
      "Egon Per\u0161ak",
      "Miguel F. Anjos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.12618",
    "title": "Automating Weight Function Generation in Graph Pebbling",
    "abstract": "Graph pebbling is a combinatorial game played on an undirected graph with an initial configuration of pebbles. A pebbling move consists of removing two pebbles from one vertex and placing one pebble on an adjacent vertex. The pebbling number of a graph is the smallest number of pebbles necessary such that, given any initial configuration of pebbles, at least one pebble can be moved to a specified root vertex. Recent lines of inquiry apply computational techniques to pebbling bound generation and improvement. Along these lines, we present a computational framework that produces a set of tree strategy weight functions that are capable of proving pebbling number upper bounds on a connected graph. Our mixed-integer linear programming approach automates the generation of large sets of such functions and provides verifiable certificates of pebbling number upper bounds. The framework is capable of producing verifiable pebbling bounds on any connected graph, regardless of its structure or pebbling properties. We apply the model to the 4th weak Bruhat to prove $\\pi(B_4) \\leq 66$ and to the Lemke square graph to produce a set of certificates that verify $\\pi(L x L) \\leq 96$. ",
    "url": "https://arxiv.org/abs/2312.12618",
    "authors": [
      "Dominic Flocco",
      "Jonad Pulaj",
      "Carl Yerger"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2312.12653",
    "title": "Diagnosis Of Takotsubo Syndrome By Robust Feature Selection From The  Complex Latent Space Of DL-based Segmentation Network",
    "abstract": "Researchers have shown significant correlations among segmented objects in various medical imaging modalities and disease related pathologies. Several studies showed that using hand crafted features for disease prediction neglects the immense possibility to use latent features from deep learning (DL) models which may reduce the overall accuracy of differential diagnosis. However, directly using classification or segmentation models on medical to learn latent features opt out robust feature selection and may lead to overfitting. To fill this gap, we propose a novel feature selection technique using the latent space of a segmentation model that can aid diagnosis. We evaluated our method in differentiating a rare cardiac disease: Takotsubo Syndrome (TTS) from the ST elevation myocardial infarction (STEMI) using echocardiogram videos (echo). TTS can mimic clinical features of STEMI in echo and extremely hard to distinguish. Our approach shows promising results in differential diagnosis of TTS with 82% diagnosis accuracy beating the previous state-of-the-art (SOTA) approach. Moreover, the robust feature selection technique using LASSO algorithm shows great potential in reducing the redundant features and creates a robust pipeline for short- and long-term disease prognoses in the downstream analysis. ",
    "url": "https://arxiv.org/abs/2312.12653",
    "authors": [
      "Fahim Ahmed Zaman",
      "Wahidul Alam",
      "Tarun Kanti Roy",
      "Amanda Chang",
      "Kan Liu",
      "Xiaodong Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.12678",
    "title": "Causal Discovery for fMRI data: Challenges, Solutions, and a Case Study",
    "abstract": "Designing studies that apply causal discovery requires navigating many researcher degrees of freedom. This complexity is exacerbated when the study involves fMRI data. In this paper we (i) describe nine challenges that occur when applying causal discovery to fMRI data, (ii) discuss the space of decisions that need to be made, (iii) review how a recent case study made those decisions, (iv) and identify existing gaps that could potentially be solved by the development of new methods. Overall, causal discovery is a promising approach for analyzing fMRI data, and multiple successful applications have indicated that it is superior to traditional fMRI functional connectivity methods, but current causal discovery methods for fMRI leave room for improvement. ",
    "url": "https://arxiv.org/abs/2312.12678",
    "authors": [
      "Eric Rawls",
      "Bryan Andrews",
      "Kelvin Lim",
      "Erich Kummerfeld"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.12764",
    "title": "Lattice Rescoring Based on Large Ensemble of Complementary Neural  Language Models",
    "abstract": "We investigate the effectiveness of using a large ensemble of advanced neural language models (NLMs) for lattice rescoring on automatic speech recognition (ASR) hypotheses. Previous studies have reported the effectiveness of combining a small number of NLMs. In contrast, in this study, we combine up to eight NLMs, i.e., forward/backward long short-term memory/Transformer-LMs that are trained with two different random initialization seeds. We combine these NLMs through iterative lattice generation. Since these NLMs work complementarily with each other, by combining them one by one at each rescoring iteration, language scores attached to given lattice arcs can be gradually refined. Consequently, errors of the ASR hypotheses can be gradually reduced. We also investigate the effectiveness of carrying over contextual information (previous rescoring results) across a lattice sequence of a long speech such as a lecture speech. In experiments using a lecture speech corpus, by combining the eight NLMs and using context carry-over, we obtained a 24.4% relative word error rate reduction from the ASR 1-best baseline. For further comparison, we performed simultaneous (i.e., non-iterative) NLM combination and 100-best rescoring using the large ensemble of NLMs, which confirmed the advantage of lattice rescoring with iterative NLM combination. ",
    "url": "https://arxiv.org/abs/2312.12764",
    "authors": [
      "Atsunori Ogawa",
      "Naohiro Tawara",
      "Marc Delcroix",
      "Shoko Araki"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2312.12789",
    "title": "SLP-Net:An efficient lightweight network for segmentation of skin  lesions",
    "abstract": "Prompt treatment for melanoma is crucial. To assist physicians in identifying lesion areas precisely in a quick manner, we propose a novel skin lesion segmentation technique namely SLP-Net, an ultra-lightweight segmentation network based on the spiking neural P(SNP) systems type mechanism. Most existing convolutional neural networks achieve high segmentation accuracy while neglecting the high hardware cost. SLP-Net, on the contrary, has a very small number of parameters and a high computation speed. We design a lightweight multi-scale feature extractor without the usual encoder-decoder structure. Rather than a decoder, a feature adaptation module is designed to replace it and implement multi-scale information decoding. Experiments at the ISIC2018 challenge demonstrate that the proposed model has the highest Acc and DSC among the state-of-the-art methods, while experiments on the PH2 dataset also demonstrate a favorable generalization ability. Finally, we compare the computational complexity as well as the computational speed of the models in experiments, where SLP-Net has the highest overall superiority ",
    "url": "https://arxiv.org/abs/2312.12789",
    "authors": [
      "Bo Yang",
      "Hong Peng",
      "Chenggang Guo",
      "Xiaohui Luo",
      "Jun Wang",
      "Xianzhong Long"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.12810",
    "title": "Unconstrained Dysfluency Modeling for Dysfluent Speech Transcription and  Detection",
    "abstract": "Dysfluent speech modeling requires time-accurate and silence-aware transcription at both the word-level and phonetic-level. However, current research in dysfluency modeling primarily focuses on either transcription or detection, and the performance of each aspect remains limited. In this work, we present an unconstrained dysfluency modeling (UDM) approach that addresses both transcription and detection in an automatic and hierarchical manner. UDM eliminates the need for extensive manual annotation by providing a comprehensive solution. Furthermore, we introduce a simulated dysfluent dataset called VCTK++ to enhance the capabilities of UDM in phonetic transcription. Our experimental results demonstrate the effectiveness and robustness of our proposed methods in both transcription and detection tasks. ",
    "url": "https://arxiv.org/abs/2312.12810",
    "authors": [
      "Jiachen Lian",
      "Carly Feng",
      "Naasir Farooqi",
      "Steve Li",
      "Anshul Kashyap",
      "Cheol Jun Cho",
      "Peter Wu",
      "Robbie Netzorg",
      "Tingle Li",
      "Gopala Krishna Anumanchipalli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2312.12821",
    "title": "CST-former: Transformer with Channel-Spectro-Temporal Attention for  Sound Event Localization and Detection",
    "abstract": "Sound event localization and detection (SELD) is a task for the classification of sound events and the localization of direction of arrival (DoA) utilizing multichannel acoustic signals. Prior studies employ spectral and channel information as the embedding for temporal attention. However, this usage limits the deep neural network from extracting meaningful features from the spectral or spatial domains. Therefore, our investigation in this paper presents a novel framework termed the Channel-Spectro-Temporal Transformer (CST-former) that bolsters SELD performance through the independent application of attention mechanisms to distinct domains. The CST-former architecture employs distinct attention mechanisms to independently process channel, spectral, and temporal information. In addition, we propose an unfolded local embedding (ULE) technique for channel attention (CA) to generate informative embedding vectors including local spectral and temporal information. Empirical validation through experimentation on the 2022 and 2023 DCASE Challenge task3 datasets affirms the efficacy of employing attention mechanisms separated across each domain and the benefit of ULE, in enhancing SELD performance. ",
    "url": "https://arxiv.org/abs/2312.12821",
    "authors": [
      "Yusun Shul",
      "Jung-Woo Choi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2312.12909",
    "title": "Energy-efficient Spiking Neural Network Equalization for IM/DD Systems  with Optimized Neural Encoding",
    "abstract": "We propose an energy-efficient equalizer for IM/DD systems based on spiking neural networks. We optimize a neural spike encoding that boosts the equalizer's performance while decreasing energy consumption. ",
    "url": "https://arxiv.org/abs/2312.12909",
    "authors": [
      "Alexander von Bank",
      "Eike-Manuel Edelmann",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2312.13013",
    "title": "User-Assisted Networked Sensing in OFDM Cellular Network with Erroneous  Anchor Position Information",
    "abstract": "In the sixth-generation (6G) integrated sensing and communication (ISAC) cellular network, base stations (BSs) can collaborate with each other to reap not only the cooperative communication gain, but also the networked sensing gain. In contrast to cooperative communication where both line-of-sight (LOS) paths and non-line-of-sight (NLOS) paths are useful, networked sensing mainly relies on the LOS paths. However, in practice, the number of BSs possessing LOS paths to a target can be small, leading to marginal networked sensing gain. Because the density of user equipments (UEs) is much larger than that of the BSs, this paper considers a UE-assisted networked sensing architecture, where a BS transmits communication signals in the downlink, while the UEs that receive the echo signals scattered by a target can cooperate with the BS to localize it. Under this scheme, however, the positions of the UEs are estimated by Global Positioning System (GPS) and subject to unknown errors. If some UEs with significantly erroneous position information are used as anchors, the localization performance can be severely degraded. Based on the outlier detection technique, this paper proposes an efficient method to select a subset of UEs with accurate position information as anchors for localizing the target. Numerical results show that our scheme can select good UEs as anchors with very high probability, indicating that networked sensing can be realized in practice with the aid of UEs. ",
    "url": "https://arxiv.org/abs/2312.13013",
    "authors": [
      "Xianzhen Guo",
      "Qin Shi",
      "Liang Liu",
      "Shuowen Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2312.13026",
    "title": "FusDom: Combining In-Domain and Out-of-Domain Knowledge for Continuous  Self-Supervised Learning",
    "abstract": "Continued pre-training (CP) offers multiple advantages, like target domain adaptation and the potential to exploit the continuous stream of unlabeled data available online. However, continued pre-training on out-of-domain distributions often leads to catastrophic forgetting of previously acquired knowledge, leading to sub-optimal ASR performance. This paper presents FusDom, a simple and novel methodology for SSL-based continued pre-training. FusDom learns speech representations that are robust and adaptive yet not forgetful of concepts seen in the past. Instead of solving the SSL pre-text task on the output representations of a single model, FusDom leverages two identical pre-trained SSL models, a teacher and a student, with a modified pre-training head to solve the CP SSL pre-text task. This head employs a cross-attention mechanism between the representations of both models while only the student receives gradient updates and the teacher does not. Finally, the student is fine-tuned for ASR. In practice, FusDom outperforms all our baselines across settings significantly, with WER improvements in the range of 0.2 WER - 7.3 WER in the target domain while retaining the performance in the earlier domain. ",
    "url": "https://arxiv.org/abs/2312.13026",
    "authors": [
      "Ashish Seth",
      "Sreyan Ghosh",
      "S. Umesh",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2312.13127",
    "title": "Pixel-to-Abundance Translation: Conditional Generative Adversarial  Networks Based on Patch Transformer for Hyperspectral Unmixing",
    "abstract": "Spectral unmixing is a significant challenge in hyperspectral image processing. Existing unmixing methods utilize prior knowledge about the abundance distribution to solve the regularization optimization problem, where the difficulty lies in choosing appropriate prior knowledge and solving the complex regularization optimization problem. To solve these problems, we propose a hyperspectral conditional generative adversarial network (HyperGAN) method as a generic unmixing framework, based on the following assumption: the unmixing process from pixel to abundance can be regarded as a transformation of two modalities with an internal specific relationship. The proposed HyperGAN is composed of a generator and discriminator, the former completes the modal conversion from mixed hyperspectral pixel patch to the abundance of corresponding endmember of the central pixel and the latter is used to distinguish whether the distribution and structure of generated abundance are the same as the true ones. We propose hyperspectral image (HSI) Patch Transformer as the main component of the generator, which utilize adaptive attention score to capture the internal pixels correlation of the HSI patch and leverage the spatial-spectral information in a fine-grained way to achieve optimization of the unmixing process. Experiments on synthetic data and real hyperspectral data achieve impressive results compared to state-of-the-art competitors. ",
    "url": "https://arxiv.org/abs/2312.13127",
    "authors": [
      "Li Wang",
      "Xiaohua Zhang",
      "Longfei Li",
      "Hongyun Meng",
      "Xianghai Cao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.13136",
    "title": "Molecular Hypergraph Neural Networks",
    "abstract": "Graph neural networks (GNNs) have demonstrated promising performance across various chemistry-related tasks. However, conventional graphs only model the pairwise connectivity in molecules, failing to adequately represent higher-order connections like multi-center bonds and conjugated structures. To tackle this challenge, we introduce molecular hypergraphs and propose Molecular Hypergraph Neural Networks (MHNN) to predict the optoelectronic properties of organic semiconductors, where hyperedges represent conjugated structures. A general algorithm is designed for irregular high-order connections, which can efficiently operate on molecular hypergraphs with hyperedges of various orders. The results show that MHNN outperforms all baseline models on most tasks of OPV, OCELOTv1 and PCQM4Mv2 datasets. Notably, MHNN achieves this without any 3D geometric information, surpassing the baseline model that utilizes atom positions. Moreover, MHNN achieves better performance than pretrained GNNs under limited training data, underscoring its excellent data efficiency. This work provides a new strategy for more general molecular representations and property prediction tasks related to high-order connections. ",
    "url": "https://arxiv.org/abs/2312.13136",
    "authors": [
      "Junwu Chen",
      "Philippe Schwaller"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.13212",
    "title": "A 3D super-resolution of wind fields via physics-informed pixel-wise  self-attention generative adversarial network",
    "abstract": "To mitigate global warming, greenhouse gas sources need to be resolved at a high spatial resolution and monitored in time to ensure the reduction and ultimately elimination of the pollution source. However, the complexity of computation in resolving high-resolution wind fields left the simulations impractical to test different time lengths and model configurations. This study presents a preliminary development of a physics-informed super-resolution (SR) generative adversarial network (GAN) that super-resolves the three-dimensional (3D) low-resolution wind fields by upscaling x9 times. We develop a pixel-wise self-attention (PWA) module that learns 3D weather dynamics via a self-attention computation followed by a 2D convolution. We also employ a loss term that regularizes the self-attention map during pretraining, capturing the vertical convection process from input wind data. The new PWA SR-GAN shows the high-fidelity super-resolved 3D wind data, learns a wind structure at the high-frequency domain, and reduces the computational cost of a high-resolution wind simulation by x89.7 times. ",
    "url": "https://arxiv.org/abs/2312.13212",
    "authors": [
      "Takuya Kurihana",
      "Kyongmin Yeo",
      "Daniela Szwarcman",
      "Bruce Elmegreen",
      "Karthik Mukkavilli",
      "Johannes Schmude",
      "Levente Klein"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.13250",
    "title": "The role of data embedding in equivariant quantum convolutional neural  networks",
    "abstract": "Geometric deep learning refers to the scenario in which the symmetries of a dataset are used to constrain the parameter space of a neural network and thus, improve their trainability and generalization. Recently this idea has been incorporated into the field of quantum machine learning, which has given rise to equivariant quantum neural networks (EQNNs). In this work, we investigate the role of classical-to-quantum embedding on the performance of equivariant quantum convolutional neural networks (EQCNNs) for the classification of images. We discuss the connection between the data embedding method and the resulting representation of a symmetry group and analyze how changing representation affects the expressibility of an EQCNN. We numerically compare the classification accuracy of EQCNNs with three different basis-permuted amplitude embeddings to the one obtained from a non-equivariant quantum convolutional neural network (QCNN). Our results show that all the EQCNNs achieve higher classification accuracy than the non-equivariant QCNN for small numbers of training iterations, while for large iterations this improvement crucially depends on the used embedding. It is expected that the results of this work can be useful to the community for a better understanding of the importance of data embedding choice in the context of geometric quantum machine learning. ",
    "url": "https://arxiv.org/abs/2312.13250",
    "authors": [
      "Sreetama Das",
      "Stefano Martina",
      "Filippo Caruso"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.07669",
    "title": "On Achievable Rates of Line Networks with Generalized Batched Network  Coding",
    "abstract": " Comments: This paper was presented in part at ISIT 2019 and 2020, and is accepted by a JSAC special issue ",
    "url": "https://arxiv.org/abs/2105.07669",
    "authors": [
      "Jie Wang",
      "Shenghao Yang",
      "Yanyan Dong",
      "Yiheng Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2201.09169",
    "title": "Rich Action-semantic Consistent Knowledge for Early Action Prediction",
    "abstract": " Comments: Accepted by IEEE TIP,15pages ",
    "url": "https://arxiv.org/abs/2201.09169",
    "authors": [
      "Xiaoli Liu",
      "Jianqin Yin",
      "Di Guo",
      "Huaping Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.02980",
    "title": "3D Object Detection from Images for Autonomous Driving: A Survey",
    "abstract": " Comments: Accepted by T-PAMI ",
    "url": "https://arxiv.org/abs/2202.02980",
    "authors": [
      "Xinzhu Ma",
      "Wanli Ouyang",
      "Andrea Simonelli",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2202.06152",
    "title": "Analysis of Dual-Based PID Controllers through Convolutional Mirror  Descent",
    "abstract": " Title: Analysis of Dual-Based PID Controllers through Convolutional Mirror  Descent ",
    "url": "https://arxiv.org/abs/2202.06152",
    "authors": [
      "Santiago R. Balseiro",
      "Haihao Lu",
      "Vahab Mirrokni",
      "Balasubramanian Sivan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15834",
    "title": "Attribution-based Explanations that Provide Recourse Cannot be Robust",
    "abstract": " Comments: 32 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2205.15834",
    "authors": [
      "Hidde Fokkema",
      "Rianne de Heide",
      "Tim van Erven"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.08615",
    "title": "On the Number of Regions of Piecewise Linear Neural Networks",
    "abstract": " Title: On the Number of Regions of Piecewise Linear Neural Networks ",
    "url": "https://arxiv.org/abs/2206.08615",
    "authors": [
      "Alexis Goujon",
      "Arian Etemadi",
      "Michael Unser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.14719",
    "title": "In Search of Projectively Equivariant Networks",
    "abstract": " Comments: v3: Another significant rewrite. Accepted for publication in TMLR. v2: Significant rewrite. The title has been changed: \"neural network\" -&gt; \"network\". More general description of projectively equivariant linear layers, with new proposed architectures, and a completely new accompanying experiment section, as a result ",
    "url": "https://arxiv.org/abs/2209.14719",
    "authors": [
      "Georg B\u00f6kman",
      "Axel Flinth",
      "Fredrik Kahl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15657",
    "title": "Detecting fake accounts through Generative Adversarial Network in online  social media",
    "abstract": " Comments: needed more investigation on final results ",
    "url": "https://arxiv.org/abs/2210.15657",
    "authors": [
      "Jinus Bordbar",
      "Mohammadreza Mohammadrezaie",
      "Saman Ardalan",
      "Mohammad Ebrahim Shiri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01039",
    "title": "SoftCorrect: Error Correction with Soft Detection for Automatic Speech  Recognition",
    "abstract": " Comments: AAAI 2023 ",
    "url": "https://arxiv.org/abs/2212.01039",
    "authors": [
      "Yichong Leng",
      "Xu Tan",
      "Wenjie Liu",
      "Kaitao Song",
      "Rui Wang",
      "Xiang-Yang Li",
      "Tao Qin",
      "Edward Lin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2212.01071",
    "title": "Fake detection in imbalance dataset by Semi-supervised learning with GAN",
    "abstract": " Comments: needed more investigation o final results ",
    "url": "https://arxiv.org/abs/2212.01071",
    "authors": [
      "Jinus Bordbar",
      "Saman Ardalan",
      "Mohammadreza Mohammadrezaie",
      "Zahra Ghasemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2212.04155",
    "title": "Latent Graph Representations for Critical View of Safety Assessment",
    "abstract": " Comments: 12 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2212.04155",
    "authors": [
      "Aditya Murali",
      "Deepak Alapatt",
      "Pietro Mascagni",
      "Armine Vardazaryan",
      "Alain Garcia",
      "Nariaki Okamoto",
      "Didier Mutter",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.06370",
    "title": "Dual Accuracy-Quality-Driven Neural Network for Prediction Interval  Generation",
    "abstract": " Comments: Accepted at the IEEE Transactions on Neural Networks and Learning Systems ",
    "url": "https://arxiv.org/abs/2212.06370",
    "authors": [
      "Giorgio Morales",
      "John W. Sheppard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.03713",
    "title": "Non-contact Respiratory Anomaly Detection using Infrared Light-wave  Sensing",
    "abstract": " Comments: 12 pages, 15 figures excluding photos of authors, submitted to IEEE Transactions on Human-machine Systems ",
    "url": "https://arxiv.org/abs/2301.03713",
    "authors": [
      "Md Zobaer Islam",
      "Brenden Martin",
      "Carly Gotcher",
      "Tyler Martinez",
      "John F. O'Hara",
      "Sabit Ekin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.00196",
    "title": "Transformed Low-Rank Parameterization Can Help Robust Generalization for  Tensor Neural Networks",
    "abstract": " Comments: 51 pages, presented on NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2303.00196",
    "authors": [
      "Andong Wang",
      "Chao Li",
      "Mingyuan Bai",
      "Zhong Jin",
      "Guoxu Zhou",
      "Qibin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.02367",
    "title": "Perirobot space representation for HRI: measuring and designing  collaborative workspace coverage by diverse sensors",
    "abstract": " Comments: 8 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2303.02367",
    "authors": [
      "Jakub Rozlivek",
      "Petr Svarny",
      "Matej Hoffmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.06854",
    "title": "Robust Contrastive Language-Image Pre-training against Data Poisoning  and Backdoor Attacks",
    "abstract": " Title: Robust Contrastive Language-Image Pre-training against Data Poisoning  and Backdoor Attacks ",
    "url": "https://arxiv.org/abs/2303.06854",
    "authors": [
      "Wenhan Yang",
      "Jingdong Gao",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11048",
    "title": "SGFormer: Semantic Graph Transformer for Point Cloud-based 3D Scene  Graph Generation",
    "abstract": " Comments: To be published in Thirty-Eighth AAAI Conference on Artificial Intelligence ",
    "url": "https://arxiv.org/abs/2303.11048",
    "authors": [
      "Changsheng Lv",
      "Mengshi Qi",
      "Xia Li",
      "Zhengyuan Yang",
      "Huadong Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16521",
    "title": "Hard Regularization to Prevent Deep Online Clustering Collapse without  Data Augmentation",
    "abstract": " Title: Hard Regularization to Prevent Deep Online Clustering Collapse without  Data Augmentation ",
    "url": "https://arxiv.org/abs/2303.16521",
    "authors": [
      "Louis Mahon",
      "Thomas Lukasiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.09679",
    "title": "Sparse graphs without long induced paths",
    "abstract": " Comments: 22 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2304.09679",
    "authors": [
      "Oscar Defrain",
      "Jean-Florent Raymond"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2305.10701",
    "title": "Personalization as a Shortcut for Few-Shot Backdoor Attack against  Text-to-Image Diffusion Models",
    "abstract": " Comments: 16 pages, accepted by AAAI 2024 ",
    "url": "https://arxiv.org/abs/2305.10701",
    "authors": [
      "Yihao Huang",
      "Felix Juefei-Xu",
      "Qing Guo",
      "Jie Zhang",
      "Yutong Wu",
      "Ming Hu",
      "Tianlin Li",
      "Geguang Pu",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12554",
    "title": "Towards Consistent Stochastic Human Motion Prediction via Motion  Diffusion",
    "abstract": " Title: Towards Consistent Stochastic Human Motion Prediction via Motion  Diffusion ",
    "url": "https://arxiv.org/abs/2305.12554",
    "authors": [
      "Jiarui Sun",
      "Girish Chowdhary"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17965",
    "title": "Improving the Generalizability of Trajectory Prediction Models with  Frenet-Based Domain Normalization",
    "abstract": " Comments: This paper was published in 2023 IEEE International Conference on Robotics and Automation (ICRA). New version updated with links to the source code of the Frenet+ strategy ",
    "url": "https://arxiv.org/abs/2305.17965",
    "authors": [
      "Luyao Ye",
      "Zikang Zhou",
      "Jianping Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.01335",
    "title": "Invertible residual networks in the context of regularization theory for  linear inverse problems",
    "abstract": " Title: Invertible residual networks in the context of regularization theory for  linear inverse problems ",
    "url": "https://arxiv.org/abs/2306.01335",
    "authors": [
      "Clemens Arndt",
      "Alexander Denker",
      "S\u00f6ren Dittmer",
      "Nick Heilenk\u00f6tter",
      "Meira Iske",
      "Tobias Kluth",
      "Peter Maass",
      "Judith Nickel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.03373",
    "title": "CiT-Net: Convolutional Neural Networks Hand in Hand with Vision  Transformers for Medical Image Segmentation",
    "abstract": " Comments: 9 pages, 3 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2306.03373",
    "authors": [
      "Tao Lei",
      "Rui Sun",
      "Xuan Wang",
      "Yingbo Wang",
      "Xi He",
      "Asoke Nandi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.03625",
    "title": "Fair and Robust Estimation of Heterogeneous Treatment Effects for Policy  Learning",
    "abstract": " Title: Fair and Robust Estimation of Heterogeneous Treatment Effects for Policy  Learning ",
    "url": "https://arxiv.org/abs/2306.03625",
    "authors": [
      "Kwangho Kim",
      "Jos\u00e9 R. Zubizarreta"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.04086",
    "title": "TEC-Net: Vision Transformer Embrace Convolutional Neural Networks for  Medical Image Segmentation",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2306.03373 ",
    "url": "https://arxiv.org/abs/2306.04086",
    "authors": [
      "Rui Sun",
      "Tao Lei",
      "Weichuan Zhang",
      "Yong Wan",
      "Yong Xia",
      "Asoke K. Nandi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.04886",
    "title": "Multi-task Bioassay Pre-training for Protein-ligand Binding Affinity  Prediction",
    "abstract": " Comments: 21 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2306.04886",
    "authors": [
      "Jiaxian Yan",
      "Zhaofeng Ye",
      "Ziyi Yang",
      "Chengqiang Lu",
      "Shengyu Zhang",
      "Qi Liu",
      "Jiezhong Qiu"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06041",
    "title": "A Graph Dynamics Prior for Relational Inference",
    "abstract": " Title: A Graph Dynamics Prior for Relational Inference ",
    "url": "https://arxiv.org/abs/2306.06041",
    "authors": [
      "Liming Pan",
      "Cheng Shi",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.02273",
    "title": "Joint Hierarchical Priors and Adaptive Spatial Resolution for Efficient  Neural Image Compression",
    "abstract": " Title: Joint Hierarchical Priors and Adaptive Spatial Resolution for Efficient  Neural Image Compression ",
    "url": "https://arxiv.org/abs/2307.02273",
    "authors": [
      "Ahmed Ghorbel",
      "Wassim Hamidouche",
      "Luce Morin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.16092",
    "title": "Feature Transportation Improves Graph Neural Networks",
    "abstract": " Comments: AAAI 2024 ",
    "url": "https://arxiv.org/abs/2307.16092",
    "authors": [
      "Moshe Eliasof",
      "Eldad Haber",
      "Eran Treister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.03108",
    "title": "SAAM: Stealthy Adversarial Attack on Monocular Depth Estimation",
    "abstract": " Title: SAAM: Stealthy Adversarial Attack on Monocular Depth Estimation ",
    "url": "https://arxiv.org/abs/2308.03108",
    "authors": [
      "Amira Guesmi",
      "Muhammad Abdullah Hanif",
      "Bassem Ouni",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.03109",
    "title": "Lost in Translation: A Study of Bugs Introduced by Large Language Models  while Translating Code",
    "abstract": " Comments: Published in ICSE 2024 ",
    "url": "https://arxiv.org/abs/2308.03109",
    "authors": [
      "Rangeet Pan",
      "Ali Reza Ibrahimzada",
      "Rahul Krishna",
      "Divya Sankar",
      "Lambert Pouguem Wassi",
      "Michele Merler",
      "Boris Sobolev",
      "Raju Pavuluri",
      "Saurabh Sinha",
      "Reyhaneh Jabbarvand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.08658",
    "title": "A Data-Theoretic Approach to Identifying Violent Facial Expressions in  Social Crime Contexts",
    "abstract": " Title: A Data-Theoretic Approach to Identifying Violent Facial Expressions in  Social Crime Contexts ",
    "url": "https://arxiv.org/abs/2308.08658",
    "authors": [
      "Arindam Kumar Paul"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.09156",
    "title": "Characterizing Information Seeking Events in Health-Related Social  Discourse",
    "abstract": " Comments: Accepted at AAAI-2024. 9 pages, 6 tables, 2 figures ",
    "url": "https://arxiv.org/abs/2308.09156",
    "authors": [
      "Omar Sharif",
      "Madhusudan Basak",
      "Tanzia Parvin",
      "Ava Scharfstein",
      "Alphonso Bradham",
      "Jacob T. Borodovsky",
      "Sarah E. Lord",
      "Sarah M. Preum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.14606",
    "title": "On the Tradeoff between Privacy Preservation and Byzantine-Robustness in  Decentralized Learning",
    "abstract": " Title: On the Tradeoff between Privacy Preservation and Byzantine-Robustness in  Decentralized Learning ",
    "url": "https://arxiv.org/abs/2308.14606",
    "authors": [
      "Haoxiang Ye",
      "Heng Zhu",
      "Qing Ling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2309.08023",
    "title": "USM-SCD: Multilingual Speaker Change Detection Based on Large Pretrained  Foundation Models",
    "abstract": " Comments: 5 pages, 2 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2309.08023",
    "authors": [
      "Guanlong Zhao",
      "Yongqiang Wang",
      "Jason Pelecanos",
      "Yu Zhang",
      "Hank Liao",
      "Yiling Huang",
      "Han Lu",
      "Quan Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.17255",
    "title": "Knowledge Graphs for the Life Sciences: Recent Developments, Challenges  and Opportunities",
    "abstract": " Comments: 33 pages, 1 figure, camera-ready version, accepted for Transactions on Graph Data and Knowledge (TGDK) ",
    "url": "https://arxiv.org/abs/2309.17255",
    "authors": [
      "Jiaoyan Chen",
      "Hang Dong",
      "Janna Hastings",
      "Ernesto Jim\u00e9nez-Ruiz",
      "Vanessa L\u00f3pez",
      "Pierre Monnin",
      "Catia Pesquita",
      "Petr \u0160koda",
      "Valentina Tamma"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.02152",
    "title": "Graph Neural Network-based EEG Classification: A Survey",
    "abstract": " Comments: 14 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2310.02152",
    "authors": [
      "Dominik Klepl",
      "Min Wu",
      "Fei He"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2310.04469",
    "title": "Taming Binarized Neural Networks and Mixed-Integer Programs",
    "abstract": " Comments: 9 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2310.04469",
    "authors": [
      "Johannes Aspman",
      "Georgios Korpas",
      "Jakub Marecek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.06958",
    "title": "Comparing the robustness of modern no-reference image- and video-quality  metrics to adversarial attacks",
    "abstract": " Title: Comparing the robustness of modern no-reference image- and video-quality  metrics to adversarial attacks ",
    "url": "https://arxiv.org/abs/2310.06958",
    "authors": [
      "Anastasia Antsiferova",
      "Khaled Abud",
      "Aleksandr Gushchin",
      "Ekaterina Shumitskaya",
      "Sergey Lavrushkin",
      "Dmitriy Vatolin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.14884",
    "title": "Budgeted Embedding Table For Recommender Systems",
    "abstract": " Comments: Accepted by WSDM 2024 ",
    "url": "https://arxiv.org/abs/2310.14884",
    "authors": [
      "Yunke Qu",
      "Tong Chen",
      "Quoc Viet Hung Nguyen",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.15582",
    "title": "SecV: Secure Code Partitioning via Multi-Language Secure Values",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2310.15582",
    "authors": [
      "Peterson Yuhala",
      "Pascal Felber",
      "Hugo Guiroux",
      "Jean-Pierre Lozi",
      "Alain Tchana",
      "Valerio Schiavoni",
      "Ga\u00ebl Thomas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2310.16999",
    "title": "Trust, but Verify: Robust Image Segmentation using Deep Learning",
    "abstract": " Comments: 5 Pages, 8 Figures, conference ",
    "url": "https://arxiv.org/abs/2310.16999",
    "authors": [
      "Fahim Ahmed Zaman",
      "Xiaodong Wu",
      "Weiyu Xu",
      "Milan Sonka",
      "Raghuraman Mudumbai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.19461",
    "title": "FoodFresh: Multi-Chain Design for an Inter-Institutional Food Supply  Chain Network",
    "abstract": " Title: FoodFresh: Multi-Chain Design for an Inter-Institutional Food Supply  Chain Network ",
    "url": "https://arxiv.org/abs/2310.19461",
    "authors": [
      "Philipp Stangl",
      "Christoph P. Neumann"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.02554",
    "title": "Pilot-Based Key Distribution and Encryption for Secure Coherent Passive  Optical Networks",
    "abstract": " Comments: The paper has been submitted to the Journal of Lightwave Technology ",
    "url": "https://arxiv.org/abs/2311.02554",
    "authors": [
      "Haide Wang",
      "Ji Zhou",
      "Qingxin Lu",
      "Jianrui Zeng",
      "Yongqing Liao",
      "Weiping Liu",
      "Changyuan Yu",
      "Zhaohui Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.06875",
    "title": "Modularity of nearly complete graphs and bipartite graphs",
    "abstract": " Title: Modularity of nearly complete graphs and bipartite graphs ",
    "url": "https://arxiv.org/abs/2311.06875",
    "authors": [
      "Colin McDiarmid",
      "Fiona Skerman"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.10197",
    "title": "You Cannot Escape Me: Detecting Evasions of SIEM Rules in Enterprise  Networks",
    "abstract": " Comments: To be published in Proceedings of the 33rd USENIX Security Symposium (USENIX Security 2024) ",
    "url": "https://arxiv.org/abs/2311.10197",
    "authors": [
      "Rafael Uetz",
      "Marco Herzog",
      "Louis Hackl\u00e4nder",
      "Simon Schwarz",
      "Martin Henze"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.12420",
    "title": "How Far Have We Gone in Vulnerability Detection Using Large Language  Models",
    "abstract": " Title: How Far Have We Gone in Vulnerability Detection Using Large Language  Models ",
    "url": "https://arxiv.org/abs/2311.12420",
    "authors": [
      "Zeyu Gao",
      "Hao Wang",
      "Yuchen Zhou",
      "Wenyu Zhu",
      "Chao Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.15803",
    "title": "SOAC: Spatio-Temporal Overlap-Aware Multi-Sensor Calibration using  Neural Radiance Fields",
    "abstract": " Comments: Paper + Supplementary, under review. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2311.15803",
    "authors": [
      "Quentin Herau",
      "Nathan Piasco",
      "Moussab Bennehar",
      "Luis Rold\u00e3o",
      "Dzmitry Tsishkou",
      "Cyrille Migniot",
      "Pascal Vasseur",
      "C\u00e9dric Demonceaux"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.15917",
    "title": "When Graph Convolution Meets Double Attention: Online Privacy Disclosure  Detection with Multi-Label Text Classification",
    "abstract": " Comments: The manuscript is accepted by Data Mining and Knowledge Discovery(ECML PKDD Journal track) ",
    "url": "https://arxiv.org/abs/2311.15917",
    "authors": [
      "Zhanbo Liang",
      "Jie Guo",
      "Weidong Qiu",
      "Zheng Huang",
      "Shujun Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.16135",
    "title": "Use of Deep Neural Networks for Uncertain Stress Functions with  Extensions to Impact Mechanics",
    "abstract": " Comments: Index Terms: Stress, Uncertainty, Impact Mechanics, Deep Learning, Neural Network. 10 pages, 9 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2311.16135",
    "authors": [
      "Garrett Blum",
      "Ryan Doris",
      "Diego Klabjan",
      "Horacio Espinosa",
      "Ron Szalkowski"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16716",
    "title": "GraphPro: Graph Pre-training and Prompt Learning for Recommendation",
    "abstract": " Title: GraphPro: Graph Pre-training and Prompt Learning for Recommendation ",
    "url": "https://arxiv.org/abs/2311.16716",
    "authors": [
      "Yuhao Yang",
      "Lianghao Xia",
      "Da Luo",
      "Kangyi Lin",
      "Chao Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16984",
    "title": "FedECA: A Federated External Control Arm Method for Causal Inference  with Time-To-Event Data in Distributed Settings",
    "abstract": " Comments: code available at: this https URL, fixed some typos, figures and acknowledgments in v2 ",
    "url": "https://arxiv.org/abs/2311.16984",
    "authors": [
      "Jean Ogier du Terrail",
      "Quentin Klopfenstein",
      "Honghao Li",
      "Imke Mayer",
      "Nicolas Loiseau",
      "Mohammad Hallal",
      "F\u00e9lix Balazard",
      "Mathieu Andreux"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.02916",
    "title": "MIND: Multi-Task Incremental Network Distillation",
    "abstract": " Comments: Accepted at the 38th AAAI Conference on Artificial Intelligence ",
    "url": "https://arxiv.org/abs/2312.02916",
    "authors": [
      "Jacopo Bonato",
      "Francesco Pelosin",
      "Luigi Sabetta",
      "Alessandro Nicolosi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.06022",
    "title": "Exploiting Representation Bias for Data Distillation in Abstractive Text  Summarization",
    "abstract": " Title: Exploiting Representation Bias for Data Distillation in Abstractive Text  Summarization ",
    "url": "https://arxiv.org/abs/2312.06022",
    "authors": [
      "Yash Kumar Atri",
      "Vikram Goyal",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2312.07392",
    "title": "ReRoGCRL: Representation-based Robustness in Goal-Conditioned  Reinforcement Learning",
    "abstract": " Comments: This paper has been accepted in AAAI24 (this https URL) ",
    "url": "https://arxiv.org/abs/2312.07392",
    "authors": [
      "Xiangyu Yin",
      "Sihao Wu",
      "Jiaxu Liu",
      "Meng Fang",
      "Xingyu Zhao",
      "Xiaowei Huang",
      "Wenjie Ruan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.08410",
    "title": "Universal Approximation Property of Random Neural Networks",
    "abstract": " Comments: 64 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2312.08410",
    "authors": [
      "Ariel Neufeld",
      "Philipp Schmocker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.09787",
    "title": "Physics-informed Neural Network Estimation of Material Properties in  Soft Tissue Nonlinear Biomechanical Models",
    "abstract": " Title: Physics-informed Neural Network Estimation of Material Properties in  Soft Tissue Nonlinear Biomechanical Models ",
    "url": "https://arxiv.org/abs/2312.09787",
    "authors": [
      "Federica Caforio",
      "Francesco Regazzoni",
      "Stefano Pagani",
      "Elias Karabelas",
      "Christoph Augustin",
      "Gundolf Haase",
      "Gernot Plank",
      "Alfio Quarteroni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Biological Physics (physics.bio-ph)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2312.10080",
    "title": "No prejudice! Fair Federated Graph Neural Networks for Personalized  Recommendation",
    "abstract": " Comments: To appear as a full paper in AAAI 2024 ",
    "url": "https://arxiv.org/abs/2312.10080",
    "authors": [
      "Nimesh Agrawal",
      "Anuj Kumar Sirohi",
      "Jayadeva",
      "Sandeep Kumar"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2312.10461",
    "title": "Rethinking the Up-Sampling Operations in CNN-based Generative Network  for Generalizable Deepfake Detection",
    "abstract": " Comments: 10 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2312.10461",
    "authors": [
      "Chuangchuang Tan",
      "Huan Liu",
      "Yao Zhao",
      "Shikui Wei",
      "Guanghua Gu",
      "Ping Liu",
      "Yunchao Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.10743",
    "title": "A Unified Framework for Multi-Domain CTR Prediction via Large Language  Models",
    "abstract": " Comments: Still being revised ",
    "url": "https://arxiv.org/abs/2312.10743",
    "authors": [
      "Zichuan Fu",
      "Xiangyang Li",
      "Chuhan Wu",
      "Yichao Wang",
      "Kuicai Dong",
      "Xiangyu Zhao",
      "Mengchen Zhao",
      "Huifeng Guo",
      "Ruiming Tang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2312.11057",
    "title": "DataElixir: Purifying Poisoned Dataset to Mitigate Backdoor Attacks via  Diffusion Models",
    "abstract": " Comments: Accepted by AAAI2024 ",
    "url": "https://arxiv.org/abs/2312.11057",
    "authors": [
      "Jiachen Zhou",
      "Peizhuo Lv",
      "Yibing Lan",
      "Guozhu Meng",
      "Kai Chen",
      "Hualong Ma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.11841",
    "title": "MixRT: Mixed Neural Representations For Real-Time NeRF Rendering",
    "abstract": " Comments: Accepted by 3DV'24. Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2312.11841",
    "authors": [
      "Chaojian Li",
      "Bichen Wu",
      "Peter Vajda",
      "Yingyan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.12010",
    "title": "Outlier detection using flexible categorisation and interrogative  agendas",
    "abstract": " Title: Outlier detection using flexible categorisation and interrogative  agendas ",
    "url": "https://arxiv.org/abs/2312.12010",
    "authors": [
      "Marcel Boersma",
      "Krishna Manoorkar",
      "Alessandra Palmigiano",
      "Mattia Panettiere",
      "Apostolos Tzimoulis",
      "Nachoem Wijnberg"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2312.12183",
    "title": "Poincar\u00e9 Differential Privacy for Hierarchy-Aware Graph Embedding",
    "abstract": " Title: Poincar\u00e9 Differential Privacy for Hierarchy-Aware Graph Embedding ",
    "url": "https://arxiv.org/abs/2312.12183",
    "authors": [
      "Yuecen Wei",
      "Haonan Yuan",
      "Xingcheng Fu",
      "Qingyun Sun",
      "Hao Peng",
      "Xianxian Li",
      "Chunming Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  }
]