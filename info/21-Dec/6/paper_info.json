[
  {
    "id": "arXiv:2112.01617",
    "title": "Label noise detection under the Noise at Random model with ensemble  filters",
    "abstract": "Label noise detection has been widely studied in Machine Learning because of its importance in improving training data quality. Satisfactory noise detection has been achieved by adopting ensembles of classifiers. In this approach, an instance is assigned as mislabeled if a high proportion of members in the pool misclassifies it. Previous authors have empirically evaluated this approach; nevertheless, they mostly assumed that label noise is generated completely at random in a dataset. This is a strong assumption since other types of label noise are feasible in practice and can influence noise detection results. This work investigates the performance of ensemble noise detection under two different noise models: the Noisy at Random (NAR), in which the probability of label noise depends on the instance class, in comparison to the Noisy Completely at Random model, in which the probability of label noise is entirely independent. In this setting, we investigate the effect of class distribution on noise detection performance since it changes the total noise level observed in a dataset under the NAR assumption. Further, an evaluation of the ensemble vote threshold is conducted to contrast with the most common approaches in the literature. In many performed experiments, choosing a noise generation model over another can lead to different results when considering aspects such as class imbalance and noise level ratio among different classes. ",
    "url": "https://arxiv.org/abs/2112.01617",
    "authors": [
      "Kecia G. Moura",
      "Ricardo B. C. Prud\u00eancio",
      "George D. C. Cavalcanti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.01696",
    "title": "A hybrid physics-informed neural network for nonlinear partial  differential equation",
    "abstract": "The recently developed physics-informed machine learning has made great progress for solving nonlinear partial differential equations (PDEs), however, it may fail to provide reasonable approximations to the PDEs with discontinuous solutions. In this paper, we focus on the discrete time physics-informed neural network (PINN), and propose a hybrid PINN scheme for the nonlinear PDEs. In this approach, the local solution structures are classified as smooth and nonsmooth scales by introducing a discontinuity indicator, and then the automatic differentiation technique is employed for resolving smooth scales, while an improved weighted essentially non-oscillatory (WENO) scheme is adopted to capture discontinuities. We then test the present approach by considering the viscous and inviscid Burgers equations , and it is shown that compared with original discrete time PINN, the present hybrid approach has a better performance in approximating the discontinuous solution even at a relatively larger time step. ",
    "url": "https://arxiv.org/abs/2112.01696",
    "authors": [
      "Chunyue Lv",
      "Lei Wang",
      "Chenming Xie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2112.01796",
    "title": "The UniNAS framework: combining modules in arbitrarily complex  configurations with argument trees",
    "abstract": "Designing code to be simplistic yet to offer choice is a tightrope walk. Additional modules such as optimizers and data sets make a framework useful to a broader audience, but the added complexity quickly becomes a problem. Framework parameters may apply only to some modules but not others, be mutually exclusive or depend on each other, often in unclear ways. Even so, many frameworks are limited to a few specific use cases. This paper presents the underlying concept of UniNAS, a framework designed to incorporate a variety of Neural Architecture Search approaches. Since they differ in the number of optimizers and networks, hyper-parameter optimization, network designs, candidate operations, and more, a traditional approach can not solve the task. Instead, every module defines its own hyper-parameters and a local tree structure of module requirements. A configuration file specifies which modules are used, their used parameters, and which other modules they use in turn This concept of argument trees enables combining and reusing modules in complex configurations while avoiding many problems mentioned above. Argument trees can also be configured from a graphical user interface so that designing and changing experiments becomes possible without writing a single line of code. UniNAS is publicly available at https://github.com/cogsys-tuebingen/uninas ",
    "url": "https://arxiv.org/abs/2112.01796",
    "authors": [
      "Kevin Alexander Laube"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2112.01921",
    "title": "In situ process quality monitoring and defect detection for direct metal  laser melting",
    "abstract": "Quality control and quality assurance are challenges in Direct Metal Laser Melting (DMLM). Intermittent machine diagnostics and downstream part inspections catch problems after undue cost has been incurred processing defective parts. In this paper we demonstrate two methodologies for in-process fault detection and part quality prediction that can be readily deployed on existing commercial DMLM systems with minimal hardware modification. Novel features were derived from the time series of common photodiode sensors along with standard machine control signals. A Bayesian approach attributes measurements to one of multiple process states and a least squares regression model predicts severity of certain material defects. ",
    "url": "https://arxiv.org/abs/2112.01921",
    "authors": [
      "Sarah Felix",
      "Saikat Ray Majumder",
      "H. Kirk Mathews",
      "Michael Lexa",
      "Gabriel Lipsa",
      "Xiaohu Ping",
      "Subhrajit Roychowdhury",
      "Thomas Spears"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Instrumentation and Detectors (physics.ins-det)"
    ]
  },
  {
    "id": "arXiv:2112.01970",
    "title": "Optimization of phase-only holograms calculated with scaled diffraction  calculation through deep neural networks",
    "abstract": "Computer-generated holograms (CGHs) are used in holographic three-dimensional (3D) displays and holographic projections. The quality of the reconstructed images using phase-only CGHs is degraded because the amplitude of the reconstructed image is difficult to control. Iterative optimization methods such as the Gerchberg-Saxton (GS) algorithm are one option for improving image quality. They optimize CGHs in an iterative fashion to obtain a higher image quality. However, such iterative computation is time consuming, and the improvement in image quality is often stagnant. Recently, deep learning-based hologram computation has been proposed. Deep neural networks directly infer CGHs from input image data. However, it is limited to reconstructing images that are the same size as the hologram. In this study, we use deep learning to optimize phase-only CGHs generated using scaled diffraction computations and the random phase-free method. By combining the random phase-free method with the scaled diffraction computation, it is possible to handle a zoomable reconstructed image larger than the hologram. In comparison to the GS algorithm, the proposed method optimizes both high quality and speed. ",
    "url": "https://arxiv.org/abs/2112.01970",
    "authors": [
      "Yoshiyuki Ishii",
      "Tomoyoshi Shimobaba",
      "David Blinder",
      "Tobias Birnbaum",
      "Peter Schelkens",
      "Takashi Kakue",
      "Tomoyoshi Ito"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2112.01991",
    "title": "A network analysis of decision strategies of human experts in steel  manufacturing",
    "abstract": "Steel production scheduling is typically accomplished by human expert planners. Hence, instead of fully automated scheduling systems steel manufacturers prefer auxiliary recommendation algorithms. Through the suggestion of suitable orders, these algorithms assist human expert planners who are tasked with the selection and scheduling of production orders. However, it is hard to estimate, what degree of complexity these algorithms should have as steel campaign planning lacks precise rule-based procedures; in fact, it requires extensive domain knowledge as well as intuition that can only be acquired by years of business experience. Here, instead of developing new algorithms or improving older ones, we introduce a shuffling-aided network method to assess the complexity of the selection patterns established by a human expert. This technique allows us to formalize and represent the tacit knowledge that enters the campaign planning. As a result of the network analysis, we have discovered that the choice of production orders is primarily determined by the orders' carbon content. Surprisingly, trace elements like manganese, silicon, and titanium have a lesser impact on the selection decision than assumed by the pertinent literature. Our approach can serve as an input to a range of decision-support systems, whenever a human expert needs to create groups of orders ('campaigns') that fulfill certain implicit selection criteria. ",
    "url": "https://arxiv.org/abs/2112.01991",
    "authors": [
      "Daniel Christopher Merten",
      "Prof. Dr. Marc-Thorsten H\u00fctt",
      "Prof. Dr. Yilmaz Uygun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2112.02077",
    "title": "MD-inferred neural network monoclinic finite-strain hyperelasticity  models for $\u03b2$-HMX: Sobolev training and validation against physical  constraints",
    "abstract": "We present a machine learning framework to train and validate neural networks to predict the anisotropic elastic response of the monoclinic organic molecular crystal $\\beta$-HMX in the geometrical nonlinear regime. A filtered molecular dynamic (MD) simulations database is used to train the neural networks with a Sobolev norm that uses the stress measure and a reference configuration to deduce the elastic stored energy functional. To improve the accuracy of the elasticity tangent predictions originating from the learned stored energy, a transfer learning technique is used to introduce additional tangential constraints from the data while necessary conditions (e.g. strong ellipticity, crystallographic symmetry) for the correctness of the model are either introduced as additional physical constraints or incorporated in the validation tests. Assessment of the neural networks is based on (1) the accuracy with which they reproduce the bottom-line constitutive responses predicted by MD, (2) detailed examination of their stability and uniqueness, and (3) admissibility of the predicted responses with respect to continuum mechanics theory in the finite-deformation regime. We compare the neural networks' training efficiency under different Sobolev constraints and assess the models' accuracy and robustness against MD benchmarks for $\\beta$-HMX. ",
    "url": "https://arxiv.org/abs/2112.02077",
    "authors": [
      "Nikolaos N. Vlassis",
      "Puhan Zhao",
      "Ran Ma",
      "Tommy Sewell",
      "WaiChing Sun"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.00184",
    "title": "Adversarially learning disentangled speech representations for robust  multi-factor voice conversion",
    "abstract": "Factorizing speech as disentangled speech representations is vital to achieve highly controllable style transfer in voice conversion (VC). Conventional speech representation learning methods in VC only factorize speech as speaker and content, lacking controllability on other prosody-related factors. State-of-the-art speech representation learning methods for more speechfactors are using primary disentangle algorithms such as random resampling and ad-hoc bottleneck layer size adjustment,which however is hard to ensure robust speech representationdisentanglement. To increase the robustness of highly controllable style transfer on multiple factors in VC, we propose a disentangled speech representation learning framework based on adversarial learning. Four speech representations characterizing content, timbre, rhythm and pitch are extracted, and further disentangled by an adversarial Mask-And-Predict (MAP)network inspired by BERT. The adversarial network is used tominimize the correlations between the speech representations,by randomly masking and predicting one of the representationsfrom the others. Experimental results show that the proposedframework significantly improves the robustness of VC on multiple factors by increasing the speech quality MOS from 2.79 to3.30 and decreasing the MCD from 3.89 to 3.58. ",
    "url": "https://arxiv.org/abs/2102.00184",
    "authors": [
      "Jie Wang",
      "Jingbei Li",
      "Xintao Zhao",
      "Zhiyong Wu",
      "Shiyin Kang",
      "Helen Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2112.01587",
    "title": "Quantifying the uncertainty of neural networks using Monte Carlo dropout  for deep learning based quantitative MRI",
    "abstract": "Dropout is conventionally used during the training phase as regularization method and for quantifying uncertainty in deep learning. We propose to use dropout during training as well as inference steps, and average multiple predictions to improve the accuracy, while reducing and quantifying the uncertainty. The results are evaluated for fractional anisotropy (FA) and mean diffusivity (MD) maps which are obtained from only 3 direction scans. With our method, accuracy can be improved significantly compared to network outputs without dropout, especially when the training dataset is small. Moreover, confidence maps are generated which may aid in diagnosis of unseen pathology or artifacts. ",
    "url": "https://arxiv.org/abs/2112.01587",
    "authors": [
      "Mehmet Yigit Avci",
      "Ziyu Li",
      "Qiuyun Fan",
      "Susie Huang",
      "Berkin Bilgic",
      "Qiyuan Tian"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:1908.02572",
    "title": "Multiplex graph matching matched filters",
    "abstract": " Comments: 27 pages, 10 figures ",
    "url": "https://arxiv.org/abs/1908.02572",
    "authors": [
      "Konstantinos Pantazis",
      "Daniel L. Sussman",
      "Youngser Park",
      "Zhirui Li",
      "Carey E. Priebe",
      "Vince Lyzinski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2002.03521",
    "title": "UGRWO-Sampling for COVID-19 dataset: A modified random walk  under-sampling approach based on graphs to imbalanced data classification",
    "abstract": " Comments: 43 pages, 4 figures, 9 tables ",
    "url": "https://arxiv.org/abs/2002.03521",
    "authors": [
      "Saeideh Roshanfekr",
      "Shahriar Esmaeili",
      "Hassan Ataeian",
      "Ali Amiri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.00334",
    "title": "Consistent feature selection for neural networks via Adaptive Group  Lasso",
    "abstract": " Title: Consistent feature selection for neural networks via Adaptive Group  Lasso ",
    "url": "https://arxiv.org/abs/2006.00334",
    "authors": [
      "Vu Dinh",
      "Lam Si Tung Ho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2102.13092",
    "title": "Quantitative approximation results for complex-valued neural networks",
    "abstract": " Title: Quantitative approximation results for complex-valued neural networks ",
    "url": "https://arxiv.org/abs/2102.13092",
    "authors": [
      "A. Caragea",
      "D.G. Lee",
      "J. Maly",
      "G. Pfander",
      "F. Voigtlaender"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.01208",
    "title": "Mind the box: $l_1$-APGD for sparse adversarial attacks on image  classifiers",
    "abstract": " Comments: In ICML 2021 ",
    "url": "https://arxiv.org/abs/2103.01208",
    "authors": [
      "Francesco Croce",
      "Matthias Hein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2103.06168",
    "title": "Towards automated brain aneurysm detection in TOF-MRA: open data, weak  labels, and anatomical knowledge",
    "abstract": " Comments: Paper submitted to a Journal ",
    "url": "https://arxiv.org/abs/2103.06168",
    "authors": [
      "Tommaso Di Noto",
      "Guillaume Marie",
      "Sebastien Tourbier",
      "Yasser Alem\u00e1n-G\u00f3mez",
      "Oscar Esteban",
      "Guillaume Saliou",
      "Meritxell Bach Cuadra",
      "Patric Hagmann",
      "Jonas Richiardi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.06093",
    "title": "A generalized hypothesis test for community structure and homophily in  networks",
    "abstract": " Title: A generalized hypothesis test for community structure and homophily in  networks ",
    "url": "https://arxiv.org/abs/2107.06093",
    "authors": [
      "Eric Yanchenko",
      "Srijan Sengupta"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2109.06152",
    "title": "Enumerating independent sets in Abelian Cayley graphs",
    "abstract": " Comments: 21 pages, fixed minor typos and citations ",
    "url": "https://arxiv.org/abs/2109.06152",
    "authors": [
      "Aditya Potukuchi",
      "Liana Yepremyan"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  }
]