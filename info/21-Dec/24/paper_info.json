[
  {
    "id": "arXiv:2112.12175",
    "title": "Recur, Attend or Convolve? Frame Dependency Modeling Matters for  Cross-Domain Robustness in Action Recognition",
    "abstract": "Most action recognition models today are highly parameterized, and evaluated on datasets with predominantly spatially distinct classes. Previous results for single images have shown that 2D Convolutional Neural Networks (CNNs) tend to be biased toward texture rather than shape for various computer vision tasks (Geirhos et al., 2019), reducing generalization. Taken together, this raises suspicion that large video models learn spurious correlations rather than to track relevant shapes over time and infer generalizable semantics from their movement. A natural way to avoid parameter explosion when learning visual patterns over time is to make use of recurrence across the time-axis. In this article, we empirically study the cross-domain robustness for recurrent, attention-based and convolutional video models, respectively, to investigate whether this robustness is influenced by the frame dependency modeling. Our novel Temporal Shape dataset is proposed as a light-weight dataset to assess the ability to generalize across temporal shapes which are not revealed from single frames. We find that when controlling for performance and layer structure, recurrent models show better out-of-domain generalization ability on the Temporal Shape dataset than convolution- and attention-based models. Moreover, our experiments indicate that convolution- and attention-based models exhibit more texture bias on Diving48 than recurrent models. ",
    "url": "https://arxiv.org/abs/2112.12175",
    "authors": [
      "Sofia Broom\u00e9",
      "Ernest Pokropek",
      "Boyu Li",
      "Hedvig Kjellstr\u00f6m"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12182",
    "title": "Fine-grained Multi-Modal Self-Supervised Learning",
    "abstract": "Multi-Modal Self-Supervised Learning from videos has been shown to improve model's performance on various downstream tasks. However, such Self-Supervised pre-training requires large batch sizes and a large amount of computation resources due to the noise present in the uncurated data. This is partly due to the fact that the prevalent training scheme is trained on coarse-grained setting, in which vectors representing the whole video clips or natural language sentences are used for computing similarity. Such scheme makes training noisy as part of the video clips can be totally not correlated with the other-modality input such as text description. In this paper, we propose a fine-grained multi-modal self-supervised training scheme that computes the similarity between embeddings at finer-scale (such as individual feature map embeddings and embeddings of phrases), and uses attention mechanisms to reduce noisy pairs' weighting in the loss function. We show that with the proposed pre-training scheme, we can train smaller models, with smaller batch-size and much less computational resources to achieve downstream tasks performances comparable to State-Of-The-Art, for tasks including action recognition and text-image retrievals. ",
    "url": "https://arxiv.org/abs/2112.12182",
    "authors": [
      "Duo Wang",
      "Salah Karout"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.12193",
    "title": "Improved 2D Keypoint Detection in Out-of-Balance and Fall Situations --  combining input rotations and a kinematic model",
    "abstract": "Injury analysis may be one of the most beneficial applications of deep learning based human pose estimation. To facilitate further research on this topic, we provide an injury specific 2D dataset for alpine skiing, covering in total 533 images. We further propose a post processing routine, that combines rotational information with a simple kinematic model. We could improve detection results in fall situations by up to 21% regarding the PCK@0.2 metric. ",
    "url": "https://arxiv.org/abs/2112.12193",
    "authors": [
      "Michael Zw\u00f6lfer",
      "Dieter Heinrich",
      "Kurt Schindelwig",
      "Bastian Wandt",
      "Helge Rhodin",
      "Joerg Spoerri",
      "Werner Nachbauer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12232",
    "title": "Electromagnetic Side-Channel Attack Resilience against PRESENT  Lightweight Block Cipher",
    "abstract": "Lightweight cryptography is a novel diversion from conventional cryptography that targets internet-of-things (IoT) platform due to resource constraints. In comparison, it offers smaller cryptographic primitives such as shorter key sizes, block sizes and lesser energy drainage. The main focus can be seen in algorithm developments in this emerging subject. Thus, verification is carried out based upon theoretical (mathematical) proofs mostly. Among the few available side-channel analysis studies found in literature, the highest percentage is taken by power attacks. PRESENT is a promising lightweight block cipher to be included in IoT devices in the near future. Thus, the emphasis of this paper is on lightweight cryptology, and our investigation shows unavailability of a correlation electromagnetic analysis (CEMA) of it. Hence, in an effort to fill in this research gap, we opted to investigate the capabilities of CEMA against the PRESENT algorithm. This work aims to determine the probability of secret key leakage with a minimum number of electromagnetic (EM) waveforms possible. The process initially started from a simple EM analysis (SEMA) and gradually enhanced up to a CEMA. This paper presents our methodology in attack modelling, current results that indicate a probability of leaking seven bytes of the key and upcoming plans for optimisation. In addition, introductions to lightweight cryptanalysis and theories of EMA are also included. ",
    "url": "https://arxiv.org/abs/2112.12232",
    "authors": [
      "Nilupulee A. Gunathilake",
      "Ahmed Al-Dubai",
      "William J. Buchanan",
      "Owen Lo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2112.12251",
    "title": "ML4CO: Is GCNN All You Need? Graph Convolutional Neural Networks Produce  Strong Baselines For Combinatorial Optimization Problems, If Tuned and  Trained Properly, on Appropriate Data",
    "abstract": "The 2021 NeurIPS Machine Learning for Combinatorial Optimization (ML4CO) competition was designed with the goal of improving state-of-the-art combinatorial optimization solvers by replacing key heuristic components with machine learning models. The competition's main scientific question was the following: is machine learning a viable option for improving traditional combinatorial optimization solvers on specific problem distributions, when historical data is available? This was motivated by the fact that in many practical scenarios, the data changes only slightly between the repetitions of a combinatorial optimization problem, and this is an area where machine learning models are particularly powerful at. This paper summarizes the solution and lessons learned by the Huawei EI-OROAS team in the dual task of the competition. The submission of our team achieved the second place in the final ranking, with a very close distance to the first spot. In addition, our solution was ranked first consistently for several weekly leaderboard updates before the final evaluation. We provide insights gained from a large number of experiments, and argue that a simple Graph Convolutional Neural Network (GCNNs) can achieve state-of-the-art results if trained and tuned properly. ",
    "url": "https://arxiv.org/abs/2112.12251",
    "authors": [
      "Amin Banitalebi-Dehkordi",
      "Yong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2112.12252",
    "title": "Leveraging Synthetic Data in Object Detection on Unmanned Aerial  Vehicles",
    "abstract": "Acquiring data to train deep learning-based object detectors on Unmanned Aerial Vehicles (UAVs) is expensive, time-consuming and may even be prohibited by law in specific environments. On the other hand, synthetic data is fast and cheap to access. In this work, we explore the potential use of synthetic data in object detection from UAVs across various application environments. For that, we extend the open-source framework DeepGTAV to work for UAV scenarios. We capture various large-scale high-resolution synthetic data sets in several domains to demonstrate their use in real-world object detection from UAVs by analyzing multiple training strategies across several models. Furthermore, we analyze several different data generation and sampling parameters to provide actionable engineering advice for further scientific research. The DeepGTAV framework is available at https://git.io/Jyf5j. ",
    "url": "https://arxiv.org/abs/2112.12252",
    "authors": [
      "Benjamin Kiefer",
      "David Ott",
      "Andreas Zell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12263",
    "title": "Crash Data Augmentation Using Conditional Generative Adversarial  Networks (CGAN) for Improving Safety Performance Functions",
    "abstract": "In this paper, we present a crash frequency data augmentation method based on Conditional Generative Adversarial Networks to improve crash frequency models. The proposed method is evaluated by comparing the performance of Base SPFs (developed using original data) and Augmented SPFs (developed using original data plus synthesised data) in terms of hotspot identification performance, model prediction accuracy, and dispersion parameter estimation accuracy. The experiments are conducted using simulated and real-world crash data sets. The results indicate that the synthesised crash data by CGAN have the same distribution as the original data and the Augmented SPFs outperforms Base SPFs in almost all aspects especially when the dispersion parameter is low. ",
    "url": "https://arxiv.org/abs/2112.12263",
    "authors": [
      "Mohammad Zarei",
      "Bruce Hellinga"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2112.12268",
    "title": "An algebraic attack on stream ciphers with application to nonlinear  filter generators and WG-PRNG",
    "abstract": "In this paper, we propose a new algebraic attack on stream ciphers. Starting from the well-known attack due to Courtois and Meier, we design an attack especially effective against nonlinear filter generators. We test it on two toy stream ciphers and we show that the level of security of one of stream ciphers submitted to the NIST competition on Lightweight Cryptography, WG-PRNG, is less than that stated before now. ",
    "url": "https://arxiv.org/abs/2112.12268",
    "authors": [
      "Carla Mascia",
      "Enrico Piccione",
      "Massimiliano Sala"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2112.12272",
    "title": "Human Activity Recognition on wrist-worn accelerometers using  self-supervised neural networks",
    "abstract": "Measures of Activity of Daily Living (ADL) are an important indicator of overall health but difficult to measure in-clinic. Automated and accurate human activity recognition (HAR) using wrist-worn accelerometers enables practical and cost efficient remote monitoring of ADL. Key obstacles in developing high quality HAR is the lack of large labeled datasets and the performance loss when applying models trained on small curated datasets to the continuous stream of heterogeneous data in real-life. In this work we design a self-supervised learning paradigm to create a robust representation of accelerometer data that can generalize across devices and subjects. We demonstrate that this representation can separate activities of daily living and achieve strong HAR accuracy (on multiple benchmark datasets) using very few labels. We also propose a segmentation algorithm which can identify segments of salient activity and boost HAR accuracy on continuous real-life data. ",
    "url": "https://arxiv.org/abs/2112.12272",
    "authors": [
      "Niranjan Sridhar",
      "Lance Myers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12297",
    "title": "Batch Processing and Data Streaming Fourier-based Convolutional Neural  Network Accelerator",
    "abstract": "Decision-making by artificial neural networks with minimal latency is paramount for numerous applications such as navigation, tracking, and real-time machine action systems. This requires the machine learning hardware to handle multidimensional data with a high throughput. Processing convolution operations being the major computational tool for data classification tasks, unfortunately, follows a challenging run-time complexity scaling law. However, implementing the convolution theorem homomorphically in a Fourier-optic display-light-processor enables a non-iterative O(1) runtime complexity for data inputs beyond 1,000 x 1,000 large matrices. Following this approach, here we demonstrate data streaming multi-kernel image batch-processing with a Fourier Convolutional Neural Network (FCNN) accelerator. We show image batch processing of large-scale matrices as passive 2-million dot-product multiplications performed by digital light-processing modules in the Fourier domain. In addition, we parallelize this optical FCNN system further by utilizing multiple spatio-parallel diffraction orders, thus achieving a 98-times throughput improvement over state-of-art FCNN accelerators. The comprehensive discussion of the practical challenges related to working on the edge of the system's capabilities highlights issues of crosstalk in the Fourier domain and resolution scaling laws. Accelerating convolutions by utilizing the massive parallelism in display technology brings forth a non-van Neuman-based machine learning acceleration. ",
    "url": "https://arxiv.org/abs/2112.12297",
    "authors": [
      "Zibo Hu",
      "Shurui Li",
      "Russell L.T. Schwartz",
      "Maria Solyanik-Gorgone",
      "Mario Miscuglio",
      "Puneet Gupta",
      "Volker J. Sorger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2112.12299",
    "title": "A Robust Initialization of Residual Blocks for Effective ResNet Training  without Batch Normalization",
    "abstract": "Batch Normalization is an essential component of all state-of-the-art neural networks architectures. However, since it introduces many practical issues, much recent research has been devoted to designing normalization-free architectures. In this paper, we show that weights initialization is key to train ResNet-like normalization-free networks. In particular, we propose a slight modification to the summation operation of a block output to the skip connection branch, so that the whole network is correctly initialized. We show that this modified architecture achieves competitive results on CIFAR-10 without further regularization nor algorithmic modifications. ",
    "url": "https://arxiv.org/abs/2112.12299",
    "authors": [
      "Enrico Civitelli",
      "Alessio Sortino",
      "Matteo Lapucci",
      "Francesco Bagattini",
      "Giulio Galvan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.12310",
    "title": "Adversarial Attacks against Windows PE Malware Detection: A Survey of  the State-of-the-Art",
    "abstract": "The malware has been being one of the most damaging threats to computers that span across multiple operating systems and various file formats. To defend against the ever-increasing and ever-evolving threats of malware, tremendous efforts have been made to propose a variety of malware detection methods that attempt to effectively and efficiently detect malware. Recent studies have shown that, on the one hand, existing ML and DL enable the superior detection of newly emerging and previously unseen malware. However, on the other hand, ML and DL models are inherently vulnerable to adversarial attacks in the form of adversarial examples, which are maliciously generated by slightly and carefully perturbing the legitimate inputs to confuse the targeted models. Basically, adversarial attacks are initially extensively studied in the domain of computer vision, and some quickly expanded to other domains, including NLP, speech recognition and even malware detection. In this paper, we focus on malware with the file format of portable executable (PE) in the family of Windows operating systems, namely Windows PE malware, as a representative case to study the adversarial attack methods in such adversarial settings. To be specific, we start by first outlining the general learning framework of Windows PE malware detection based on ML/DL and subsequently highlighting three unique challenges of performing adversarial attacks in the context of PE malware. We then conduct a comprehensive and systematic review to categorize the state-of-the-art adversarial attacks against PE malware detection, as well as corresponding defenses to increase the robustness of PE malware detection. We conclude the paper by first presenting other related attacks against Windows PE malware detection beyond the adversarial attacks and then shedding light on future research directions and opportunities. ",
    "url": "https://arxiv.org/abs/2112.12310",
    "authors": [
      "Xiang Ling",
      "Lingfei Wu",
      "Jiangyu Zhang",
      "Zhenqing Qu",
      "Wei Deng",
      "Xiang Chen",
      "Chunming Wu",
      "Shouling Ji",
      "Tianyue Luo",
      "Jingzheng Wu",
      "Yanjun Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.12315",
    "title": "A Multi-Objective Degree-Based Network Anonymization Approach",
    "abstract": "Enormous amounts of data collected from social networks or other online platforms are being published for the sake of statistics, marketing, and research, among other objectives. The consequent privacy and data security concerns have motivated the work on degree-based data anonymization. We propose and study a new multi-objective anonymization approach that generalizes the known degree anonymization problem and attempts at improving it as a more realistic model for data security/privacy. Our suggested model guarantees a convenient privacy level based on modifying the degrees in a way that respects some given local restrictions, per node, such that the total modifications at the global level (in the whole graph/network) are bounded by some given value. The corresponding multi-objective graph realization approach is solved using Integer Linear Programming to obtain the best possible solutions. Our experimental studies provide empirical evidence of the effectiveness of the new approach; by specifically showing that the introduced anonymization algorithm has a negligible effect on the way nodes are clustered, thereby preserving valuable network information while significantly improving data privacy. ",
    "url": "https://arxiv.org/abs/2112.12315",
    "authors": [
      "Ola N. Halawi",
      "Faisal N. Abu-Khzam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2112.12316",
    "title": "Signed and Unsigned Partial Information Decompositions of Continuous  Network Interactions",
    "abstract": "We investigate the partial information decomposition (PID) framework as a tool for edge nomination. We consider both the $I_{\\cap}^{\\text{min}}$ and $I_{\\cap}^{\\text{PM}}$ PIDs, from arXiv:1004.2515 and arXiv:1801.09010 respectively, and we both numerically and analytically investigate the utility of these frameworks for discovering significant edge interactions. In the course of our work, we extend both the $I_{\\cap}^{\\text{min}}$ and $I_{\\cap}^{\\text{PM}}$ PIDs to a general class of continuous trivariate systems. Moreover, we examine how each PID apportions information into redundant, synergistic, and unique information atoms within the source-bivariate PID framework. Both our simulation experiments and analytic inquiry indicate that the atoms of the $I_{\\cap}^{\\text{PM}}$ PID have a non-specific sensitivity to high predictor-target mutual information, regardless of whether or not the predictors are truly interacting. By contrast, the $I_{\\cap}^{\\text{min}}$ PID is quite specific, although simulations suggest that it lacks sensitivity. ",
    "url": "https://arxiv.org/abs/2112.12316",
    "authors": [
      "Jesse Milzman",
      "Vince Lyzinski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2112.12321",
    "title": "Physics Constrained Flow Neural Network for Short-Timescale Predictions  in Data Communications Networks",
    "abstract": "Machine learning is gaining growing momentum in various recent models for the dynamic analysis of information flows in data communications networks. These preliminary models often rely on off-the-shelf learning models to predict from historical statistics while disregarding the physics governing the generating behaviors of these flows. This paper instead introduces Flow Neural Network (FlowNN) to improve the feature representation with learned physical bias. This is implemented by an induction layer, working upon the embedding layer, to impose the physics connected data correlations, and a self-supervised learning strategy with stop-gradient to make the learned physics universal. For the short-timescale network prediction tasks, FlowNN achieves 17% - 71% of loss decrease than the state-of-the-art baselines on both synthetic and real-world networking datasets, which shows the strength of this new approach. Code will be made available. ",
    "url": "https://arxiv.org/abs/2112.12321",
    "authors": [
      "Xiangle Cheng",
      "James He",
      "Shihan Xiao",
      "Yingxue Zhang",
      "Zhitang Chen",
      "Pascal Poupart",
      "Fenglin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2112.12326",
    "title": "Age of Information in Energy Harvesting Aided Massive Multiple Access  Networks",
    "abstract": "Given the proliferation of the massive machine type communication devices (MTCDs) in beyond 5G (B5G) wireless networks, energy harvesting (EH) aided next generation multiple access (NGMA) systems have drawn substantial attention in the context of energy-efficient data sensing and transmission. However, without adaptive time slot (TS) and power allocation schemes, NGMA systems relying on stochastic sampling instants might lead to tardy actions associated both with high age of information (AoI) as well as high power consumption. For mitigating the energy consumption, we exploit a pair of sleep-scheduling policies, namely the multiple vacation (MV) policy and start-up threshold (ST) policy, which are characterized in the context of three typical multiple access protocols, including time-division multiple access (TDMA), frequency-division multiple access (FDMA) and non-orthogonal multiple access (NOMA). Furthermore, we derive closed-form expressions for the MTCD system's peak AoI, which are formulated as the optimization objective under the constraints of EH power, status update rate and stability conditions. An exact linear search based algorithm is proposed for finding the optimal solution by fixing the status update rate. As a design alternative, a low complexity concave-convex procedure (CCP) is also formulated for finding a near-optimal solution relying on the original problem's transformation into a form represented by the difference of two convex problems. Our simulation results show that the proposed algorithms are beneficial in terms of yielding a lower peak AoI at a low power consumption in the context of the multiple access protocols considered. ",
    "url": "https://arxiv.org/abs/2112.12326",
    "authors": [
      "Zhengru Fang",
      "Jingjing Wang",
      "Yong Ren",
      "Zhu Han",
      "H. Vincent Poor",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2112.12328",
    "title": "Robust and Precise Facial Landmark Detection by Self-Calibrated Pose  Attention Network",
    "abstract": "Current fully-supervised facial landmark detection methods have progressed rapidly and achieved remarkable performance. However, they still suffer when coping with faces under large poses and heavy occlusions for inaccurate facial shape constraints and insufficient labeled training samples. In this paper, we propose a semi-supervised framework, i.e., a Self-Calibrated Pose Attention Network (SCPAN) to achieve more robust and precise facial landmark detection in challenging scenarios. To be specific, a Boundary-Aware Landmark Intensity (BALI) field is proposed to model more effective facial shape constraints by fusing boundary and landmark intensity field information. Moreover, a Self-Calibrated Pose Attention (SCPA) model is designed to provide a self-learned objective function that enforces intermediate supervision without label information by introducing a self-calibrated mechanism and a pose attention mask. We show that by integrating the BALI fields and SCPA model into a novel self-calibrated pose attention network, more facial prior knowledge can be learned and the detection accuracy and robustness of our method for faces with large poses and heavy occlusions have been improved. The experimental results obtained for challenging benchmark datasets demonstrate that our approach outperforms state-of-the-art methods in the literature. ",
    "url": "https://arxiv.org/abs/2112.12328",
    "authors": [
      "Jun Wan",
      "Hui Xi",
      "Jie Zhou",
      "Zhihui Lai",
      "Witold Pedrycz",
      "Xu Wang",
      "Hang Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12343",
    "title": "Graph attentive feature aggregation for text-independent speaker  verification",
    "abstract": "The objective of this paper is to combine multiple frame-level features into a single utterance-level representation considering pairwise relationship. For this purpose, we propose a novel graph attentive feature aggregation module by interpreting each frame-level feature as a node of a graph. The inter-relationship between all possible pairs of features, typically exploited indirectly, can be directly modeled using a graph. The module comprises a graph attention layer and a graph pooling layer followed by a readout operation. The graph attention layer first models the non-Euclidean data manifold between different nodes. Then, the graph pooling layer discards less informative nodes considering the significance of the nodes. Finally, the readout operation combines the remaining nodes into a single representation. We employ two recent systems, SE-ResNet and RawNet2, with different input features and architectures and demonstrate that the proposed feature aggregation module consistently shows a relative improvement over 10%, compared to the baseline. ",
    "url": "https://arxiv.org/abs/2112.12343",
    "authors": [
      "Hye-jin Shim",
      "Jungwoo Heo",
      "Jae-han Park",
      "Ga-hui Lee",
      "Ha-Jin Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2112.12346",
    "title": "Statistical Feature-based Personal Information Detection in Mobile  Network Traffic",
    "abstract": "With the popularity of smartphones, mobile applications (apps) have penetrated the daily life of people. Although apps provide rich functionalities, they also access a large amount of personal information simultaneously. As a result, privacy concerns are raised. To understand what personal information the apps collect, many solutions are presented to detect privacy leaks in apps. Recently, the traffic monitoring-based privacy leak detection method has shown promising performance and strong scalability. However, it still has some shortcomings. Firstly, it suffers from detecting the leakage of personal information with obfuscation. Secondly, it cannot discover the privacy leaks of undefined type. Aiming at solving the above problems, a new personal information detection method based on traffic monitoring is proposed in this paper. In this paper, statistical features of personal information are designed to depict the occurrence patterns of personal information in the traffic, including local patterns and global patterns. Then a detector is trained based on machine learning algorithms to discover potential personal information with similar patterns. Since the statistical features are independent of the value and type of personal information, the trained detector is capable of identifying various types of privacy leaks and obfuscated privacy leaks. As far as we know, this is the first work that detects personal information based on statistical features. Finally, the experimental results show that the proposed method could achieve better performance than the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2112.12346",
    "authors": [
      "Shuang Zhao",
      "Shuhui Chen",
      "Ziling Wei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.12376",
    "title": "Revisiting and Advancing Fast Adversarial Training Through The Lens of  Bi-Level Optimization",
    "abstract": "Adversarial training (AT) has become a widely recognized defense mechanism to improve the robustness of deep neural networks against adversarial attacks. It solves a min-max optimization problem, where the minimizer (i.e., defender) seeks a robust model to minimize the worst-case training loss in the presence of adversarial examples crafted by the maximizer (i.e., attacker). However, the min-max nature makes AT computationally intensive and thus difficult to scale. Meanwhile, the FAST-AT algorithm, and in fact many recent algorithms that improve AT, simplify the min-max based AT by replacing its maximization step with the simple one-shot gradient sign based attack generation step. Although easy to implement, FAST-AT lacks theoretical guarantees, and its practical performance can be unsatisfactory, suffering from the robustness catastrophic overfitting when training with strong adversaries. In this paper, we propose to design FAST-AT from the perspective of bi-level optimization (BLO). We first make the key observation that the most commonly-used algorithmic specification of FAST-AT is equivalent to using some gradient descent-type algorithm to solve a bi-level problem involving a sign operation. However, the discrete nature of the sign operation makes it difficult to understand the algorithm performance. Based on the above observation, we propose a new tractable bi-level optimization problem, design and analyze a new set of algorithms termed Fast Bi-level AT (FAST-BAT). FAST-BAT is capable of defending sign-based projected gradient descent (PGD) attacks without calling any gradient sign method and explicit robust regularization. Furthermore, we empirically show that our method outperforms state-of-the-art FAST-AT baselines, by achieving superior model robustness without inducing robustness catastrophic overfitting, or suffering from any loss of standard accuracy. ",
    "url": "https://arxiv.org/abs/2112.12376",
    "authors": [
      "Yihua Zhang",
      "Guanhuan Zhang",
      "Prashant Khanduri",
      "Mingyi Hong",
      "Shiyu Chang",
      "Sijia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.12388",
    "title": "Reservoir: Named Data for Pervasive Computation Reuse at the Network  Edge",
    "abstract": "In edge computing use cases (e.g., smart cities), where several users and devices may be in close proximity to each other, computational tasks with similar input data for the same services (e.g., image or video annotation) may be offloaded to the edge. The execution of such tasks often yields the same results (output) and thus duplicate (redundant) computation. Based on this observation, prior work has advocated for \"computation reuse\", a paradigm where the results of previously executed tasks are stored at the edge and are reused to satisfy incoming tasks with similar input data, instead of executing these incoming tasks from scratch. However, realizing computation reuse in practical edge computing deployments, where services may be offered by multiple (distributed) edge nodes (servers) for scalability and fault tolerance, is still largely unexplored. To tackle this challenge, in this paper, we present Reservoir, a framework to enable pervasive computation reuse at the edge, while imposing marginal overheads on user devices and the operation of the edge network infrastructure. Reservoir takes advantage of Locality Sensitive Hashing (LSH) and runs on top of Named-Data Networking (NDN), extending the NDN architecture for the realization of the computation reuse semantics in the network. Our evaluation demonstrated that Reservoir can reuse computation with up to an almost perfect accuracy, achieving 4.25-21.34x lower task completion times compared to cases without computation reuse. ",
    "url": "https://arxiv.org/abs/2112.12388",
    "authors": [
      "Md Washik Al Azad",
      "Spyridon Mastorakis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2112.12389",
    "title": "S+PAGE: A Speaker and Position-Aware Graph Neural Network Model for  Emotion Recognition in Conversation",
    "abstract": "Emotion recognition in conversation (ERC) has attracted much attention in recent years for its necessity in widespread applications. Existing ERC methods mostly model the self and inter-speaker context separately, posing a major issue for lacking enough interaction between them. In this paper, we propose a novel Speaker and Position-Aware Graph neural network model for ERC (S+PAGE), which contains three stages to combine the benefits of both Transformer and relational graph convolution network (R-GCN) for better contextual modeling. Firstly, a two-stream conversational Transformer is presented to extract the coarse self and inter-speaker contextual features for each utterance. Then, a speaker and position-aware conversation graph is constructed, and we propose an enhanced R-GCN model, called PAG, to refine the coarse features guided by a relative positional encoding. Finally, both of the features from the former two stages are input into a conditional random field layer to model the emotion transfer. ",
    "url": "https://arxiv.org/abs/2112.12389",
    "authors": [
      "Chen Liang",
      "Chong Yang",
      "Jing Xu",
      "Juyang Huang",
      "Yongliang Wang",
      "Yang Dong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2112.12390",
    "title": "DD-NeRF: Double-Diffusion Neural Radiance Field as a Generalizable  Implicit Body Representation",
    "abstract": "We present DD-NeRF, a novel generalizable implicit field for representing human body geometry and appearance from arbitrary input views. The core contribution is a double diffusion mechanism, which leverages the sparse convolutional neural network to build two volumes that represent a human body at different levels: a coarse body volume takes advantage of unclothed deformable mesh to provide the large-scale geometric guidance, and a detail feature volume learns the intricate geometry from local image features. We also employ a transformer network to aggregate image features and raw pixels across views, for computing the final high-fidelity radiance field. Experiments on various datasets show that the proposed approach outperforms previous works in both geometry reconstruction and novel view synthesis quality. ",
    "url": "https://arxiv.org/abs/2112.12390",
    "authors": [
      "Guangming Yao",
      "Hongzhi Wu",
      "Yi Yuan",
      "Kun Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12398",
    "title": "Towards Fully Declarative Program Analysis via Source Code  Transformation",
    "abstract": "Advances in logic programming and increasing industrial uptake of Datalog-inspired approaches demonstrate the emerging need to express powerful code analyses more easily. Declarative program analysis frameworks (e.g., using logic programming like Datalog) significantly ease defining analyses compared to imperative implementations. However, the declarative benefits of these frameworks only materialize after parsing and translating source code to generate facts. Fact generation remains a non-declarative precursor to analysis where imperative implementations first parse and interpret program structures (e.g., abstract syntax trees and control-flow graphs). The procedure of fact generation thus remains opaque and difficult for non-experts to understand or modify. We present a new perspective on this analysis workflow by proposing declarative fact generation to ease specification and exploration of lightweight declarative analyses. Our approach demonstrates the first venture towards fully declarative analysis specification across multiple languages. The key idea is to translate source code directly to Datalog facts in the analysis domain using declarative syntax transformation. We then reuse existing Datalog analyses over generated facts, yielding an end-to-end declarative pipeline. As a first approximation we pursue a syntax-driven approach and demonstrate the feasibility of generating and using lightweight versions of liveness and call graph reachability properties. We then discuss the workability of extending declarative fact generation to also incorporate semantic information. ",
    "url": "https://arxiv.org/abs/2112.12398",
    "authors": [
      "Rijnard van Tonder"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2112.12411",
    "title": "Mitigating Leakage from Data Dependent Communications in Decentralized  Computing using Differential Privacy",
    "abstract": "Imagine a group of citizens willing to collectively contribute their personal data for the common good to produce socially useful information, resulting from data analytics or machine learning computations. Sharing raw personal data with a centralized server performing the computation could raise concerns about privacy and a perceived risk of mass surveillance. Instead, citizens may trust each other and their own devices to engage into a decentralized computation to collaboratively produce an aggregate data release to be shared. In the context of secure computing nodes exchanging messages over secure channels at runtime, a key security issue is to protect against external attackers observing the traffic, whose dependence on data may reveal personal information. Existing solutions are designed for the cloud setting, with the goal of hiding all properties of the underlying dataset, and do not address the specific privacy and efficiency challenges that arise in the above context. In this paper, we define a general execution model to control the data-dependence of communications in user-side decentralized computations, in which differential privacy guarantees for communication patterns in global execution plans can be analyzed by combining guarantees obtained on local clusters of nodes. We propose a set of algorithms which allow to trade-off between privacy, utility and efficiency. Our formal privacy guarantees leverage and extend recent results on privacy amplification by shuffling. We illustrate the usefulness of our proposal on two representative examples of decentralized execution plans with data-dependent communications. ",
    "url": "https://arxiv.org/abs/2112.12411",
    "authors": [
      "Riad Ladjel",
      "Nicolas Anciaux",
      "Aur\u00e9lien Bellet",
      "Guillaume Scerri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.12431",
    "title": "Adaptive Modeling Against Adversarial Attacks",
    "abstract": "Adversarial training, the process of training a deep learning model with adversarial data, is one of the most successful adversarial defense methods for deep learning models. We have found that the robustness to white-box attack of an adversarially trained model can be further improved if we fine tune this model in inference stage to adapt to the adversarial input, with the extra information in it. We introduce an algorithm that \"post trains\" the model at inference stage between the original output class and a \"neighbor\" class, with existing training data. The accuracy of pre-trained Fast-FGSM CIFAR10 classifier base model against white-box projected gradient attack (PGD) can be significantly improved from 46.8% to 64.5% with our algorithm. ",
    "url": "https://arxiv.org/abs/2112.12431",
    "authors": [
      "Zhiwen Yan",
      "Teck Khim Ng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12441",
    "title": "TOD-DA: Towards Boosting the Robustness of Task-oriented Dialogue  Modeling on Spoken Conversations",
    "abstract": "Task-oriented dialogue systems have been plagued by the difficulties of obtaining large-scale and high-quality annotated conversations. Furthermore, most of the publicly available datasets only include written conversations, which are insufficient to reflect actual human behaviors in practical spoken dialogue systems. In this paper, we propose Task-oriented Dialogue Data Augmentation (TOD-DA), a novel model-agnostic data augmentation paradigm to boost the robustness of task-oriented dialogue modeling on spoken conversations. The TOD-DA consists of two modules: 1) Dialogue Enrichment to expand training data on task-oriented conversations for easing data sparsity and 2) Spoken Conversation Simulator to imitate oral style expressions and speech recognition errors in diverse granularities for bridging the gap between written and spoken conversations. With such designs, our approach ranked first in both tasks of DSTC10 Track2, a benchmark for task-oriented dialogue modeling on spoken conversations, demonstrating the superiority and effectiveness of our proposed TOD-DA. ",
    "url": "https://arxiv.org/abs/2112.12441",
    "authors": [
      "Xin Tian",
      "Xinxian Huang",
      "Dongfeng He",
      "Yingzhan Lin",
      "Siqi Bao",
      "Huang He",
      "Liankai Huang",
      "Qiang Ju",
      "Xiyuan Zhang",
      "Jian Xie",
      "Shuqi Sun",
      "Fan Wang",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.12445",
    "title": "An analysis of Coggia-Couvreur attack on Loidreau's rank-metric public  key encryption scheme in the general case",
    "abstract": "In this paper we show that in the case where the public-key can be distinguished from a random code in Loidreau's encryption scheme, then Coggia-Couvreur attack can be extended to recover an equivalent secret key. This attack can be conducted in polynomial-time if the masking vector space has dimension 3, thus recovering the results of Ghatak. ",
    "url": "https://arxiv.org/abs/2112.12445",
    "authors": [
      "Pierre Loidreau",
      "Ba-Duc Pham"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2112.12446",
    "title": "Robust error bounds for the Navier-Stokes equations using  implicit-explicit second order BDF method with variable steps",
    "abstract": "This paper studies fully discrete finite element approximations to the Navier-Stokes equations using inf-sup stable elements and grad-div stabilization. For the time integration two implicit-explicit second order backward differentiation formulae (BDF2) schemes are applied. In both the laplacian is implicit while the nonlinear term is explicit, in the first one, and semi-implicit, in the second one. The grad-div stabilization allow us to prove error bounds in which the constants are independent of inverse powers of the viscosity. Error bounds of order $r$ in space are obtained for the $L^2$ error of the velocity using piecewise polynomials of degree $r$ to approximate the velocity together with second order bounds in time, both for fixed time step methods and for methods with variable time steps. A CFL-type condition is needed for the method in which the nonlinear term is explicit relating time step and spatial mesh sizes parameters. ",
    "url": "https://arxiv.org/abs/2112.12446",
    "authors": [
      "Bosco Garcia-Archilla",
      "Julia Novo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2112.12458",
    "title": "Local Advantage Networks for Cooperative Multi-Agent Reinforcement  Learning",
    "abstract": "Multi-agent reinforcement learning (MARL) enables us to create adaptive agents in challenging environments, even when the agents have limited observation. Modern MARL methods have hitherto focused on finding factorized value functions. While this approach has proven successful, the resulting methods have convoluted network structures. We take a radically different approach, and build on the structure of independent Q-learners. Inspired by influence-based abstraction, we start from the observation that compact representations of the observation-action histories can be sufficient to learn close to optimal decentralized policies. Combining this observation with a dueling architecture, our algorithm, LAN, represents these policies as separate individual advantage functions w.r.t. a centralized critic. These local advantage networks condition only on a single agent's local observation-action history. The centralized value function conditions on the agents' representations as well as the full state of the environment. The value function, which is cast aside before execution, serves as a stabilizer that coordinates the learning and to formulate DQN targets during learning. In contrast with other methods, this enables LAN to keep the number of network parameters of its centralized network independent in the number of agents, without imposing additional constraints like monotonic value functions. When evaluated on the StarCraft multi-agent challenge benchmark, LAN shows state-of-the-art performance and scores more than 80% wins in two previously unsolved maps `corridor' and `3s5z_vs_3s6z', leading to an improvement of 10% over QPLEX on average performance on the 14 maps. Moreover when the number of agents becomes large, LAN uses significantly fewer parameters than QPLEX or even QMIX. We thus show that LAN's structure forms a key improvement that helps MARL methods remain scalable. ",
    "url": "https://arxiv.org/abs/2112.12458",
    "authors": [
      "Rapha\u00ebl Avalos",
      "Mathieu Reymond",
      "Ann Now\u00e9",
      "Diederik M. Roijers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.12478",
    "title": "Hierarchical Multi-Building And Multi-Floor Indoor Localization Based On  Recurrent Neural Networks",
    "abstract": "There has been an increasing tendency to move from outdoor to indoor lifestyle in modern cities. The emergence of big shopping malls, indoor sports complexes, factories, and warehouses is accelerating this tendency. In such an environment, indoor localization becomes one of the essential services, and the indoor localization systems to be deployed should be scalable enough to cover the expected expansion of those indoor facilities. One of the most economical and practical approaches to indoor localization is Wi-Fi fingerprinting, which exploits the widely-deployed Wi-Fi networks using mobile devices (e.g., smartphones) without any modification of the existing infrastructure. Traditional Wi-Fi fingerprinting schemes rely on complicated data pre/post-processing and time-consuming manual parameter tuning. In this paper, we propose hierarchical multi-building and multi-floor indoor localization based on a recurrent neural network (RNN) using Wi-Fi fingerprinting, eliminating the need of complicated data pre/post-processing and with less parameter tuning. The RNN in the proposed scheme estimates locations in a sequential manner from a general to a specific one (e.g., building->floor->location) in order to exploit the hierarchical nature of the localization in multi-building and multi-floor environments. The experimental results with the UJIIndoorLoc dataset demonstrate that the proposed scheme estimates building and floor with 100% and 95.24% accuracy, respectively, and provides three-dimensional positioning error of 8.62 m, which outperforms existing deep neural network-based schemes. ",
    "url": "https://arxiv.org/abs/2112.12478",
    "authors": [
      "Abdalla Elmokhtar Ahmed Elesawi",
      "Kyeong Soo Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2112.12517",
    "title": "Adaptive Neural Domain Refinement for Solving Time-Dependent  Differential Equations",
    "abstract": "A classic approach for solving differential equations with neural networks builds upon neural forms, in which a cost function can be constructed directly using the differential equation with a discretisation of the solution domain. Making use of neural forms for time-dependent differential equations, one can apply the recently developed method of domain fragmentation. That is, the domain may be split into several subdomains, on which the optimisation problem is solved. In classic adaptive numerical methods for solving differential equations, the mesh as well as the domain may be refined or decomposed, respectively, in order to improve accuracy. Also the degree of approximation accuracy may be adapted. It would be desirable to transfer such important and successful strategies to the field of neural network based solutions. In the present work, we propose a novel adaptive neural approach to meet this aim for solving time-dependent problems. To this end, each subdomain is reduced in size until the optimisation is resolved up to a predefined training accuracy. In addition, while the neural networks employed are by default small, the number of neurons may also be adjusted in an adaptive way. We introduce conditions to automatically confirm the solution reliability and optimise computational parameters whenever it is necessary. We provide results for three carefully chosen example initial value problems and illustrate important properties of the method alongside. ",
    "url": "https://arxiv.org/abs/2112.12517",
    "authors": [
      "Toni Schneidereit",
      "Michael Breu\u00df"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2112.12522",
    "title": "Data Augmentation based Consistency Contrastive Pre-training for  Automatic Speech Recognition",
    "abstract": "Self-supervised acoustic pre-training has achieved amazing results on the automatic speech recognition (ASR) task. Most of the successful acoustic pre-training methods use contrastive learning to learn the acoustic representations by distinguish the representations from different time steps, ignoring the speaker and environment robustness. As a result, the pre-trained model could show poor performance when meeting out-of-domain data during fine-tuning. In this letter, we design a novel consistency contrastive learning (CCL) method by utilizing data augmentation for acoustic pre-training. Different kinds of augmentation are applied on the original audios and then the augmented audios are fed into an encoder. The encoder should not only contrast the representations within one audio but also maximize the measurement of the representations across different augmented audios. By this way, the pre-trained model can learn a text-related representation method which is more robust with the change of the speaker or the environment.Experiments show that by applying the CCL method on the Wav2Vec2.0, better results can be realized both on the in-domain data and the out-of-domain data. Especially for noisy out-of-domain data, more than 15% relative improvement can be obtained. ",
    "url": "https://arxiv.org/abs/2112.12522",
    "authors": [
      "Changfeng Gao",
      "Gaofeng Cheng",
      "Yifan Guo",
      "Qingwei Zhao",
      "Pengyuan Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2112.12535",
    "title": "FourierMask: Instance Segmentation using Fourier Mapping in Implicit  Neural Networks",
    "abstract": "We present FourierMask, which employs Fourier series combined with implicit neural representations to generate instance segmentation masks. We apply a Fourier mapping (FM) to the coordinate locations and utilize the mapped features as inputs to an implicit representation (coordinate-based multi-layer perceptron (MLP)). FourierMask learns to predict the coefficients of the FM for a particular instance, and therefore adapts the FM to a specific object. This allows FourierMask to be generalized to predict instance segmentation masks from natural images. Since implicit functions are continuous in the domain of input coordinates, we illustrate that by sub-sampling the input pixel coordinates, we can generate higher resolution masks during inference. Furthermore, we train a renderer MLP (FourierRend) on the uncertain predictions of FourierMask and illustrate that it significantly improves the quality of the masks. FourierMask shows competitive results on the MS COCO dataset compared to the baseline Mask R-CNN at the same output resolution and surpasses it on higher resolution. ",
    "url": "https://arxiv.org/abs/2112.12535",
    "authors": [
      "Hamd ul Moqeet Riaz",
      "Nuri Benbarka",
      "Timon Hoeffer",
      "Andreas Zell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.12546",
    "title": "Collaborative adversary nodes learning on the logs of IoT devices in an  IoT network",
    "abstract": "Artificial Intelligence (AI) development has encouraged many new research areas, including AI-enabled Internet of Things (IoT) network. AI analytics and intelligent paradigms greatly improve learning efficiency and accuracy. Applying these learning paradigms to network scenarios provide technical advantages of new networking solutions. In this paper, we propose an improved approach for IoT security from data perspective. The network traffic of IoT devices can be analyzed using AI techniques. The Adversary Learning (AdLIoTLog) model is proposed using Recurrent Neural Network (RNN) with attention mechanism on sequences of network events in the network traffic. We define network events as a sequence of the time series packets of protocols captured in the log. We have considered different packets TCP packets, UDP packets, and HTTP packets in the network log to make the algorithm robust. The distributed IoT devices can collaborate to cripple our world which is extending to Internet of Intelligence. The time series packets are converted into structured data by removing noise and adding timestamps. The resulting data set is trained by RNN and can detect the node pairs collaborating with each other. We used the BLEU score to evaluate the model performance. Our results show that the predicting performance of the AdLIoTLog model trained by our method degrades by 3-4% in the presence of attack in comparison to the scenario when the network is not under attack. AdLIoTLog can detect adversaries because when adversaries are present the model gets duped by the collaborative events and therefore predicts the next event with a biased event rather than a benign event. We conclude that AI can provision ubiquitous learning for the new generation of Internet of Things. ",
    "url": "https://arxiv.org/abs/2112.12546",
    "authors": [
      "Sandhya Aneja",
      "Melanie Ang Xuan En",
      "Nagender Aneja"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2112.12566",
    "title": "Integrating Material Selection with Design Optimization via Neural  Networks",
    "abstract": "The engineering design process often entails optimizing the underlying geometry while simultaneously selecting a suitable material. For a certain class of simple problems, the two are separable where, for example, one can first select an optimal material, and then optimize the geometry. However, in general, the two are not separable. Furthermore, the discrete nature of material selection is not compatible with gradient-based geometry optimization, making simultaneous optimization challenging. In this paper, we propose the use of variational autoencoders (VAE) for simultaneous optimization. First, a data-driven VAE is used to project the discrete material database onto a continuous and differentiable latent space. This is then coupled with a fully-connected neural network, embedded with a finite-element solver, to simultaneously optimize the material and geometry. The neural-network's built-in gradient optimizer and back-propagation are exploited during optimization. The proposed framework is demonstrated using trusses, where an optimal material needs to be chosen from a database, while simultaneously optimizing the cross-sectional areas of the truss members. Several numerical examples illustrate the efficacy of the proposed framework. The Python code used in these experiments is available at github.com/UW-ERSL/MaTruss ",
    "url": "https://arxiv.org/abs/2112.12566",
    "authors": [
      "Aaditya Chandrasekhar",
      "Saketh Sridhara",
      "Krishnan Suresh"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.12573",
    "title": "Boosting Generative Zero-Shot Learning by Synthesizing Diverse Features  with Attribute Augmentation",
    "abstract": "The recent advance in deep generative models outlines a promising perspective in the realm of Zero-Shot Learning (ZSL). Most generative ZSL methods use category semantic attributes plus a Gaussian noise to generate visual features. After generating unseen samples, this family of approaches effectively transforms the ZSL problem into a supervised classification scheme. However, the existing models use a single semantic attribute, which contains the complete attribute information of the category. The generated data also carry the complete attribute information, but in reality, visual samples usually have limited attributes. Therefore, the generated data from attribute could have incomplete semantics. Based on this fact, we propose a novel framework to boost ZSL by synthesizing diverse features. This method uses augmented semantic attributes to train the generative model, so as to simulate the real distribution of visual features. We evaluate the proposed model on four benchmark datasets, observing significant performance improvement against the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2112.12573",
    "authors": [
      "Xiaojie Zhao",
      "Yuming Shen",
      "Shidong Wang",
      "Haofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12577",
    "title": "NVS-MonoDepth: Improving Monocular Depth Prediction with Novel View  Synthesis",
    "abstract": "Building upon the recent progress in novel view synthesis, we propose its application to improve monocular depth estimation. In particular, we propose a novel training method split in three main steps. First, the prediction results of a monocular depth network are warped to an additional view point. Second, we apply an additional image synthesis network, which corrects and improves the quality of the warped RGB image. The output of this network is required to look as similar as possible to the ground-truth view by minimizing the pixel-wise RGB reconstruction error. Third, we reapply the same monocular depth estimation onto the synthesized second view point and ensure that the depth predictions are consistent with the associated ground truth depth. Experimental results prove that our method achieves state-of-the-art or comparable performance on the KITTI and NYU-Depth-v2 datasets with a lightweight and simple vanilla U-Net architecture. ",
    "url": "https://arxiv.org/abs/2112.12577",
    "authors": [
      "Zuria Bauer",
      "Zuoyue Li",
      "Sergio Orts-Escolano",
      "Miguel Cazorla",
      "Marc Pollefeys",
      "Martin R. Oswald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12579",
    "title": "Data-efficient learning for 3D mirror symmetry detection",
    "abstract": "We introduce a geometry-inspired deep learning method for detecting 3D mirror plane from single-view images. We reduce the demand for massive training data by explicitly adding 3D mirror geometry into learning as an inductive prior. We extract semantic features, calculate intra-pixel correlations, and build a 3D correlation volume for each plane. The correlation volume indicates the extent to which the input resembles its mirrors at various depth, allowing us to identify the likelihood of the given plane being a mirror plane. Subsequently, we treat the correlation volumes as feature descriptors for sampled planes and map them to a unit hemisphere where the normal of sampled planes lies. Lastly, we design multi-stage spherical convolutions to identify the optimal mirror plane in a coarse-to-fine manner. Experiments on both synthetic and real-world datasets show the benefit of 3D mirror geometry in improving data efficiency and inference speed (up to 25 FPS). ",
    "url": "https://arxiv.org/abs/2112.12579",
    "authors": [
      "Yancong Lin",
      "Silvia-Laura Pintea",
      "Jan van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12591",
    "title": "Black-Box Testing of Deep Neural Networks through Test Case Diversity",
    "abstract": "Deep Neural Networks (DNNs) have been extensively used in many areas including image processing, medical diagnostics, and autonomous driving. However, DNNs can exhibit erroneous behaviours that may lead to critical errors, especially when used in safety-critical systems. Inspired by testing techniques for traditional software systems, researchers have proposed neuron coverage criteria, as an analogy to source code coverage, to guide the testing of DNN models. Despite very active research on DNN coverage, several recent studies have questioned the usefulness of such criteria in guiding DNN testing. Further, from a practical standpoint, these criteria are white-box as they require access to the internals or training data of DNN models, which is in many contexts not feasible or convenient. In this paper, we investigate black-box input diversity metrics as an alternative to white-box coverage criteria. To this end, we first select and adapt three diversity metrics and study, in a controlled manner, their capacity to measure actual diversity in input sets. We then analyse their statistical association with fault detection using two datasets and three DNN models. We further compare diversity with state-of-the-art white-box coverage criteria. Our experiments show that relying on the diversity of image features embedded in test input sets is a more reliable indicator than coverage criteria to effectively guide the testing of DNNs. Indeed, we found that one of our selected black-box diversity metrics far outperforms existing coverage criteria in terms of fault-revealing capability and computational time. Results also confirm the suspicions that state-of-the-art coverage metrics are not adequate to guide the construction of test input sets to detect as many faults as possible with natural inputs. ",
    "url": "https://arxiv.org/abs/2112.12591",
    "authors": [
      "Zohreh Aghababaeyan",
      "Manel Abdellatif",
      "Lionel Briand",
      "Ramesh S",
      "Mojtaba Bagherzadeh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.12595",
    "title": "KGSecConfig: A Knowledge Graph Based Approach for Secured Container  Orchestrator Configuration",
    "abstract": "Container Orchestrator (CO) is a vital technology for managing clusters of containers, which may form a virtualized infrastructure for developing and operating software systems. Like any other software system, securing CO is critical, but can be quite challenging task due to large number of configurable options. Manual configuration is not only knowledge intensive and time consuming, but also is error prone. For automating security configuration of CO, we propose a novel Knowledge Graph based Security Configuration, KGSecConfig, approach. Our solution leverages keyword and learning models to systematically capture, link, and correlate heterogeneous and multi-vendor configuration space in a unified structure for supporting automation of security configuration of CO. We implement KGSecConfig on Kubernetes, Docker, Azure, and VMWare to build secured configuration knowledge graph. Our evaluation results show 0.98 and 0.94 accuracy for keyword and learning-based secured configuration option and concept extraction, respectively. We also demonstrate the utilization of the knowledge graph for automated misconfiguration mitigation in a Kubernetes cluster. We assert that our knowledge graph based approach can help in addressing several challenges, e.g., misconfiguration of security, associated with manually configuring the security of CO. ",
    "url": "https://arxiv.org/abs/2112.12595",
    "authors": [
      "Mubin Ul Haque",
      "M. Mehdi Kholoosi",
      "M. Ali Babar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2112.12606",
    "title": "Towards Universal GAN Image Detection",
    "abstract": "The ever higher quality and wide diffusion of fake images have spawn a quest for reliable forensic tools. Many GAN image detectors have been proposed, recently. In real world scenarios, however, most of them show limited robustness and generalization ability. Moreover, they often rely on side information not available at test time, that is, they are not universal. We investigate these problems and propose a new GAN image detector based on a limited sub-sampling architecture and a suitable contrastive learning paradigm. Experiments carried out in challenging conditions prove the proposed method to be a first step towards universal GAN image detection, ensuring also good robustness to common image impairments, and good generalization to unseen architectures. ",
    "url": "https://arxiv.org/abs/2112.12606",
    "authors": [
      "Davide Cozzolino",
      "Diego Gragnaniello",
      "Giovanni Poggi",
      "Luisa Verdoliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12625",
    "title": "Comparison and Analysis of Image-to-Image Generative Adversarial  Networks: A Survey",
    "abstract": "Generative Adversarial Networks (GANs) have recently introduced effective methods of performing Image-to-Image translations. These models can be applied and generalized to a variety of domains in Image-to-Image translation without changing any parameters. In this paper, we survey and analyze eight Image-to-Image Generative Adversarial Networks: Pix2Px, CycleGAN, CoGAN, StarGAN, MUNIT, StarGAN2, DA-GAN, and Self Attention GAN. Each of these models presented state-of-the-art results and introduced new techniques to build Image-to-Image GANs. In addition to a survey of the models, we also survey the 18 datasets they were trained on and the 9 metrics they were evaluated on. Finally, we present results of a controlled experiment for 6 of these models on a common set of metrics and datasets. The results were mixed and showed that on certain datasets, tasks, and metrics some models outperformed others. The last section of this paper discusses those results and establishes areas of future research. As researchers continue to innovate new Image-to-Image GANs, it is important that they gain a good understanding of the existing methods, datasets, and metrics. This paper provides a comprehensive overview and discussion to help build this foundation. ",
    "url": "https://arxiv.org/abs/2112.12625",
    "authors": [
      "Sagar Saxena",
      "Mohammad Nayeem Teli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12630",
    "title": "A Survey of Near-Data Processing Architectures for Neural Networks",
    "abstract": "Data-intensive workloads and applications, such as machine learning (ML), are fundamentally limited by traditional computing systems based on the von-Neumann architecture. As data movement operations and energy consumption become key bottlenecks in the design of computing systems, the interest in unconventional approaches such as Near-Data Processing (NDP), machine learning, and especially neural network (NN)-based accelerators has grown significantly. Emerging memory technologies, such as ReRAM and 3D-stacked, are promising for efficiently architecting NDP-based accelerators for NN due to their capabilities to work as both: High-density/low-energy storage and in/near-memory computation/search engine. In this paper, we present a survey of techniques for designing NDP architectures for NN. By classifying the techniques based on the memory technology employed, we underscore their similarities and differences. Finally, we discuss open challenges and future perspectives that need to be explored in order to improve and extend the adoption of NDP architectures for future computing platforms. This paper will be valuable for computer architects, chip designers and researchers in the area of machine learning. ",
    "url": "https://arxiv.org/abs/2112.12630",
    "authors": [
      "Mehdi Hassanpour",
      "Marc Riera",
      "Antonio Gonz\u00e1lez"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.12670",
    "title": "The interplay between ranking and communities in networks",
    "abstract": "Community detection and hierarchy extraction are usually thought of as separate inference tasks on networks. Considering only one of the two when studying real-world data can be an oversimplification. In this work, we present a generative model based on an interplay between community and hierarchical structures. It assumes that each node has a preference in the interaction mechanism and nodes with the same preference are more likely to interact, while heterogeneous interactions are still allowed. The algorithmic implementation is efficient, as it exploits the sparsity of network datasets. We demonstrate our method on synthetic and real-world data and compare performance with two standard approaches for community detection and ranking extraction. We find that the algorithm accurately retrieves each node's preference in different scenarios and we show that it can distinguish small subsets of nodes that behave differently than the majority. As a consequence, the model can recognise whether a network has an overall preferred interaction mechanism. This is relevant in situations where there is no clear \"a priori\" information about what structure explains the observed network datasets well. Our model allows practitioners to learn this automatically from the data. ",
    "url": "https://arxiv.org/abs/2112.12670",
    "authors": [
      "Laura Iacovissi",
      "Caterina De Bacco"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.12707",
    "title": "Improving Robustness and Uncertainty Modelling in Neural Ordinary  Differential Equations",
    "abstract": "Neural ordinary differential equations (NODE) have been proposed as a continuous depth generalization to popular deep learning models such as Residual networks (ResNets). They provide parameter efficiency and automate the model selection process in deep learning models to some extent. However, they lack the much-required uncertainty modelling and robustness capabilities which are crucial for their use in several real-world applications such as autonomous driving and healthcare. We propose a novel and unique approach to model uncertainty in NODE by considering a distribution over the end-time $T$ of the ODE solver. The proposed approach, latent time NODE (LT-NODE), treats $T$ as a latent variable and apply Bayesian learning to obtain a posterior distribution over $T$ from the data. In particular, we use variational inference to learn an approximate posterior and the model parameters. Prediction is done by considering the NODE representations from different samples of the posterior and can be done efficiently using a single forward pass. As $T$ implicitly defines the depth of a NODE, posterior distribution over $T$ would also help in model selection in NODE. We also propose, adaptive latent time NODE (ALT-NODE), which allow each data point to have a distinct posterior distribution over end-times. ALT-NODE uses amortized variational inference to learn an approximate posterior using inference networks. We demonstrate the effectiveness of the proposed approaches in modelling uncertainty and robustness through experiments on synthetic and several real-world image classification data. ",
    "url": "https://arxiv.org/abs/2112.12707",
    "authors": [
      "Srinivas Anumasa",
      "P.K. Srijith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.12717",
    "title": "Forward Composition Propagation for Explainable Neural Reasoning",
    "abstract": "This paper proposes an algorithm called Forward Composition Propagation (FCP) to explain the predictions of feed-forward neural networks operating on structured pattern recognition problems. In the proposed FCP algorithm, each neuron is described by a composition vector indicating the role of each problem feature in that neuron. Composition vectors are initialized using a given input instance and subsequently propagated through the whole network until we reach the output layer. It is worth mentioning that the algorithm is executed once the network's training network is done. The sign of each composition value indicates whether the corresponding feature excites or inhibits the neuron, while the absolute value quantifies such an impact. Aiming to validate the FCP algorithm's correctness, we develop a case study concerning bias detection in a state-of-the-art problem in which the ground truth is known. The simulation results show that the composition values closely align with the expected behavior of protected features. ",
    "url": "https://arxiv.org/abs/2112.12717",
    "authors": [
      "Isel Grau",
      "Gonzalo N\u00e1poles",
      "Marilyn Bello",
      "Yamisleydi Salgueiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.12728",
    "title": "Latent Time Neural Ordinary Differential Equations",
    "abstract": "Neural ordinary differential equations (NODE) have been proposed as a continuous depth generalization to popular deep learning models such as Residual networks (ResNets). They provide parameter efficiency and automate the model selection process in deep learning models to some extent. However, they lack the much-required uncertainty modelling and robustness capabilities which are crucial for their use in several real-world applications such as autonomous driving and healthcare. We propose a novel and unique approach to model uncertainty in NODE by considering a distribution over the end-time $T$ of the ODE solver. The proposed approach, latent time NODE (LT-NODE), treats $T$ as a latent variable and apply Bayesian learning to obtain a posterior distribution over $T$ from the data. In particular, we use variational inference to learn an approximate posterior and the model parameters. Prediction is done by considering the NODE representations from different samples of the posterior and can be done efficiently using a single forward pass. As $T$ implicitly defines the depth of a NODE, posterior distribution over $T$ would also help in model selection in NODE. We also propose, adaptive latent time NODE (ALT-NODE), which allow each data point to have a distinct posterior distribution over end-times. ALT-NODE uses amortized variational inference to learn an approximate posterior using inference networks. We demonstrate the effectiveness of the proposed approaches in modelling uncertainty and robustness through experiments on synthetic and several real-world image classification data. ",
    "url": "https://arxiv.org/abs/2112.12728",
    "authors": [
      "Srinivas Anumasa",
      "P.K. Srijith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.12761",
    "title": "BANMo: Building Animatable 3D Neural Models from Many Casual Videos",
    "abstract": "Prior work for articulated 3D shape reconstruction often relies on specialized sensors (e.g., synchronized multi-camera systems), or pre-built 3D deformable models (e.g., SMAL or SMPL). Such methods are not able to scale to diverse sets of objects in the wild. We present BANMo, a method that requires neither a specialized sensor nor a pre-defined template shape. BANMo builds high-fidelity, articulated 3D models (including shape and animatable skinning weights) from many monocular casual videos in a differentiable rendering framework. While the use of many videos provides more coverage of camera views and object articulations, they introduce significant challenges in establishing correspondence across scenes with different backgrounds, illumination conditions, etc. Our key insight is to merge three schools of thought; (1) classic deformable shape models that make use of articulated bones and blend skinning, (2) volumetric neural radiance fields (NeRFs) that are amenable to gradient-based optimization, and (3) canonical embeddings that generate correspondences between pixels and an articulated model. We introduce neural blend skinning models that allow for differentiable and invertible articulated deformations. When combined with canonical embeddings, such models allow us to establish dense correspondences across videos that can be self-supervised with cycle consistency. On real and synthetic datasets, BANMo shows higher-fidelity 3D reconstructions than prior works for humans and animals, with the ability to render realistic images from novel viewpoints and poses. Project webpage: banmo-www.github.io . ",
    "url": "https://arxiv.org/abs/2112.12761",
    "authors": [
      "Gengshan Yang",
      "Minh Vo",
      "Natalia Neverova",
      "Deva Ramanan",
      "Andrea Vedaldi",
      "Hanbyul Joo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2112.12768",
    "title": "An Ontological Knowledge Representation for Smart Agriculture",
    "abstract": "In order to provide the agricultural industry with the infrastructure it needs to take advantage of advanced technology, such as big data, the cloud, and the internet of things (IoT); smart farming is a management concept that focuses on providing the infrastructure necessary to track, monitor, automate, and analyse operations. To represent the knowledge extracted from the primary data collected is of utmost importance. An agricultural ontology framework for smart agriculture systems is presented in this study. The knowledge graph is represented as a lattice to capture and perform reasoning on spatio-temporal agricultural data. ",
    "url": "https://arxiv.org/abs/2112.12768",
    "authors": [
      "Bikram Pratim Bhuyan",
      "Ravi Tomar",
      "Maanak Gupta",
      "Amar Ramdane-Cherif"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.12785",
    "title": "NinjaDesc: Content-Concealing Visual Descriptors via Adversarial  Learning",
    "abstract": "In the light of recent analyses on privacy-concerning scene revelation from visual descriptors, we develop descriptors that conceal the input image content. In particular, we propose an adversarial learning framework for training visual descriptors that prevent image reconstruction, while maintaining the matching accuracy. We let a feature encoding network and image reconstruction network compete with each other, such that the feature encoder tries to impede the image reconstruction with its generated descriptors, while the reconstructor tries to recover the input image from the descriptors. The experimental results demonstrate that the visual descriptors obtained with our method significantly deteriorate the image reconstruction quality with minimal impact on correspondence matching and camera localization performance. ",
    "url": "https://arxiv.org/abs/2112.12785",
    "authors": [
      "Tony Ng",
      "Hyo Jin Kim",
      "Vincent Lee",
      "Daniel Detone",
      "Tsun-Yi Yang",
      "Tianwei Shen",
      "Eddy Ilg",
      "Vassileios Balntas",
      "Krystian Mikolajczyk",
      "Chris Sweeney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12173",
    "title": "Conflict-free coloring on open neighborhoods of claw-free graphs",
    "abstract": "The `Conflict-Free Open (Closed) Neighborhood coloring', abbreviated CFON (CFCN) coloring, of a graph $G$ using $r$ colors is a coloring of the vertices of $G$ such that every vertex sees some color exactly once in its open (closed) neighborhood. The minimum $r$ such that $G$ has a CFON (CFCN) coloring using $r$ colors is called the `CFON chromatic number' (`CFCN chromatic number') of $G$. This is denoted by $\\chi_{CF}^{ON}(G)$ ($\\chi_{CF}^{CN}(G)$). D\\k ebski and Przyby\\l{}o in [J. Graph Theory, 2021] showed that if $G$ is a line graph with maximum degree $\\Delta$, then $\\chi_{CF}^{CN}(G) = O(\\ln \\Delta)$. As an open question, they asked if the result could be extended to claw-free ($K_{1,3}$-free) graphs, which are a superclass of line graphs. For $k\\geq 3$, we show that if $G$ is $K_{1,k}$-free, then $\\chi_{CF}^{ON}(G) = O(k^2\\ln \\Delta)$. Since it is known that the CFCN chromatic number of a graph is at most twice its CFON chromatic number, this answers the question posed by D\\k{e}bski and Przyby\\l{}o. ",
    "url": "https://arxiv.org/abs/2112.12173",
    "authors": [
      "Sriram Bhyravarapu",
      "Subrahmanyam Kalyanasundaram",
      "Rogers Mathew"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2112.12454",
    "title": "Cardinality-constrained Distributionally Robust Portfolio Optimization",
    "abstract": "This paper studies a distributionally robust portfolio optimization model with a cardinality constraint for limiting the number of invested assets. We formulate this model as a mixed-integer semidefinite optimization (MISDO) problem by means of the moment-based uncertainty set of probability distributions of asset returns. To exactly solve large-scale problems, we propose a specialized cutting-plane algorithm that is based on bilevel optimization reformulation. We prove the finite convergence of the algorithm. We also apply a matrix completion technique to lower-level SDO problems to make their problem sizes much smaller. Numerical experiments demonstrate that our cutting-plane algorithm is significantly faster than the state-of-the-art MISDO solver SCIP-SDP. We also show that our portfolio optimization model can achieve good investment performance compared with the conventional mean-variance model. ",
    "url": "https://arxiv.org/abs/2112.12454",
    "authors": [
      "Ken Kobayashi",
      "Yuichi Takano",
      "Kazuhide Nakata"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2112.12474",
    "title": "Generalization capabilities of neural networks in lattice applications",
    "abstract": "In recent years, the use of machine learning has become increasingly popular in the context of lattice field theories. An essential element of such theories is represented by symmetries, whose inclusion in the neural network properties can lead to high reward in terms of performance and generalizability. A fundamental symmetry that usually characterizes physical systems on a lattice with periodic boundary conditions is equivariance under spacetime translations. Here we investigate the advantages of adopting translationally equivariant neural networks in favor of non-equivariant ones. The system we consider is a complex scalar field with quartic interaction on a two-dimensional lattice in the flux representation, on which the networks carry out various regression and classification tasks. Promising equivariant and non-equivariant architectures are identified with a systematic search. We demonstrate that in most of these tasks our best equivariant architectures can perform and generalize significantly better than their non-equivariant counterparts, which applies not only to physical parameters beyond those represented in the training set, but also to different lattice sizes. ",
    "url": "https://arxiv.org/abs/2112.12474",
    "authors": [
      "Srinath Bulusu",
      "Matteo Favoni",
      "Andreas Ipp",
      "David I. M\u00fcller",
      "Daniel Schuh"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.12482",
    "title": "Self-supervised Representation Learning of Neuronal Morphologies",
    "abstract": "Understanding the diversity of cell types and their function in the brain is one of the key challenges in neuroscience. The advent of large-scale datasets has given rise to the need of unbiased and quantitative approaches to cell type classification. We present GraphDINO, a purely data-driven approach to learning a low dimensional representation of the 3D morphology of neurons. GraphDINO is a novel graph representation learning method for spatial graphs utilizing self-supervised learning on transformer models. It smoothly interpolates between attention-based global interaction between nodes and classic graph convolutional processing. We show that this method is able to yield morphological cell type clustering that is comparable to manual feature-based classification and shows a good correspondence to expert-labeled cell types in two different species and cortical areas. Our method is applicable beyond neuroscience in settings where samples in a dataset are graphs and graph-level embeddings are desired. ",
    "url": "https://arxiv.org/abs/2112.12482",
    "authors": [
      "Marissa A. Weis",
      "Laura Pede",
      "Timo L\u00fcddecke",
      "Alexander S. Ecker"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2112.12493",
    "title": "Equivariance and generalization in neural networks",
    "abstract": "The crucial role played by the underlying symmetries of high energy physics and lattice field theories calls for the implementation of such symmetries in the neural network architectures that are applied to the physical system under consideration. In these proceedings, we focus on the consequences of incorporating translational equivariance among the network properties, particularly in terms of performance and generalization. The benefits of equivariant networks are exemplified by studying a complex scalar field theory, on which various regression and classification tasks are examined. For a meaningful comparison, promising equivariant and non-equivariant architectures are identified by means of a systematic search. The results indicate that in most of the tasks our best equivariant architectures can perform and generalize significantly better than their non-equivariant counterparts, which applies not only to physical parameters beyond those represented in the training set, but also to different lattice sizes. ",
    "url": "https://arxiv.org/abs/2112.12493",
    "authors": [
      "Srinath Bulusu",
      "Matteo Favoni",
      "Andreas Ipp",
      "David I. M\u00fcller",
      "Daniel Schuh"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.12555",
    "title": "Optimal learning of high-dimensional classification problems using deep  neural networks",
    "abstract": "We study the problem of learning classification functions from noiseless training samples, under the assumption that the decision boundary is of a certain regularity. We establish universal lower bounds for this estimation problem, for general classes of continuous decision boundaries. For the class of locally Barron-regular decision boundaries, we find that the optimal estimation rates are essentially independent of the underlying dimension and can be realized by empirical risk minimization methods over a suitable class of deep neural networks. These results are based on novel estimates of the $L^1$ and $L^\\infty$ entropies of the class of Barron-regular functions. ",
    "url": "https://arxiv.org/abs/2112.12555",
    "authors": [
      "Philipp Petersen",
      "Felix Voigtlaender"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.12660",
    "title": "InDuDoNet+: A Model-Driven Interpretable Dual Domain Network for Metal  Artifact Reduction in CT Images",
    "abstract": "During the computed tomography (CT) imaging process, metallic implants within patients always cause harmful artifacts, which adversely degrade the visual quality of reconstructed CT images and negatively affect the subsequent clinical diagnosis. For the metal artifact reduction (MAR) task, current deep learning based methods have achieved promising performance. However, most of them share two main common limitations: 1) the CT physical imaging geometry constraint is not comprehensively incorporated into deep network structures; 2) the entire framework has weak interpretability for the specific MAR task; hence, the role of every network module is difficult to be evaluated. To alleviate these issues, in the paper, we construct a novel interpretable dual domain network, termed InDuDoNet+, into which CT imaging process is finely embedded. Concretely, we derive a joint spatial and Radon domain reconstruction model and propose an optimization algorithm with only simple operators for solving it. By unfolding the iterative steps involved in the proposed algorithm into the corresponding network modules, we easily build the InDuDoNet+ with clear interpretability. Furthermore, we analyze the CT values among different tissues, and merge the prior observations into a prior network for our InDuDoNet+, which significantly improve its generalization performance. Comprehensive experiments on synthesized data and clinical data substantiate the superiority of the proposed methods as well as the superior generalization performance beyond the current state-of-the-art (SOTA) MAR methods. Code is available at \\url{https://github.com/hongwang01/InDuDoNet_plus}. ",
    "url": "https://arxiv.org/abs/2112.12660",
    "authors": [
      "Hong Wang",
      "Yuexiang Li",
      "Haimiao Zhang",
      "Deyu Meng",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12665",
    "title": "Omni-Seg: A Single Dynamic Network for Multi-label Renal Pathology Image  Segmentation using Partially Labeled Data",
    "abstract": "Computer-assisted quantitative analysis on Giga-pixel pathology images has provided a new avenue in precision medicine. The innovations have been largely focused on cancer pathology (i.e., tumor segmentation and characterization). In non-cancer pathology, the learning algorithms can be asked to examine more comprehensive tissue types simultaneously, as a multi-label setting. The prior arts typically needed to train multiple segmentation networks in order to match the domain-specific knowledge for heterogeneous tissue types (e.g., glomerular tuft, glomerular unit, proximal tubular, distal tubular, peritubular capillaries, and arteries). In this paper, we propose a dynamic single segmentation network (Omni-Seg) that learns to segment multiple tissue types using partially labeled images (i.e., only one tissue type is labeled for each training image) for renal pathology. By learning from ~150,000 patch-wise pathological images from six tissue types, the proposed Omni-Seg network achieved superior segmentation accuracy and less resource consumption when compared to the previous the multiple-network and multi-head design. In the testing stage, the proposed method obtains \"completely labeled\" tissue segmentation results using only \"partially labeled\" training images. The source code is available at https://github.com/ddrrnn123/Omni-Seg. ",
    "url": "https://arxiv.org/abs/2112.12665",
    "authors": [
      "Ruining Deng",
      "Quan Liu",
      "Can Cui",
      "Zuhayr Asad",
      "Haichun Yang",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2006.04043",
    "title": "SVGA-Net: Sparse Voxel-Graph Attention Network for 3D Object Detection  from Point Clouds",
    "abstract": " Comments: 9 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2006.04043",
    "authors": [
      "Qingdong He",
      "Zhengning Wang",
      "Hao Zeng",
      "Yi Zeng",
      "Yijun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2006.14514",
    "title": "Taming neural networks with TUSLA: Non-convex learning via adaptive  stochastic gradient Langevin algorithms",
    "abstract": " Title: Taming neural networks with TUSLA: Non-convex learning via adaptive  stochastic gradient Langevin algorithms ",
    "url": "https://arxiv.org/abs/2006.14514",
    "authors": [
      "Attila Lovas",
      "Iosif Lytras",
      "Mikl\u00f3s R\u00e1sonyi",
      "Sotirios Sabanis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.07252",
    "title": "Ego2Hands: A Dataset for Egocentric Two-hand Segmentation and Detection",
    "abstract": " Title: Ego2Hands: A Dataset for Egocentric Two-hand Segmentation and Detection ",
    "url": "https://arxiv.org/abs/2011.07252",
    "authors": [
      "Fanqing Lin",
      "Brian Price",
      "Tony Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.13635",
    "title": "Logic Tensor Networks",
    "abstract": " Comments: 68 pages, 28 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2012.13635",
    "authors": [
      "Samy Badreddine",
      "Artur d'Avila Garcez",
      "Luciano Serafini",
      "Michael Spranger"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2104.07001",
    "title": "Burling graphs revisited, part I: New characterizations",
    "abstract": " Comments: 35 pages, 20 figures ",
    "url": "https://arxiv.org/abs/2104.07001",
    "authors": [
      "Pegah Pournajafi",
      "Nicolas Trotignon"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2105.04660",
    "title": "Deletion to Scattered Graph Classes I -- case of finite number of graph  classes",
    "abstract": " Comments: An extended abstract of the paper appeared in IPEC 2020. This version has a new co-author Jari J. H. de Kroon and an extension of our main result for the case when forbidden subgraphs of each class can be infinite, under certain other conditions ",
    "url": "https://arxiv.org/abs/2105.04660",
    "authors": [
      "Ashwin Jacob",
      "Jari J. H. de Kroon",
      "Diptapriyo Majumdar",
      "Venkatesh Raman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2106.10180",
    "title": "Determining when a truncated generalised Reed-Solomon code is Hermitian  self-orthogonal",
    "abstract": " Title: Determining when a truncated generalised Reed-Solomon code is Hermitian  self-orthogonal ",
    "url": "https://arxiv.org/abs/2106.10180",
    "authors": [
      "Simeon Ball",
      "Ricard Vilar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2107.03423",
    "title": "Recurrence-Aware Long-Term Cognitive Network for Explainable Pattern  Classification",
    "abstract": " Title: Recurrence-Aware Long-Term Cognitive Network for Explainable Pattern  Classification ",
    "url": "https://arxiv.org/abs/2107.03423",
    "authors": [
      "Gonzalo N\u00e1poles",
      "Yamisleydi Salgueiro",
      "Isel Grau",
      "Maikel Leon Espinosa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.09137",
    "title": "Eigenvector Centrality and Uniform Dominant Eigenvalue of Graph  Components",
    "abstract": " Comments: 21 pages ",
    "url": "https://arxiv.org/abs/2107.09137",
    "authors": [
      "Collins Anguzu",
      "Christopher Engstr\u00f6m",
      "John Magero Mango",
      "Henry Kasumba",
      "Sergei Silvestrov",
      "Benard Abola"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2108.07481",
    "title": "RRLFSOR: An Efficient Self-Supervised Learning Strategy of Graph  Convolutional Networks",
    "abstract": " Comments: 27 pages ",
    "url": "https://arxiv.org/abs/2108.07481",
    "authors": [
      "Feng Sun",
      "Ajith Kumar V",
      "Guanci Yang",
      "Qikui Zhu",
      "Yiyun Zhang",
      "Ansi Zhang",
      "Dhruv Makwana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.12604",
    "title": "New Pruning Method Based on DenseNet Network for Image Classification",
    "abstract": " Comments: 5 pages, 3 figures, Technologies and Applications of Artificial Intelligence 2021 ",
    "url": "https://arxiv.org/abs/2108.12604",
    "authors": [
      "Rui-Yang Ju",
      "Ting-Yu Lin",
      "Jen-Shiun Chiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.01191",
    "title": "3D-Transformer: Molecular Representation with Transformer in 3D Space",
    "abstract": " Title: 3D-Transformer: Molecular Representation with Transformer in 3D Space ",
    "url": "https://arxiv.org/abs/2110.01191",
    "authors": [
      "Fang Wu",
      "Qiang Zhang",
      "Dragomir Radev",
      "Jiyu Cui",
      "Wen Zhang",
      "Huabin Xing",
      "Ningyu Zhang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.12981",
    "title": "Neural ODE and DAE Modules for Power System Dynamic Component Modeling",
    "abstract": " Comments: 10 pages, 8 figures, 3 table ",
    "url": "https://arxiv.org/abs/2110.12981",
    "authors": [
      "Tannan Xiao",
      "Ying Chen",
      "Tirui He",
      "Huizhe Guan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.15064",
    "title": "Towards Fine-Grained Reasoning for Fake News Detection",
    "abstract": " Comments: Published as a conference paper at AAAI 2022 ",
    "url": "https://arxiv.org/abs/2110.15064",
    "authors": [
      "Yiqiao Jin",
      "Xiting Wang",
      "Ruichao Yang",
      "Yizhou Sun",
      "Wei Wang",
      "Hao Liao",
      "Xing Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.00698",
    "title": "Influential Prototypical Networks for Few Shot Learning: A  Dermatological Case Study",
    "abstract": " Comments: Paper needs revision on data so want to withdraw ",
    "url": "https://arxiv.org/abs/2111.00698",
    "authors": [
      "Ranjana Roy Chowdhury",
      "Deepti R. Bathula"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.07764",
    "title": "Fidelity-Guarantee Entanglement Routing in Quantum Networks",
    "abstract": " Title: Fidelity-Guarantee Entanglement Routing in Quantum Networks ",
    "url": "https://arxiv.org/abs/2111.07764",
    "authors": [
      "Jian Li",
      "Mingjun Wang",
      "Qidong Jia",
      "Kaiping Xue",
      "Nenghai Yu",
      "Qibin Sun",
      "Jun Lu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2111.12493",
    "title": "Time and Memory Efficient Parallel Algorithm for Structural Graph  Summaries and two Extensions to Incremental Summarization and  $k$-Bisimulation for Long $k$-Chaining",
    "abstract": " Title: Time and Memory Efficient Parallel Algorithm for Structural Graph  Summaries and two Extensions to Incremental Summarization and  $k$-Bisimulation for Long $k$-Chaining ",
    "url": "https://arxiv.org/abs/2111.12493",
    "authors": [
      "Till Blume",
      "Jannik Rau",
      "David Richerby",
      "Ansgar Scherp"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2112.01176",
    "title": "Overcoming the Domain Gap in Neural Action Representations",
    "abstract": " Title: Overcoming the Domain Gap in Neural Action Representations ",
    "url": "https://arxiv.org/abs/2112.01176",
    "authors": [
      "Semih G\u00fcnel",
      "Florian Aymanns",
      "Sina Honari",
      "Pavan Ramdya",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.02248",
    "title": "Algorithms for Maximum Internal Spanning Tree Problem for Some Graph  Classes",
    "abstract": " Title: Algorithms for Maximum Internal Spanning Tree Problem for Some Graph  Classes ",
    "url": "https://arxiv.org/abs/2112.02248",
    "authors": [
      "Gopika Sharma",
      "Arti Pandey",
      "Michael C. Wigal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2112.08782",
    "title": "Improved YOLOv5 network for real-time multi-scale traffic sign detection",
    "abstract": " Title: Improved YOLOv5 network for real-time multi-scale traffic sign detection ",
    "url": "https://arxiv.org/abs/2112.08782",
    "authors": [
      "Junfan Wang",
      "Yi Chen",
      "Mingyu Gao",
      "Zhekang Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.08954",
    "title": "Advancing Residual Learning towards Powerful Deep Spiking Neural  Networks",
    "abstract": " Title: Advancing Residual Learning towards Powerful Deep Spiking Neural  Networks ",
    "url": "https://arxiv.org/abs/2112.08954",
    "authors": [
      "Yifan Hu",
      "Yujie Wu",
      "Lei Deng",
      "Guoqi Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.09641",
    "title": "Embedding Graph Convolutional Networks in Recurrent Neural Networks for  Predictive Monitoring",
    "abstract": " Title: Embedding Graph Convolutional Networks in Recurrent Neural Networks for  Predictive Monitoring ",
    "url": "https://arxiv.org/abs/2112.09641",
    "authors": [
      "Efr\u00e9n Rama-Maneiro",
      "Juan C. Vidal",
      "Manuel Lama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.09891",
    "title": "Equilibrated Zeroth-Order Unrolled Deep Networks for Accelerated MRI",
    "abstract": " Comments: 11 figures ",
    "url": "https://arxiv.org/abs/2112.09891",
    "authors": [
      "Zhuo-Xu Cui",
      "Jing Cheng",
      "Qingyong Zhu",
      "Yuanyuan Liu",
      "Sen Jia",
      "Kankan Zhao",
      "Ziwen Ke",
      "Wenqi Huang",
      "Haifeng Wang",
      "Yanjie Zhu",
      "Dong Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2112.10767",
    "title": "GCN-Geo: A Graph Convolution Network-based Fine-grained IP Geolocation  Framework",
    "abstract": " Comments: Under Review ",
    "url": "https://arxiv.org/abs/2112.10767",
    "authors": [
      "Shichang Ding",
      "Xiangyang Luo",
      "Jinwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.11970",
    "title": "Burling graphs revisited, part III: Applications to $\u03c7$-boundedness",
    "abstract": " Comments: 24 pages, 15 figures Some typos fixed in this new version ",
    "url": "https://arxiv.org/abs/2112.11970",
    "authors": [
      "Pegah Pournajafi",
      "Nicolas Trotignon"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  }
]