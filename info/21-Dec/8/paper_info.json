[
  {
    "id": "arXiv:2112.03337",
    "title": "Dense and well-connected subgraph detection in dual networks",
    "abstract": "Dense subgraph discovery is a fundamental problem in graph mining with a wide range of applications \\cite{gionis2015dense}. Despite a large number of applications ranging from computational neuroscience to social network analysis, that take as input a {\\em dual} graph, namely a pair of graphs on the same set of nodes, dense subgraph discovery methods focus on a single graph input with few notable exceptions \\cite{semertzidis2019finding,charikar2018finding,reinthal2016finding,jethava2015finding}. In this work, we focus the following problem: given a pair of graphs $G,H$ on the same set of nodes $V$, how do we find a subset of nodes $S \\subseteq V$ that induces a well-connected subgraph in $G$ and a dense subgraph in $H$? Our formulation generalizes previous research on dual graphs \\cite{Wu+15,WuZLFJZ16,Cui2018}, by enabling the {\\em control} of the connectivity constraint on $G$. We propose a novel mathematical formulation based on $k$-edge connectivity, and prove that it is solvable exactly in polynomial time. We compare our method to state-of-the-art competitors; we find empirically that ranging the connectivity constraint enables the practitioner to obtain insightful information that is otherwise inaccessible. Finally, we show that our proposed mining tool can be used to better understand how users interact on Twitter, and connectivity aspects of human brain networks with and without Autism Spectrum Disorder (ASD). ",
    "url": "https://arxiv.org/abs/2112.03337",
    "authors": [
      "Tianyi Chen",
      "Francesco Bonchi",
      "David Garcia-Soriano",
      "Atsushi Miyauchi",
      "Charalampos E. Tsourakakis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2112.03345",
    "title": "Learning-based synthesis of robust linear time-invariant controllers",
    "abstract": "Recent advances in learning for control allow to synthesize controllers from learned system dynamics and maintain robust stability guarantees. However, no approach is well-suited for training linear time-invariant (LTI) controllers using arbitrary learned models of the dynamics. This article introduces a method to do so. It uses a robust control framework to derive robust stability criteria. It also uses simulated policy rollouts to obtain gradients on the controller parameters, which serve to improve the closed-loop performance. By formulating the stability criteria as penalties with computable gradients, they can be used to guide the controller parameters toward robust stability during gradient descent. The approach is flexible as it does not restrict the type of learned model for the simulated rollouts. The robust control framework ensures that the controller is already robustly stabilizing when first implemented on the actual system and no data is yet collected. It also ensures that the system stays stable in the event of a shift in dynamics, given the system behavior remains within assumed uncertainty bounds. We demonstrate the approach by synthesizing a controller for simulated autonomous lane change maneuvers. This work thus presents a flexible approach to learning robustly stabilizing LTI controllers that take advantage of modern machine learning techniques. ",
    "url": "https://arxiv.org/abs/2112.03345",
    "authors": [
      "Marc-Antoine Beaudoin",
      "Benoit Boulet"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2112.03546",
    "title": "Predicting peer-to-peer and collective social contagion from individual  behaviour",
    "abstract": "Understanding the heterogeneous role of individuals for large-scale information spreading is essential to manage online behaviour as well as its potential offline consequences. To this end, most existing studies from diverse research domains focus on the disproportionate role played by highly-connected \"hub\" individuals. However, we demonstrate here that information spreading in online social media is best understood and predicted by simultaneously uncovering two individual-level behavioural traits: influence and susceptibility. Specifically, we derive a nonlinear network-based algorithm to quantify individuals' influence and susceptibility from multiple spreading event data. By applying the algorithm to large-scale data from Twitter and Weibo, we demonstrate that both individuals' influence and susceptibility are key determinants of peer-to-peer information propagation: neglecting one of the two properties leads to sub-optimal propagation predictions. Besides, we show that both properties are needed to accurately identify superspreaders of information, which challenges common assumptions in studies on influential individuals in social networks. ",
    "url": "https://arxiv.org/abs/2112.03546",
    "authors": [
      "Fang Zhou",
      "Linyuan L\u00fc",
      "Jianguo Liu",
      "Manuel Sebastian Mariani"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2112.03588",
    "title": "A deep language model to predict metabolic network equilibria",
    "abstract": "We show that deep learning models, and especially architectures like the Transformer, originally intended for natural language, can be trained on randomly generated datasets to predict to very high accuracy both the qualitative and quantitative features of metabolic networks. Using standard mathematical techniques, we create large sets (40 million elements) of random networks that can be used to train our models. These trained models can predict network equilibrium on random graphs in more than 99% of cases. They can also generalize to graphs with different structure than those encountered at training. Finally, they can predict almost perfectly the equilibria of a small set of known biological networks. Our approach is both very economical in experimental data and uses only small and shallow deep-learning model, far from the large architectures commonly used in machine translation. Such results pave the way for larger use of deep learning models for problems related to biological networks in key areas such as quantitative systems pharmacology, systems biology, and synthetic biology. ",
    "url": "https://arxiv.org/abs/2112.03588",
    "authors": [
      "Fran\u00e7ois Charton",
      "Amaury Hayat",
      "Sean T. McQuade",
      "Nathaniel J. Merrill",
      "Benedetto Piccoli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.03670",
    "title": "Hybrid Self-Attention NEAT: A novel evolutionary approach to improve the  NEAT algorithm",
    "abstract": "This article presents a \"Hybrid Self-Attention NEAT\" method to improve the original NeuroEvolution of Augmenting Topologies (NEAT) algorithm in high-dimensional inputs. Although the NEAT algorithm has shown a significant result in different challenging tasks, as input representations are high dimensional, it cannot create a well-tuned network. Our study addresses this limitation by using self-attention as an indirect encoding method to select the most important parts of the input. In addition, we improve its overall performance with the help of a hybrid method to evolve the final network weights. The main conclusion is that Hybrid Self- Attention NEAT can eliminate the restriction of the original NEAT. The results indicate that in comparison with evolutionary algorithms, our model can get comparable scores in Atari games with raw pixels input with a much lower number of parameters. ",
    "url": "https://arxiv.org/abs/2112.03670",
    "authors": [
      "Saman Khamesian",
      "Hamed Malek"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.03753",
    "title": "Tell me why! -- Explanations support learning of relational and causal  structure",
    "abstract": "Explanations play a considerable role in human learning, especially in areas thatremain major challenges for AI -- forming abstractions, and learning about the re-lational and causal structure of the world. Here, we explore whether reinforcement learning agents might likewise benefit from explanations. We outline a family of relational tasks that involve selecting an object that is the odd one out in a set (i.e., unique along one of many possible feature dimensions). Odd-one-out tasks require agents to reason over multi-dimensional relationships among a set of objects. We show that agents do not learn these tasks well from reward alone, but achieve >90% performance when they are also trained to generate language explaining object properties or why a choice is correct or incorrect. In further experiments, we show how predicting explanations enables agents to generalize appropriately from ambiguous, causally-confounded training, and even to meta-learn to perform experimental interventions to identify causal structure. We show that explanations help overcome the tendency of agents to fixate on simple features, and explore which aspects of explanations make them most beneficial. Our results suggest that learning from explanations is a powerful principle that could offer a promising path towards training more robust and general machine learning systems. ",
    "url": "https://arxiv.org/abs/2112.03753",
    "authors": [
      "Andrew K. Lampinen",
      "Nicholas A. Roy",
      "Ishita Dasgupta",
      "Stephanie C. Y. Chan",
      "Allison C. Tam",
      "James L. McClelland",
      "Chen Yan",
      "Adam Santoro",
      "Neil C. Rabinowitz",
      "Jane X. Wang",
      "Felix Hill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.03909",
    "title": "Vehicle trajectory prediction works, but not everywhere",
    "abstract": "Vehicle trajectory prediction is nowadays a fundamental pillar of self-driving cars. Both the industry and research communities have acknowledged the need for such a pillar by running public benchmarks. While state-of-the-art methods are impressive, i.e., they have no off-road prediction, their generalization to cities outside of the benchmark is unknown. In this work, we show that those methods do not generalize to new scenes. We present a novel method that automatically generates realistic scenes that cause state-of-the-art models go off-road. We frame the problem through the lens of adversarial scene generation. We promote a simple yet effective generative model based on atomic scene generation functions along with physical constraints. Our experiments show that more than $60\\%$ of the existing scenes from the current benchmarks can be modified in a way to make prediction methods fail (predicting off-road). We further show that (i) the generated scenes are realistic since they do exist in the real world, and (ii) can be used to make existing models robust by 30-40%. Code is available at https://s-attack.github.io/. ",
    "url": "https://arxiv.org/abs/2112.03909",
    "authors": [
      "Mohammadhossein Bahari",
      "Saeed Saadatnejad",
      "Ahmad Rahimi",
      "Mohammad Shaverdikondori",
      "Mohammad Shahidzadeh",
      "Seyed-Mohsen Moosavi-Dezfooli",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.03491",
    "title": "Explicitly antisymmetrized neural network layers for variational Monte  Carlo simulation",
    "abstract": "The combination of neural networks and quantum Monte Carlo methods has arisen as a path forward for highly accurate electronic structure calculations. Previous proposals have combined equivariant neural network layers with an antisymmetric layer to satisfy the antisymmetry requirements of the electronic wavefunction. However, to date it is unclear if one can represent antisymmetric functions of physical interest, and it is difficult to measure the expressiveness of the antisymmetric layer. This work attempts to address this problem by introducing explicitly antisymmetrized universal neural network layers as a diagnostic tool. We first introduce a generic antisymmetric (GA) layer, which we use to replace the entire antisymmetric layer of the highly accurate ansatz known as the FermiNet. We demonstrate that the resulting FermiNet-GA architecture can yield effectively the exact ground state energy for small systems. We then consider a factorized antisymmetric (FA) layer which more directly generalizes the FermiNet by replacing products of determinants with products of antisymmetrized neural networks. Interestingly, the resulting FermiNet-FA architecture does not outperform the FermiNet. This suggests that the sum of products of antisymmetries is a key limiting aspect of the FermiNet architecture. To explore this further, we investigate a slight modification of the FermiNet called the full determinant mode, which replaces each product of determinants with a single combined determinant. The full single-determinant FermiNet closes a large part of the gap between the standard single-determinant FermiNet and FermiNet-GA. Surprisingly, on the nitrogen molecule at a dissociating bond length of 4.0 Bohr, the full single-determinant FermiNet can significantly outperform the standard 64-determinant FermiNet, yielding an energy within 0.4 kcal/mol of the best available computational benchmark. ",
    "url": "https://arxiv.org/abs/2112.03491",
    "authors": [
      "Jeffmin Lin",
      "Gil Goldshlager",
      "Lin Lin"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2011.09218",
    "title": "Modelling imperfect knowledge via location semantics for realistic  privacy risks estimation in trajectory data",
    "abstract": " Title: Modelling imperfect knowledge via location semantics for realistic  privacy risks estimation in trajectory data ",
    "url": "https://arxiv.org/abs/2011.09218",
    "authors": [
      "Stefano Bennati",
      "Aleksandra Kovacevic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2105.04040",
    "title": "Truly shift-equivariant convolutional neural networks with adaptive  polyphase upsampling",
    "abstract": " Title: Truly shift-equivariant convolutional neural networks with adaptive  polyphase upsampling ",
    "url": "https://arxiv.org/abs/2105.04040",
    "authors": [
      "Anadi Chaman",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2106.15577",
    "title": "As easy as APC: overcoming missing data and class imbalance in time  series with self-supervised learning",
    "abstract": " Comments: Accepted to the NeurIPS 2021 Workshop on Self-Supervised Learning: Theory and Practice ",
    "url": "https://arxiv.org/abs/2106.15577",
    "authors": [
      "Fiorella Wever",
      "T. Anderson Keller",
      "Victor Garcia",
      "Laura Symul"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2107.01163",
    "title": "Unveiling the structure of wide flat minima in neural networks",
    "abstract": " Comments: 15 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2107.01163",
    "authors": [
      "Carlo Baldassi",
      "Clarissa Lauditi",
      "Enrico M. Malatesta",
      "Gabriele Perugini",
      "Riccardo Zecchina"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2110.15718",
    "title": "Deep convolutional forest: a dynamic deep ensemble approach for spam  detection in text",
    "abstract": " Title: Deep convolutional forest: a dynamic deep ensemble approach for spam  detection in text ",
    "url": "https://arxiv.org/abs/2110.15718",
    "authors": [
      "Mai A. Shaaban",
      "Yasser F. Hassan",
      "Shawkat K. Guirguis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.04841",
    "title": "First equilibrium reconstruction for ITER with the code NICE",
    "abstract": " Comments: ICFRD2020 ",
    "url": "https://arxiv.org/abs/2111.04841",
    "authors": [
      "Blaise Faugeras",
      "Jacques Blum",
      "Cedric Boulbe"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  }
]