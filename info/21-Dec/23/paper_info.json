[
  {
    "id": "arXiv:2112.11459",
    "title": "Self-Supervised Learning based Monaural Speech Enhancement with  Multi-Task Pre-Training",
    "abstract": "In self-supervised learning, it is challenging to reduce the gap between the enhancement performance on the estimated and target speech signals with existed pre-tasks. In this paper, we propose a multi-task pre-training method to improve the speech enhancement performance with self-supervised learning. Within the pre-training autoencoder (PAE), only a limited set of clean speech signals are required to learn their latent representations. Meanwhile, to solve the limitation of single pre-task, the proposed masking module exploits the dereverberated mask and estimated ratio mask to denoise the mixture as the second pre-task. Different from the PAE, where the target speech signals are estimated, the downstream task autoencoder (DAE) utilizes a large number of unlabeled and unseen reverberant mixtures to generate the estimated mixtures. The trained DAE is shared by the learned representations and masks. Experimental results on a benchmark dataset demonstrate that the proposed method outperforms the state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2112.11459",
    "authors": [
      "Yi Li",
      "Yang Sun",
      "Syed Mohsen Naqvi"
    ],
    "subjectives": [
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2112.11461",
    "title": "Deep Reinforcement Learning for Optimal Power Flow with Renewables Using  Spatial-Temporal Graph Information",
    "abstract": "Renewable energy resources (RERs) have been increasingly integrated into modern power systems, especially in large-scale distribution networks (DNs). In this paper, we propose a deep reinforcement learning (DRL)-based approach to dynamically search for the optimal operation point, i.e., optimal power flow (OPF), in DNs with a high uptake of RERs. Considering uncertainties and voltage fluctuation issues caused by RERs, we formulate OPF into a multi-objective optimization (MOO) problem. To solve the MOO problem, we develop a novel DRL algorithm leveraging the graphical information of the distribution network. Specifically, we employ the state-of-the-art DRL algorithm, i.e., deep deterministic policy gradient (DDPG), to learn an optimal strategy for OPF. Since power flow reallocation in the DN is a consecutive process, where nodes are self-correlated and interrelated in temporal and spatial views, to make full use of DNs' graphical information, we develop a multi-grained attention-based spatial-temporal graph convolution network (MG-ASTGCN) for spatial-temporal graph information extraction, preparing for its sequential DDPG. We validate our proposed DRL-based approach in modified IEEE 33, 69, and 118-bus radial distribution systems (RDSs) and show that our DRL-based approach outperforms other benchmark algorithms. Our experimental results also reveal that MG-ASTGCN can significantly accelerate the DDPG training process and improve DDPG's capability in reallocating power flow for OPF. The proposed DRL-based approach also promotes DNs' stability in the presence of node faults, especially for large-scale DNs. ",
    "url": "https://arxiv.org/abs/2112.11461",
    "authors": [
      "Jinhao Li",
      "Ruichang Zhang",
      "Hao Wang",
      "Zhi Liu",
      "Hongyang Lai",
      "Yanru Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2112.11479",
    "title": "AtteSTNet -- An attention and subword tokenization based approach for  code-switched Hindi-English hate speech detection",
    "abstract": "Recent advancements in technology have led to a boost in social media usage which has ultimately led to large amounts of user-generated data which also includes hateful and offensive speech. The language used in social media is often a combination of English and the native language in the region. In India, Hindi is used predominantly and is often code-switched with English, giving rise to the Hinglish (Hindi+English) language. Various approaches have been made in the past to classify the code-mixed Hinglish hate speech using different machine learning and deep learning-based techniques. However, these techniques make use of recurrence on convolution mechanisms which are computationally expensive and have high memory requirements. Past techniques also make use of complex data processing making the existing techniques very complex and non-sustainable to change in data. We propose a much simpler approach which is not only at par with these complex networks but also exceeds performance with the use of subword tokenization algorithms like BPE and Unigram along with multi-head attention-based technique giving an accuracy of 87.41% and F1 score of 0.851 on standard datasets. Efficient use of BPE and Unigram algorithms help handle the non-conventional Hinglish vocabulary making our technique simple, efficient and sustainable to use in the real world. ",
    "url": "https://arxiv.org/abs/2112.11479",
    "authors": [
      "Vedangi Wagh",
      "Geet Shingi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.11485",
    "title": "On-the-fly Resource-Aware Model Aggregation for Federated Learning in  Heterogeneous Edge",
    "abstract": "Edge computing has revolutionized the world of mobile and wireless networks world thanks to its flexible, secure, and performing characteristics. Lately, we have witnessed the increasing use of it to make more performing the deployment of machine learning (ML) techniques such as federated learning (FL). FL was debuted to improve communication efficiency compared to conventional distributed machine learning (ML). The original FL assumes a central aggregation server to aggregate locally optimized parameters and might bring reliability and latency issues. In this paper, we conduct an in-depth study of strategies to replace this central server by a flying master that is dynamically selected based on the current participants and/or available resources at every FL round of optimization. Specifically, we compare different metrics to select this flying master and assess consensus algorithms to perform the selection. Our results demonstrate a significant reduction of runtime using our flying master FL framework compared to the original FL from measurements results conducted in our EdgeAI testbed and over real 5G networks using an operational edge testbed. ",
    "url": "https://arxiv.org/abs/2112.11485",
    "authors": [
      "Hung T. Nguyen",
      "Roberto Morabito",
      "Kwang Taik Kim",
      "Mung Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2112.11491",
    "title": "Adversarial Neural Networks for Error Correcting Codes",
    "abstract": "Error correcting codes are a fundamental component in modern day communication systems, demanding extremely high throughput, ultra-reliability and low latency. Recent approaches using machine learning (ML) models as the decoders offer both improved performance and great adaptability to unknown environments, where traditional decoders struggle. We introduce a general framework to further boost the performance and applicability of ML models. We propose to combine ML decoders with a competing discriminator network that tries to distinguish between codewords and noisy words, and, hence, guides the decoding models to recover transmitted codewords. Our framework is game-theoretic, motivated by generative adversarial networks (GANs), with the decoder and discriminator competing in a zero-sum game. The decoder learns to simultaneously decode and generate codewords while the discriminator learns to tell the differences between decoded outputs and codewords. Thus, the decoder is able to decode noisy received signals into codewords, increasing the probability of successful decoding. We show a strong connection of our framework with the optimal maximum likelihood decoder by proving that this decoder defines a Nash equilibrium point of our game. Hence, training to equilibrium has a good possibility of achieving the optimal maximum likelihood performance. Moreover, our framework does not require training labels, which are typically unavailable during communications, and, thus, seemingly can be trained online and adapt to channel dynamics. To demonstrate the performance of our framework, we combine it with the very recent neural decoders and show improved performance compared to the original models and traditional decoding algorithms on various codes. ",
    "url": "https://arxiv.org/abs/2112.11491",
    "authors": [
      "Hung T. Nguyen",
      "Steven Bottone",
      "Kwang Taik Kim",
      "Mung Chiang",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2112.11507",
    "title": "Multiple Imputation via Generative Adversarial Network for  High-dimensional Blockwise Missing Value Problems",
    "abstract": "Missing data are present in most real world problems and need careful handling to preserve the prediction accuracy and statistical consistency in the downstream analysis. As the gold standard of handling missing data, multiple imputation (MI) methods are proposed to account for the imputation uncertainty and provide proper statistical inference. In this work, we propose Multiple Imputation via Generative Adversarial Network (MI-GAN), a deep learning-based (in specific, a GAN-based) multiple imputation method, that can work under missing at random (MAR) mechanism with theoretical support. MI-GAN leverages recent progress in conditional generative adversarial neural works and shows strong performance matching existing state-of-the-art imputation methods on high-dimensional datasets, in terms of imputation error. In particular, MI-GAN significantly outperforms other imputation methods in the sense of statistical inference and computational speed. ",
    "url": "https://arxiv.org/abs/2112.11507",
    "authors": [
      "Zongyu Dai",
      "Zhiqi Bu",
      "Qi Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2112.11542",
    "title": "MIA-Former: Efficient and Robust Vision Transformers via Multi-grained  Input-Adaptation",
    "abstract": "ViTs are often too computationally expensive to be fitted onto real-world resource-constrained devices, due to (1) their quadratically increased complexity with the number of input tokens and (2) their overparameterized self-attention heads and model depth. In parallel, different images are of varied complexity and their different regions can contain various levels of visual information, indicating that treating all regions/tokens equally in terms of model complexity is unnecessary while such opportunities for trimming down ViTs' complexity have not been fully explored. To this end, we propose a Multi-grained Input-adaptive Vision Transformer framework dubbed MIA-Former that can input-adaptively adjust the structure of ViTs at three coarse-to-fine-grained granularities (i.e., model depth and the number of model heads/tokens). In particular, our MIA-Former adopts a low-cost network trained with a hybrid supervised and reinforcement training method to skip unnecessary layers, heads, and tokens in an input adaptive manner, reducing the overall computational cost. Furthermore, an interesting side effect of our MIA-Former is that its resulting ViTs are naturally equipped with improved robustness against adversarial attacks over their static counterparts, because MIA-Former's multi-grained dynamic control improves the model diversity similar to the effect of ensemble and thus increases the difficulty of adversarial attacks against all its sub-models. Extensive experiments and ablation studies validate that the proposed MIA-Former framework can effectively allocate computation budgets adaptive to the difficulty of input images meanwhile increase robustness, achieving state-of-the-art (SOTA) accuracy-efficiency trade-offs, e.g., 20% computation savings with the same or even a higher accuracy compared with SOTA dynamic transformer models. ",
    "url": "https://arxiv.org/abs/2112.11542",
    "authors": [
      "Zhongzhi Yu",
      "Yonggan Fu",
      "Sicheng Li",
      "Chaojian Li",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.11594",
    "title": "GCoD: Graph Convolutional Network Acceleration via Dedicated Algorithm  and Accelerator Co-Design",
    "abstract": "Graph Convolutional Networks (GCNs) have emerged as the state-of-the-art graph learning model. However, it can be notoriously challenging to inference GCNs over large graph datasets, limiting their application to large real-world graphs and hindering the exploration of deeper and more sophisticated GCN graphs. This is because real-world graphs can be extremely large and sparse. Furthermore, the node degree of GCNs tends to follow the power-law distribution and therefore have highly irregular adjacency matrices, resulting in prohibitive inefficiencies in both data processing and movement and thus substantially limiting the achievable GCN acceleration efficiency. To this end, this paper proposes a GCN algorithm and accelerator Co-Design framework dubbed GCoD which can largely alleviate the aforementioned GCN irregularity and boost GCNs' inference efficiency. Specifically, on the algorithm level, GCoD integrates a split and conquer GCN training strategy that polarizes the graphs to be either denser or sparser in local neighborhoods without compromising the model accuracy, resulting in graph adjacency matrices that (mostly) have merely two levels of workload and enjoys largely enhanced regularity and thus ease of acceleration. On the hardware level, we further develop a dedicated two-pronged accelerator with a separated engine to process each of the aforementioned denser and sparser workloads, further boosting the overall utilization and acceleration efficiency. Extensive experiments and ablation studies validate that our GCoD consistently reduces the number of off-chip accesses, leading to speedups of 15286x, 294x, 7.8x, and 2.5x as compared to CPUs, GPUs, and prior-art GCN accelerators including HyGCN and AWB-GCN, respectively, while maintaining or even improving the task accuracy. ",
    "url": "https://arxiv.org/abs/2112.11594",
    "authors": [
      "Haoran You",
      "Tong Geng",
      "Yongan Zhang",
      "Ang Li",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.11602",
    "title": "Identifying Mixtures of Bayesian Network Distributions",
    "abstract": "A Bayesian Network is a directed acyclic graph (DAG) on a set of $n$ random variables (identified with the vertices); a Bayesian Network Distribution (BND) is a probability distribution on the rv's that is Markovian on the graph. A finite mixture of such models is the projection on these variables of a BND on the larger graph which has an additional \"hidden\" (or \"latent\") random variable $U$, ranging in $\\{1,\\ldots,k\\}$, and a directed edge from $U$ to every other vertex. Models of this type are fundamental to research in Causal Inference, where $U$ models a confounding effect. One extremely special case has been of longstanding interest in the theory literature: the empty graph. Such a distribution is simply a mixture of $k$ product distributions. A longstanding problem has been, given the joint distribution of a mixture of $k$ product distributions, to identify each of the product distributions, and their mixture weights. Our results are: (1) We improve the sample complexity (and runtime) for identifying mixtures of $k$ product distributions from $\\exp(O(k^2))$ to $\\exp(O(k \\log k))$. This is almost best possible in view of a known $\\exp(\\Omega(k))$ lower bound. (2) We give the first algorithm for the case of non-empty graphs. The complexity for a graph of maximum degree $\\Delta$ is $\\exp(O(k(\\Delta^2 + \\log k)))$. (The above complexities are approximate and suppress dependence on secondary parameters.) ",
    "url": "https://arxiv.org/abs/2112.11602",
    "authors": [
      "Spencer L. Gordon",
      "Bijan Mazaheri",
      "Yuval Rabani",
      "Leonard J. Schulman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.11610",
    "title": "EyePAD++: A Distillation-based approach for joint Eye Authentication and  Presentation Attack Detection using Periocular Images",
    "abstract": "A practical eye authentication (EA) system targeted for edge devices needs to perform authentication and be robust to presentation attacks, all while remaining compute and latency efficient. However, existing eye-based frameworks a) perform authentication and Presentation Attack Detection (PAD) independently and b) involve significant pre-processing steps to extract the iris region. Here, we introduce a joint framework for EA and PAD using periocular images. While a deep Multitask Learning (MTL) network can perform both the tasks, MTL suffers from the forgetting effect since the training datasets for EA and PAD are disjoint. To overcome this, we propose Eye Authentication with PAD (EyePAD), a distillation-based method that trains a single network for EA and PAD while reducing the effect of forgetting. To further improve the EA performance, we introduce a novel approach called EyePAD++ that includes training an MTL network on both EA and PAD data, while distilling the `versatility' of the EyePAD network through an additional distillation step. Our proposed methods outperform the SOTA in PAD and obtain near-SOTA performance in eye-to-eye verification, without any pre-processing. We also demonstrate the efficacy of EyePAD and EyePAD++ in user-to-user verification with PAD across network backbones and image quality. ",
    "url": "https://arxiv.org/abs/2112.11610",
    "authors": [
      "Prithviraj Dhar",
      "Amit Kumar",
      "Kirsten Kaplan",
      "Khushi Gupta",
      "Rakesh Ranjan",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11619",
    "title": "A Convergent ADMM Framework for Efficient Neural Network Training",
    "abstract": "As a well-known optimization framework, the Alternating Direction Method of Multipliers (ADMM) has achieved tremendous success in many classification and regression applications. Recently, it has attracted the attention of deep learning researchers and is considered to be a potential substitute to Gradient Descent (GD). However, as an emerging domain, several challenges remain unsolved, including 1) The lack of global convergence guarantees, 2) Slow convergence towards solutions, and 3) Cubic time complexity with regard to feature dimensions. In this paper, we propose a novel optimization framework to solve a general neural network training problem via ADMM (dlADMM) to address these challenges simultaneously. Specifically, the parameters in each layer are updated backward and then forward so that parameter information in each layer is exchanged efficiently. When the dlADMM is applied to specific architectures, the time complexity of subproblems is reduced from cubic to quadratic via a dedicated algorithm design utilizing quadratic approximations and backtracking techniques. Last but not least, we provide the first proof of convergence to a critical point sublinearly for an ADMM-type method (dlADMM) under mild conditions. Experiments on seven benchmark datasets demonstrate the convergence, efficiency, and effectiveness of our proposed dlADMM algorithm. ",
    "url": "https://arxiv.org/abs/2112.11619",
    "authors": [
      "Junxiang Wang",
      "Hongyi Li",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.11628",
    "title": "SkipNode: On Alleviating Over-smoothing for Deep Graph Convolutional  Networks",
    "abstract": "Over-smoothing is a challenging problem, which degrades the performance of deep graph convolutional networks (GCNs). However, existing studies for alleviating the over-smoothing problem lack either generality or effectiveness. In this paper, we analyze the underlying issues behind the over-smoothing problem, i.e., feature-diversity degeneration, gradient vanishing, and model weights over-decaying. Inspired by this, we propose a simple yet effective plug-and-play module, SkipNode, to alleviate over-smoothing. Specifically, for each middle layer of a GCN model, SkipNode randomly (or based on node degree) selects nodes to skip the convolutional operation by directly feeding their input features to the nonlinear function. Analytically, 1) skipping the convolutional operation prevents the features from losing diversity; and 2) the \"skipped\" nodes enable gradients to be directly passed back, thus mitigating the gradient vanishing and model weights over-decaying issues. To demonstrate the superiority of SkipNode, we conduct extensive experiments on nine popular datasets, including both homophilic and heterophilic graphs, with different graph sizes on two typical tasks: node classification and link prediction. Specifically, 1) SkipNode has strong generalizability of being applied to various GCN-based models on different datasets and tasks; and 2) SkipNode outperforms recent state-of-the-art anti-over-smoothing plug-and-play modules, i.e., DropEdge and DropNode, in different settings. Code will be made publicly available on GitHub. ",
    "url": "https://arxiv.org/abs/2112.11628",
    "authors": [
      "Weigang Lu",
      "Yibing Zhan",
      "Ziyu Guan",
      "Liu Liu",
      "Baosheng Yu",
      "Wei Zhao",
      "Yaming Yang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.11629",
    "title": "Convolutional neural network based on transfer learning for breast  cancer screening",
    "abstract": "Breast cancer is the most common cancer in the world and the most prevalent cause of death among women worldwide. Nevertheless, it is also one of the most treatable malignancies if detected early. In this paper, a deep convolutional neural network-based algorithm is proposed to aid in accurately identifying breast cancer from ultrasonic images. In this algorithm, several neural networks are fused in a parallel architecture to perform the classification process and the voting criteria are applied in the final classification decision between the candidate object classes where the output of each neural network is representing a single vote. Several experiments were conducted on the breast ultrasound dataset consisting of 537 Benign, 360 malignant, and 133 normal images. These experiments show an optimistic result and a capability of the proposed model to outperform many state-of-the-art algorithms on several measures. Using k-fold cross-validation and a bagging classifier ensemble, we achieved an accuracy of 99.5% and a sensitivity of 99.6%. ",
    "url": "https://arxiv.org/abs/2112.11629",
    "authors": [
      "Hussin Ragb",
      "Redha Ali",
      "Elforjani Jera",
      "Nagi Buaossa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.11632",
    "title": "Diformer: Directional Transformer for Neural Machine Translation",
    "abstract": "Autoregressive (AR) and Non-autoregressive (NAR) models have their own superiority on the performance and latency, combining them into one model may take advantage of both. Current combination frameworks focus more on the integration of multiple decoding paradigms with a unified generative model, e.g. Masked Language Model. However, the generalization can be harmful to the performance due to the gap between training objective and inference. In this paper, we aim to close the gap by preserving the original objective of AR and NAR under a unified framework. Specifically, we propose the Directional Transformer (Diformer) by jointly modelling AR and NAR into three generation directions (left-to-right, right-to-left and straight) with a newly introduced direction variable, which works by controlling the prediction of each token to have specific dependencies under that direction. The unification achieved by direction successfully preserves the original dependency assumption used in AR and NAR, retaining both generalization and performance. Experiments on 4 WMT benchmarks demonstrate that Diformer outperforms current united-modelling works with more than 1.5 BLEU points for both AR and NAR decoding, and is also competitive to the state-of-the-art independent AR and NAR models. ",
    "url": "https://arxiv.org/abs/2112.11632",
    "authors": [
      "Minghan Wang",
      "Jiaxin Guo",
      "Yuxia Wang",
      "Daimeng Wei",
      "Hengchao Shang",
      "Chang Su",
      "Yimeng Chen",
      "Yinglu Li",
      "Min Zhang",
      "Shimin Tao",
      "Hao Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.11640",
    "title": "Self-Distillation Mixup Training for Non-autoregressive Neural Machine  Translation",
    "abstract": "Recently, non-autoregressive (NAT) models predict outputs in parallel, achieving substantial improvements in generation speed compared to autoregressive (AT) models. While performing worse on raw data, most NAT models are trained as student models on distilled data generated by AT teacher models, which is known as sequence-level Knowledge Distillation. An effective training strategy to improve the performance of AT models is Self-Distillation Mixup (SDM) Training, which pre-trains a model on raw data, generates distilled data by the pre-trained model itself and finally re-trains a model on the combination of raw data and distilled data. In this work, we aim to view SDM for NAT models, but find directly adopting SDM to NAT models gains no improvements in terms of translation quality. Through careful analysis, we observe the invalidation is correlated to Modeling Diversity and Confirmation Bias between the AT teacher model and the NAT student models. Based on these findings, we propose an enhanced strategy named SDMRT by adding two stages to classic SDM: one is Pre-Rerank on self-distilled data, the other is Fine-Tune on Filtered teacher-distilled data. Our results outperform baselines by 0.6 to 1.2 BLEU on multiple NAT models. As another bonus, for Iterative Refinement NAT models, our methods can outperform baselines within half iteration number, which means 2X acceleration. ",
    "url": "https://arxiv.org/abs/2112.11640",
    "authors": [
      "Jiaxin Guo",
      "Minghan Wang",
      "Daimeng Wei",
      "Hengchao Shang",
      "Yuxia Wang",
      "Zongyao Li",
      "Zhengzhe Yu",
      "Zhanglin Wu",
      "Yimeng Chen",
      "Chang Su",
      "Min Zhang",
      "Lizhi Lei",
      "shimin tao",
      "Hao Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.11642",
    "title": "Joint-training on Symbiosis Networks for Deep Nueral Machine Translation  models",
    "abstract": "Deep encoders have been proven to be effective in improving neural machine translation (NMT) systems, but it reaches the upper bound of translation quality when the number of encoder layers exceeds 18. Worse still, deeper networks consume a lot of memory, making it impossible to train efficiently. In this paper, we present Symbiosis Networks, which include a full network as the Symbiosis Main Network (M-Net) and another shared sub-network with the same structure but less layers as the Symbiotic Sub Network (S-Net). We adopt Symbiosis Networks on Transformer-deep (m-n) architecture and define a particular regularization loss $\\mathcal{L}_{\\tau}$ between the M-Net and S-Net in NMT. We apply joint-training on the Symbiosis Networks and aim to improve the M-Net performance. Our proposed training strategy improves Transformer-deep (12-6) by 0.61, 0.49 and 0.69 BLEU over the baselines under classic training on WMT'14 EN->DE, DE->EN and EN->FR tasks. Furthermore, our Transformer-deep (12-6) even outperforms classic Transformer-deep (18-6). ",
    "url": "https://arxiv.org/abs/2112.11642",
    "authors": [
      "Zhengzhe Yu",
      "Jiaxin Guo",
      "Minghan Wang",
      "Daimeng Wei",
      "Hengchao Shang",
      "Zongyao Li",
      "Zhanglin Wu",
      "Yuxia Wang",
      "Yimeng Chen",
      "Chang Su",
      "Min Zhang",
      "Lizhi Lei",
      "shimin tao",
      "Hao Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.11668",
    "title": "How Should Pre-Trained Language Models Be Fine-Tuned Towards Adversarial  Robustness?",
    "abstract": "The fine-tuning of pre-trained language models has a great success in many NLP fields. Yet, it is strikingly vulnerable to adversarial examples, e.g., word substitution attacks using only synonyms can easily fool a BERT-based sentiment analysis model. In this paper, we demonstrate that adversarial training, the prevalent defense technique, does not directly fit a conventional fine-tuning scenario, because it suffers severely from catastrophic forgetting: failing to retain the generic and robust linguistic features that have already been captured by the pre-trained model. In this light, we propose Robust Informative Fine-Tuning (RIFT), a novel adversarial fine-tuning method from an information-theoretical perspective. In particular, RIFT encourages an objective model to retain the features learned from the pre-trained model throughout the entire fine-tuning process, whereas a conventional one only uses the pre-trained weights for initialization. Experimental results show that RIFT consistently outperforms the state-of-the-arts on two popular NLP tasks: sentiment analysis and natural language inference, under different attacks across various pre-trained language models. ",
    "url": "https://arxiv.org/abs/2112.11668",
    "authors": [
      "Xinhsuai Dong",
      "Luu Anh Tuan",
      "Min Lin",
      "Shuicheng Yan",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.11679",
    "title": "Ghost-dil-NetVLAD: A Lightweight Neural Network for Visual Place  Recognition",
    "abstract": "Visual place recognition (VPR) is a challenging task with the unbalance between enormous computational cost and high recognition performance. Thanks to the practical feature extraction ability of the lightweight convolution neural networks (CNNs) and the train-ability of the vector of locally aggregated descriptors (VLAD) layer, we propose a lightweight weakly supervised end-to-end neural network consisting of a front-ended perception model called GhostCNN and a learnable VLAD layer as a back-end. GhostCNN is based on Ghost modules that are lightweight CNN-based architectures. They can generate redundant feature maps using linear operations instead of the traditional convolution process, making a good trade-off between computation resources and recognition accuracy. To enhance our proposed lightweight model further, we add dilated convolutions to the Ghost module to get features containing more spatial semantic information, improving accuracy. Finally, rich experiments conducted on a commonly used public benchmark and our private dataset validate that the proposed neural network reduces the FLOPs and parameters of VGG16-NetVLAD by 99.04% and 80.16%, respectively. Besides, both models achieve similar accuracy. ",
    "url": "https://arxiv.org/abs/2112.11679",
    "authors": [
      "Qingyuan Gong",
      "Yu Liu",
      "Liqiang Zhang",
      "Renhe Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11684",
    "title": "HP-GNN: Generating High Throughput GNN Training Implementation on  CPU-FPGA Heterogeneous Platform",
    "abstract": "Graph Neural Networks (GNNs) have shown great success in many applications such as recommendation systems, molecular property prediction, traffic prediction, etc. Recently, CPU-FPGA heterogeneous platforms have been used to accelerate many applications by exploiting customizable data path and abundant user-controllable on-chip memory resources of FPGAs. Yet, accelerating and deploying GNN training on such platforms requires not only expertise in hardware design but also substantial development efforts. We propose HP-GNN, a novel framework that generates high throughput GNN training implementations on a given CPU-FPGA platform that can benefit both application developers and machine learning researchers. HP-GNN takes GNN training algorithms, GNN models as the inputs, and automatically performs hardware mapping onto the target CPU-FPGA platform. HP-GNN consists of: (1) data layout and internal representation that reduce the memory traffic and random memory accesses; (2) optimized hardware templates that support various GNN models; (3) a design space exploration engine for automatic hardware mapping; (4) high-level application programming interfaces (APIs) that allows users to specify GNN training with only a handful of lines of code. To evaluate HP-GNN, we experiment with two well-known sampling-based GNN training algorithms and two GNN models. For each training algorithm and model, HP-GNN generates implementation on a state-of-the-art CPU-FPGA platform. Compared with CPU-only and CPU-GPU platforms, experimental results show that the generated implementations achieve $55.67\\times$ and $2.17\\times$ speedup on the average, respectively. Compared with the state-of-the-art GNN training implementations, HP-GNN achieves up to $4.45\\times$ speedup. ",
    "url": "https://arxiv.org/abs/2112.11684",
    "authors": [
      "Yi-Chien Lin",
      "Bingyi Zhang",
      "Viktor Prasanna"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2112.11689",
    "title": "Multi-Centroid Representation Network for Domain Adaptive Person Re-ID",
    "abstract": "Recently, many approaches tackle the Unsupervised Domain Adaptive person re-identification (UDA re-ID) problem through pseudo-label-based contrastive learning. During training, a uni-centroid representation is obtained by simply averaging all the instance features from a cluster with the same pseudo label. However, a cluster may contain images with different identities (label noises) due to the imperfect clustering results, which makes the uni-centroid representation inappropriate. In this paper, we present a novel Multi-Centroid Memory (MCM) to adaptively capture different identity information within the cluster. MCM can effectively alleviate the issue of label noises by selecting proper positive/negative centroids for the query image. Moreover, we further propose two strategies to improve the contrastive learning process. First, we present a Domain-Specific Contrastive Learning (DSCL) mechanism to fully explore intradomain information by comparing samples only from the same domain. Second, we propose Second-Order Nearest Interpolation (SONI) to obtain abundant and informative negative samples. We integrate MCM, DSCL, and SONI into a unified framework named Multi-Centroid Representation Network (MCRN). Extensive experiments demonstrate the superiority of MCRN over state-of-the-art approaches on multiple UDA re-ID tasks and fully unsupervised re-ID tasks. ",
    "url": "https://arxiv.org/abs/2112.11689",
    "authors": [
      "Yuhang Wu",
      "Tengteng Huang",
      "Haotian Yao",
      "Chi Zhang",
      "Yuanjie Shao",
      "Chuchu Han",
      "Changxin Gao",
      "Nong Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11713",
    "title": "High-Accuracy RGB-D Face Recognition via Segmentation-Aware Face Depth  Estimation and Mask-Guided Attention Network",
    "abstract": "Deep learning approaches have achieved highly accurate face recognition by training the models with very large face image datasets. Unlike the availability of large 2D face image datasets, there is a lack of large 3D face datasets available to the public. Existing public 3D face datasets were usually collected with few subjects, leading to the over-fitting problem. This paper proposes two CNN models to improve the RGB-D face recognition task. The first is a segmentation-aware depth estimation network, called DepthNet, which estimates depth maps from RGB face images by including semantic segmentation information for more accurate face region localization. The other is a novel mask-guided RGB-D face recognition model that contains an RGB recognition branch, a depth map recognition branch, and an auxiliary segmentation mask branch with a spatial attention module. Our DepthNet is used to augment a large 2D face image dataset to a large RGB-D face dataset, which is used for training an accurate RGB-D face recognition model. Furthermore, the proposed mask-guided RGB-D face recognition model can fully exploit the depth map and segmentation mask information and is more robust against pose variation than previous methods. Our experimental results show that DepthNet can produce more reliable depth maps from face images with the segmentation mask. Our mask-guided face recognition model outperforms state-of-the-art methods on several public 3D face datasets. ",
    "url": "https://arxiv.org/abs/2112.11713",
    "authors": [
      "Meng-Tzu Chiu",
      "Hsun-Ying Cheng",
      "Chien-Yi Wang",
      "Shang-Hong Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11731",
    "title": "Graph augmented Deep Reinforcement Learning in the GameRLand3D  environment",
    "abstract": "We address planning and navigation in challenging 3D video games featuring maps with disconnected regions reachable by agents using special actions. In this setting, classical symbolic planners are not applicable or difficult to adapt. We introduce a hybrid technique combining a low level policy trained with reinforcement learning and a graph based high level classical planner. In addition to providing human-interpretable paths, the approach improves the generalization performance of an end-to-end approach in unseen maps, where it achieves a 20% absolute increase in success rate over a recurrent end-to-end agent on a point to point navigation task in yet unseen large-scale maps of size 1km x 1km. In an in-depth experimental study, we quantify the limitations of end-to-end Deep RL approaches in vast environments and we also introduce \"GameRLand3D\", a new benchmark and soon to be released environment can generate complex procedural 3D maps for navigation tasks. ",
    "url": "https://arxiv.org/abs/2112.11731",
    "authors": [
      "Edward Beeching",
      "Maxim Peter",
      "Philippe Marcotte",
      "Jilles Debangoye",
      "Olivier Simonin",
      "Joshua Romoff",
      "Christian Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.11734",
    "title": "Investigating Neighborhood Modeling and Asymmetry Preservation in  Digraph Representation Learning",
    "abstract": "Graph Neural Networks (GNNs) traditionally exhibit poor performance for directed graphs (digraphs) due to notable challenges in 1) modeling neighborhoods and 2) preserving asymmetry. In this paper, we address these challenges in traditional GNNs by leveraging hyperbolic collaborative learning from multi-ordered and partitioned neighborhoods, and regularizers inspired by socio-psychological factors. Our resulting formalism, Digraph Hyperbolic Network (D-HYPR) learns node representations in hyperbolic space to avoid structural and semantic distortion of real-world digraphs. We conduct comprehensive experimentation on 4 tasks: link prediction, node classification, sign prediction, and embedding visualization. D-HYPR statistically significantly outperforms the current state of the art on a majority of tasks and datasets, while achieving competitive performance otherwise. Our code and data will be available. ",
    "url": "https://arxiv.org/abs/2112.11734",
    "authors": [
      "Honglu Zhou",
      "Advith Chegu",
      "Samuel Sohn",
      "Mubbasir Kapadia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.11736",
    "title": "An Efficient Pruning Process with Locality Aware Exploration and Dynamic  Graph Editing for Subgraph Matching",
    "abstract": "Subgraph matching is a NP-complete problem that extracts isomorphic embeddings of a query graph $q$ in a data graph $G$. In this paper, we present a framework with three components: Preprocessing, Reordering and Enumeration. While pruning is the core technique for almost all existing subgraph matching solvers, it mainly eliminates unnecessary enumeration over data graph without alternation of query graph. By formulating a problem: Assignment under Conditional Candidate Set(ACCS), which is proven to be equivalent to Subgraph matching problem, we propose Dynamic Graph Editing(DGE) that is for the first time designed to tailor the query graph to achieve pruning effect and performance acceleration. As a result, we proposed DGEE(Dynamic Graph Editing Enumeration), a novel enumeration algorithm combines Dynamic Graph Editing and Failing Set optimization. Our second contribution is proposing fGQL , an optimized version of GQL algorithm, that is utilized during the Preprocessing phase. Extensive experimental results show that the DGEE-based framework can outperform state-of-the-art subgraph matching algorithms. ",
    "url": "https://arxiv.org/abs/2112.11736",
    "authors": [
      "Zite Jiang",
      "Boxiao Liu",
      "Shuai Zhang",
      "Xingzhong Hou",
      "Mengting Yuan",
      "Haihang You"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2112.11790",
    "title": "BEVDet: High-performance Multi-camera 3D Object Detection in  Bird-Eye-View",
    "abstract": "Autonomous driving perceives the surrounding environment for decision making, which is one of the most complicated scenes for visual perception. The great power of paradigm innovation in solving the 2D object detection task inspires us to seek an elegant, feasible, and scalable paradigm for pushing the performance boundary in this area. To this end, we contribute the BEVDet paradigm in this paper. BEVDet is developed by following the principle of detecting the 3D objects in Bird-Eye-View (BEV), where route planning can be handily performed. In this paradigm, four kinds of modules are conducted in succession with different roles: an image-view encoder for encoding feature in image view, a view transformer for feature transformation from image view to BEV, a BEV encoder for further encoding feature in BEV, and a task-specific head for predicting the targets in BEV. We merely reuse the existing modules for constructing BEVDet and make it feasible for multi-camera 3D object detection by constructing an exclusive data augmentation strategy. The proposed paradigm works well in multi-camera 3D object detection and offers a good trade-off between computing budget and performance. BEVDet with 704x256 (1/8 of the competitors) image size scores 29.4% mAP and 38.4% NDS on the nuScenes val set, which is comparable with FCOS3D (i.e., 2008.2 GFLOPs, 1.7 FPS, 29.5% mAP and 37.2% NDS), while requires merely 12% computing budget of 239.4 GFLOPs and runs 4.3 times faster. Scaling up the input size to 1408x512, BEVDet scores 34.9% mAP, and 41.7% NDS, which requires just 601.4 GFLOPs and significantly suppresses FCOS3D by 5.4% mAP and 4.5% NDS. The superior performance of BEVDet tells the magic of paradigm innovation. ",
    "url": "https://arxiv.org/abs/2112.11790",
    "authors": [
      "Junjie Huang",
      "Guan Huang",
      "Zheng Zhu",
      "Dalong Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11798",
    "title": "YOLO-Z: Improving small object detection in YOLOv5 for autonomous  vehicles",
    "abstract": "As autonomous vehicles and autonomous racing rise in popularity, so does the need for faster and more accurate detectors. While our naked eyes are able to extract contextual information almost instantly, even from far away, image resolution and computational resources limitations make detecting smaller objects (that is, objects that occupy a small pixel area in the input image) a genuinely challenging task for machines and a wide-open research field. This study explores how the popular YOLOv5 object detector can be modified to improve its performance in detecting smaller objects, with a particular application in autonomous racing. To achieve this, we investigate how replacing certain structural elements of the model (as well as their connections and other parameters) can affect performance and inference time. In doing so, we propose a series of models at different scales, which we name `YOLO-Z', and which display an improvement of up to 6.9% in mAP when detecting smaller objects at 50% IOU, at the cost of just a 3ms increase in inference time compared to the original YOLOv5. Our objective is to inform future research on the potential of adjusting a popular detector such as YOLOv5 to address specific tasks and provide insights on how specific changes can impact small object detection. Such findings, applied to the broader context of autonomous vehicles, could increase the amount of contextual information available to such systems. ",
    "url": "https://arxiv.org/abs/2112.11798",
    "authors": [
      "Aduen Benjumea",
      "Izzedin Teeti",
      "Fabio Cuzzolin",
      "Andrew Bradley"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11799",
    "title": "Breaching the 2-Approximation Barrier for the Forest Augmentation  Problem",
    "abstract": "The basic goal of survivable network design is to build cheap networks that guarantee the connectivity of certain pairs of nodes despite the failure of a few edges or nodes. A celebrated result by Jain [Combinatorica'01] provides a 2-approximation for a wide class of these problems. However nothing better is known even for very basic special cases, raising the natural question whether any improved approximation factor is possible at all. In this paper we address one of the most basic problems in this family for which 2 is still the best-known approximation factor, the Forest Augmentation Problem (FAP): given an undirected unweighted graph (that w.l.o.g. is a forest) and a collection of extra edges (links), compute a minimum cardinality subset of links whose addition to the graph makes it 2-edge-connected. Several better-than-2 approximation algorithms are known for the special case where the input graph is a tree, a.k.a. the Tree Augmentation Problem (TAP). Recently this was achieved also for the weighted version of TAP, and for the k-edge-connectivity generalization of TAP. These results heavily exploit the fact that the input graph is connected, a condition that does not hold in FAP. In this paper we breach the 2-approximation barrier for FAP. Our result is based on two main ingredients. First, we describe a reduction to the Path Augmentation Problem (PAP), the special case of FAP where the input graph is a collection of disjoint paths. Our reduction is not approximation preserving, however it is sufficiently accurate to improve on a factor 2 approximation. Second, we present a better-than-2 approximation algorithm for PAP, an open problem on its own. Here we exploit a novel notion of implicit credits which might turn out to be helpful in future related work. ",
    "url": "https://arxiv.org/abs/2112.11799",
    "authors": [
      "Fabrizio Grandoni",
      "Afrouz Jabal Ameli",
      "Vera Traub"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2112.11831",
    "title": "Online Graph Algorithms with Predictions",
    "abstract": "Online algorithms with predictions is a popular and elegant framework for bypassing pessimistic lower bounds in competitive analysis. In this model, online algorithms are supplied with future predictions, and the goal is for the competitive ratio to smoothly interpolate between the best offline and online bounds as a function of the prediction error. In this paper, we study online graph problems with predictions. Our contributions are the following: * The first question is defining prediction error. For graph/metric problems, there can be two types of error, locations that are not predicted, and locations that are predicted but the predicted and actual locations do not coincide exactly. We design a novel definition of prediction error called metric error with outliers to simultaneously capture both types of errors, which thereby generalizes previous definitions of error that only capture one of the two error types. * We give a general framework for obtaining online algorithms with predictions that combines, in a \"black box\" fashion, existing online and offline algorithms, under certain technical conditions. To the best of our knowledge, this is the first general-purpose tool for obtaining online algorithms with predictions. * Using our framework, we obtain tight bounds on the competitive ratio of several classical graph problems as a function of metric error with outliers: Steiner tree, Steiner forest, priority Steiner tree/forest, and uncapacitated/capacitated facility location. Both the definition of metric error with outliers and the general framework for combining offline and online algorithms are not specific to the problems that we consider in this paper. We hope that these will be useful for future work in this domain. ",
    "url": "https://arxiv.org/abs/2112.11831",
    "authors": [
      "Yossi Azar",
      "Debmalya Panigrahi",
      "Noam Touitou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2112.11846",
    "title": "A Discriminative Single-Shot Segmentation Network for Visual Object  Tracking",
    "abstract": "Template-based discriminative trackers are currently the dominant tracking paradigm due to their robustness, but are restricted to bounding box tracking and a limited range of transformation models, which reduces their localization accuracy. We propose a discriminative single-shot segmentation tracker -- D3S2, which narrows the gap between visual object tracking and video object segmentation. A single-shot network applies two target models with complementary geometric properties, one invariant to a broad range of transformations, including non-rigid deformations, the other assuming a rigid object to simultaneously achieve robust online target segmentation. The overall tracking reliability is further increased by decoupling the object and feature scale estimation. Without per-dataset finetuning, and trained only for segmentation as the primary output, D3S2 outperforms all published trackers on the recent short-term tracking benchmark VOT2020 and performs very close to the state-of-the-art trackers on the GOT-10k, TrackingNet, OTB100 and LaSoT. D3S2 outperforms the leading segmentation tracker SiamMask on video object segmentation benchmarks and performs on par with top video object segmentation algorithms. ",
    "url": "https://arxiv.org/abs/2112.11846",
    "authors": [
      "Alan Luke\u017ei\u010d",
      "Ji\u0159\u00ed Matas",
      "Matej Kristan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11916",
    "title": "ALP: Data Augmentation using Lexicalized PCFGs for Few-Shot Text  Classification",
    "abstract": "Data augmentation has been an important ingredient for boosting performances of learned models. Prior data augmentation methods for few-shot text classification have led to great performance boosts. However, they have not been designed to capture the intricate compositional structure of natural language. As a result, they fail to generate samples with plausible and diverse sentence structures. Motivated by this, we present the data Augmentation using Lexicalized Probabilistic context-free grammars (ALP) that generates augmented samples with diverse syntactic structures with plausible grammar. The lexicalized PCFG parse trees consider both the constituents and dependencies to produce a syntactic frame that maximizes a variety of word choices in a syntactically preservable manner without specific domain experts. Experiments on few-shot text classification tasks demonstrate that ALP enhances many state-of-the-art classification methods. As a second contribution, we delve into the train-val splitting methodologies when a data augmentation method comes into play. We argue empirically that the traditional splitting of training and validation sets is sub-optimal compared to our novel augmentation-based splitting strategies that further expand the training split with the same number of labeled data. Taken together, our contributions on the data augmentation strategies yield a strong training recipe for few-shot text classification tasks. ",
    "url": "https://arxiv.org/abs/2112.11916",
    "authors": [
      "Hazel Kim",
      "Daecheol Woo",
      "Seong Joon Oh",
      "Jeong-Won Cha",
      "Yo-Sub Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.11929",
    "title": "Meta-Learning and Self-Supervised Pretraining for Real World Image  Translation",
    "abstract": "Recent advances in deep learning, in particular enabled by hardware advances and big data, have provided impressive results across a wide range of computational problems such as computer vision, natural language, or reinforcement learning. Many of these improvements are however constrained to problems with large-scale curated data-sets which require a lot of human labor to gather. Additionally, these models tend to generalize poorly under both slight distributional shifts and low-data regimes. In recent years, emerging fields such as meta-learning or self-supervised learning have been closing the gap between proof-of-concept results and real-life applications of machine learning by extending deep-learning to the semi-supervised and few-shot domains. We follow this line of work and explore spatio-temporal structure in a recently introduced image-to-image translation problem in order to: i) formulate a novel multi-task few-shot image generation benchmark and ii) explore data augmentations in contrastive pre-training for image translation downstream tasks. We present several baselines for the few-shot problem and discuss trade-offs between different approaches. Our code is available at https://github.com/irugina/meta-image-translation. ",
    "url": "https://arxiv.org/abs/2112.11929",
    "authors": [
      "Ileana Rugina",
      "Rumen Dangovski",
      "Mark Veillette",
      "Pooya Khorrami",
      "Brian Cheung",
      "Olga Simek",
      "Marin Solja\u010di\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.11937",
    "title": "Adversarial Deep Reinforcement Learning for Trustworthy Autonomous  Driving Policies",
    "abstract": "Deep reinforcement learning is widely used to train autonomous cars in a simulated environment. Still, autonomous cars are well known for being vulnerable when exposed to adversarial attacks. This raises the question of whether we can train the adversary as a driving agent for finding failure scenarios in autonomous cars, and then retrain autonomous cars with new adversarial inputs to improve their robustness. In this work, we first train and compare adversarial car policy on two custom reward functions to test the driving control decision of autonomous cars in a multi-agent setting. Second, we verify that adversarial examples can be used not only for finding unwanted autonomous driving behavior, but also for helping autonomous driving cars in improving their deep reinforcement learning policies. By using a high fidelity urban driving simulation environment and vision-based driving agents, we demonstrate that the autonomous cars retrained using the adversary player noticeably increase the performance of their driving policies in terms of reducing collision and offroad steering errors. ",
    "url": "https://arxiv.org/abs/2112.11937",
    "authors": [
      "Aizaz Sharif",
      "Dusica Marijan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.11947",
    "title": "Evaluating the Robustness of Deep Reinforcement Learning for Autonomous  and Adversarial Policies in a Multi-agent Urban Driving Environment",
    "abstract": "Deep reinforcement learning is actively used for training autonomous driving agents in a vision-based urban simulated environment. Due to the large availability of various reinforcement learning algorithms, we are still unsure of which one works better while training autonomous cars in single-agent as well as multi-agent driving environments. A comparison of deep reinforcement learning in vision-based autonomous driving will open up the possibilities for training better autonomous car policies. Also, autonomous cars trained on deep reinforcement learning-based algorithms are known for being vulnerable to adversarial attacks, and we have less information on which algorithms would act as a good adversarial agent. In this work, we provide a systematic evaluation and comparative analysis of 6 deep reinforcement learning algorithms for autonomous and adversarial driving in four-way intersection scenario. Specifically, we first train autonomous cars using state-of-the-art deep reinforcement learning algorithms. Second, we test driving capabilities of the trained autonomous policies in single-agent as well as multi-agent scenarios. Lastly, we use the same deep reinforcement learning algorithms to train adversarial driving agents, in order to test the driving performance of autonomous cars and look for possible collision and offroad driving scenarios. We perform experiments by using vision-only high fidelity urban driving simulated environments. ",
    "url": "https://arxiv.org/abs/2112.11947",
    "authors": [
      "Aizaz Sharif",
      "Dusica Marijan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2112.11986",
    "title": "Compromised ACC vehicles can degrade current mixed-autonomy traffic  performance while remaining stealthy against detection",
    "abstract": "We demonstrate that a supply-chain level compromise of the adaptive cruise control (ACC) capability on equipped vehicles can be used to significantly degrade system level performance of current day mixed-autonomy freeway networks. Via a simple threat model which causes random deceleration attacks (RDAs), compromised vehicles create congestion waves in the traffic that decrease average speed and network throughput. We use a detailed and realistic traffic simulation environment to quantify the impacts of the attack on a model of a real high-volume freeway in the United States. We find that the effect of the attack depends both on the level of underlying traffic congestion, and what percentage of ACC vehicles can be compromised. In moderate congestion regimes the attack can degrade mean commuter speed by over 7%. In high density regimes overall network throughput can be reduced by up to 3%. And, in moderate to high congestion regimes, it can cost commuters on the network over 300 USD/km hr. All of these results motivate that the proposed attack is able to significantly degrade performance of the traffic network. We also develop an anomaly detection technique that uses GPS traces on vehicles to identify malicious/compromised vehicles. We employ this technique on data from the simulation experiments and find that it is unable to identify compromised ACCs compared to benign/normal drivers. That is, these attacks are stealthy to detection. Stronger attacks can be accurately labeled as malicious, motivating that there is a limit to how impactful attacks can be before they are no longer stealthy. Finally, we experimentally execute the attack on a real and commercially available ACC vehicle, demonstrating the possible real world feasibility of an RDA. ",
    "url": "https://arxiv.org/abs/2112.11986",
    "authors": [
      "George Gunter",
      "Huichen Li",
      "Avesta Hojjati",
      "Matthew Nice",
      "Matthew Bunting",
      "Carl A. Gunter",
      "Bo Li",
      "Jonathan Sprinkle",
      "Daniel Work"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2112.12001",
    "title": "DA-FDFtNet: Dual Attention Fake Detection Fine-tuning Network to Detect  Various AI-Generated Fake Images",
    "abstract": "Due to the advancement of Generative Adversarial Networks (GAN), Autoencoders, and other AI technologies, it has been much easier to create fake images such as \"Deepfakes\". More recent research has introduced few-shot learning, which uses a small amount of training data to produce fake images and videos more effectively. Therefore, the ease of generating manipulated images and the difficulty of distinguishing those images can cause a serious threat to our society, such as propagating fake information. However, detecting realistic fake images generated by the latest AI technology is challenging due to the reasons mentioned above. In this work, we propose Dual Attention Fake Detection Fine-tuning Network (DA-FDFtNet) to detect the manipulated fake face images from the real face data. Our DA-FDFtNet integrates the pre-trained model with Fine-Tune Transformer, MBblockV3, and a channel attention module to improve the performance and robustness across different types of fake images. In particular, Fine-Tune Transformer consists of multiple numbers of an image-based self-attention module and a down-sampling layer. The channel attention module is also connected with the pre-trained model to capture the fake images feature space. We experiment with our DA-FDFtNet with the FaceForensics++ dataset and various GAN-generated datasets, and we show that our approach outperforms the previous baseline models. ",
    "url": "https://arxiv.org/abs/2112.12001",
    "authors": [
      "Young Oh Bang",
      "Simon S. Woo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12002",
    "title": "Looking Beyond Corners: Contrastive Learning of Visual Representations  for Keypoint Detection and Description Extraction",
    "abstract": "Learnable keypoint detectors and descriptors are beginning to outperform classical hand-crafted feature extraction methods. Recent studies on self-supervised learning of visual representations have driven the increasing performance of learnable models based on deep networks. By leveraging traditional data augmentations and homography transformations, these networks learn to detect corners under adverse conditions such as extreme illumination changes. However, their generalization capabilities are limited to corner-like features detected a priori by classical methods or synthetically generated data. In this paper, we propose the Correspondence Network (CorrNet) that learns to detect repeatable keypoints and to extract discriminative descriptions via unsupervised contrastive learning under spatial constraints. Our experiments show that CorrNet is not only able to detect low-level features such as corners, but also high-level features that represent similar objects present in a pair of input images through our proposed joint guided backpropagation of their latent space. Our approach obtains competitive results under viewpoint changes and achieves state-of-the-art performance under illumination changes. ",
    "url": "https://arxiv.org/abs/2112.12002",
    "authors": [
      "Henrique Siqueira",
      "Patrick Ruhkamp",
      "Ibrahim Halfaoui",
      "Markus Karmann",
      "Onay Urfalioglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12009",
    "title": "Travel Guides for Creative Tourists, Powered by Geotagged Social Media",
    "abstract": "Many modern tourists want to know about everyday life and spend time like a local in a new city. Current tools and guides typically provide them with lists of sights to see, which do not meet their needs. Manually building new tools for them would not scale. However, public geotagged social media data, like tweets and photos, have the potential to fill this gap, showing users an interesting and unique side of a place. Through three studies surrounding the design and construction of a social-media-powered Neighborhood Guides website, we show recommendations for building such a site. Our findings highlight an important aspect of social media: while it lacks the user base and consistency to directly reflect users' lives, it does reveal the idealized everyday life that so many visitors want to know about. ",
    "url": "https://arxiv.org/abs/2112.12009",
    "authors": [
      "Dan Tasse",
      "Jason I. Hong"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2112.12024",
    "title": "Evaluating categorical encoding methods on a real credit card fraud  detection database",
    "abstract": "Correctly dealing with categorical data in a supervised learning context is still a major issue. Furthermore, though some machine learning methods embody builtin methods to deal with categorical features, it is unclear whether they bring some improvements and how do they compare with usual categorical encoding methods. In this paper, we describe several well-known categorical encoding methods that are based on target statistics and weight of evidence. We apply them on a large and real credit card fraud detection database. Then, we train the encoded databases using state-of-the-art gradient boosting methods and evaluate their performances. We show that categorical encoding methods generally bring substantial improvements with respect to the absence of encoding. The contribution of this work is twofold: (1) we compare many state-of-the-art \"lite\" categorical encoding methods on a large scale database and (2) we use a real credit card fraud detection database. ",
    "url": "https://arxiv.org/abs/2112.12024",
    "authors": [
      "Fran\u00e7ois de la Bourdonnaye",
      "Fabrice Daniel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.12070",
    "title": "A Single-Target License Plate Detection with Attention",
    "abstract": "With the development of deep learning, Neural Network is commonly adopted to the License Plate Detection (LPD) task and achieves much better performance and precision, especially CNN-based networks can achieve state of the art RetinaNet[1]. For a single object detection task such as LPD, modified general object detection would be time-consuming, unable to cope with complex scenarios and a cumbersome weights file that is too hard to deploy on the embedded device. ",
    "url": "https://arxiv.org/abs/2112.12070",
    "authors": [
      "Wenyun Li",
      "Chi-Man Pun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12073",
    "title": "Two Stream Network for Stroke Detection in Table Tennis",
    "abstract": "This paper presents a table tennis stroke detection method from videos. The method relies on a two-stream Convolutional Neural Network processing in parallel the RGB Stream and its computed optical flow. The method has been developed as part of the MediaEval 2021 benchmark for the Sport task. Our contribution did not outperform the provided baseline on the test set but has performed the best among the other participants with regard to the mAP metric. ",
    "url": "https://arxiv.org/abs/2112.12073",
    "authors": [
      "Anam Zahra",
      "Pierre-Etienne Martin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2112.12084",
    "title": "Input-Specific Robustness Certification for Randomized Smoothing",
    "abstract": "Although randomized smoothing has demonstrated high certified robustness and superior scalability to other certified defenses, the high computational overhead of the robustness certification bottlenecks the practical applicability, as it depends heavily on the large sample approximation for estimating the confidence interval. In existing works, the sample size for the confidence interval is universally set and agnostic to the input for prediction. This Input-Agnostic Sampling (IAS) scheme may yield a poor Average Certified Radius (ACR)-runtime trade-off which calls for improvement. In this paper, we propose Input-Specific Sampling (ISS) acceleration to achieve the cost-effectiveness for robustness certification, in an adaptive way of reducing the sampling size based on the input characteristic. Furthermore, our method universally controls the certified radius decline from the ISS sample size reduction. The empirical results on CIFAR-10 and ImageNet show that ISS can speed up the certification by more than three times at a limited cost of 0.05 certified radius. Meanwhile, ISS surpasses IAS on the average certified radius across the extensive hyperparameter settings. Specifically, ISS achieves ACR=0.958 on ImageNet ($\\sigma=1.0$) in 250 minutes, compared to ACR=0.917 by IAS under the same condition. We release our code in \\url{https://github.com/roy-ch/Input-Specific-Certification}. ",
    "url": "https://arxiv.org/abs/2112.12084",
    "authors": [
      "Ruoxin Chen",
      "Jie Li",
      "Junchi Yan",
      "Ping Li",
      "Bin Sheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12086",
    "title": "Improved skin lesion recognition by a Self-Supervised Curricular Deep  Learning approach",
    "abstract": "State-of-the-art deep learning approaches for skin lesion recognition often require pretraining on larger and more varied datasets, to overcome the generalization limitations derived from the reduced size of the skin lesion imaging datasets. ImageNet is often used as the pretraining dataset, but its transferring potential is hindered by the domain gap between the source dataset and the target dermatoscopic scenario. In this work, we introduce a novel pretraining approach that sequentially trains a series of Self-Supervised Learning pretext tasks and only requires the unlabeled skin lesion imaging data. We present a simple methodology to establish an ordering that defines a pretext task curriculum. For the multi-class skin lesion classification problem, and ISIC-2019 dataset, we provide experimental evidence showing that: i) a model pretrained by a curriculum of pretext tasks outperforms models pretrained by individual pretext tasks, and ii) a model pretrained by the optimal pretext task curriculum outperforms a model pretrained on ImageNet. We demonstrate that this performance gain is related to the fact that the curriculum of pretext tasks better focuses the attention of the final model on the skin lesion. Beyond performance improvement, this strategy allows for a large reduction in the training time with respect to ImageNet pretraining, which is especially advantageous for network architectures tailored for a specific problem. ",
    "url": "https://arxiv.org/abs/2112.12086",
    "authors": [
      "Kirill Sirotkin",
      "Marcos Escudero Vi\u00f1olo",
      "Pablo Carballeira",
      "Juan Carlos SanMiguel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12095",
    "title": "Detect & Reject for Transferability of Black-box Adversarial Attacks  Against Network Intrusion Detection Systems",
    "abstract": "In the last decade, the use of Machine Learning techniques in anomaly-based intrusion detection systems has seen much success. However, recent studies have shown that Machine learning in general and deep learning specifically are vulnerable to adversarial attacks where the attacker attempts to fool models by supplying deceptive input. Research in computer vision, where this vulnerability was first discovered, has shown that adversarial images designed to fool a specific model can deceive other machine learning models. In this paper, we investigate the transferability of adversarial network traffic against multiple machine learning-based intrusion detection systems. Furthermore, we analyze the robustness of the ensemble intrusion detection system, which is notorious for its better accuracy compared to a single model, against the transferability of adversarial attacks. Finally, we examine Detect & Reject as a defensive mechanism to limit the effect of the transferability property of adversarial network traffic against machine learning-based intrusion detection systems. ",
    "url": "https://arxiv.org/abs/2112.12095",
    "authors": [
      "Islam Debicha",
      "Thibault Debatty",
      "Jean-Michel Dricot",
      "Wim Mees",
      "Tayeb Kenaza"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.12130",
    "title": "NICE-SLAM: Neural Implicit Scalable Encoding for SLAM",
    "abstract": "Neural implicit representations have recently shown encouraging results in various domains, including promising progress in simultaneous localization and mapping (SLAM). Nevertheless, existing methods produce over-smoothed scene reconstructions and have difficulty scaling up to large scenes. These limitations are mainly due to their simple fully-connected network architecture that does not incorporate local information in the observations. In this paper, we present NICE-SLAM, a dense SLAM system that incorporates multi-level local information by introducing a hierarchical scene representation. Optimizing this representation with pre-trained geometric priors enables detailed reconstruction on large indoor scenes. Compared to recent neural implicit SLAM systems, our approach is more scalable, efficient, and robust. Experiments on five challenging datasets demonstrate competitive results of NICE-SLAM in both mapping and tracking quality. ",
    "url": "https://arxiv.org/abs/2112.12130",
    "authors": [
      "Zihan Zhu",
      "Songyou Peng",
      "Viktor Larsson",
      "Weiwei Xu",
      "Hujun Bao",
      "Zhaopeng Cui",
      "Martin R. Oswald",
      "Marc Pollefeys"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.12133",
    "title": "Can Deep Neural Networks be Converted to Ultra Low-Latency Spiking  Neural Networks?",
    "abstract": "Spiking neural networks (SNNs), that operate via binary spikes distributed over time, have emerged as a promising energy efficient ML paradigm for resource-constrained devices. However, the current state-of-the-art (SOTA) SNNs require multiple time steps for acceptable inference accuracy, increasing spiking activity and, consequently, energy consumption. SOTA training strategies for SNNs involve conversion from a non-spiking deep neural network (DNN). In this paper, we determine that SOTA conversion strategies cannot yield ultra low latency because they incorrectly assume that the DNN and SNN pre-activation values are uniformly distributed. We propose a new training algorithm that accurately captures these distributions, minimizing the error between the DNN and converted SNN. The resulting SNNs have ultra low latency and high activation sparsity, yielding significant improvements in compute efficiency. In particular, we evaluate our framework on image recognition tasks from CIFAR-10 and CIFAR-100 datasets on several VGG and ResNet architectures. We obtain top-1 accuracy of 64.19% with only 2 time steps on the CIFAR-100 dataset with ~159.2x lower compute energy compared to an iso-architecture standard DNN. Compared to other SOTA SNN models, our models perform inference 2.5-8x faster (i.e., with fewer time steps). ",
    "url": "https://arxiv.org/abs/2112.12133",
    "authors": [
      "Gourav Datta",
      "Peter A. Beerel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11592",
    "title": "Neural Echo State Network using oscillations of gas bubbles in water:  Computational validation by Mackey-Glass time series forecasting",
    "abstract": "Physical reservoir computing (RC) is a computational framework, where machine learning algorithms designed for digital computers are executed using analog computer-like nonlinear physical systems that can provide high computational power for predicting time-dependent quantities that can be found using nonlinear differential equations. Here we suggest an RC system that combines the nonlinearity of an acoustic response of a cluster of oscillating gas bubbles in water with a standard Echo State Network (ESN) algorithm that is well-suited to forecast nonlinear and chaotic time series. We computationally confirm the plausibility of the proposed RC system by demonstrating its ability to forecast a chaotic Mackey-Glass time series with the efficiency of ESN. ",
    "url": "https://arxiv.org/abs/2112.11592",
    "authors": [
      "Ivan S. Maksymov",
      "Andrey Pototsky",
      "Sergey A. Suslov"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2112.11644",
    "title": "Reconstructing public engagement from social media content volume",
    "abstract": "The consumption of news produces uneven social reactions. In most cases, people share information and discuss their opinions within their environment and social media; public interest remains therefore bounded to language expressions. A few cases, in contrast, fuel up the collective sensibility and give rise to social movements. Here we analyze a series of events related to violence in the US during 2020. For each event, we use the volume of tweets and retweets as a proxy of public interest, and the volume of news as a proxy of media coverage. We set up a simple mathematical model for public interest that succesfully explains the collected data. Crucially, this allows inferring a measure of public engagement that correlates with human mobility data, capturing a fundamental mechanism of social dynamics. ",
    "url": "https://arxiv.org/abs/2112.11644",
    "authors": [
      "Sebasti\u00e1n Pinto",
      "Marcos Trevisan",
      "Pablo Balenzuela"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2112.11696",
    "title": "RepBin: Constraint-based Graph Representation Learning for Metagenomic  Binning",
    "abstract": "Mixed communities of organisms are found in many environments (from the human gut to marine ecosystems) and can have profound impact on human health and the environment. Metagenomics studies the genomic material of such communities through high-throughput sequencing that yields DNA subsequences for subsequent analysis. A fundamental problem in the standard workflow, called binning, is to discover clusters, of genomic subsequences, associated with the unknown constituent organisms. Inherent noise in the subsequences, various biological constraints that need to be imposed on them and the skewed cluster size distribution exacerbate the difficulty of this unsupervised learning problem. In this paper, we present a new formulation using a graph where the nodes are subsequences and edges represent homophily information. In addition, we model biological constraints providing heterophilous signal about nodes that cannot be clustered together. We solve the binning problem by developing new algorithms for (i) graph representation learning that preserves both homophily relations and heterophily constraints (ii) constraint-based graph clustering method that addresses the problems of skewed cluster size distribution. Extensive experiments, on real and synthetic datasets, demonstrate that our approach, called RepBin, outperforms a wide variety of competing methods. Our constraint-based graph representation learning and clustering methods, that may be useful in other domains as well, advance the state-of-the-art in both metagenomics binning and graph representation learning. ",
    "url": "https://arxiv.org/abs/2112.11696",
    "authors": [
      "Hansheng Xue",
      "Vijini Mallawaarachchi",
      "Yujia Zhang",
      "Vaibhav Rajan",
      "Yu Lin"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2112.11768",
    "title": "Robust learning of data anomalies with analytically-solvable entropic  outlier sparsification",
    "abstract": "Entropic Outlier Sparsification (EOS) is proposed as a robust computational strategy for the detection of data anomalies in a broad class of learning methods, including the unsupervised problems (like detection of non-Gaussian outliers in mostly-Gaussian data) and in the supervised learning with mislabeled data. EOS dwells on the derived analytic closed-form solution of the (weighted) expected error minimization problem subject to the Shannon entropy regularization. In contrast to common regularization strategies requiring computational costs that scale polynomial with the data dimension, identified closed-form solution is proven to impose additional iteration costs that depend linearly on statistics size and are independent of data dimension. Obtained analytic results also explain why the mixtures of spherically-symmetric Gaussians - used heuristically in many popular data analysis algorithms - represent an optimal choice for the non-parametric probability distributions when working with squared Euclidean distances, combining expected error minimality, maximal entropy/unbiasedness, and a linear cost scaling. The performance of EOS is compared to a range of commonly-used tools on synthetic problems and on partially-mislabeled supervised classification problems from biomedicine. ",
    "url": "https://arxiv.org/abs/2112.11768",
    "authors": [
      "Illia Horenko"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.11833",
    "title": "Deep learning for brain metastasis detection and segmentation in  longitudinal MRI data",
    "abstract": "Brain metastases occur frequently in patients with metastatic cancer. Early and accurate detection of brain metastases is very essential for treatment planning and prognosis in radiation therapy. To improve brain metastasis detection performance with deep learning, a custom detection loss called volume-level sensitivity-specificity (VSS) is proposed, which rates individual metastasis detection sensitivity and specificity in (sub-)volume levels. As sensitivity and precision are always a trade-off in a metastasis level, either a high sensitivity or a high precision can be achieved by adjusting the weights in the VSS loss without decline in dice score coefficient for segmented metastases. To reduce metastasis-like structures being detected as false positive metastases, a temporal prior volume is proposed as an additional input of the neural network. Our proposed VSS loss improves the sensitivity of brain metastasis detection, increasing the sensitivity from 86.7% to 95.5%. Alternatively, it improves the precision from 68.8% to 97.8%. With the additional temporal prior volume, about 45% of the false positive metastases are reduced in the high sensitivity model and the precision reaches 99.6% for the high specificity model. The mean dice coefficient for all metastases is about 0.81. With the ensemble of the high sensitivity and high specificity models, on average only 1.5 false positive metastases per patient needs further check, while the majority of true positive metastases are confirmed. The ensemble learning is able to distinguish high confidence true positive metastases from metastases candidates that require special expert review or further follow-up, being particularly well-fit to the requirements of expert support in real clinical practice. ",
    "url": "https://arxiv.org/abs/2112.11833",
    "authors": [
      "Yixing Huang",
      "Christoph Bert",
      "Philipp Sommer",
      "Benjamin Frey",
      "Udo Gaipl",
      "Luitpold V. Distel",
      "Thomas Weissmann",
      "Michael Uder",
      "Manuel A. Schmidt",
      "Arnd D\u00f6rfler",
      "Andrreas Maier",
      "Rainer Fietkau",
      "Florian Putz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11950",
    "title": "POD-Galerkin reduced order models and physics-informed neural networks  for solving inverse problems for the Navier-Stokes equations",
    "abstract": "We present a Reduced Order Model (ROM) which exploits recent developments in Physics Informed Neural Networks (PINNs) for solving inverse problems for the Navier--Stokes equations (NSE). In the proposed approach, the presence of simulated data for the fluid dynamics fields is assumed. A POD-Galerkin ROM is then constructed by applying POD on the snapshots matrices of the fluid fields and performing a Galerkin projection of the NSE (or the modified equations in case of turbulence modeling) onto the POD reduced basis. A $\\textit{POD-Galerkin PINN ROM}$ is then derived by introducing deep neural networks which approximate the reduced outputs with the input being time and/or parameters of the model. The neural networks incorporate the physical equations (the POD-Galerkin reduced equations) into their structure as part of the loss function. Using this approach, the reduced model is able to approximate unknown parameters such as physical constants or the boundary conditions. A demonstration of the applicability of the proposed ROM is illustrated by two cases which are the steady flow around a backward step and the unsteady turbulent flow around a surface mounted cubic obstacle. ",
    "url": "https://arxiv.org/abs/2112.11950",
    "authors": [
      "Saddam Hijazi",
      "Melina Freitag",
      "Niels Landwehr"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2112.11970",
    "title": "Burling graphs revisited, part III: Applications to $\u03c7$-boundedness",
    "abstract": "The Burling sequence is a sequence of triangle-free graphs of unbounded chromatic number. The class of Burling graphs consists of all the induced subgraphs of the graphs of this sequence. In the first and second parts of this work, we introduced derived graphs, a class of graphs, equal to the class of Burling graphs, and proved several geometric and structural results about them. In this third part, we use those results to find some Burling and non-Burling graphs, and we see some applications of this in the theory of $\\chi$-boundedness. In particular, we show that several graphs, like $ K_5 $, some series-parallel graphs that we call necklaces, and some other graphs are not weakly pervasive. ",
    "url": "https://arxiv.org/abs/2112.11970",
    "authors": [
      "Pegah Pournajafi",
      "Nicolas Trotignon"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2112.12021",
    "title": "Community Detection in Medical Image Datasets: Using Wavelets and  Spectral Methods",
    "abstract": "Medical image datasets can have large number of images representing patients with different health conditions and various disease severity. When dealing with raw unlabeled image datasets, the large number of samples often makes it hard for experts and non-experts to understand the variety of images present in a dataset. Supervised learning methods rely on labeled images which requires a considerable effort by medical experts to first understand the communities of images present in the data and then labeling the images. Here, we propose an algorithm to facilitate the automatic identification of communities in medical image datasets. We further explain that such analysis can also be insightful in a supervised setting, when the images are already labeled. Such insights are useful because in reality, health and disease severity can be considered a continuous spectrum, and within each class, there usually are finer communities worthy of investigation, especially when they have similarities to communities in other classes. In our approach, we use wavelet decomposition of images in tandem with spectral methods. We show that the eigenvalues of a graph Laplacian can reveal the number of notable communities in an image dataset. In our experiments, we use a dataset of images labeled with different conditions for COVID patients. We detect 25 communities in the dataset and then observe that only 6 of those communities contain patients with pneumonia. We also investigate the contents of a colorectal cancer histopathology dataset. ",
    "url": "https://arxiv.org/abs/2112.12021",
    "authors": [
      "Roozbeh Yousefzadeh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.12033",
    "title": "Encoding protein dynamic information in graph representation for  functional residue identification",
    "abstract": "Recent advances in protein function prediction exploit graph-based deep learning approaches to correlate the structural and topological features of proteins with their molecular functions. However, proteins in vivo are not static but dynamic molecules that alter conformation for functional purposes. Here we apply normal mode analysis to native protein conformations and augment protein graphs by connecting edges between dynamically correlated residue pairs. In the multilabel function classification task, our method demonstrates a remarkable performance gain based on this dynamics-informed representation. The proposed graph neural network, ProDAR, increases the interpretability and generalizability of residue-level annotations and robustly reflects structural nuance in proteins. We elucidate the importance of dynamic information in graph representation by comparing class activation maps for the hMTH1, nitrophorin, and SARS-CoV-2 receptor binding domain. Our model successfully learns the dynamic fingerprints of proteins and provides molecular insights into protein functions, with vast untapped potential for broad biotechnology and pharmaceutical applications. ",
    "url": "https://arxiv.org/abs/2112.12033",
    "authors": [
      "Yuan Chiang",
      "Wei-Han Hui",
      "Shu-Wei Chang"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)",
      "Atomic and Molecular Clusters (physics.atm-clus)",
      "Biological Physics (physics.bio-ph)"
    ]
  },
  {
    "id": "arXiv:1904.02345",
    "title": "Preference Neural Network",
    "abstract": " Comments: The current content is inappropriate and requires to be comprehensively reviewed again ",
    "url": "https://arxiv.org/abs/1904.02345",
    "authors": [
      "Ayman Elgharabawy",
      "Mukesh Prasad",
      "Chin-Teng Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:1909.07558",
    "title": "HAD-GAN: A Human-perception Auxiliary Defense GAN to Defend Adversarial  Examples",
    "abstract": " Title: HAD-GAN: A Human-perception Auxiliary Defense GAN to Defend Adversarial  Examples ",
    "url": "https://arxiv.org/abs/1909.07558",
    "authors": [
      "Wanting Yu",
      "Hongyi Yu",
      "Lingyun Jiang",
      "Mengli Zhang",
      "Kai Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:1910.07234",
    "title": "Aerial Images Processing for Car Detection using Convolutional Neural  Networks: Comparison between Faster R-CNN and YoloV3",
    "abstract": " Title: Aerial Images Processing for Car Detection using Convolutional Neural  Networks: Comparison between Faster R-CNN and YoloV3 ",
    "url": "https://arxiv.org/abs/1910.07234",
    "authors": [
      "Adel Ammar",
      "Anis Koubaa",
      "Mohanned Ahmed",
      "Abdulrahman Saad",
      "Bilel Benjdira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2004.14174",
    "title": "Reevaluating Adversarial Examples in Natural Language",
    "abstract": " Comments: 15 pages; 9 Tables; 5 Figures ",
    "url": "https://arxiv.org/abs/2004.14174",
    "authors": [
      "John X. Morris",
      "Eli Lifland",
      "Jack Lanchantin",
      "Yangfeng Ji",
      "Yanjun Qi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2009.02092",
    "title": "Popularity Prediction for Social Media over Arbitrary Time Horizons",
    "abstract": " Comments: International Conference on Very Large Data Bases (VLDB'2022) ",
    "url": "https://arxiv.org/abs/2009.02092",
    "authors": [
      "Daniel Haimovich",
      "Dima Karamshuk",
      "Thomas J. Leeper",
      "Evgeniy Riabenko",
      "Milan Vojnovic"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2101.01163",
    "title": "SmartDeal: Re-Modeling Deep Network Weights for Efficient Inference and  Training",
    "abstract": " Comments: Accepted to IEEE Transactions on Neural Networks and Learning Systems arXiv admin note: substantial text overlap with arXiv:2005.03403 ",
    "url": "https://arxiv.org/abs/2101.01163",
    "authors": [
      "Xiaohan Chen",
      "Yang Zhao",
      "Yue Wang",
      "Pengfei Xu",
      "Haoran You",
      "Chaojian Li",
      "Yonggan Fu",
      "Yingyan Lin",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.06527",
    "title": "Mutually exciting point process graphs for modelling dynamic networks",
    "abstract": " Title: Mutually exciting point process graphs for modelling dynamic networks ",
    "url": "https://arxiv.org/abs/2102.06527",
    "authors": [
      "Francesco Sanna Passino",
      "Nicholas A. Heard"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.09384",
    "title": "Buffered Streaming Graph Partitioning",
    "abstract": " Title: Buffered Streaming Graph Partitioning ",
    "url": "https://arxiv.org/abs/2102.09384",
    "authors": [
      "Marcelo Fonseca Faraj",
      "Christian Schulz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2102.13490",
    "title": "Case Level Counterfactual Reasoning in Process Mining",
    "abstract": " Comments: 8 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2102.13490",
    "authors": [
      "Mahnaz Sadat Qafari",
      "Wil van der Aalst"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2103.04623",
    "title": "Consistency Regularization for Adversarial Robustness",
    "abstract": " Comments: Published as a conference proceeding for AAAI 2022 ",
    "url": "https://arxiv.org/abs/2103.04623",
    "authors": [
      "Jihoon Tack",
      "Sihyun Yu",
      "Jongheon Jeong",
      "Minseon Kim",
      "Sung Ju Hwang",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2103.14718",
    "title": "Increasing the Efficiency of Policy Learning for Autonomous Vehicles by  Multi-Task Representation Learning",
    "abstract": " Title: Increasing the Efficiency of Policy Learning for Autonomous Vehicles by  Multi-Task Representation Learning ",
    "url": "https://arxiv.org/abs/2103.14718",
    "authors": [
      "Eshagh Kargar",
      "Ville Kyrki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2104.05703",
    "title": "Adversarial Open Domain Adaptation for Sketch-to-Photo Synthesis",
    "abstract": " Comments: Accepted by WACV 2022 ",
    "url": "https://arxiv.org/abs/2104.05703",
    "authors": [
      "Xiaoyu Xiang",
      "Ding Liu",
      "Xiao Yang",
      "Yiheng Zhu",
      "Xiaohui Shen",
      "Jan P. Allebach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2104.12710",
    "title": "Optimal Algorithm Allocation for Robotic Network Cloud Systems",
    "abstract": " Title: Optimal Algorithm Allocation for Robotic Network Cloud Systems ",
    "url": "https://arxiv.org/abs/2104.12710",
    "authors": [
      "Saeid Alirezazadeh",
      "Andr\u00e9 Correia",
      "Lu\u00eds A. Alexandre"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2106.01970",
    "title": "NeRFactor: Neural Factorization of Shape and Reflectance Under an  Unknown Illumination",
    "abstract": " Comments: Camera-ready version for SIGGRAPH Asia 2021. Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2106.01970",
    "authors": [
      "Xiuming Zhang",
      "Pratul P. Srinivasan",
      "Boyang Deng",
      "Paul Debevec",
      "William T. Freeman",
      "Jonathan T. Barron"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2107.03377",
    "title": "Long Short-Term Transformer for Online Action Detection",
    "abstract": " Comments: NeurIPS 2021 Spotlight ",
    "url": "https://arxiv.org/abs/2107.03377",
    "authors": [
      "Mingze Xu",
      "Yuanjun Xiong",
      "Hao Chen",
      "Xinyu Li",
      "Wei Xia",
      "Zhuowen Tu",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2107.10295",
    "title": "A Review of Some Techniques for Inclusion of Domain-Knowledge into Deep  Neural Networks",
    "abstract": " Comments: 16 pages; Accepted at Nature Scientific Reports. arXiv admin note: substantial text overlap with arXiv:2103.00180 ",
    "url": "https://arxiv.org/abs/2107.10295",
    "authors": [
      "Tirtharaj Dash",
      "Sharad Chitlangia",
      "Aditya Ahuja",
      "Ashwin Srinivasan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2107.11673",
    "title": "ScaleHLS: A New Scalable High-Level Synthesis Framework on Multi-Level  Intermediate Representation",
    "abstract": " Comments: Accepted as a conference paper at HPCA'22 ",
    "url": "https://arxiv.org/abs/2107.11673",
    "authors": [
      "Hanchen Ye",
      "Cong Hao",
      "Jianyi Cheng",
      "Hyunmin Jeong",
      "Jack Huang",
      "Stephen Neuendorffer",
      "Deming Chen"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2108.03530",
    "title": "Covert, Low-Delay, Coded Message Passing in Mobile (IoT) Networks",
    "abstract": " Comments: Made some revisions, added some future directions, and corrected some typos ",
    "url": "https://arxiv.org/abs/2108.03530",
    "authors": [
      "Pei Peng",
      "Emina Soljanin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2108.04327",
    "title": "Natural Numerical Networks for Natura 2000 habitats classification by  satellite images",
    "abstract": " Title: Natural Numerical Networks for Natura 2000 habitats classification by  satellite images ",
    "url": "https://arxiv.org/abs/2108.04327",
    "authors": [
      "Karol Mikula",
      "Michal Kollar",
      "Aneta A. Ozvat",
      "Martin Ambroz",
      "Lucia Cahojova",
      "Ivan Jarolimek",
      "Jozef Sibik",
      "Maria Sibikova"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.04824",
    "title": "Inverse design of 3d molecular structures with conditional generative  neural networks",
    "abstract": " Title: Inverse design of 3d molecular structures with conditional generative  neural networks ",
    "url": "https://arxiv.org/abs/2109.04824",
    "authors": [
      "Niklas W. A. Gebauer",
      "Michael Gastegger",
      "Stefaan S. P. Hessmann",
      "Klaus-Robert M\u00fcller",
      "Kristof T. Sch\u00fctt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.13715",
    "title": "ConE: Cone Embeddings for Multi-Hop Reasoning over Knowledge Graphs",
    "abstract": " Comments: Accepted to NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2110.13715",
    "authors": [
      "Zhanqiu Zhang",
      "Jie Wang",
      "Jiajun Chen",
      "Shuiwang Ji",
      "Feng Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.13900",
    "title": "WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech  Processing",
    "abstract": " Title: WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech  Processing ",
    "url": "https://arxiv.org/abs/2110.13900",
    "authors": [
      "Sanyuan Chen",
      "Chengyi Wang",
      "Zhengyang Chen",
      "Yu Wu",
      "Shujie Liu",
      "Zhuo Chen",
      "Jinyu Li",
      "Naoyuki Kanda",
      "Takuya Yoshioka",
      "Xiong Xiao",
      "Jian Wu",
      "Long Zhou",
      "Shuo Ren",
      "Yanmin Qian",
      "Yao Qian",
      "Jian Wu",
      "Michael Zeng",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2111.10656",
    "title": "Simple End-to-end Deep Learning Model for CDR-H3 Loop Structure  Prediction",
    "abstract": " Comments: NeurIPS 2021 Machine Learning for Structural Biology Workshop ",
    "url": "https://arxiv.org/abs/2111.10656",
    "authors": [
      "Natalia Zenkova",
      "Ekaterina Sedykh",
      "Tatiana Shugaeva",
      "Vladislav Strashko",
      "Timofei Ermak",
      "Aleksei Shpilman"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.10686",
    "title": "Representing Prior Knowledge Using Randomly, Weighted Feature Networks  for Visual Relationship Detection",
    "abstract": " Comments: 9 pages, 2 figures, Accepted to CLeaR2022 at AAAI2022 ",
    "url": "https://arxiv.org/abs/2111.10686",
    "authors": [
      "Jinyung Hong",
      "Theodore P. Pavlic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.14934",
    "title": "Generative Adversarial Networks with Conditional Neural Movement  Primitives for An Interactive Generative Drawing Tool",
    "abstract": " Comments: 9 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2111.14934",
    "authors": [
      "Suzan Ece Ada",
      "M. Yunus Seker"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2111.14973",
    "title": "MultiPath++: Efficient Information Fusion and Trajectory Aggregation for  Behavior Prediction",
    "abstract": " Title: MultiPath++: Efficient Information Fusion and Trajectory Aggregation for  Behavior Prediction ",
    "url": "https://arxiv.org/abs/2111.14973",
    "authors": [
      "Balakrishnan Varadarajan",
      "Ahmed Hefny",
      "Avikalp Srivastava",
      "Khaled S. Refaat",
      "Nigamaa Nayakanti",
      "Andre Cornman",
      "Kan Chen",
      "Bertrand Douillard",
      "Chi Pang Lam",
      "Dragomir Anguelov",
      "Benjamin Sapp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2112.02936",
    "title": "Pairwise Learning for Neural Link Prediction",
    "abstract": " Title: Pairwise Learning for Neural Link Prediction ",
    "url": "https://arxiv.org/abs/2112.02936",
    "authors": [
      "Zhitao Wang",
      "Yong Zhou",
      "Litao Hong",
      "Yuanhang Zou",
      "Hanjing Su",
      "Shouzhi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2112.04744",
    "title": "Superpixel-Based Building Damage Detection from Post-earthquake Very  High Resolution Imagery Using Deep Neural Networks",
    "abstract": " Title: Superpixel-Based Building Damage Detection from Post-earthquake Very  High Resolution Imagery Using Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2112.04744",
    "authors": [
      "Jun Wang",
      "Zhoujing Li",
      "Yixuan Qiao",
      "Qiming Qin",
      "Peng Gao",
      "Guotong Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2112.07893",
    "title": "Graph-based Ensemble Machine Learning for Student Performance Prediction",
    "abstract": " Comments: 5 pages, 3 figures and 3 tables ",
    "url": "https://arxiv.org/abs/2112.07893",
    "authors": [
      "Yinkai Wang",
      "Aowei Ding",
      "Kaiyi Guan",
      "Shixi Wu",
      "Yuanqi Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2112.08902",
    "title": "Toward Minimal Misalignment at Minimal Cost in One-Stage and Anchor-Free  Object Detection",
    "abstract": " Title: Toward Minimal Misalignment at Minimal Cost in One-Stage and Anchor-Free  Object Detection ",
    "url": "https://arxiv.org/abs/2112.08902",
    "authors": [
      "Shuaizheng Hao",
      "Hongzhe Liu",
      "Ningwei Wang",
      "Cheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.08914",
    "title": "Characterizing and addressing the issue of oversmoothing in neural  autoregressive sequence modeling",
    "abstract": " Comments: Ilia Kulikov and Maksim Eremeev contributed equally ",
    "url": "https://arxiv.org/abs/2112.08914",
    "authors": [
      "Ilia Kulikov",
      "Maksim Eremeev",
      "Kyunghyun Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.10938",
    "title": "CADV: A software visualization approach for code annotations  distribution",
    "abstract": " Comments: 53 pages ",
    "url": "https://arxiv.org/abs/2112.10938",
    "authors": [
      "Phyllipe Lima",
      "Jorge Melegati",
      "Everaldo Gomes",
      "Nathalya Stefhany Pereira",
      "Eduardo Guerra",
      "Paulo Meirelles"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2112.10969",
    "title": "Generalizing Interactive Backpropagating Refinement for Dense Prediction",
    "abstract": " Title: Generalizing Interactive Backpropagating Refinement for Dense Prediction ",
    "url": "https://arxiv.org/abs/2112.10969",
    "authors": [
      "Fanqing Lin",
      "Brian Price",
      "Tony Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11243",
    "title": "Projected Sliced Wasserstein Autoencoder-based Hyperspectral Images  Anomaly Detection",
    "abstract": " Title: Projected Sliced Wasserstein Autoencoder-based Hyperspectral Images  Anomaly Detection ",
    "url": "https://arxiv.org/abs/2112.11243",
    "authors": [
      "Yurong Chen",
      "Hui Zhang",
      "Yaonan Wang",
      "Q. M. Jonathan Wu",
      "Yimin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.11360",
    "title": "Multigoal-oriented dual-weighted-residual error estimation using deep  neural networks",
    "abstract": " Title: Multigoal-oriented dual-weighted-residual error estimation using deep  neural networks ",
    "url": "https://arxiv.org/abs/2112.11360",
    "authors": [
      "Ayan Chakraborty",
      "Thomas Wick",
      "Xiaoying Zhuang",
      "Timon Rabczuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  }
]