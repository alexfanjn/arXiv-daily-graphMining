[
  {
    "id": "arXiv:2112.00004",
    "title": "cliquematch: Finding correspondence via cliques in large graphs",
    "abstract": "The maximum clique problem finds applications in computer vision, bioinformatics, and network analysis, many of which involve the construction of correspondence graphs to find similarities between two given objects. cliquematch is a Python package designed for this purpose: it provides a simple framework to construct correspondence graphs, and implements an algorithm to find and enumerate maximum cliques in C++, that can process graphs of a few million edges on consumer hardware, with comparable performance to publicly available methods. ",
    "url": "https://arxiv.org/abs/2112.00004",
    "authors": [
      "Gautham Venkatasubramanian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Software (cs.MS)"
    ]
  },
  {
    "id": "arXiv:2112.00220",
    "title": "A generic physics-informed neural network-based framework for  reliability assessment of multi-state systems",
    "abstract": "In this paper, we leverage the recent advances in physics-informed neural network (PINN) and develop a generic PINN-based framework to assess the reliability of multi-state systems (MSSs). The proposed methodology consists of two major steps. In the first step, we recast the reliability assessment of MSS as a machine learning problem using the framework of PINN. A feedforward neural network with two individual loss groups are constructed to encode the initial condition and state transitions governed by ordinary differential equations (ODEs) in MSS. Next, we tackle the problem of high imbalance in the magnitude of the back-propagated gradients in PINN from a multi-task learning perspective. Particularly, we treat each element in the loss function as an individual task, and adopt a gradient surgery approach named projecting conflicting gradients (PCGrad), where a task's gradient is projected onto the norm plane of any other task that has a conflicting gradient. The gradient projection operation significantly mitigates the detrimental effects caused by the gradient interference when training PINN, thus accelerating the convergence speed of PINN to high-precision solutions to MSS reliability assessment. With the proposed PINN-based framework, we investigate its applications for MSS reliability assessment in several different contexts in terms of time-independent or dependent state transitions and system scales varying from small to medium. The results demonstrate that the proposed PINN-based framework shows generic and remarkable performance in MSS reliability assessment, and the incorporation of PCGrad in PINN leads to substantial improvement in solution quality and convergence speed. ",
    "url": "https://arxiv.org/abs/2112.00220",
    "authors": [
      "Taotao Zhou",
      "Xiaoge Zhang",
      "Enrique Lopez Droguett",
      "Ali Mosleh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.00248",
    "title": "Simulation platform for pattern recognition based on reservoir computing  with memristor networks",
    "abstract": "Memristive systems and devices are potentially available for implementing reservoir computing (RC) systems applied to pattern recognition. However, the computational ability of memristive RC systems depends on intertwined factors such as system architectures and physical properties of memristive elements, which complicates identifying the key factor for system performance. Here we develop a simulation platform for RC with memristor device networks, which enables testing different system designs for performance improvement. Numerical simulations show that the memristor-network-based RC systems can yield high computational performance comparable to that of state-of-the-art methods in three time series classification tasks. We demonstrate that the excellent and robust computation under device-to-device variability can be achieved by appropriately setting network structures, nonlinearity of memristors, and pre/post-processing, which increases the potential for reliable computation with unreliable component devices. Our results contribute to an establishment of a design guide for memristive reservoirs toward a realization of energy-efficient machine learning hardware. ",
    "url": "https://arxiv.org/abs/2112.00248",
    "authors": [
      "Gouhei Tanaka",
      "Ryosho Nakane"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2112.00629",
    "title": "Classifying grounded intersection graphs via ordered forbidden patterns",
    "abstract": "It was noted already in the 90s that many classic graph classes, such as interval, chordal, and bipartite graphs, can be characterized by the existence of an ordering of the vertices avoiding some ordered subgraphs, called \\emph{patterns}. Very recently, all the classes corresponding to patterns on three vertices (including the ones mentioned above) have been listed, and proved to be efficiently recognizable. In contrast, very little is known about patterns on four vertices. One of the few graph classes characterized by a pattern on four vertices is the class of intersection graphs of rectangles that are said to be \\emph{grounded on a line}. This class appears naturally in the study of intersection graphs, and similar grounded classes have recently attracted a lot of attention. This paper contains three parts. First, we make a survey of grounded intersection graph classes, summarizing all the known inclusions between these various classes. Second, we show that the correspondence between a pattern on four vertices and grounded rectangle graphs is not an isolated phenomenon. We establish several other pattern characterizations for geometric classes, and show that the hierarchy of grounded intersection graph classes is tightly interleaved with the classes defined patterns on four vertices. We claim that forbidden patterns are a useful tool to classify grounded intersection graphs. Finally, we give an overview of the complexity of the recognition of classes defined by forbidden patterns on four vertices and list several interesting open problems. ",
    "url": "https://arxiv.org/abs/2112.00629",
    "authors": [
      "Laurent Feuilloley",
      "Michel Habib"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2112.00183",
    "title": "Descriptive vs. inferential community detection: pitfalls, myths and  half-truths",
    "abstract": "Community detection is one of the most important methodological fields of network science, and one which has attracted a significant amount of attention over the past decades. This area deals with the automated division of a network into fundamental building blocks, with the objective of providing a summary of its large-scale structure. Despite its importance and widespread adoption, there is a noticeable gap between what is considered the state-of-the-art and the methods that are actually used in practice in a variety of fields. Here we attempt to address this discrepancy by dividing existing methods according to whether they have a \"descriptive\" or an \"inferential\" goal. While descriptive methods find patterns in networks based on intuitive notions of community structure, inferential methods articulate a precise generative model, and attempt to fit it to data. In this way, they are able to provide insights into the mechanisms of network formation, and separate structure from randomness in a manner supported by statistical evidence. We review how employing descriptive methods with inferential aims is riddled with pitfalls and misleading answers, and thus should be in general avoided. We argue that inferential methods are more typically aligned with clearer scientific questions, yield more robust results, and should be in general preferred. We attempt to dispel some myths and half-truths often believed when community detection is employed in practice, in an effort to improve both the use of such methods as well as the interpretation of their results. ",
    "url": "https://arxiv.org/abs/2112.00183",
    "authors": [
      "Tiago P. Peixoto"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.00365",
    "title": "Mixed neural network Gaussian processes",
    "abstract": "This paper makes two contributions. Firstly, it introduces mixed compositional kernels and mixed neural network Gaussian processes (NGGPs). Mixed compositional kernels are generated by composition of probability generating functions (PGFs). A mixed NNGP is a Gaussian process (GP) with a mixed compositional kernel, arising in the infinite-width limit of multilayer perceptrons (MLPs) that have a different activation function for each layer. Secondly, $\\theta$ activation functions for neural networks and $\\theta$ compositional kernels are introduced by building upon the theory of branching processes, and more specifically upon $\\theta$ PGFs. While $\\theta$ compositional kernels are recursive, they are expressed in closed form. It is shown that $\\theta$ compositional kernels have non-degenerate asymptotic properties under certain conditions. Thus, GPs with $\\theta$ compositional kernels do not require non-explicit recursive kernel evaluations and have controllable infinite-depth asymptotic properties. An open research question is whether GPs with $\\theta$ compositional kernels are limits of infinitely-wide MLPs with $\\theta$ activation functions. ",
    "url": "https://arxiv.org/abs/2112.00365",
    "authors": [
      "Alexey Lindo",
      "Theodore Papamarkou",
      "Serik Sagitov",
      "Laura Stewart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.00720",
    "title": "Quasi-universality of Reeb graph distances",
    "abstract": "We establish bi-Lipschitz bounds certifying quasi-universality (universality up to a constant factor) for various distances between Reeb graphs: the interleaving distance, the functional distortion distance, and the functional contortion distance. The definition of the latter distance is a novel contribution, and for the special case of contour trees we also prove strict universality of this distance. Furthermore, we prove that for the special case of merge trees the functional contortion distance coincides with the interleaving distance, yielding universality of all four distances in this case. ",
    "url": "https://arxiv.org/abs/2112.00720",
    "authors": [
      "Ulrich Bauer",
      "H\u00e5vard Bakke Bjerkevik",
      "Benedikt Fluhr"
    ],
    "subjectives": [
      "Geometric Topology (math.GT)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:1905.12707",
    "title": "Heterogeneous causal effects with imperfect compliance: a Bayesian  machine learning approach",
    "abstract": " Comments: To appear in the Annals of Applied Statistics ",
    "url": "https://arxiv.org/abs/1905.12707",
    "authors": [
      "Falco J. Bargagli-Stoffi",
      "Kristof De-Witte",
      "Giorgio Gnecco"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2007.14823",
    "title": "Theory of gating in recurrent neural networks",
    "abstract": " Comments: 13 figures ",
    "url": "https://arxiv.org/abs/2007.14823",
    "authors": [
      "Kamesh Krishnamurthy",
      "Tankut Can",
      "David J. Schwab"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2012.00118",
    "title": "A new operational representation of dependencies in Event Structures",
    "abstract": " Title: A new operational representation of dependencies in Event Structures ",
    "url": "https://arxiv.org/abs/2012.00118",
    "authors": [
      "G. Michele Pinna"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2105.11521",
    "title": "Deep neural network enabled corrective source term approach to hybrid  analysis and modeling",
    "abstract": " Title: Deep neural network enabled corrective source term approach to hybrid  analysis and modeling ",
    "url": "https://arxiv.org/abs/2105.11521",
    "authors": [
      "Sindre Stenen Blakseth",
      "Adil Rasheed",
      "Trond Kvamsdal",
      "Omer San"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2107.12719",
    "title": "The CORSMAL benchmark for the prediction of the properties of containers",
    "abstract": " Comments: 13 pages, 6 tables, 7 figures, Pre-print submitted to IEEE Access ",
    "url": "https://arxiv.org/abs/2107.12719",
    "authors": [
      "Alessio Xompero",
      "Santiago Donaher",
      "Vladimir Iashin",
      "Francesca Palermo",
      "G\u00f6khan Solak",
      "Claudio Coppola",
      "Reina Ishikawa",
      "Yuichi Nagao",
      "Ryo Hachiuma",
      "Qi Liu",
      "Fan Feng",
      "Chuanlin Lan",
      "Rosa H. M. Chan",
      "Guilherme Christmann",
      "Jyun-Ting Song",
      "Gonuguntla Neeharika",
      "Chinnakotla Krishna Teja Reddy",
      "Dinesh Jain",
      "Bakhtawar Ur Rehman",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2110.06634",
    "title": "End-to-end translation of human neural activity to speech with a  dual-dual generative adversarial network",
    "abstract": " Comments: 12 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2110.06634",
    "authors": [
      "Yina Guo",
      "Xiaofei Zhang",
      "Zhenying Gong",
      "Anhong Wang",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2110.07037",
    "title": "Solving multiscale steady radiative transfer equation using neural  networks with uniform stability",
    "abstract": " Title: Solving multiscale steady radiative transfer equation using neural  networks with uniform stability ",
    "url": "https://arxiv.org/abs/2110.07037",
    "authors": [
      "Yulong Lu",
      "Li Wang",
      "Wuzhe Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2111.02174",
    "title": "Unsupervised detection and open-set classification of fast-ramped  flexibility activation events",
    "abstract": " Comments: Submitted to Applied Energy. Revised by the authors ",
    "url": "https://arxiv.org/abs/2111.02174",
    "authors": [
      "Nils M\u00fcller",
      "Carsten Heinrich",
      "Kai Heussen",
      "Henrik W. Bindner"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.12143",
    "title": "Critical initialization of wide and deep neural networks through partial  Jacobians: general theory and applications to LayerNorm",
    "abstract": " Comments: 28 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2111.12143",
    "authors": [
      "Darshil Doshi",
      "Tianyu He",
      "Andrey Gromov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.14831",
    "title": "MIST-net: Multi-domain Integrative Swin Transformer network for  Sparse-View CT Reconstruction",
    "abstract": " Comments: 24 pages, 10 figures, 57 references ",
    "url": "https://arxiv.org/abs/2111.14831",
    "authors": [
      "Jiayi Pan",
      "Weiwen Wu",
      "Zhifan Gao",
      "Heye Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  }
]