[
  {
    "id": "arXiv:2112.03975",
    "title": "Tailored neural networks for learning optimal value functions in MPC",
    "abstract": "Learning-based predictive control is a promising alternative to optimization-based MPC. However, efficiently learning the optimal control policy, the optimal value function, or the Q-function requires suitable function approximators. Often, artificial neural networks (ANN) are considered but choosing a suitable topology is also non-trivial. Against this background, it has recently been shown that tailored ANN allow, in principle, to exactly describe the optimal control policy in linear MPC by exploiting its piecewise affine structure. In this paper, we provide a similar result for representing the optimal value function and the Q-function that are both known to be piecewise quadratic for linear MPC. ",
    "url": "https://arxiv.org/abs/2112.03975",
    "authors": [
      "Dieter Teichrib",
      "Moritz Schulze Darup"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.04033",
    "title": "Image classifiers can not be made robust to small perturbations",
    "abstract": "The sensitivity of image classifiers to small perturbations in the input is often viewed as a defect of their construction. We demonstrate that this sensitivity is a fundamental property of classifiers. For any arbitrary classifier over the set of $n$-by-$n$ images, we show that for all but one class it is possible to change the classification of all but a tiny fraction of the images in that class with a tiny modification compared to the diameter of the image space when measured in any $p$-norm, including the hamming distance. We then examine how this phenomenon manifests in human visual perception and discuss its implications for the design considerations of computer vision systems. ",
    "url": "https://arxiv.org/abs/2112.04033",
    "authors": [
      "Zheng Dai",
      "David K. Gifford"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.04035",
    "title": "Relating transformers to models and neural representations of the  hippocampal formation",
    "abstract": "Many deep neural network architectures loosely based on brain networks have recently been shown to replicate neural firing patterns observed in the brain. One of the most exciting and promising novel architectures, the Transformer neural network, was developed without the brain in mind. In this work, we show that transformers, when equipped with recurrent position encodings, replicate the precisely tuned spatial representations of the hippocampal formation; most notably place and grid cells. Furthermore, we show that this result is no surprise since it is closely related to current hippocampal models from neuroscience. We additionally show the transformer version offers dramatic performance gains over the neuroscience version. This work continues to bind computations of artificial and brain networks, offers a novel understanding of the hippocampal-cortical interaction, and suggests how wider cortical areas may perform complex tasks beyond current neuroscience models such as language comprehension. ",
    "url": "https://arxiv.org/abs/2112.04035",
    "authors": [
      "James C.R. Whittington",
      "Joseph Warren",
      "Timothy E.J. Behrens"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2112.04231",
    "title": "Towards automation of threat modeling based on a semantic model of  attack patterns and weaknesses",
    "abstract": "This works considers challenges of building and usage a formal knowledge base (model), which unites the ATT&CK, CAPEC, CWE, CVE security enumerations. The proposed model can be used to learn relations between attack techniques, attack pattern, weaknesses, and vulnerabilities in order to build various threat landscapes, in particular, for threat modeling. The model is created as an ontology with freely available datasets in the OWL and RDF formats. The use of ontologies is an alternative of structural and graph based approaches to integrate the security enumerations. In this work we consider an approach of threat modeling with the data components of ATT&CK based on the knowledge base and an ontology driven threat modeling framework. Also, some evaluations are made, how it can be possible to use the ontological approach of threat modeling and which challenges this can be faced. ",
    "url": "https://arxiv.org/abs/2112.04231",
    "authors": [
      "Andrei Brazhuk"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.04257",
    "title": "Tutorial on communication between access networks and the 5G core",
    "abstract": "Fifth-generation (5G) networks enable a variety of use cases, e.g., Ultra-Reliable and Low-Latency Communications, enhanced Mobile Broadband, and massive Machine Type Communication. To explore the full potential of these use cases, it is mandatory to understand the communication between User Equipment (UE), Radio Access Network (RAN), and 5G Core (5GC), which support new network concepts and paradigms. For example, network slicing plays a crucial role in the communication system to address the challenges expected by the 5G networks. 3rd Generation Partnership Project has recently published Release 16, including the protocols used to communicate between RANs and 5GC, i.e., Non-Access Stratum (NAS) and NG Application Protocol (NGAP). The main goal of this article is to present a comprehensive tutorial about NAS and NGAP specifications using a didactic and practical approach. The tutorial describes the protocol stacks and aspects of the functionality of these protocols in 5G networks, such as authentication and identification procedures, data session establishment, and allocation of resources. Moreover, we review message flows related to these protocols in UE and Next Generation Node B (gNodeB) registration. To illustrate the concepts presented in the tutorial, we introduce a 5GC tester that implements NAS and NGAP for availing of three open-source 5GC projects on a black-box testing methodology. ",
    "url": "https://arxiv.org/abs/2112.04257",
    "authors": [
      "Lucas Baleeiro Dominato",
      "Henrique Carvalho de Resende",
      "Cristiano Bonato Both",
      "Johann M. Marquez-Barja",
      "Bruno O. Silvestre",
      "Kleber V. Cardoso"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2112.04288",
    "title": "Non parametric estimation of causal populations in a counterfactual  scenario",
    "abstract": "In causality, estimating the effect of a treatment without confounding inference remains a major issue because requires to assess the outcome in both case with and without treatment. Not being able to observe simultaneously both of them, the estimation of potential outcome remains a challenging task. We propose an innovative approach where the problem is reformulated as a missing data model. The aim is to estimate the hidden distribution of \\emph{causal populations}, defined as a function of treatment and outcome. A Causal Auto-Encoder (CAE), enhanced by a prior dependent on treatment and outcome information, assimilates the latent space to the probability distribution of the target populations. The features are reconstructed after being reduced to a latent space and constrained by a mask introduced in the intermediate layer of the network, containing treatment and outcome information. ",
    "url": "https://arxiv.org/abs/2112.04288",
    "authors": [
      "Celine Beji",
      "Florian Yger",
      "Jamal Atif"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2112.04350",
    "title": "Transformer based trajectory prediction",
    "abstract": "To plan a safe and efficient route, an autonomous vehicle should anticipate future motions of other agents around it. Motion prediction is an extremely challenging task which recently gained significant attention of the research community. In this work, we present a simple and yet strong baseline for uncertainty aware motion prediction based purely on transformer neural networks, which has shown its effectiveness in conditions of domain change. While being easy-to-implement, the proposed approach achieves competitive performance and ranks 1$^{st}$ on the 2021 Shifts Vehicle Motion Prediction Competition. ",
    "url": "https://arxiv.org/abs/2112.04350",
    "authors": [
      "Aleksey Postnikov",
      "Aleksander Gamayunov",
      "Gonzalo Ferrer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2112.04359",
    "title": "Ethical and social risks of harm from Language Models",
    "abstract": "This paper aims to help structure the risk landscape associated with large-scale Language Models (LMs). In order to foster advances in responsible innovation, an in-depth understanding of the potential risks posed by these models is needed. A wide range of established and anticipated risks are analysed in detail, drawing on multidisciplinary expertise and literature from computer science, linguistics, and social sciences. We outline six specific risk areas: I. Discrimination, Exclusion and Toxicity, II. Information Hazards, III. Misinformation Harms, V. Malicious Uses, V. Human-Computer Interaction Harms, VI. Automation, Access, and Environmental Harms. The first area concerns the perpetuation of stereotypes, unfair discrimination, exclusionary norms, toxic language, and lower performance by social group for LMs. The second focuses on risks from private data leaks or LMs correctly inferring sensitive information. The third addresses risks arising from poor, false or misleading information including in sensitive domains, and knock-on risks such as the erosion of trust in shared information. The fourth considers risks from actors who try to use LMs to cause harm. The fifth focuses on risks specific to LLMs used to underpin conversational agents that interact with human users, including unsafe use, manipulation or deception. The sixth discusses the risk of environmental harm, job automation, and other challenges that may have a disparate effect on different social groups or communities. In total, we review 21 risks in-depth. We discuss the points of origin of different risks and point to potential mitigation approaches. Lastly, we discuss organisational responsibilities in implementing mitigations, and the role of collaboration and participation. We highlight directions for further research, particularly on expanding the toolkit for assessing and evaluating the outlined risks in LMs. ",
    "url": "https://arxiv.org/abs/2112.04359",
    "authors": [
      "Laura Weidinger",
      "John Mellor",
      "Maribeth Rauh",
      "Conor Griffin",
      "Jonathan Uesato",
      "Po-Sen Huang",
      "Myra Cheng",
      "Mia Glaese",
      "Borja Balle",
      "Atoosa Kasirzadeh",
      "Zac Kenton",
      "Sasha Brown",
      "Will Hawkins",
      "Tom Stepleton",
      "Courtney Biles",
      "Abeba Birhane",
      "Julia Haas",
      "Laura Rimell",
      "Lisa Anne Hendricks",
      "William Isaac",
      "Sean Legassick",
      "Geoffrey Irving",
      "Iason Gabriel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2112.04367",
    "title": "On visual self-supervision and its effect on model robustness",
    "abstract": "Recent self-supervision methods have found success in learning feature representations that could rival ones from full supervision, and have been shown to be beneficial to the model in several ways: for example improving models robustness and out-of-distribution detection. In our paper, we conduct an empirical study to understand more precisely in what way can self-supervised learning - as a pre-training technique or part of adversarial training - affects model robustness to $l_2$ and $l_{\\infty}$ adversarial perturbations and natural image corruptions. Self-supervision can indeed improve model robustness, however it turns out the devil is in the details. If one simply adds self-supervision loss in tandem with adversarial training, then one sees improvement in accuracy of the model when evaluated with adversarial perturbations smaller or comparable to the value of $\\epsilon_{train}$ that the robust model is trained with. However, if one observes the accuracy for $\\epsilon_{test} \\ge \\epsilon_{train}$, the model accuracy drops. In fact, the larger the weight of the supervision loss, the larger the drop in performance, i.e. harming the robustness of the model. We identify primary ways in which self-supervision can be added to adversarial training, and observe that using a self-supervised loss to optimize both network parameters and find adversarial examples leads to the strongest improvement in model robustness, as this can be viewed as a form of ensemble adversarial training. Although self-supervised pre-training yields benefits in improving adversarial training as compared to random weight initialization, we observe no benefit in model robustness or accuracy if self-supervision is incorporated into adversarial training. ",
    "url": "https://arxiv.org/abs/2112.04367",
    "authors": [
      "Michal Kucer",
      "Diane Oyen",
      "Garrett Kenyon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.04388",
    "title": "A graph representation based on fluid diffusion model for multimodal  data analysis: theoretical aspects and enhanced community detection",
    "abstract": "Representing data by means of graph structures identifies one of the most valid approach to extract information in several data analysis applications. This is especially true when multimodal datasets are investigated, as records collected by means of diverse sensing strategies are taken into account and explored. Nevertheless, classic graph signal processing is based on a model for information propagation that is configured according to heat diffusion mechanism. This system provides several constraints and assumptions on the data properties that might be not valid for multimodal data analysis, especially when large scale datasets collected from heterogeneous sources are considered, so that the accuracy and robustness of the outcomes might be severely jeopardized. In this paper, we introduce a novel model for graph definition based on fluid diffusion. The proposed approach improves the ability of graph-based data analysis to take into account several issues of modern data analysis in operational scenarios, so to provide a platform for precise, versatile, and efficient understanding of the phenomena underlying the records under exam, and to fully exploit the potential provided by the diversity of the records in obtaining a thorough characterization of the data and their significance. In this work, we focus our attention to using this fluid diffusion model to drive a community detection scheme, i.e., to divide multimodal datasets into many groups according to similarity among nodes in an unsupervised fashion. Experimental results achieved by testing real multimodal datasets in diverse application scenarios show that our method is able to strongly outperform state-of-the-art schemes for community detection in multimodal data analysis. ",
    "url": "https://arxiv.org/abs/2112.04388",
    "authors": [
      "Andrea Marinoni",
      "Christian Jutten",
      "Mark Girolami"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.04395",
    "title": "On anti-stochastic properties of unlabeled graphs",
    "abstract": "We study vulnerability of a uniformly distributed random graph to an attack by an adversary who aims for a global change of the distribution while being able to make only a local change in the graph. We call a graph property $A$ anti-stochastic if the probability that a random graph $G$ satisfies $A$ is small but, with high probability, there is a small perturbation transforming $G$ into a graph satisfying $A$. While for labeled graphs such properties are easy to obtain from binary covering codes, the existence of anti-stochastic properties for unlabeled graphs is not so evident. If an admissible perturbation is either the addition or the deletion of one edge, we exhibit an anti-stochastic property that is satisfied by a random unlabeled graph of order $n$ with probability $(2+o(1))/n^2$, which is as small as possible. We also express another anti-stochastic property in terms of the degree sequence of a graph. This property has probability $(2+o(1))/(n\\ln n)$, which is optimal up to factor of 2. ",
    "url": "https://arxiv.org/abs/2112.04395",
    "authors": [
      "Sergei Kiselev",
      "Andrey Kupavskii",
      "Oleg Verbitsky",
      "Maksim Zhukovskii"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Cryptography and Security (cs.CR)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2112.03251",
    "title": "Computing a link diagram from its exterior",
    "abstract": "A knot is circle piecewise-linearly embedded into the 3-sphere. The topology of a knot is intimately related to that of its exterior, which is the complement of an open regular neighborhood of the knot. Knots are typically encoded by planar diagrams, whereas their exteriors, which are compact 3-manifolds with torus boundary, are encoded by triangulations. Here, we give the first practical algorithm for finding a diagram of a knot given a triangulation of its exterior. Our method applies to links as well as knots, and allows us to recover links with hundreds of crossings. We use it to find the first diagrams known for 19 principal congruence arithmetic link exteriors; the largest has over 1,000 crossings. Other applications include finding pairs of knots with the same 0-surgery, which relates to questions about slice knots and the smooth 4D Poincar\\'e conjecture. ",
    "url": "https://arxiv.org/abs/2112.03251",
    "authors": [
      "Cameron Gates Rudd",
      "Nathan M. Dunfield",
      "Malik Obeidin"
    ],
    "subjectives": [
      "Geometric Topology (math.GT)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2112.03916",
    "title": "BT-Unet: A self-supervised learning framework for biomedical image  segmentation using Barlow Twins with U-Net models",
    "abstract": "Deep learning has brought the most profound contribution towards biomedical image segmentation to automate the process of delineation in medical imaging. To accomplish such task, the models are required to be trained using huge amount of annotated or labelled data that highlights the region of interest with a binary mask. However, efficient generation of the annotations for such huge data requires expert biomedical analysts and extensive manual effort. It is a tedious and expensive task, while also being vulnerable to human error. To address this problem, a self-supervised learning framework, BT-Unet is proposed that uses the Barlow Twins approach to pre-train the encoder of a U-Net model via redundancy reduction in an unsupervised manner to learn data representation. Later, complete network is fine-tuned to perform actual segmentation. The BT-Unet framework can be trained with a limited number of annotated samples while having high number of unannotated samples, which is mostly the case in real-world problems. This framework is validated over multiple U-Net models over diverse datasets by generating scenarios of a limited number of labelled samples using standard evaluation metrics. With exhaustive experiment trials, it is observed that the BT-Unet framework enhances the performance of the U-Net models with significant margin under such circumstances. ",
    "url": "https://arxiv.org/abs/2112.03916",
    "authors": [
      "Narinder Singh Punn",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2006.10919",
    "title": "On the effect of normalization layers on Differentially Private training  of deep Neural networks",
    "abstract": " Title: On the effect of normalization layers on Differentially Private training  of deep Neural networks ",
    "url": "https://arxiv.org/abs/2006.10919",
    "authors": [
      "Ali Davody",
      "David Ifeoluwa Adelani",
      "Thomas Kleinbauer",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.08148",
    "title": "Causal motifs and existence of endogenous cascades in directed networks  with application to company defaults",
    "abstract": " Comments: 12 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2011.08148",
    "authors": [
      "Irena Barja\u0161i\u0107",
      "Hrvoje \u0160tefan\u010di\u0107",
      "Vedrana Pribi\u010devi\u0107",
      "Vinko Zlati\u0107"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Econometrics (econ.EM)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2105.02083",
    "title": "AdaBoost and robust one-bit compressed sensing",
    "abstract": " Comments: 40 pages, 4 figures, code available at this https URL, extended results to features that satisfy weak-moment and anti-concentration assumption ",
    "url": "https://arxiv.org/abs/2105.02083",
    "authors": [
      "Geoffrey Chinot",
      "Felix Kuchelmeister",
      "Matthias L\u00f6ffler",
      "Sara van de Geer"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.10436",
    "title": "A counter-example to the probabilistic universal graph conjecture via  randomized communication complexity",
    "abstract": " Comments: 7 pages ",
    "url": "https://arxiv.org/abs/2111.10436",
    "authors": [
      "Lianna Hambardzumyan",
      "Hamed Hatami",
      "Pooya Hatami"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2112.00183",
    "title": "Descriptive vs. inferential community detection: pitfalls, myths and  half-truths",
    "abstract": " Comments: 52 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2112.00183",
    "authors": [
      "Tiago P. Peixoto"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.03753",
    "title": "Tell me why! -- Explanations support learning of relational and causal  structure",
    "abstract": " Comments: 22 pages ",
    "url": "https://arxiv.org/abs/2112.03753",
    "authors": [
      "Andrew K. Lampinen",
      "Nicholas A. Roy",
      "Ishita Dasgupta",
      "Stephanie C. Y. Chan",
      "Allison C. Tam",
      "James L. McClelland",
      "Chen Yan",
      "Adam Santoro",
      "Neil C. Rabinowitz",
      "Jane X. Wang",
      "Felix Hill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  }
]