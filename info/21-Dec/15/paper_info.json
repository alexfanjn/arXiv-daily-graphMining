[
  {
    "id": "arXiv:2112.06990",
    "title": "Factorization and pseudofactorization of weighted graphs",
    "abstract": "For unweighted graphs, finding isometric embeddings is closely related to decompositions of $G$ into Cartesian products of smaller graphs. When $G$ is isomorphic to a Cartesian graph product, we call the factors of this product a factorization of $G$. When $G$ is isomorphic to an isometric subgraph of a Cartesian graph product, we call those factors a pseudofactorization of $G$. Prior work has shown that an unweighted graph's pseudofactorization can be used to generate a canonical isometric embedding into a product of the smallest possible pseudofactors. However, for arbitrary weighted graphs, which represent a richer variety of metric spaces, methods for finding isometric embeddings or determining their existence remain elusive, and indeed pseudofactorization and factorization have not previously been extended to this context. In this work, we address the problem of finding the factorization and pseudofactorization of a weighted graph $G$, where $G$ satisfies the property that every edge constitutes a shortest path between its endpoints. We term such graphs minimal graphs, noting that every graph can be made minimal by removing edges not affecting its path metric. We generalize pseudofactorization and factorization to minimal graphs and develop new proof techniques that extend the previously proposed algorithms due to Graham and Winkler [Graham and Winkler, '85] and Feder [Feder, '92] for pseudofactorization and factorization of unweighted graphs. We show that any $m$-edge, $n$-vertex graph with positive integer edge weights can be factored in $O(m^2)$ time, plus the time to find all pairs shortest paths (APSP) distances in a weighted graph, resulting in an overall running time of $O(m^2+n^2\\log\\log n)$ time. We also show that a pseudofactorization for such a graph can be computed in $O(mn)$ time, plus the time to solve APSP, resulting in an $O(mn+n^2\\log\\log n)$ running time. ",
    "url": "https://arxiv.org/abs/2112.06990",
    "authors": [
      "Kristin Sheridan",
      "Joseph Berleant",
      "Mark Bathe",
      "Anne Condon",
      "Virginia Vassilevska Williams"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2112.06994",
    "title": "Isometric Hamming embeddings of weighted graphs",
    "abstract": "A mapping $\\alpha : V(G) \\to V(H)$ from the vertex set of one graph $G$ to another graph $H$ is an isometric embedding if the shortest path distance between any two vertices in $G$ equals the distance between their images in $H$. Here, we consider isometric embeddings of a weighted graph $G$ into unweighted Hamming graphs, called Hamming embeddings, when $G$ satisfies the property that every edge is a shortest path between its endpoints. Using a Cartesian product decomposition of $G$ called its pseudofactorization, we show that every Hamming embedding of $G$ may be partitioned into Hamming embeddings for each irreducible pseudofactor graph of $G$, which we call its canonical partition. This implies that $G$ permits a Hamming embedding if and only if each of its irreducible pseudofactors is Hamming embeddable. This result extends prior work on unweighted graphs that showed that an unweighted graph permits a Hamming embedding if and only if each irreducible pseudofactor is a complete graph. When a graph $G$ has nontrivial pseudofactors, determining whether $G$ has a Hamming embedding can be simplified to checking embeddability of two or more smaller graphs. ",
    "url": "https://arxiv.org/abs/2112.06994",
    "authors": [
      "Joseph Berleant",
      "Kristin Sheridan",
      "Anne Condon",
      "Virginia Vassilevska Williams",
      "Mark Bathe"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2112.06999",
    "title": "Designing weighted and multiplex networks for deep learning user  geolocation in Twitter",
    "abstract": "Predicting the geographical location of users of social media like Twitter has found several applications in health surveillance, emergency monitoring, content personalization, and social studies in general. In this work we contribute to the research in this area by designing and evaluating new methods based on the literature of weighted multigraphs combined with state-of-the-art deep learning techniques. The explored methods depart from a similar underlying structure (that of an extended mention and/or follower network) but use different information processing strategies, e.g., information diffusion through transductive and inductive algorithms -- RGCNs and GraphSAGE, respectively -- and node embeddings with Node2vec+. These graphs are then combined with attention mechanisms to incorporate the users' text view into the models. We assess the performance of each of these methods and compare them to baseline models in the publicly available Twitter-US dataset; we also make a new dataset available based on a large Twitter capture in Latin America. Finally, our work discusses the limitations and validity of the comparisons among methods in the context of different label definitions and metrics. ",
    "url": "https://arxiv.org/abs/2112.06999",
    "authors": [
      "Federico M. Funes",
      "Jos\u00e9 Ignacio Alvarez-Hamelin",
      "Mariano G. Beir\u00f3"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.07007",
    "title": "Acceleration techniques for optimization over trained neural network  ensembles",
    "abstract": "We study optimization problems where the objective function is modeled through feedforward neural networks with rectified linear unit (ReLU) activation. Recent literature has explored the use of a single neural network to model either uncertain or complex elements within an objective function. However, it is well known that ensembles of neural networks produce more stable predictions and have better generalizability than models with single neural networks, which suggests the application of ensembles of neural networks in a decision-making pipeline. We study how to incorporate a neural network ensemble as the objective function of an optimization model and explore computational approaches for the ensuing problem. We present a mixed-integer linear program based on existing popular big-$M$ formulations for optimizing over a single neural network. We develop two acceleration techniques for our model, the first one is a preprocessing procedure to tighten bounds for critical neurons in the neural network while the second one is a set of valid inequalities based on Benders decomposition. Experimental evaluations of our solution methods are conducted on one global optimization problem and two real-world data sets; the results suggest that our optimization algorithm outperforms the adaption of an state-of-the-art approach in terms of computational time and optimality gaps. ",
    "url": "https://arxiv.org/abs/2112.07007",
    "authors": [
      "Keliang Wang",
      "Leonardo Lozano",
      "Carlos Cardonha",
      "David Bergman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2112.07054",
    "title": "Graph network for simultaneous learning of forward and inverse physics",
    "abstract": "In this work, we propose an end-to-end graph network that learns forward and inverse models of particle-based physics using interpretable inductive biases. Physics-informed neural networks are often engineered to solve specific problems through problem-specific regularization and loss functions. Such explicit learning biases the network to learn data specific patterns and may require a change in the loss function or neural network architecture hereby limiting their generalizabiliy. While recent studies have proposed graph networks to study forward dynamics, they rely on particle specific parameters such as mass, etc. to approximate the dynamics of the system. Our graph network is implicitly biased by learning to solve several tasks, thereby sharing representations between tasks in order to learn the forward dynamics as well as infer the probability distribution of unknown particle specific properties. We evaluate our approach on one-step next state prediction tasks across diverse datasets that feature different particle interactions. Our comparison against related data-driven physics learning approaches reveals that our model is able to predict the forward dynamics with at least an order of magnitude higher accuracy. We also show that our approach is able to recover multi-modal probability distributions of unknown physical parameters using orders of magnitude fewer samples. ",
    "url": "https://arxiv.org/abs/2112.07054",
    "authors": [
      "Sakthi Kumar Arul Prakash",
      "Conrad Tucker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.07131",
    "title": "VPVnet: a velocity-pressure-vorticity neural network method for the  Stokes' equations under reduced regularity",
    "abstract": "We present VPVnet, a deep neural network method for the Stokes' equations under reduced regularity. Different with recently proposed deep learning methods [40,51] which are based on the original form of PDEs, VPVnet uses the least square functional of the first-order velocity-pressure-vorticity (VPV) formulation ([30]) as loss functions. As such, only first-order derivative is required in the loss functions, hence the method is applicable to a much larger class of problems, e.g. problems with non-smooth solutions. Despite that several methods have been proposed recently to reduce the regularity requirement by transforming the original problem into a corresponding variational form, while for the Stokes' equations, the choice of approximating spaces for the velocity and the pressure has to satisfy the LBB condition additionally. Here by making use of the VPV formulation, lower regularity requirement is achieved with no need for considering the LBB condition. Convergence and error estimates have been established for the proposed method. It is worth emphasizing that the VPVnet method is divergence-free and pressure-robust, while classical inf-sup stable mixed finite elements for the Stokes' equations are not pressure-robust. Various numerical experiments including 2D and 3D lid-driven cavity test cases are conducted to demonstrate its efficiency and accuracy. ",
    "url": "https://arxiv.org/abs/2112.07131",
    "authors": [
      "Yujie Liu",
      "Chao Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2112.07236",
    "title": "Logics in fungal mycelium networks",
    "abstract": "The living mycelium networks are capable of efficient sensorial fusion over very large areas and distributed decision making. The information processing in the mycelium networks is implemented via propagation of electrical and chemical signals en pair with morphological changes in the mycelium structure. These information processing mechanisms are manifested in experimental laboratory findings that show that the mycelium networks exhibit rich dynamics of neuron-like spiking behaviour and a wide range of non-linear electrical properties. On an example of a single real colony of \\emph{Aspergillus niger}, we demonstrate that the non-linear transformation of electrical signals and trains of extracellular voltage spikes can be used to implement logical gates and circuits. The approaches adopted include numerical modelling of excitation propagation on the mycelium network, representation of the mycelium network as a resistive and capacitive (RC) network and an experimental laboratory study on mining logical circuits in mycelium bound composites. ",
    "url": "https://arxiv.org/abs/2112.07236",
    "authors": [
      "Andrew Adamatzky",
      "Phil Ayres",
      "Alexander E. Beasley",
      "Nic Roberts",
      "Martin Tegelaar",
      "Michail-Antisthenis Tsompanas",
      "Han A. B. W\u00f6sten"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2112.07239",
    "title": "Compensating trajectory bias for unsupervised patient stratification  using adversarial recurrent neural networks",
    "abstract": "Electronic healthcare records are an important source of information which can be used in patient stratification to discover novel disease phenotypes. However, they can be challenging to work with as data is often sparse and irregularly sampled. One approach to solve these limitations is learning dense embeddings that represent individual patient trajectories using a recurrent neural network autoencoder (RNN-AE). This process can be susceptible to unwanted data biases. We show that patient embeddings and clusters using previously proposed RNN-AE models might be impacted by a trajectory bias, meaning that results are dominated by the amount of data contained in each patients trajectory, instead of clinically relevant details. We investigate this bias on 2 datasets (from different hospitals) and 2 disease areas as well as using different parts of the patient trajectory. Our results using 2 previously published baseline methods indicate a particularly strong bias in case of an event-to-end trajectory. We present a method that can overcome this issue using an adversarial training scheme on top of a RNN-AE. Our results show that our approach can reduce the trajectory bias in all cases. ",
    "url": "https://arxiv.org/abs/2112.07239",
    "authors": [
      "Avelino Javer",
      "Owen Parsons",
      "Oliver Carr",
      "Janie Baxter",
      "Christian Diedrich",
      "Eren El\u00e7i",
      "Steffen Schaper",
      "Katrin Coboeken",
      "Robert D\u00fcrichen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.07285",
    "title": "Automatic COVID-19 disease diagnosis using 1D convolutional neural  network and augmentation with human respiratory sound based on parameters:  cough, breath, and voice",
    "abstract": "The issue in respiratory sound classification has attained good attention from the clinical scientists and medical researcher's group in the last year to diagnosing COVID-19 disease. To date, various models of Artificial Intelligence (AI) entered into the real-world to detect the COVID-19 disease from human-generated sounds such as voice/speech, cough, and breath. The Convolutional Neural Network (CNN) model is implemented for solving a lot of real-world problems on machines based on Artificial Intelligence (AI). In this context, one dimension (1D) CNN is suggested and implemented to diagnose respiratory diseases of COVID-19 from human respiratory sounds such as a voice, cough, and breath. An augmentation-based mechanism is applied to improve the preprocessing performance of the COVID-19 sounds dataset and to automate COVID-19 disease diagnosis using the 1D convolutional network. Furthermore, a DDAE (Data De-noising Auto Encoder) technique is used to generate deep sound features such as the input function to the 1D CNN instead of adopting the standard input of MFCC (Mel-frequency cepstral coefficient), and it is performed better accuracy and performance than previous models. ",
    "url": "https://arxiv.org/abs/2112.07285",
    "authors": [
      "Kranthi Kumar Lella",
      "Alphonse Pja"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2112.07322",
    "title": "Right-hand side decoding of Gabidulin code and applications",
    "abstract": "We discuss the decoding of Gabidulin and interleaved Gabidulin codes. We give the full presentation of a decoding algorithm for Gabidulin codes, which as Loidreau's seminal algorithm consists in localizing errors in the spirit of Berlekamp-Welch algorithm for Reed-Solomon codes. On the other hand, this algorithm consists in acting on codewords on the right while Loidreau's algorithm considers an action on the left. This right-hand side decoder was already introduced by the authors in a previous work for cryptanalytic applications. We give here a generalised version which applies to the case of non-full length Gabidulin codes. Finally, we show that this algorithm turns out to provide a very clear and natural approach for the decoding of interleaved Gabidulin codes. ",
    "url": "https://arxiv.org/abs/2112.07322",
    "authors": [
      "Maxime Bombar",
      "Alain Couvreur"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2112.07343",
    "title": "Learning phase field mean curvature flows with neural networks",
    "abstract": "We introduce in this paper new, efficient numerical methods based on neural networks for the approximation of the mean curvature flow of either oriented or non-orientable surfaces. To learn the correct interface evolution law, our neural networks are trained on phase field representations of exact evolving interfaces. The structure of the networks draws inspiration from splitting schemes used for the discretization of the Allen-Cahn equation. But when the latter approximates the mean curvature motion of oriented interfaces only, the approach we propose extends very naturally to the non-orientable case. In addition, although trained on smooth flows only, our networks can handle singularities as well. Furthermore, they can be coupled easily with additional constraints which allows us to show various applications illustrating the flexibility and efficiency of our approach: mean curvature flows with volume constraint, multiphase mean curvature flows, numerical approximation of Steiner trees, numerical approximation of minimal surfaces. ",
    "url": "https://arxiv.org/abs/2112.07343",
    "authors": [
      "Elie Bretin",
      "Roland Denis",
      "Simon Masnou",
      "Garry Terii"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2112.07369",
    "title": "Convergence proof for stochastic gradient descent in the training of  deep neural networks with ReLU activation for constant target functions",
    "abstract": "In many numerical simulations stochastic gradient descent (SGD) type optimization methods perform very effectively in the training of deep neural networks (DNNs) but till this day it remains an open problem of research to provide a mathematical convergence analysis which rigorously explains the success of SGD type optimization methods in the training of DNNs. In this work we study SGD type optimization methods in the training of fully-connected feedforward DNNs with rectified linear unit (ReLU) activation. We first establish general regularity properties for the risk functions and their generalized gradient functions appearing in the training of such DNNs and, thereafter, we investigate the plain vanilla SGD optimization method in the training of such DNNs under the assumption that the target function under consideration is a constant function. Specifically, we prove under the assumption that the learning rates (the step sizes of the SGD optimization method) are sufficiently small but not $L^1$-summable and under the assumption that the target function is a constant function that the expectation of the riskof the considered SGD process converges in the training of such DNNs to zero as the number of SGD steps increases to infinity. ",
    "url": "https://arxiv.org/abs/2112.07369",
    "authors": [
      "Martin Hutzenthaler",
      "Arnulf Jentzen",
      "Katharina Pohl",
      "Adrian Riekert",
      "Luca Scarpa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2112.07395",
    "title": "Handwritten text generation and strikethrough characters augmentation",
    "abstract": "We introduce two data augmentation techniques, which, used with a Resnet-BiLSTM-CTC network, significantly reduce Word Error Rate (WER) and Character Error Rate (CER) beyond best-reported results on handwriting text recognition (HTR) tasks. We apply a novel augmentation that simulates strikethrough text (HandWritten Blots) and a handwritten text generation method based on printed text (StackMix), which proved to be very effective in HTR tasks. StackMix uses weakly-supervised framework to get character boundaries. Because these data augmentation techniques are independent of the network used, they could also be applied to enhance the performance of other networks and approaches to HTR. Extensive experiments on ten handwritten text datasets show that HandWritten Blots augmentation and StackMix significantly improve the quality of HTR models ",
    "url": "https://arxiv.org/abs/2112.07395",
    "authors": [
      "Alex Shonenkov",
      "Denis Karachev",
      "Max Novopoltsev",
      "Mark Potanin",
      "Denis Dimitrov",
      "Andrey Chertok"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.07528",
    "title": "$n$-CPS: Generalising Cross Pseudo Supervision to $n$ networks for  Semi-Supervised Semantic Segmentation",
    "abstract": "We present $n$-CPS - a generalisation of the recent state-of-the-art cross pseudo supervision (CPS) approach for the task of semi-supervised semantic segmentation. In $n$-CPS, there are $n$ simultaneously trained subnetworks that learn from each other through one-hot encoding perturbation and consistency regularisation. We also show that ensembling techniques applied to subnetworks outputs can significantly improve the performance. To the best of our knowledge, $n$-CPS paired with CutMix outperforms CPS and sets the new state-of-the-art for Pascal VOC 2012 with (1/16, 1/8, 1/4, and 1/2 supervised regimes) and Cityscapes (1/16 supervised). ",
    "url": "https://arxiv.org/abs/2112.07528",
    "authors": [
      "Dominik Filipiak",
      "Piotr Tempczyk",
      "Marek Cygan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.07059",
    "title": "Self-induced emergence of consensus in social networks: Reddit and the  GameStop short squeeze",
    "abstract": "The short squeeze of GameStop (GME) shares in mid-January 2021, primarily orchestrated by retail investors of the Reddit r/wallstreetbets community, represents a paramount example of collective coordination action on social media, resulting in large-scale consensus formation and significant market impact. In this work we characterise the structure and time evolution of Reddit conversation data, showing that the occurrence and sentiment of GME-related comments (representing how much users are engaged with GME) increased significantly much before the short squeeze actually took place. We then introduce a model of opinion dynamics where user engagement can trigger a self-reinforcing mechanism leading to the emergence of consensus on the short squeeze operation. We observe a clear phase transition from heterogeneous to homogeneous opinions as engagement grows, with the presence of hubs easing the formation of diffuse consensus. Our results shed light on the increasingly important phenomenon of self-organized collective actions taking place on social networks. ",
    "url": "https://arxiv.org/abs/2112.07059",
    "authors": [
      "Anna Mancini",
      "Antonio Desiderio",
      "Riccardo Di Clemente",
      "Giulio Cimini"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2112.07156",
    "title": "ImportantAug: a data augmentation agent for speech",
    "abstract": "We introduce ImportantAug, a technique to augment training data for speech classification and recognition models by adding noise to unimportant regions of the speech and not to important regions. Importance is predicted for each utterance by a data augmentation agent that is trained to maximize the amount of noise it adds while minimizing its impact on recognition performance. The effectiveness of our method is illustrated on version two of the Google Speech Commands (GSC) dataset. On the standard GSC test set, it achieves a 23.3% relative error rate reduction compared to conventional noise augmentation which applies noise to speech without regard to where it might be most effective. It also provides a 25.4% error rate reduction compared to a baseline without data augmentation. Additionally, the proposed ImportantAug outperforms the conventional noise augmentation and the baseline on two test sets with additional noise added. ",
    "url": "https://arxiv.org/abs/2112.07156",
    "authors": [
      "Viet Anh Trinh",
      "Hassan Salami Kavaki",
      "Michael I Mandel"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2112.07297",
    "title": "Parameterized codes over graphs",
    "abstract": "In this article we review known results on parameterized linear codes over graphs, introduced by Renter\\'ia, Simis and Villarreal in 2011. Very little is known about their basic parameters and invariants. We review in detail the parameters dimension, regularity and minimum distance. As regards the parameter dimension, we explore the connection to Eulerian ideals in the ternary case and we give new combinatorial formulas. ",
    "url": "https://arxiv.org/abs/2112.07297",
    "authors": [
      "Jorge Neves",
      "Maria Vaz Pinto"
    ],
    "subjectives": [
      "Commutative Algebra (math.AC)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2007.02413",
    "title": "Elimination distance to bounded degree on planar graphs",
    "abstract": " Title: Elimination distance to bounded degree on planar graphs ",
    "url": "https://arxiv.org/abs/2007.02413",
    "authors": [
      "Alexander Lindermayr",
      "Sebastian Siebertz",
      "Alexandre Vigny"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2107.13862",
    "title": "Subsequent embedding in targeted image steganalysis: Theoretical  framework and practical applications",
    "abstract": " Title: Subsequent embedding in targeted image steganalysis: Theoretical  framework and practical applications ",
    "url": "https://arxiv.org/abs/2107.13862",
    "authors": [
      "David Meg\u00edas",
      "Daniel Lerch-Hostalot"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2112.05648",
    "title": "Minimax detection of localized signals in statistical inverse problems",
    "abstract": " Title: Minimax detection of localized signals in statistical inverse problems ",
    "url": "https://arxiv.org/abs/2112.05648",
    "authors": [
      "Markus Pohlmann",
      "Frank Werner",
      "Axel Munk"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2112.06348",
    "title": "MedGraph: An experimental semantic information retrieval method using  knowledge graph embedding for the biomedical citations indexed in PubMed",
    "abstract": " Comments: Accepted at the 19th International Conference on Information Technology : New Generations (ITNG 2022) ",
    "url": "https://arxiv.org/abs/2112.06348",
    "authors": [
      "Islam Akef Ebeid",
      "Elizabeth Pierce"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  }
]