[
  {
    "id": "arXiv:2112.01008",
    "title": "Editing a classifier by rewriting its prediction rules",
    "abstract": "We present a methodology for modifying the behavior of a classifier by directly rewriting its prediction rules. Our approach requires virtually no additional data collection and can be applied to a variety of settings, including adapting a model to new environments, and modifying it to ignore spurious features. Our code is available at https://github.com/MadryLab/EditingClassifiers . ",
    "url": "https://arxiv.org/abs/2112.01008",
    "authors": [
      "Shibani Santurkar",
      "Dimitris Tsipras",
      "Mahalaxmi Elango",
      "David Bau",
      "Antonio Torralba",
      "Aleksander Madry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.01079",
    "title": "Who will dropout from university? Academic risk prediction based on  interpretable machine learning",
    "abstract": "In the institutional research mode, in order to explore which characteristics are the best indicators for predicting academic risk from the student behavior data sets that have high-dimensional, unbalanced classified small sample, it transforms the academic risk prediction of college students into a binary classification task. It predicts academic risk based on the LightGBM model and the interpretable machine learning method of Shapley value. The simulation results show that from the global perspective of the prediction model, characteristics such as the quality of academic partners, the seating position in classroom, the dormitory study atmosphere, the English scores of the college entrance examination, the quantity of academic partners, the addiction level of video games, the mobility of academic partners, and the degree of truancy are the best 8 predictors for academic risk. It is contrary to intuition that characteristics such as living in campus or not, work-study, lipstick addiction, student leader or not, lover amount, and smoking have little correlation with university academic risk in this experiment. From the local perspective of the sample, the factors affecting academic risk vary from person to person. It can perform personalized interpretable analysis through Shapley values, which cannot be done by traditional mathematical statistical prediction models. The academic contributions of this research are mainly in two aspects: First, the learning interaction networks is proposed for the first time, so that social behavior can be used to compensate for the one-sided individual behavior and improve the performance of academic risk prediction. Second, the introduction of Shapley value calculation makes machine learning that lacks a clear reasoning process visualized, and provides intuitive decision support for education managers. ",
    "url": "https://arxiv.org/abs/2112.01079",
    "authors": [
      "Shudong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.01082",
    "title": "Grafana plugin for visualising vote based consensus mechanisms, and  network P2P overlay networks",
    "abstract": "In this paper, we present a plugin for visualising vote based consensus mechanisms primarily aimed to help engineers understand and debug blockchain and distributed ledger protocols. Both tools are built as Grafana plugins and make no assumptions on the data storage implementation. The plugins can be configured via Grafana plugin configuration interface to fit the specifics of the protocol implementation. ",
    "url": "https://arxiv.org/abs/2112.01082",
    "authors": [
      "Daniil Baldouski",
      "Aleksandar To\u0161i\u0107"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2112.01189",
    "title": "Simplifying heterogeneous migration between x86 and ARM machines",
    "abstract": "Heterogeneous computing is the strategy of deploying multiple types of processing elements within a single workflow, and allowing each to perform the tasks to which is best suited. To fully harness the power of heterogeneity, we want to be able to dynamically schedule portions of the code and migrate processes at runtime between the architectures. Also, migration includes transforming the execution state of the process, which induces a significant overhead that offsets the benefits of migrating in the first place. The goal of my PhD is to work on techniques that allow applications to run on heterogeneous cores under a shared programming model, and to tackle the generic problem of creating a uniform address space between processes running on these highly diverse systems. This would greatly simplify the migration process. We will start by examining a common stack layout between x86 and ARM binaries, focusing on these two widely spread architectures, and later we will try to generalize to other more diverse execution environments. On top of that, the performance and energy efficiency of the above effort compared to current approaches will be benchmarked. ",
    "url": "https://arxiv.org/abs/2112.01189",
    "authors": [
      "Nikolaos Mavrogeorgis"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2112.01224",
    "title": "Using word embedding for environmental violation analysis: Evidence from  Pennsylvania unconventional oil and gas compliance reports",
    "abstract": "With the booming of the unconventional oil and gas industry, its inevitable damage to the environment and human health has attracted public attention. We applied text mining on a total 6057 the type of Environmental Health and Safety compliance reports from 2008 to 2018 lunched by the Department of Environmental Protection in Pennsylvania, USA, to discover the intern mechanism of environmental violations. ",
    "url": "https://arxiv.org/abs/2112.01224",
    "authors": [
      "Dan Bi",
      "Ju-e Guo",
      "Erlong Zhao",
      "Shaolong Sun",
      "Shouyang Wang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.01304",
    "title": "The voice of few, the opinions of many: evidence of social biases in  Twitter COVID-19 fake news sharing",
    "abstract": "Online platforms play a relevant role in creation and diffusion of false or misleading news. Concerningly, the COVID-19 pandemic is shaping a communication network - barely considered in the literature - which reflects the emergence of collective attention towards a topic that rapidly gained universal interest. Here, we characterize the dynamics of this network on Twitter, analyzing how unreliable content distributes among its users. We find that a minority of accounts is responsible for the majority of the misinformation circulating online, and identify two categories of users: a few active ones, playing the role of \"creators\", and a majority playing the role of \"consumers\". The relative proportion of these groups ($\\approx$14% creators - 86% consumers) appears stable over time: Consumers are mostly exposed to the opinions of a vocal minority of creators, that could be mistakenly understood as of representative of the majority of users. The corresponding pressure from a perceived majority is identified as a potential driver of the ongoing COVID-19 infodemic. ",
    "url": "https://arxiv.org/abs/2112.01304",
    "authors": [
      "Piergiorgio Castioni",
      "Giulia Andrighetto",
      "Riccardo Gallotti",
      "Eugenia Polizzi",
      "Manlio De Domenico"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2112.01401",
    "title": "Newton methods based convolution neural networks using parallel  processing",
    "abstract": "Training of convolutional neural networks is a high dimensional and a non-convex optimization problem. At present, it is inefficient in situations where parametric learning rates can not be confidently set. Some past works have introduced Newton methods for training deep neural networks. Newton methods for convolutional neural networks involve complicated operations. Finding the Hessian matrix in second-order methods becomes very complex as we mainly use the finite differences method with the image data. Newton methods for convolutional neural networks deals with this by using the sub-sampled Hessian Newton methods. In this paper, we have used the complete data instead of the sub-sampled methods that only handle partial data at a time. Further, we have used parallel processing instead of serial processing in mini-batch computations. The results obtained using parallel processing in this study, outperform the time taken by the previous approach. ",
    "url": "https://arxiv.org/abs/2112.01401",
    "authors": [
      "Ujjwal Thakur",
      "Anuj Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.01421",
    "title": "Deep residential representations: Using unsupervised learning to unlock  elevation data for geo-demographic prediction",
    "abstract": "LiDAR (short for \"Light Detection And Ranging\" or \"Laser Imaging, Detection, And Ranging\") technology can be used to provide detailed three-dimensional elevation maps of urban and rural landscapes. To date, airborne LiDAR imaging has been predominantly confined to the environmental and archaeological domains. However, the geographically granular and open-source nature of this data also lends itself to an array of societal, organizational and business applications where geo-demographic type data is utilised. Arguably, the complexity involved in processing this multi-dimensional data has thus far restricted its broader adoption. In this paper, we propose a series of convenient task-agnostic tile elevation embeddings to address this challenge, using recent advances from unsupervised Deep Learning. We test the potential of our embeddings by predicting seven English indices of deprivation (2019) for small geographies in the Greater London area. These indices cover a range of socio-economic outcomes and serve as a proxy for a wide variety of downstream tasks to which the embeddings can be applied. We consider the suitability of this data not just on its own but also as an auxiliary source of data in combination with demographic features, thus providing a realistic use case for the embeddings. Having trialled various model/embedding configurations, we find that our best performing embeddings lead to Root-Mean-Squared-Error (RMSE) improvements of up to 21% over using standard demographic features alone. We also demonstrate how our embedding pipeline, using Deep Learning combined with K-means clustering, produces coherent tile segments which allow the latent embedding features to be interpreted. ",
    "url": "https://arxiv.org/abs/2112.01421",
    "authors": [
      "Matthew Stevenson",
      "Christophe Mues",
      "Cristi\u00e1n Bravo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.01438",
    "title": "Level set learning with pseudo-reversible neural networks for nonlinear  dimension reduction in function approximation",
    "abstract": "Due to the curse of dimensionality and the limitation on training data, approximating high-dimensional functions is a very challenging task even for powerful deep neural networks. Inspired by the Nonlinear Level set Learning (NLL) method that uses the reversible residual network (RevNet), in this paper we propose a new method of Dimension Reduction via Learning Level Sets (DRiLLS) for function approximation. Our method contains two major components: one is the pseudo-reversible neural network (PRNN) module that effectively transforms high-dimensional input variables to low-dimensional active variables, and the other is the synthesized regression module for approximating function values based on the transformed data in the low-dimensional space. The PRNN not only relaxes the invertibility constraint of the nonlinear transformation present in the NLL method due to the use of RevNet, but also adaptively weights the influence of each sample and controls the sensitivity of the function to the learned active variables. The synthesized regression uses Euclidean distance in the input space to select neighboring samples, whose projections on the space of active variables are used to perform local least-squares polynomial fitting. This helps to resolve numerical oscillation issues present in traditional local and global regressions. Extensive experimental results demonstrate that our DRiLLS method outperforms both the NLL and Active Subspace methods, especially when the target function possesses critical points in the interior of its input domain. ",
    "url": "https://arxiv.org/abs/2112.01438",
    "authors": [
      "Yuankai Teng",
      "Zhu Wang",
      "Lili Ju",
      "Anthony Gruber",
      "Guannan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2112.01474",
    "title": "Approximation by tree tensor networks in high dimensions: Sobolev and  compositional functions",
    "abstract": "This paper is concerned with convergence estimates for fully discrete tree tensor network approximations of high-dimensional functions from several model classes. For functions having standard or mixed Sobolev regularity, new estimates generalizing and refining known results are obtained, based on notions of linear widths of multivariate functions. In the main results of this paper, such techniques are applied to classes of functions with compositional structure, which are known to be particularly suitable for approximation by deep neural networks. As shown here, such functions can also be approximated by tree tensor networks without a curse of dimensionality -- however, subject to certain conditions, in particular on the depth of the underlying tree. In addition, a constructive encoding of compositional functions in tree tensor networks is given. ",
    "url": "https://arxiv.org/abs/2112.01474",
    "authors": [
      "Markus Bachmayr",
      "Anthony Nouy",
      "Reinhold Schneider"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2112.01023",
    "title": "A higher order Minkowski loss for improved prediction ability of  acoustic model in ASR",
    "abstract": "Conventional automatic speech recognition (ASR) system uses second-order minkowski loss during inference time which is suboptimal as it incorporates only first order statistics in posterior estimation [2]. In this paper we have proposed higher order minkowski loss (4th Order and 6th Order) during inference time, without any changes during training time. The main contribution of the paper is to show that higher order loss uses higher order statistics in posterior estimation, which improves the prediction ability of acoustic model in ASR system. We have shown mathematically that posterior probability obtained due to higher order loss is function of second order posterior and thus the method can be incorporated in standard ASR system in an easy manner. It is to be noted that all changes are proposed during test(inference) time, we do not make any change in any training pipeline. Multiple baseline systems namely, TDNN1, TDNN2, DNN and LSTM are developed to verify the improvement incurred due to higher order minkowski loss. All experiments are conducted on LibriSpeech dataset and performance metrics are word error rate (WER) on \"dev-clean\", \"test-clean\", \"dev-other\" and \"test-other\" datasets. ",
    "url": "https://arxiv.org/abs/2112.01023",
    "authors": [
      "Vishwanath Pratap Singh",
      "Shakti P. Rath",
      "Abhishek Pandey"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2008.09052",
    "title": "On transversality of bent hyperplane arrangements and the topological  expressiveness of ReLU neural networks",
    "abstract": " Comments: 29 pages, 1 figure; exposition and notation streamlined from version 1; to appear in SIAM Journal on Applied Algebra and Geometry ",
    "url": "https://arxiv.org/abs/2008.09052",
    "authors": [
      "J. Elisenda Grigsby",
      "Kathryn Lindsey"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Geometric Topology (math.GT)"
    ]
  },
  {
    "id": "arXiv:2012.14704",
    "title": "Advances in deep learning methods for pavement surface crack detection  and identification with visible light visual images",
    "abstract": " Comments: 15 pages, 14 figures, 11 tables ",
    "url": "https://arxiv.org/abs/2012.14704",
    "authors": [
      "Kailiang Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2104.14368",
    "title": "Fast computation of matrix function-based centrality measures for  layer-coupled multiplex networks",
    "abstract": " Title: Fast computation of matrix function-based centrality measures for  layer-coupled multiplex networks ",
    "url": "https://arxiv.org/abs/2104.14368",
    "authors": [
      "Kai Bergermann",
      "Martin Stoll"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2106.16009",
    "title": "MissFormer: (In-)attention-based handling of missing observations for  trajectory filtering and prediction",
    "abstract": " Comments: Accepted at the International Symposium on Visual Computing (ISVC) 2021 ",
    "url": "https://arxiv.org/abs/2106.16009",
    "authors": [
      "Stefan Becker",
      "Ronny Hug",
      "Wolfgang H\u00fcbner",
      "Michael Arens",
      "Brendan T. Morris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.06152",
    "title": "Enumerating independent sets in Abelian Cayley graphs",
    "abstract": " Comments: 21 pages, fixed minor typos and citations ",
    "url": "https://arxiv.org/abs/2109.06152",
    "authors": [
      "Aditya Potukuchi",
      "Liana Yepremyan"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2111.14831",
    "title": "MIST-net: Multi-domain Integrative Swin Transformer network for  Sparse-View CT Reconstruction",
    "abstract": " Comments: 24 pages, 10 figures, 57 references ",
    "url": "https://arxiv.org/abs/2111.14831",
    "authors": [
      "Jiayi Pan",
      "Weiwen Wu",
      "Zhifan Gao",
      "Heye Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  }
]