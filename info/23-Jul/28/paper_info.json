[
  {
    "id": "arXiv:2307.14345",
    "title": "NOMA for STAR-RIS Assisted UAV Networks",
    "abstract": "This paper proposes a novel simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) assisted unmanned aerial vehicle (UAV) non-orthogonal multiple access (NOMA) emergency communication network. Multiple STAR-RISs are deployed to provide additional and intelligent transmission links between trapped users and UAV-mounted base station (BS). Each user selects the nearest STAR-RIS for uploading data, and NOMA is employed for users located at the same side of the same STAR-RIS. Considering piratical requirements of post-disaster emergency communications, we formulate a throughput maximization problem subject to constraints on minimum average rate and maximum energy consumption, where the UAV trajectory, STAR-RIS passive beamforming, and time and power allocation are jointly optimized. Furthermore, we propose a Lagrange based reward constrained proximal policy optimization (LRCPPO) algorithm, which provides an adaptive method for solving the long-term optimization problem with cumulative constraints. Specifically, using Lagrange relaxation, the original problem is transformed into an unconstrained problem with a two-layer structure. The inner layer is solved by penalized reward based proximal policy optimization (PPO) algorithm. In the outer layer, Lagrange multipliers are updated by gradient descent. Numerical results show the proposed algorithm can effectively improve network performance while satisfying the constraints well. It also demonstrates the superiority of the proposed STAR-RIS assisted UAV NOMA network architecture over the benchmark schemes employing reflecting-only RISs and orthogonal multiple access. ",
    "url": "https://arxiv.org/abs/2307.14345",
    "authors": [
      "Jiayi Lei",
      "Tiankui Zhang",
      "Xidong Mu",
      "Yuanwei Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.14348",
    "title": "Solving the inverse potential problem in the parabolic equation by the  deep neural networks method",
    "abstract": "In this work, we consider an inverse potential problem in the parabolic equation, where the unknown potential is a space-dependent function and the used measurement is the final time data. The unknown potential in this inverse problem is parameterized by deep neural networks (DNNs) for the reconstruction scheme. First, the uniqueness of the inverse problem is proved under some regularities assumption on the input sources. Then we propose a new loss function with regularization terms depending on the derivatives of the residuals for partial differential equations (PDEs) and the measurements. These extra terms effectively induce higher regularity in solutions so that the ill-posedness of the inverse problem can be handled. Moreover, we establish the corresponding generalization error estimates rigorously. Our proofs exploit the conditional stability of the classical linear inverse source problems, and the mollification on the noisy measurement data which is set to reduce the perturbation errors. Finally, the numerical algorithm and some numerical results are provided. ",
    "url": "https://arxiv.org/abs/2307.14348",
    "authors": [
      "Mengmeng Zhang",
      "Zhidong Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ]
  },
  {
    "id": "arXiv:2307.14371",
    "title": "Prediction of depression status in college students using a Naive Bayes  classifier based machine learning model",
    "abstract": "This study presents a machine learning model based on the Naive Bayes classifier for predicting the level of depression in university students, the objective was to improve prediction accuracy using a machine learning model involving 70% training data and 30% validation data based on the Naive Bayes classifier, the collected data includes factors associated with depression from 519 university students, the results showed an accuracy of 78.03%, high sensitivity in detecting positive cases of depression, especially at moderate and severe levels, and significant specificity in correctly classifying negative cases, these findings highlight the effectiveness of the model in early detection and treatment of depression, benefiting vulnerable sectors and contributing to the improvement of mental health in the student population. ",
    "url": "https://arxiv.org/abs/2307.14371",
    "authors": [
      "Fred Torres Cruz",
      "Evelyn Eliana Coaquira Flores",
      "Sebastian Jarom Condori Quispe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2307.14373",
    "title": "Piecewise Linear Functions Representable with Infinite Width Shallow  ReLU Neural Networks",
    "abstract": "This paper analyzes representations of continuous piecewise linear functions with infinite width, finite cost shallow neural networks using the rectified linear unit (ReLU) as an activation function. Through its integral representation, a shallow neural network can be identified by the corresponding signed, finite measure on an appropriate parameter space. We map these measures on the parameter space to measures on the projective $n$-sphere cross $\\mathbb{R}$, allowing points in the parameter space to be bijectively mapped to hyperplanes in the domain of the function. We prove a conjecture of Ongie et al. that every continuous piecewise linear function expressible with this kind of infinite width neural network is expressible as a finite width shallow ReLU neural network. ",
    "url": "https://arxiv.org/abs/2307.14373",
    "authors": [
      "Sarah McCarty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)"
    ]
  },
  {
    "id": "arXiv:2307.14380",
    "title": "Robust Assignment of Labels for Active Learning with Sparse and Noisy  Annotations",
    "abstract": "Supervised classification algorithms are used to solve a growing number of real-life problems around the globe. Their performance is strictly connected with the quality of labels used in training. Unfortunately, acquiring good-quality annotations for many tasks is infeasible or too expensive to be done in practice. To tackle this challenge, active learning algorithms are commonly employed to select only the most relevant data for labeling. However, this is possible only when the quality and quantity of labels acquired from experts are sufficient. Unfortunately, in many applications, a trade-off between annotating individual samples by multiple annotators to increase label quality vs. annotating new samples to increase the total number of labeled instances is necessary. In this paper, we address the issue of faulty data annotations in the context of active learning. In particular, we propose two novel annotation unification algorithms that utilize unlabeled parts of the sample space. The proposed methods require little to no intersection between samples annotated by different experts. Our experiments on four public datasets indicate the robustness and superiority of the proposed methods in both, the estimation of the annotator's reliability, and the assignment of actual labels, against the state-of-the-art algorithms and the simple majority voting. ",
    "url": "https://arxiv.org/abs/2307.14380",
    "authors": [
      "Daniel Ka\u0142u\u017ca",
      "Andrzej Janusz",
      "Dominik \u015al\u0119zak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2307.14381",
    "title": "EdgeConvEns: Convolutional Ensemble Learning for Edge Intelligence",
    "abstract": "Deep edge intelligence aims to deploy deep learning models that demand computationally expensive training in the edge network with limited computational power. Moreover, many deep edge intelligence applications require handling distributed data that cannot be transferred to a central server due to privacy concerns. Decentralized learning methods, such as federated learning, offer solutions where models are learned collectively by exchanging learned weights. However, they often require complex models that edge devices may not handle and multiple rounds of network communication to achieve state-of-the-art performances. This study proposes a convolutional ensemble learning approach, coined EdgeConvEns, that facilitates training heterogeneous weak models on edge and learning to ensemble them where data on edge are heterogeneously distributed. Edge models are implemented and trained independently on Field-Programmable Gate Array (FPGA) devices with various computational capacities. Learned data representations are transferred to a central server where the ensemble model is trained with the learned features received from the edge devices to boost the overall prediction performance. Extensive experiments demonstrate that the EdgeConvEns can outperform the state-of-the-art performance with fewer communications and less data in various training scenarios. ",
    "url": "https://arxiv.org/abs/2307.14381",
    "authors": [
      "Ilkay Sikdokur",
      "\u0130nci M. Bayta\u015f",
      "Arda Yurdakul"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2307.14385",
    "title": "Leveraging Large Language Models for Mental Health Prediction via Online  Text Data",
    "abstract": "The recent technology boost of large language models (LLMs) has empowered a variety of applications. However, there is very little research on understanding and improving LLMs' capability for the mental health domain. In this work, we present the first comprehensive evaluation of multiple LLMs, including Alpaca, Alpaca-LoRA, and GPT-3.5, on various mental health prediction tasks via online text data. We conduct a wide range of experiments, covering zero-shot prompting, few-shot prompting, and instruction finetuning. The results indicate the promising yet limited performance of LLMs with zero-shot and few-shot prompt designs for mental health tasks. More importantly, our experiments show that instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned model, Mental-Alpaca, outperforms GPT-3.5 (25 times bigger) by 16.7\\% on balanced accuracy and performs on par with the state-of-the-art task-specific model. We summarize our findings into a set of action guidelines for future researchers, engineers, and practitioners on how to empower LLMs with better mental health domain knowledge and become an expert in mental health prediction tasks. ",
    "url": "https://arxiv.org/abs/2307.14385",
    "authors": [
      "Xuhai Xu",
      "Bingshen Yao",
      "Yuanzhe Dong",
      "Hong Yu",
      "James Hendler",
      "Anind K. Dey",
      "Dakuo Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.14387",
    "title": "Dual-Space Attacks against Random-Walk-based Anomaly Detection",
    "abstract": "Random Walks-based Anomaly Detection (RWAD) is commonly used to identify anomalous patterns in various applications. An intriguing characteristic of RWAD is that the input graph can either be pre-existing or constructed from raw features. Consequently, there are two potential attack surfaces against RWAD: graph-space attacks and feature-space attacks. In this paper, we explore this vulnerability by designing practical dual-space attacks, investigating the interplay between graph-space and feature-space attacks. To this end, we conduct a thorough complexity analysis, proving that attacking RWAD is NP-hard. Then, we proceed to formulate the graph-space attack as a bi-level optimization problem and propose two strategies to solve it: alternative iteration (alterI-attack) or utilizing the closed-form solution of the random walk model (cf-attack). Finally, we utilize the results from the graph-space attacks as guidance to design more powerful feature-space attacks (i.e., graph-guided attacks). Comprehensive experiments demonstrate that our proposed attacks are effective in enabling the target nodes from RWAD with a limited attack budget. In addition, we conduct transfer attack experiments in a black-box setting, which show that our feature attack significantly decreases the anomaly scores of target nodes. Our study opens the door to studying the dual-space attack against graph anomaly detection in which the graph space relies on the feature space. ",
    "url": "https://arxiv.org/abs/2307.14387",
    "authors": [
      "Yuni Lai",
      "Marcin Waniek",
      "Yulin Zhu",
      "Liying Li",
      "Jingwen Wu",
      "Tomasz P. Michalak",
      "Talal Rahwan",
      "Kai Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.14388",
    "title": "Online Context-aware Data Release with Sequence Information Privacy",
    "abstract": "Publishing streaming data in a privacy-preserving manner has been a key research focus for many years. This issue presents considerable challenges, particularly due to the correlations prevalent within the data stream. Existing approaches either fall short in effectively leveraging these correlations, leading to a suboptimal utility-privacy tradeoff, or they involve complex mechanism designs that increase the computation complexity with respect to the sequence length. In this paper, we introduce Sequence Information Privacy (SIP), a new privacy notion designed to guarantee privacy for an entire data stream, taking into account the intrinsic data correlations. We show that SIP provides a similar level of privacy guarantee compared to local differential privacy (LDP), and it also enjoys a lightweight modular mechanism design. We further study two online data release models (instantaneous or batched) and propose corresponding privacy-preserving data perturbation mechanisms. We provide a numerical evaluation of how correlations influence noise addition in data streams. Lastly, we conduct experiments using real-world data to compare the utility-privacy tradeoff offered by our approaches with those from existing literature. The results reveal that our mechanisms offer utility improvements more than twice those based on LDP-based mechanisms. ",
    "url": "https://arxiv.org/abs/2307.14388",
    "authors": [
      "Bo Jiang",
      "Ming Li",
      "Ravi Tandon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.14406",
    "title": "Demystifying Code Snippets in Code Reviews: A Study of the OpenStack and  Qt Communities and A Practitioner Survey",
    "abstract": "Code review is widely known as one of the best practices for software quality assurance in software development. In a typical code review process, reviewers check the code committed by developers to ensure the quality of the code, during which reviewers and developers would communicate with each other in review comments to exchange necessary information. As a result, understanding the information in review comments is a prerequisite for reviewers and developers to conduct an effective code review. Code snippet, as a special form of code, can be used to convey necessary information in code reviews. For example, reviewers can use code snippets to make suggestions or elaborate their ideas to meet developers' information needs in code reviews. However, little research has focused on the practices of providing code snippets in code reviews. To bridge this gap, we conduct a mixed-methods study to mine information and knowledge related to code snippets in code reviews, which can help practitioners and researchers get a better understanding about using code snippets in code review. Specifically, our study includes two phases: mining code review data and conducting practitioners' survey. The study results highlight that reviewers can provide code snippets in appropriate scenarios to meet developers' specific information needs in code reviews, which will facilitate and accelerate the code review process. ",
    "url": "https://arxiv.org/abs/2307.14406",
    "authors": [
      "Beiqi Zhang",
      "Liming Fu",
      "Peng Liang",
      "Jiaxin Yu",
      "Chong Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2307.14439",
    "title": "Fixed Integral Neural Networks",
    "abstract": "It is often useful to perform integration over learned functions represented by neural networks. However, this integration is usually performed numerically, as analytical integration over learned functions (especially neural networks) is generally viewed as intractable. In this work, we present a method for representing the analytical integral of a learned function $f$. This allows the exact integral of a neural network to be computed, and enables constrained neural networks to be parametrised by applying constraints directly to the integral. Crucially, we also introduce a method to constrain $f$ to be positive, a necessary condition for many applications (e.g. probability distributions, distance metrics, etc). Finally, we introduce several applications where our fixed-integral neural network (FINN) can be utilised. ",
    "url": "https://arxiv.org/abs/2307.14439",
    "authors": [
      "Ryan Kortvelesy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14446",
    "title": "Self-supervised Few-shot Learning for Semantic Segmentation: An  Annotation-free Approach",
    "abstract": "Few-shot semantic segmentation (FSS) offers immense potential in the field of medical image analysis, enabling accurate object segmentation with limited training data. However, existing FSS techniques heavily rely on annotated semantic classes, rendering them unsuitable for medical images due to the scarcity of annotations. To address this challenge, multiple contributions are proposed: First, inspired by spectral decomposition methods, the problem of image decomposition is reframed as a graph partitioning task. The eigenvectors of the Laplacian matrix, derived from the feature affinity matrix of self-supervised networks, are analyzed to estimate the distribution of the objects of interest from the support images. Secondly, we propose a novel self-supervised FSS framework that does not rely on any annotation. Instead, it adaptively estimates the query mask by leveraging the eigenvectors obtained from the support images. This approach eliminates the need for manual annotation, making it particularly suitable for medical images with limited annotated data. Thirdly, to further enhance the decoding of the query image based on the information provided by the support image, we introduce a multi-scale large kernel attention module. By selectively emphasizing relevant features and details, this module improves the segmentation process and contributes to better object delineation. Evaluations on both natural and medical image datasets demonstrate the efficiency and effectiveness of our method. Moreover, the proposed approach is characterized by its generality and model-agnostic nature, allowing for seamless integration with various deep architectures. The code is publicly available at \\href{https://github.com/mindflow-institue/annotation_free_fewshot}{\\textcolor{magenta}{GitHub}}. ",
    "url": "https://arxiv.org/abs/2307.14446",
    "authors": [
      "Sanaz Karimijafarbigloo",
      "Reza Azad",
      "Dorit Merhof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14460",
    "title": "MiDaS v3.1 -- A Model Zoo for Robust Monocular Relative Depth Estimation",
    "abstract": "We release MiDaS v3.1 for monocular depth estimation, offering a variety of new models based on different encoder backbones. This release is motivated by the success of transformers in computer vision, with a large variety of pretrained vision transformers now available. We explore how using the most promising vision transformers as image encoders impacts depth estimation quality and runtime of the MiDaS architecture. Our investigation also includes recent convolutional approaches that achieve comparable quality to vision transformers in image classification tasks. While the previous release MiDaS v3.0 solely leverages the vanilla vision transformer ViT, MiDaS v3.1 offers additional models based on BEiT, Swin, SwinV2, Next-ViT and LeViT. These models offer different performance-runtime tradeoffs. The best model improves the depth estimation quality by 28% while efficient models enable downstream tasks requiring high frame rates. We also describe the general process for integrating new backbones. A video summarizing the work can be found at https://youtu.be/UjaeNNFf9sE and the code is available at https://github.com/isl-org/MiDaS. ",
    "url": "https://arxiv.org/abs/2307.14460",
    "authors": [
      "Reiner Birkl",
      "Diana Wofk",
      "Matthias M\u00fcller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14464",
    "title": "Single Channel Speech Enhancement Using U-Net Spiking Neural Networks",
    "abstract": "Speech enhancement (SE) is crucial for reliable communication devices or robust speech recognition systems. Although conventional artificial neural networks (ANN) have demonstrated remarkable performance in SE, they require significant computational power, along with high energy costs. In this paper, we propose a novel approach to SE using a spiking neural network (SNN) based on a U-Net architecture. SNNs are suitable for processing data with a temporal dimension, such as speech, and are known for their energy-efficient implementation on neuromorphic hardware. As such, SNNs are thus interesting candidates for real-time applications on devices with limited resources. The primary objective of the current work is to develop an SNN-based model with comparable performance to a state-of-the-art ANN model for SE. We train a deep SNN using surrogate-gradient-based optimization and evaluate its performance using perceptual objective tests under different signal-to-noise ratios and real-world noise conditions. Our results demonstrate that the proposed energy-efficient SNN model outperforms the Intel Neuromorphic Deep Noise Suppression Challenge (Intel N-DNS Challenge) baseline solution and achieves acceptable performance compared to an equivalent ANN model. ",
    "url": "https://arxiv.org/abs/2307.14464",
    "authors": [
      "Abir Riahi",
      "\u00c9ric Plourde"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.14489",
    "title": "SuperInpaint: Learning Detail-Enhanced Attentional Implicit  Representation for Super-resolutional Image Inpainting",
    "abstract": "In this work, we introduce a challenging image restoration task, referred to as SuperInpaint, which aims to reconstruct missing regions in low-resolution images and generate completed images with arbitrarily higher resolutions. We have found that this task cannot be effectively addressed by stacking state-of-the-art super-resolution and image inpainting methods as they amplify each other's flaws, leading to noticeable artifacts. To overcome these limitations, we propose the detail-enhanced attentional implicit representation (DEAR) that can achieve SuperInpaint with a single model, resulting in high-quality completed images with arbitrary resolutions. Specifically, we use a deep convolutional network to extract the latent embedding of an input image and then enhance the high-frequency components of the latent embedding via an adaptive high-pass filter. This leads to detail-enhanced semantic embedding. We further feed the semantic embedding into an unmask-attentional module that suppresses embeddings from ineffective masked pixels. Additionally, we extract a pixel-wise importance map that indicates which pixels should be used for image reconstruction. Given the coordinates of a pixel we want to reconstruct, we first collect its neighboring pixels in the input image and extract their detail-enhanced semantic embeddings, unmask-attentional semantic embeddings, importance values, and spatial distances to the desired pixel. Then, we feed all the above terms into an implicit representation and generate the color of the specified pixel. To evaluate our method, we extend three existing datasets for this new task and build 18 meaningful baselines using SOTA inpainting and super-resolution methods. Extensive experimental results demonstrate that our method outperforms all existing methods by a significant margin on four widely used metrics. ",
    "url": "https://arxiv.org/abs/2307.14489",
    "authors": [
      "Canyu Zhang",
      "Qing Guo",
      "Xiaoguang Li",
      "Renjie Wan",
      "Hongkai Yu",
      "Ivor Tsang",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14490",
    "title": "HUGE: Huge Unsupervised Graph Embeddings with TPUs",
    "abstract": "Graphs are a representation of structured data that captures the relationships between sets of objects. With the ubiquity of available network data, there is increasing industrial and academic need to quickly analyze graphs with billions of nodes and trillions of edges. A common first step for network understanding is Graph Embedding, the process of creating a continuous representation of nodes in a graph. A continuous representation is often more amenable, especially at scale, for solving downstream machine learning tasks such as classification, link prediction, and clustering. A high-performance graph embedding architecture leveraging Tensor Processing Units (TPUs) with configurable amounts of high-bandwidth memory is presented that simplifies the graph embedding problem and can scale to graphs with billions of nodes and trillions of edges. We verify the embedding space quality on real and synthetic large-scale datasets. ",
    "url": "https://arxiv.org/abs/2307.14490",
    "authors": [
      "Brandon Mayer",
      "Anton Tsitsulin",
      "Hendrik Fichtenberger",
      "Jonathan Halcrow",
      "Bryan Perozzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2307.14491",
    "title": "Modality-Agnostic Audio-Visual Deepfake Detection",
    "abstract": "As AI-generated content (AIGC) thrives, Deepfakes have expanded from single-modality falsification to cross-modal fake content creation, where either audio or visual components can be manipulated. While using two unimodal detectors can detect audio-visual deepfakes, cross-modal forgery clues could be overlooked. Existing multimodal deepfake detection methods typically establish correspondence between the audio and visual modalities for binary real/fake classification, and require the co-occurrence of both modalities. However, in real-world multi-modal applications, missing modality scenarios may occur where either modality is unavailable. In such cases, audio-visual detection methods are less practical than two independent unimodal methods. Consequently, the detector can not always obtain the number or type of manipulated modalities beforehand, necessitating a fake-modality-agnostic audio-visual detector. In this work, we propose a unified fake-modality-agnostic scenarios framework that enables the detection of multimodal deepfakes and handles missing modalities cases, no matter the manipulation hidden in audio, video, or even cross-modal forms. To enhance the modeling of cross-modal forgery clues, we choose audio-visual speech recognition (AVSR) as a preceding task, which effectively extracts speech correlation across modalities, which is difficult for deepfakes to reproduce. Additionally, we propose a dual-label detection approach that follows the structure of AVSR to support the independent detection of each modality. Extensive experiments show that our scheme not only outperforms other state-of-the-art binary detection methods across all three audio-visual datasets but also achieves satisfying performance on detection modality-agnostic audio/video fakes. Moreover, it even surpasses the joint use of two unimodal methods in the presence of missing modality cases. ",
    "url": "https://arxiv.org/abs/2307.14491",
    "authors": [
      "Cai Yu",
      "Peng Chen",
      "Jiahe Tian",
      "Jin Liu",
      "Jiao Dai",
      "Xi Wang",
      "Yesheng Chai",
      "Jizhong Han"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.14494",
    "title": "Finding roots of complex analytic functions via generalized colleague  matrices",
    "abstract": "We present a scheme for finding all roots of an analytic function in a square domain in the complex plane. The scheme can be viewed as a generalization of the classical approach to finding roots of a function on the real line, by first approximating it by a polynomial in the Chebyshev basis, followed by diagonalizing the so-called ''colleague matrices''. Our extension of the classical approach is based on several observations that enable the construction of polynomial bases in compact domains that satisfy three-term recurrences and are reasonably well-conditioned. This class of polynomial bases gives rise to ''generalized colleague matrices'', whose eigenvalues are roots of functions expressed in these bases. In this paper, we also introduce a special-purpose QR algorithm for finding the eigenvalues of generalized colleague matrices, which is a straightforward extension of the recently introduced componentwise stable QR algorithm for the classical cases (See [Serkh]). The performance of the schemes is illustrated with several numerical examples. ",
    "url": "https://arxiv.org/abs/2307.14494",
    "authors": [
      "Hanwen Zhang",
      "Vladimir Rokhlin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.14510",
    "title": "Attention of Robot Touch: Tactile Saliency Prediction for Robust  Sim-to-Real Tactile Control",
    "abstract": "High-resolution tactile sensing can provide accurate information about local contact in contact-rich robotic tasks. However, the deployment of such tasks in unstructured environments remains under-investigated. To improve the robustness of tactile robot control in unstructured environments, we propose and study a new concept: \\textit{tactile saliency} for robot touch, inspired by the human touch attention mechanism from neuroscience and the visual saliency prediction problem from computer vision. In analogy to visual saliency, this concept involves identifying key information in tactile images captured by a tactile sensor. While visual saliency datasets are commonly annotated by humans, manually labelling tactile images is challenging due to their counterintuitive patterns. To address this challenge, we propose a novel approach comprised of three interrelated networks: 1) a Contact Depth Network (ConDepNet), which generates a contact depth map to localize deformation in a real tactile image that contains target and noise features; 2) a Tactile Saliency Network (TacSalNet), which predicts a tactile saliency map to describe the target areas for an input contact depth map; 3) and a Tactile Noise Generator (TacNGen), which generates noise features to train the TacSalNet. Experimental results in contact pose estimation and edge-following in the presence of distractors showcase the accurate prediction of target features from real tactile images. Overall, our tactile saliency prediction approach gives robust sim-to-real tactile control in environments with unknown distractors. Project page: https://sites.google.com/view/tactile-saliency/. ",
    "url": "https://arxiv.org/abs/2307.14510",
    "authors": [
      "Yijiong Lin",
      "Mauro Comi",
      "Alex Church",
      "Dandan Zhang",
      "Nathan F. Lepora"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.14523",
    "title": "Towards multi-modal anatomical landmark detection for ultrasound-guided  brain tumor resection with contrastive learning",
    "abstract": "Homologous anatomical landmarks between medical scans are instrumental in quantitative assessment of image registration quality in various clinical applications, such as MRI-ultrasound registration for tissue shift correction in ultrasound-guided brain tumor resection. While manually identified landmark pairs between MRI and ultrasound (US) have greatly facilitated the validation of different registration algorithms for the task, the procedure requires significant expertise, labor, and time, and can be prone to inter- and intra-rater inconsistency. So far, many traditional and machine learning approaches have been presented for anatomical landmark detection, but they primarily focus on mono-modal applications. Unfortunately, despite the clinical needs, inter-modal/contrast landmark detection has very rarely been attempted. Therefore, we propose a novel contrastive learning framework to detect corresponding landmarks between MRI and intra-operative US scans in neurosurgery. Specifically, two convolutional neural networks were trained jointly to encode image features in MRI and US scans to help match the US image patch that contain the corresponding landmarks in the MRI. We developed and validated the technique using the public RESECT database. With a mean landmark detection accuracy of 5.88+-4.79 mm against 18.78+-4.77 mm with SIFT features, the proposed method offers promising results for MRI-US landmark detection in neurosurgical applications for the first time. ",
    "url": "https://arxiv.org/abs/2307.14523",
    "authors": [
      "Soorena Salari",
      "Amirhossein Rasoulian",
      "Hassan Rivaz",
      "Yiming Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14531",
    "title": "Controlling the Inductive Bias of Wide Neural Networks by Modifying the  Kernel's Spectrum",
    "abstract": "Wide neural networks are biased towards learning certain functions, influencing both the rate of convergence of gradient descent (GD) and the functions that are reachable with GD in finite training time. As such, there is a great need for methods that can modify this bias according to the task at hand. To that end, we introduce Modified Spectrum Kernels (MSKs), a novel family of constructed kernels that can be used to approximate kernels with desired eigenvalues for which no closed form is known. We leverage the duality between wide neural networks and Neural Tangent Kernels and propose a preconditioned gradient descent method, which alters the trajectory of GD. As a result, this allows for a polynomial and, in some cases, exponential training speedup without changing the final solution. Our method is both computationally efficient and simple to implement. ",
    "url": "https://arxiv.org/abs/2307.14531",
    "authors": [
      "Amnon Geifman",
      "Daniel Barzilai",
      "Ronen Basri",
      "Meirav Galun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14540",
    "title": "Lateral-Direction Localization Attack in High-Level Autonomous Driving:  Domain-Specific Defense Opportunity via Lane Detection",
    "abstract": "Localization in high-level Autonomous Driving (AD) systems is highly security critical. While the popular Multi-Sensor Fusion (MSF) based design can be more robust against single-source sensor spoofing attacks, it is found recently that state-of-the-art MSF algorithms is vulnerable to GPS spoofing alone due to practical factors, which can cause various road hazards such as driving off road or onto the wrong way. In this work, we perform the first systematic exploration of the novel usage of lane detection (LD) to defend against such attacks. We first systematically analyze the potentials of such a domain-specific defense opportunity, and then design a novel LD-based defense approach, $LD^3$, that aims at not only detecting such attacks effectively in the real time, but also safely stopping the victim in the ego lane upon detection considering the absence of onboard human drivers. We evaluate $LD^3$ on real-world sensor traces and find that it can achieve effective and timely detection against existing attack with 100% true positive rates and 0% false positive rates. Results also show that $LD^3$ is robust to diverse environmental conditions and is effective at steering the AD vehicle to safely stop within the current traffic lane. We implement $LD^3$ on two open-source high-level AD systems, Baidu Apollo and Autoware, and validate its defense capability in both simulation and the physical world in end-to-end driving. We further conduct adaptive attack evaluations and find that $LD^3$ is effective at bounding the deviations from reaching the attack goals in stealthy attacks and is robust to latest LD-side attack. ",
    "url": "https://arxiv.org/abs/2307.14540",
    "authors": [
      "Junjie Shen",
      "Yunpeng Luo",
      "Ziwen Wan",
      "Qi Alfred Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.14549",
    "title": "Adversarial Sleeping Bandit Problems with Multiple Plays: Algorithm and  Ranking Application",
    "abstract": "This paper presents an efficient algorithm to solve the sleeping bandit with multiple plays problem in the context of an online recommendation system. The problem involves bounded, adversarial loss and unknown i.i.d. distributions for arm availability. The proposed algorithm extends the sleeping bandit algorithm for single arm selection and is guaranteed to achieve theoretical performance with regret upper bounded by $\\bigO(kN^2\\sqrt{T\\log T})$, where $k$ is the number of arms selected per time step, $N$ is the total number of arms, and $T$ is the time horizon. ",
    "url": "https://arxiv.org/abs/2307.14549",
    "authors": [
      "Jianjun Yuan",
      "Wei Lee Woon",
      "Ludovik Coba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.14570",
    "title": "Physically Plausible 3D Human-Scene Reconstruction from Monocular RGB  Image using an Adversarial Learning Approach",
    "abstract": "Holistic 3D human-scene reconstruction is a crucial and emerging research area in robot perception. A key challenge in holistic 3D human-scene reconstruction is to generate a physically plausible 3D scene from a single monocular RGB image. The existing research mainly proposes optimization-based approaches for reconstructing the scene from a sequence of RGB frames with explicitly defined physical laws and constraints between different scene elements (humans and objects). However, it is hard to explicitly define and model every physical law in every scenario. This paper proposes using an implicit feature representation of the scene elements to distinguish a physically plausible alignment of humans and objects from an implausible one. We propose using a graph-based holistic representation with an encoded physical representation of the scene to analyze the human-object and object-object interactions within the scene. Using this graphical representation, we adversarially train our model to learn the feasible alignments of the scene elements from the training data itself without explicitly defining the laws and constraints between them. Unlike the existing inference-time optimization-based approaches, we use this adversarially trained model to produce a per-frame 3D reconstruction of the scene that abides by the physical laws and constraints. Our learning-based method achieves comparable 3D reconstruction quality to existing optimization-based holistic human-scene reconstruction methods and does not need inference time optimization. This makes it better suited when compared to existing methods, for potential use in robotic applications, such as robot navigation, etc. ",
    "url": "https://arxiv.org/abs/2307.14570",
    "authors": [
      "Sandika Biswas",
      "Kejie Li",
      "Biplab Banerjee",
      "Subhasis Chaudhuri",
      "Hamid Rezatofighi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.14571",
    "title": "Robust Detection, Assocation, and Localization of Vehicle Lights: A  Context-Based Cascaded CNN Approach and Evaluations",
    "abstract": "Vehicle light detection is required for important downstream safe autonomous driving tasks, such as predicting a vehicle's light state to determine if the vehicle is making a lane change or turning. Currently, many vehicle light detectors use single-stage detectors which predict bounding boxes to identify a vehicle light, in a manner decoupled from vehicle instances. In this paper, we present a method for detecting a vehicle light given an upstream vehicle detection and approximation of a visible light's center. Our method predicts four approximate corners associated with each vehicle light. We experiment with CNN architectures, data augmentation, and contextual preprocessing methods designed to reduce surrounding-vehicle confusion. We achieve an average distance error from the ground truth corner of 5.09 pixels, about 17.24% of the size of the vehicle light on average. We train and evaluate our model on the LISA Lights dataset, allowing us to thoroughly evaluate our vehicle light corner detection model on a large variety of vehicle light shapes and lighting conditions. We propose that this model can be integrated into a pipeline with vehicle detection and vehicle light center detection to make a fully-formed vehicle light detection network, valuable to identifying trajectory-informative signals in driving scenes. ",
    "url": "https://arxiv.org/abs/2307.14571",
    "authors": [
      "Akshay Gopalkrishnan",
      "Ross Greer",
      "Maitrayee Keskar",
      "Mohan Trivedi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14575",
    "title": "A Memory-Augmented Multi-Task Collaborative Framework for Unsupervised  Traffic Accident Detection in Driving Videos",
    "abstract": "Identifying traffic accidents in driving videos is crucial to ensuring the safety of autonomous driving and driver assistance systems. To address the potential danger caused by the long-tailed distribution of driving events, existing traffic accident detection (TAD) methods mainly rely on unsupervised learning. However, TAD is still challenging due to the rapid movement of cameras and dynamic scenes in driving scenarios. Existing unsupervised TAD methods mainly rely on a single pretext task, i.e., an appearance-based or future object localization task, to detect accidents. However, appearance-based approaches are easily disturbed by the rapid movement of the camera and changes in illumination, which significantly reduce the performance of traffic accident detection. Methods based on future object localization may fail to capture appearance changes in video frames, making it difficult to detect ego-involved accidents (e.g., out of control of the ego-vehicle). In this paper, we propose a novel memory-augmented multi-task collaborative framework (MAMTCF) for unsupervised traffic accident detection in driving videos. Different from previous approaches, our method can more accurately detect both ego-involved and non-ego accidents by simultaneously modeling appearance changes and object motions in video frames through the collaboration of optical flow reconstruction and future object localization tasks. Further, we introduce a memory-augmented motion representation mechanism to fully explore the interrelation between different types of motion representations and exploit the high-level features of normal traffic patterns stored in memory to augment motion representations, thus enlarging the difference from anomalies. Experimental results on recently published large-scale dataset demonstrate that our method achieves better performance compared to previous state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2307.14575",
    "authors": [
      "Rongqin Liang",
      "Yuanman Li",
      "Yingxin Yi",
      "Jiantao Zhou",
      "Xia Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.14578",
    "title": "GADER: GAit DEtection and Recognition in the Wild",
    "abstract": "Gait recognition holds the promise of robustly identifying subjects based on their walking patterns instead of color information. While previous approaches have performed well for curated indoor scenes, they have significantly impeded applicability in unconstrained situations, e.g. outdoor, long distance scenes. We propose an end-to-end GAit DEtection and Recognition (GADER) algorithm for human authentication in challenging outdoor scenarios. Specifically, GADER leverages a Double Helical Signature to detect the fragment of human movement and incorporates a novel gait recognition method, which learns representations by distilling from an auxiliary RGB recognition model. At inference time, GADER only uses the silhouette modality but benefits from a more robust representation. Extensive experiments on indoor and outdoor datasets demonstrate that the proposed method outperforms the State-of-The-Arts for gait recognition and verification, with a significant 20.6% improvement on unconstrained, long distance scenes. ",
    "url": "https://arxiv.org/abs/2307.14578",
    "authors": [
      "Yuxiang Guo",
      "Cheng Peng",
      "Ram Prabhakar",
      "Chun Pong Lau",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14579",
    "title": "Neural Representation-Based Method for Metal-induced Artifact Reduction  in Dental CBCT Imaging",
    "abstract": "This study introduces a novel reconstruction method for dental cone-beam computed tomography (CBCT), focusing on effectively reducing metal-induced artifacts commonly encountered in the presence of prevalent metallic implants. Despite significant progress in metal artifact reduction techniques, challenges persist owing to the intricate physical interactions between polychromatic X-ray beams and metal objects, which are further compounded by the additional effects associated with metal-tooth interactions and factors specific to the dental CBCT data environment. To overcome these limitations, we propose an implicit neural network that generates two distinct and informative tomographic images. One image represents the monochromatic attenuation distribution at a specific energy level, whereas the other captures the nonlinear beam-hardening factor resulting from the polychromatic nature of X-ray beams. In contrast to existing CT reconstruction techniques, the proposed method relies exclusively on the Beer--Lambert law, effectively preventing the generation of metal-induced artifacts during the backprojection process commonly implemented in conventional methods. Extensive experimental evaluations demonstrate that the proposed method effectively reduces metal artifacts while providing high-quality image reconstructions, thus emphasizing the significance of the second image in capturing the nonlinear beam-hardening factor. ",
    "url": "https://arxiv.org/abs/2307.14579",
    "authors": [
      "Hyoung Suk Park",
      "Kiwan Jeon",
      "Jin Keun Seo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14591",
    "title": "The detection and rectification for identity-switch based on unfalsified  control",
    "abstract": "The purpose of multi-object tracking (MOT) is to continuously track and identify objects detected in videos. Currently, most methods for multi-object tracking model the motion information and combine it with appearance information to determine and track objects. In this paper, unfalsified control is employed to address the ID-switch problem in multi-object tracking. We establish sequences of appearance information variations for the trajectories during the tracking process and design a detection and rectification module specifically for ID-switch detection and recovery. We also propose a simple and effective strategy to address the issue of ambiguous matching of appearance information during the data association process. Experimental results on publicly available MOT datasets demonstrate that the tracker exhibits excellent effectiveness and robustness in handling tracking errors caused by occlusions and rapid movements. ",
    "url": "https://arxiv.org/abs/2307.14591",
    "authors": [
      "Junchao Huang",
      "Xiaoqi He",
      "Sheng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.14605",
    "title": "Clustering based Point Cloud Representation Learning for 3D Analysis",
    "abstract": "Point cloud analysis (such as 3D segmentation and detection) is a challenging task, because of not only the irregular geometries of many millions of unordered points, but also the great variations caused by depth, viewpoint, occlusion, etc. Current studies put much focus on the adaption of neural networks to the complex geometries of point clouds, but are blind to a fundamental question: how to learn an appropriate point embedding space that is aware of both discriminative semantics and challenging variations? As a response, we propose a clustering based supervised learning scheme for point cloud analysis. Unlike current de-facto, scene-wise training paradigm, our algorithm conducts within-class clustering on the point embedding space for automatically discovering subclass patterns which are latent yet representative across scenes. The mined patterns are, in turn, used to repaint the embedding space, so as to respect the underlying distribution of the entire training dataset and improve the robustness to the variations. Our algorithm is principled and readily pluggable to modern point cloud segmentation networks during training, without extra overhead during testing. With various 3D network architectures (i.e., voxel-based, point-based, Transformer-based, automatically searched), our algorithm shows notable improvements on famous point cloud segmentation datasets (i.e.,2.0-2.6% on single-scan and 2.0-2.2% multi-scan of SemanticKITTI, 1.8-1.9% on S3DIS, in terms of mIoU). Our algorithm also demonstrates utility in 3D detection, showing 2.0-3.4% mAP gains on KITTI. ",
    "url": "https://arxiv.org/abs/2307.14605",
    "authors": [
      "Tuo Feng",
      "Wenguan Wang",
      "Xiaohan Wang",
      "Yi Yang",
      "Qinghua Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.14611",
    "title": "TextManiA: Enriching Visual Feature by Text-driven Manifold Augmentation",
    "abstract": "Recent label mix-based augmentation methods have shown their effectiveness in generalization despite their simplicity, and their favorable effects are often attributed to semantic-level augmentation. However, we found that they are vulnerable to highly skewed class distribution, because scarce data classes are rarely sampled for inter-class perturbation. We propose TextManiA, a text-driven manifold augmentation method that semantically enriches visual feature spaces, regardless of data distribution. TextManiA augments visual data with intra-class semantic perturbation by exploiting easy-to-understand visually mimetic words, i.e., attributes. To this end, we bridge between the text representation and a target visual feature space, and propose an efficient vector augmentation. To empirically support the validity of our design, we devise two visualization-based analyses and show the plausibility of the bridge between two different modality spaces. Our experiments demonstrate that TextManiA is powerful in scarce samples with class imbalance as well as even distribution. We also show compatibility with the label mix-based approaches in evenly distributed scarce data. ",
    "url": "https://arxiv.org/abs/2307.14611",
    "authors": [
      "Moon Ye-Bin",
      "Jisoo Kim",
      "Hongyeob Kim",
      "Kilho Son",
      "Tae-Hyun Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14613",
    "title": "Self-Contrastive Graph Diffusion Network",
    "abstract": "Augmentation techniques and sampling strategies are crucial in contrastive learning, but in most existing works, augmentation techniques require careful design, and their sampling strategies can only capture a small amount of intrinsic supervision information. Additionally, the existing methods require complex designs to obtain two different representations of the data. To overcome these limitations, we propose a novel framework called the Self-Contrastive Graph Diffusion Network (SCGDN). Our framework consists of two main components: the Attentional Module (AttM) and the Diffusion Module (DiFM). AttM aggregates higher-order structure and feature information to get an excellent embedding, while DiFM balances the state of each node in the graph through Laplacian diffusion learning and allows the cooperative evolution of adjacency and feature information in the graph. Unlike existing methodologies, SCGDN is an augmentation-free approach that avoids \"sampling bias\" and semantic drift, without the need for pre-training. We conduct a high-quality sampling of samples based on structure and feature information. If two nodes are neighbors, they are considered positive samples of each other. If two disconnected nodes are also unrelated on $k$NN graph, they are considered negative samples for each other. The contrastive objective reasonably uses our proposed sampling strategies, and the redundancy reduction term minimizes redundant information in the embedding and can well retain more discriminative information. In this novel framework, the graph self-contrastive learning paradigm gives expression to a powerful force. SCGDN effectively balances between preserving high-order structure information and avoiding overfitting. The results manifest that SCGDN can consistently generate outperformance over both the contrastive methods and the classical methods. ",
    "url": "https://arxiv.org/abs/2307.14613",
    "authors": [
      "Yixian Ma",
      "Kun Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.14617",
    "title": "Multiscale Dynamic Graph Representation for Biometric Recognition with  Occlusions",
    "abstract": "Occlusion is a common problem with biometric recognition in the wild. The generalization ability of CNNs greatly decreases due to the adverse effects of various occlusions. To this end, we propose a novel unified framework integrating the merits of both CNNs and graph models to overcome occlusion problems in biometric recognition, called multiscale dynamic graph representation (MS-DGR). More specifically, a group of deep features reflected on certain subregions is recrafted into a feature graph (FG). Each node inside the FG is deemed to characterize a specific local region of the input sample, and the edges imply the co-occurrence of non-occluded regions. By analyzing the similarities of the node representations and measuring the topological structures stored in the adjacent matrix, the proposed framework leverages dynamic graph matching to judiciously discard the nodes corresponding to the occluded parts. The multiscale strategy is further incorporated to attain more diverse nodes representing regions of various sizes. Furthermore, the proposed framework exhibits a more illustrative and reasonable inference by showing the paired nodes. Extensive experiments demonstrate the superiority of the proposed framework, which boosts the accuracy in both natural and occlusion-simulated cases by a large margin compared with that of baseline methods. ",
    "url": "https://arxiv.org/abs/2307.14617",
    "authors": [
      "Min Ren",
      "Yunlong Wang",
      "Yuhao Zhu",
      "Kunbo Zhang",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14619",
    "title": "Imitating Complex Trajectories: Bridging Low-Level Stability and  High-Level Behavior",
    "abstract": "We propose a theoretical framework for studying the imitation of stochastic, non-Markovian, potentially multi-modal (i.e. \"complex\" ) expert demonstrations in nonlinear dynamical systems. Our framework invokes low-level controllers - either learned or implicit in position-command control - to stabilize imitation policies around expert demonstrations. We show that with (a) a suitable low-level stability guarantee and (b) a stochastic continuity property of the learned policy we call \"total variation continuity\" (TVC), an imitator that accurately estimates actions on the demonstrator's state distribution closely matches the demonstrator's distribution over entire trajectories. We then show that TVC can be ensured with minimal degradation of accuracy by combining a popular data-augmentation regimen with a novel algorithmic trick: adding augmentation noise at execution time. We instantiate our guarantees for policies parameterized by diffusion models and prove that if the learner accurately estimates the score of the (noise-augmented) expert policy, then the distribution of imitator trajectories is close to the demonstrator distribution in a natural optimal transport distance. Our analysis constructs intricate couplings between noise-augmented trajectories, a technique that may be of independent interest. We conclude by empirically validating our algorithmic recommendations. ",
    "url": "https://arxiv.org/abs/2307.14619",
    "authors": [
      "Adam Block",
      "Daniel Pfrommer",
      "Max Simchowitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.14620",
    "title": "NeRF-Det: Learning Geometry-Aware Volumetric Representation for  Multi-View 3D Object Detection",
    "abstract": "We present NeRF-Det, a novel method for indoor 3D detection with posed RGB images as input. Unlike existing indoor 3D detection methods that struggle to model scene geometry, our method makes novel use of NeRF in an end-to-end manner to explicitly estimate 3D geometry, thereby improving 3D detection performance. Specifically, to avoid the significant extra latency associated with per-scene optimization of NeRF, we introduce sufficient geometry priors to enhance the generalizability of NeRF-MLP. Furthermore, we subtly connect the detection and NeRF branches through a shared MLP, enabling an efficient adaptation of NeRF to detection and yielding geometry-aware volumetric representations for 3D detection. Our method outperforms state-of-the-arts by 3.9 mAP and 3.1 mAP on the ScanNet and ARKITScenes benchmarks, respectively. We provide extensive analysis to shed light on how NeRF-Det works. As a result of our joint-training design, NeRF-Det is able to generalize well to unseen scenes for object detection, view synthesis, and depth estimation tasks without requiring per-scene optimization. Code is available at \\url{https://github.com/facebookresearch/NeRF-Det}. ",
    "url": "https://arxiv.org/abs/2307.14620",
    "authors": [
      "Chenfeng Xu",
      "Bichen Wu",
      "Ji Hou",
      "Sam Tsai",
      "Ruilong Li",
      "Jialiang Wang",
      "Wei Zhan",
      "Zijian He",
      "Peter Vajda",
      "Kurt Keutzer",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14626",
    "title": "Multi-Agent Graph Reinforcement Learning based On-Demand Wireless Energy  Transfer in Multi-UAV-aided IoT Network",
    "abstract": "This paper proposes a new on-demand wireless energy transfer (WET) scheme of multiple unmanned aerial vehicles (UAVs). Unlike the existing studies that simply pursuing the total or the minimum harvested energy maximization at the Internet of Things (IoT) devices, where the IoT devices' own energy requirements are barely considered, we propose a new metric called the hungry-level of energy (HoE), which reflects the time-varying energy demand of each IoT device based on the energy gap between its required energy and the harvested energy from the UAVs. With the purpose to minimize the overall HoE of the IoT devices whose energy requirements are not satisfied, we optimally determine all the UAVs' trajectories and WET decisions over time, under the practical mobility and energy constraints of the UAVs. Although the proposed problem is of high complexity to solve, by excavating the UAVs' self-attentions for their collaborative WET, we propose the multiagent graph reinforcement learning (MAGRL) based approach. Through the offline training of the MAGRL model, where the global training at the central controller guides the local training at each UAV agent, each UAV then distributively determines its trajectory and WET based on the well-trained local neural networks. Simulation results show that the proposed MAGRL-based approach outperforms various benchmarks for meeting the IoT devices' energy requirements. ",
    "url": "https://arxiv.org/abs/2307.14626",
    "authors": [
      "Ze Yu Zhao",
      "Yueling Che",
      "Sheng Luo",
      "Kaishun Wu",
      "Victor C. M. Leung"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2307.14663",
    "title": "The Unweighted and Weighted Reverse Shortest Path Problem for Disk  Graphs",
    "abstract": "We study the reverse shortest path problem on disk graphs in the plane. In this problem we consider the proximity graph of a set of $n$ disks in the plane of arbitrary radii: In this graph two disks are connected if the distance between them is at most some threshold parameter $r$. The case of intersection graphs is a special case with $r=0$. We give an algorithm that, given a target length $k$, computes the smallest value of $r$ for which there is a path of length at most $k$ between some given pair of disks in the proximity graph. Our algorithm runs in $O^*(n^{5/4})$ randomized expected time, which improves to $O^*(n^{6/5})$ for unit disk graphs, where all the disks have the same radius. Our technique is robust and can be applied to many variants of the problem. One significant variant is the case of weighted proximity graphs, where edges are assigned real weights equal to the distance between the disks or between their centers, and $k$ is replaced by a target weight $w$; that is, we seek a path whose length is at most $w$. In other variants, we want to optimize a parameter different from $r$, such as a scale factor of the radii of the disks. The main technique for the decision version of the problem (determining whether the graph with a given $r$ has the desired property) is based on efficient implementations of BFS (for the unweighted case) and of Dijkstra's algorithm (for the weighted case), using efficient data structures for maintaining the bichromatic closest pair for certain bicliques and several distance functions. The optimization problem is then solved by combining the resulting decision procedure with enhanced variants of the interval shrinking and bifurcation technique of [4]. ",
    "url": "https://arxiv.org/abs/2307.14663",
    "authors": [
      "Haim Kaplan",
      "Matthew J. Katz",
      "Rachel Saban",
      "Micha Sharir"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2307.14675",
    "title": "Prediction of wind turbines power with physics-informed neural networks  and evidential uncertainty quantification",
    "abstract": "The ever-growing use of wind energy makes necessary the optimization of turbine operations through pitch angle controllers and their maintenance with early fault detection. It is crucial to have accurate and robust models imitating the behavior of wind turbines, especially to predict the generated power as a function of the wind speed. Existing empirical and physics-based models have limitations in capturing the complex relations between the input variables and the power, aggravated by wind variability. Data-driven methods offer new opportunities to enhance wind turbine modeling of large datasets by improving accuracy and efficiency. In this study, we used physics-informed neural networks to reproduce historical data coming from 4 turbines in a wind farm, while imposing certain physical constraints to the model. The developed models for regression of the power, torque, and power coefficient as output variables showed great accuracy for both real data and physical equations governing the system. Lastly, introducing an efficient evidential layer provided uncertainty estimations of the predictions, proved to be consistent with the absolute error, and made possible the definition of a confidence interval in the power curve. ",
    "url": "https://arxiv.org/abs/2307.14675",
    "authors": [
      "Alfonso Gij\u00f3n",
      "Ainhoa Pujana-Goitia",
      "Eugenio Perea",
      "Miguel Molina-Solana",
      "Juan G\u00f3mez-Romero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.14680",
    "title": "TimeGNN: Temporal Dynamic Graph Learning for Time Series Forecasting",
    "abstract": "Time series forecasting lies at the core of important real-world applications in many fields of science and engineering. The abundance of large time series datasets that consist of complex patterns and long-term dependencies has led to the development of various neural network architectures. Graph neural network approaches, which jointly learn a graph structure based on the correlation of raw values of multivariate time series while forecasting, have recently seen great success. However, such solutions are often costly to train and difficult to scale. In this paper, we propose TimeGNN, a method that learns dynamic temporal graph representations that can capture the evolution of inter-series patterns along with the correlations of multiple series. TimeGNN achieves inference times 4 to 80 times faster than other state-of-the-art graph-based methods while achieving comparable forecasting performance ",
    "url": "https://arxiv.org/abs/2307.14680",
    "authors": [
      "Nancy Xu",
      "Chrysoula Kosma",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14682",
    "title": "Unified Adversarial Patch for Visible-Infrared Cross-modal Attacks in  the Physical World",
    "abstract": "Physical adversarial attacks have put a severe threat to DNN-based object detectors. To enhance security, a combination of visible and infrared sensors is deployed in various scenarios, which has proven effective in disabling existing single-modal physical attacks. To further demonstrate the potential risks in such cases, we design a unified adversarial patch that can perform cross-modal physical attacks, achieving evasion in both modalities simultaneously with a single patch. Given the different imaging mechanisms of visible and infrared sensors, our work manipulates patches' shape features, which can be captured in different modalities when they undergo changes. To deal with challenges, we propose a novel boundary-limited shape optimization approach that aims to achieve compact and smooth shapes for the adversarial patch, making it easy to implement in the physical world. And a score-aware iterative evaluation method is also introduced to balance the fooling degree between visible and infrared detectors during optimization, which guides the adversarial patch to iteratively reduce the predicted scores of the multi-modal sensors. Furthermore, we propose an Affine-Transformation-based enhancement strategy that makes the learnable shape robust to various angles, thus mitigating the issue of shape deformation caused by different shooting angles in the real world. Our method is evaluated against several state-of-the-art object detectors, achieving an Attack Success Rate (ASR) of over 80%. We also demonstrate the effectiveness of our approach in physical-world scenarios under various settings, including different angles, distances, postures, and scenes for both visible and infrared sensors. ",
    "url": "https://arxiv.org/abs/2307.14682",
    "authors": [
      "Xingxing Wei",
      "Yao Huang",
      "Yitong Sun",
      "Jie Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14692",
    "title": "Backdoor Attacks for In-Context Learning with Language Models",
    "abstract": "Because state-of-the-art language models are expensive to train, most practitioners must make use of one of the few publicly available language models or language model APIs. This consolidation of trust increases the potency of backdoor attacks, where an adversary tampers with a machine learning model in order to make it perform some malicious behavior on inputs that contain a predefined backdoor trigger. We show that the in-context learning ability of large language models significantly complicates the question of developing backdoor attacks, as a successful backdoor must work against various prompting strategies and should not affect the model's general purpose capabilities. We design a new attack for eliciting targeted misclassification when language models are prompted to perform a particular target task and demonstrate the feasibility of this attack by backdooring multiple large language models ranging in size from 1.3 billion to 6 billion parameters. Finally we study defenses to mitigate the potential harms of our attack: for example, while in the white-box setting we show that fine-tuning models for as few as 500 steps suffices to remove the backdoor behavior, in the black-box setting we are unable to develop a successful defense that relies on prompt engineering alone. ",
    "url": "https://arxiv.org/abs/2307.14692",
    "authors": [
      "Nikhil Kandpal",
      "Matthew Jagielski",
      "Florian Tram\u00e8r",
      "Nicholas Carlini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.14697",
    "title": "Space-Air-Ground Integrated Network (SAGIN): A Survey",
    "abstract": "Since existing mobile communication networks may not be able to meet the low latency and high-efficiency requirements of emerging technologies and applications, novel network architectures need to be investigated to support these new requirements. As a new network architecture that integrates satellite systems, air networks and ground communication, Space-Air-Ground Integrated Network (SAGIN) has attracted extensive attention in recent years. This paper summarizes the recent research work on SAGIN from several aspects, with the basic information of SAGIN first introduced, followed by the physical characteristics. Then the drive and prospects of the current SAGIN architecture in supporting new requirements are deeply analyzed. On this basis, the requirements and challenges are analyzed. Finally, it summarizes the existing solutions and prospects the future research directions. ",
    "url": "https://arxiv.org/abs/2307.14697",
    "authors": [
      "Jiming Chen",
      "Han Zhang",
      "Zhe Xie"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.14701",
    "title": "MIM-OOD: Generative Masked Image Modelling for Out-of-Distribution  Detection in Medical Images",
    "abstract": "Unsupervised Out-of-Distribution (OOD) detection consists in identifying anomalous regions in images leveraging only models trained on images of healthy anatomy. An established approach is to tokenize images and model the distribution of tokens with Auto-Regressive (AR) models. AR models are used to 1) identify anomalous tokens and 2) in-paint anomalous representations with in-distribution tokens. However, AR models are slow at inference time and prone to error accumulation issues which negatively affect OOD detection performance. Our novel method, MIM-OOD, overcomes both speed and error accumulation issues by replacing the AR model with two task-specific networks: 1) a transformer optimized to identify anomalous tokens and 2) a transformer optimized to in-paint anomalous tokens using masked image modelling (MIM). Our experiments with brain MRI anomalies show that MIM-OOD substantially outperforms AR models (DICE 0.458 vs 0.301) while achieving a nearly 25x speedup (9.5s vs 244s). ",
    "url": "https://arxiv.org/abs/2307.14701",
    "authors": [
      "Sergio {Naval Marimont}",
      "Vasilis Siomos",
      "Giacomo Tarroni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14723",
    "title": "EFLNet: Enhancing Feature Learning for Infrared Small Target Detection",
    "abstract": "Single-frame infrared small target detection is considered to be a challenging task, due to the extreme imbalance between target and background, bounding box regression is extremely sensitive to infrared small targets, and small target information is easy to lose in the high-level semantic layer. In this paper, we propose an enhancing feature learning network (EFLNet) based on YOLOv7 framework to solve these problems. First, we notice that there is an extremely imbalance between the target and the background in the infrared image, which makes the model pay more attention to the background features, resulting in missed detection. To address this problem, we propose a new adaptive threshold focal loss function that adjusts the loss weight automatically, compelling the model to allocate greater attention to target features. Second, we introduce the normalized Gaussian Wasserstein distance to alleviate the difficulty of model convergence caused by the extreme sensitivity of the bounding box regression to infrared small targets. Finally, we incorporate a dynamic head mechanism into the network to enable adaptive learning of the relative importance of each semantic layer. Experimental results demonstrate our method can achieve better performance in the detection performance of infrared small targets compared to state-of-the-art deep-learning based methods. ",
    "url": "https://arxiv.org/abs/2307.14723",
    "authors": [
      "Bo Yang",
      "Xinyu Zhang",
      "Jiahao Zhu",
      "Jian Zhang",
      "Dongjian Tian",
      "Jun Luo",
      "Mingliang Zhou",
      "Yangjun Pi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14725",
    "title": "vox2vec: A Framework for Self-supervised Contrastive Learning of  Voxel-level Representations in Medical Images",
    "abstract": "This paper introduces vox2vec - a contrastive method for self-supervised learning (SSL) of voxel-level representations. vox2vec representations are modeled by a Feature Pyramid Network (FPN): a voxel representation is a concatenation of the corresponding feature vectors from different pyramid levels. The FPN is pre-trained to produce similar representations for the same voxel in different augmented contexts and distinctive representations for different voxels. This results in unified multi-scale representations that capture both global semantics (e.g., body part) and local semantics (e.g., different small organs or healthy versus tumor tissue). We use vox2vec to pre-train a FPN on more than 6500 publicly available computed tomography images. We evaluate the pre-trained representations by attaching simple heads on top of them and training the resulting models for 22 segmentation tasks. We show that vox2vec outperforms existing medical imaging SSL techniques in three evaluation setups: linear and non-linear probing and end-to-end fine-tuning. Moreover, a non-linear head trained on top of the frozen vox2vec representations achieves competitive performance with the FPN trained from scratch while having 50 times fewer trainable parameters. The code is available at https://github.com/mishgon/vox2vec . ",
    "url": "https://arxiv.org/abs/2307.14725",
    "authors": [
      "Mikhail Goncharov",
      "Vera Soboleva",
      "Anvar Kurmukov",
      "Maxim Pisov",
      "Mikhail Belyaev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14726",
    "title": "P2C: Self-Supervised Point Cloud Completion from Single Partial Clouds",
    "abstract": "Point cloud completion aims to recover the complete shape based on a partial observation. Existing methods require either complete point clouds or multiple partial observations of the same object for learning. In contrast to previous approaches, we present Partial2Complete (P2C), the first self-supervised framework that completes point cloud objects using training samples consisting of only a single incomplete point cloud per object. Specifically, our framework groups incomplete point clouds into local patches as input and predicts masked patches by learning prior information from different partial objects. We also propose Region-Aware Chamfer Distance to regularize shape mismatch without limiting completion capability, and devise the Normal Consistency Constraint to incorporate a local planarity assumption, encouraging the recovered shape surface to be continuous and complete. In this way, P2C no longer needs multiple observations or complete point clouds as ground truth. Instead, structural cues are learned from a category-specific dataset to complete partial point clouds of objects. We demonstrate the effectiveness of our approach on both synthetic ShapeNet data and real-world ScanNet data, showing that P2C produces comparable results to methods trained with complete shapes, and outperforms methods learned with multiple partial observations. Code is available at https://github.com/CuiRuikai/Partial2Complete. ",
    "url": "https://arxiv.org/abs/2307.14726",
    "authors": [
      "Ruikai Cui",
      "Shi Qiu",
      "Saeed Anwar",
      "Jiawei Liu",
      "Chaoyue Xing",
      "Jing Zhang",
      "Nick Barnes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2307.14731",
    "title": "Bi-level Network Design for UAM Vertiport Allocation Using  Activity-Based Transport Simulations",
    "abstract": "The design or the optimization of transport systems is a difficult task. This is especially true in the case of the introduction of new transport modes in an existing system. The main reason is, that even small additions and changes result in the emergence of new travel patterns, likely resulting in an adaptation of the travel behavior of multiple other agents in the system. Here we consider the optimization of future Urban Air Mobility services under consideration of effects induced by the new mode to an existing system. We tackle this problem through a bi-level network design approach, in which the discrete decisions of the network design planner are optimized based on the evaluated dynamic demand of the user's mode choices. We solve the activity-based network design problem (AB-NDP) using a Genetic Algorithm on a multi-objective optimization problem while evaluating the dynamic demand with the large-scale Multi-Agent Transport Simulation (MATSim) framework. The proposed bi-level approach is compared against the results of a coverage approach using a static demand method. The bi-level study shows better results for expected UAM demand and total travel time savings across the transportation system. Due to its generic character, the demonstrated utilization of a bi-level method is applicable to other mobility service design questions and to other regions. ",
    "url": "https://arxiv.org/abs/2307.14731",
    "authors": [
      "Sebastian Brulin",
      "Markus Olhofer"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.14733",
    "title": "StubCoder: Automated Generation and Repair of Stub Code for Mock Objects",
    "abstract": "Mocking is an essential unit testing technique for isolating the class under test (CUT) from its dependencies. Developers often leverage mocking frameworks to develop stub code that specifies the behaviors of mock objects. However, developing and maintaining stub code is labor-intensive and error-prone. In this paper, we present StubCoder to automatically generate and repair stub code for regression testing. StubCoder implements a novel evolutionary algorithm that synthesizes test-passing stub code guided by the runtime behavior of test cases. We evaluated our proposed approach on 59 test cases from 13 open-source projects. Our evaluation results show that StubCoder can effectively generate stub code for incomplete test cases without stub code and repair obsolete test cases with broken stub code. ",
    "url": "https://arxiv.org/abs/2307.14733",
    "authors": [
      "Hengcheng Zhu",
      "Lili Wei",
      "Valerio Terragni",
      "Yepang Liu",
      "Shing-Chi Cheung",
      "Jiarong Wu",
      "Qin Sheng",
      "Bing Zhang",
      "Lihong Song"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2307.14740",
    "title": "New Interaction Paradigm for Complex EDA Software Leveraging GPT",
    "abstract": "In the rapidly growing field of electronic design automation (EDA), professional software such as KiCad, Cadence , and Altium Designer provide increasingly extensive design functionalities. However, the intricate command structure and high learning curve create a barrier, particularly for novice printed circuit board (PCB) designers. This results in difficulties in selecting appropriate functions or plugins for varying design purposes, compounded by the lack of intuitive learning methods beyond traditional documentation, videos, and online forums. To address this challenge, an artificial intelligence (AI) interaction assist plugin for EDA software named SmartonAl is developed here, also KiCad is taken as the first example. SmartonAI is inspired by the HuggingGPT framework and employs large language models, such as GPT and BERT, to facilitate task planning and execution. On receiving a designer request, SmartonAI conducts a task breakdown and efficiently executes relevant subtasks, such as analysis of help documentation paragraphs and execution of different plugins, along with leveraging the built-in schematic and PCB manipulation functions in both SmartonAl itself and software. Our preliminary results demonstrate that SmartonAI can significantly streamline the PCB design process by simplifying complex commands into intuitive language-based interactions. By harnessing the powerful language capabilities of ChatGPT and the rich design functions of KiCad, the plugin effectively bridges the gap between complex EDA software and user-friendly interaction. Meanwhile, the new paradigm behind SmartonAI can also extend to other complex software systems, illustrating the immense potential of AI-assisted user interfaces in advancing digital interactions across various domains. ",
    "url": "https://arxiv.org/abs/2307.14740",
    "authors": [
      "Boyu Han",
      "Xinyu Wang",
      "Yifan Wang",
      "Junyu Yan",
      "Yidong Tian"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.14747",
    "title": "Robust Task-Space Quadratic Programming for Kinematic-Controlled Robots",
    "abstract": "Task-space quadratic programming (QP) is an elegant approach for controlling robots subject to constraints. Yet, in the case of kinematic-controlled (i.e., high-gains position or velocity) robots, closed-loop QP control scheme can be prone to instability depending on how the gains related to the tasks or the constraints are chosen. In this paper, we address such instability shortcomings. First, we highlight the non-robustness of the closed-loop system against non-modeled dynamics, such as those relative to joint-dynamics, flexibilities, external perturbations, etc. Then, we propose a robust QP control formulation based on high-level integral feedback terms in the task-space including the constraints. The proposed method is formally proved to ensure closed-loop robust stability and is intended to be applied to any kinematic-controlled robots under practical assumptions. We assess our approach through experiments on a fixed-base robot performing stable fast motions, and a floating-base humanoid robot robustly reacting to perturbations to keep its balance. ",
    "url": "https://arxiv.org/abs/2307.14747",
    "authors": [
      "Mohamed Djeha",
      "Pierre Gergondet",
      "Abderrahmane Kheddar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.14751",
    "title": "FLARE: Fingerprinting Deep Reinforcement Learning Agents using Universal  Adversarial Masks",
    "abstract": "We propose FLARE, the first fingerprinting mechanism to verify whether a suspected Deep Reinforcement Learning (DRL) policy is an illegitimate copy of another (victim) policy. We first show that it is possible to find non-transferable, universal adversarial masks, i.e., perturbations, to generate adversarial examples that can successfully transfer from a victim policy to its modified versions but not to independently trained policies. FLARE employs these masks as fingerprints to verify the true ownership of stolen DRL policies by measuring an action agreement value over states perturbed via such masks. Our empirical evaluations show that FLARE is effective (100% action agreement on stolen copies) and does not falsely accuse independent policies (no false positives). FLARE is also robust to model modification attacks and cannot be easily evaded by more informed adversaries without negatively impacting agent performance. We also show that not all universal adversarial masks are suitable candidates for fingerprints due to the inherent characteristics of DRL policies. The spatio-temporal dynamics of DRL problems and sequential decision-making process make characterizing the decision boundary of DRL policies more difficult, as well as searching for universal masks that capture the geometry of it. ",
    "url": "https://arxiv.org/abs/2307.14751",
    "authors": [
      "Buse G. A. Tekgul",
      "N. Asokan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.14788",
    "title": "Likely, Light, and Accurate Context-Free Clusters-based Trajectory  Prediction",
    "abstract": "Autonomous systems in the road transportation network require intelligent mechanisms that cope with uncertainty to foresee the future. In this paper, we propose a multi-stage probabilistic approach for trajectory forecasting: trajectory transformation to displacement space, clustering of displacement time series, trajectory proposals, and ranking proposals. We introduce a new deep feature clustering method, underlying self-conditioned GAN, which copes better with distribution shifts than traditional methods. Additionally, we propose novel distance-based ranking proposals to assign probabilities to the generated trajectories that are more efficient yet accurate than an auxiliary neural network. The overall system surpasses context-free deep generative models in human and road agents trajectory data while performing similarly to point estimators when comparing the most probable trajectory. ",
    "url": "https://arxiv.org/abs/2307.14788",
    "authors": [
      "Tiago Rodrigues de Almeida",
      "Oscar Martinez Mozos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14791",
    "title": "Automatic Parallelization of Software Network Functions",
    "abstract": "Software network functions (NFs) trade-off flexibility and ease of deployment for an increased challenge of performance. The traditional way to increase NF performance is by distributing traffic to multiple CPU cores, but this poses a significant challenge: how to parallelize an NF without breaking its semantics? We propose Maestro, a tool that analyzes a sequential implementation of an NF and automatically generates an enhanced parallel version that carefully configures the NIC's Receive Side Scaling mechanism to distribute traffic across cores, while preserving semantics. When possible, Maestro orchestrates a shared-nothing architecture, with each core operating independently without shared memory coordination, maximizing performance. Otherwise, Maestro choreographs a fine-grained read-write locking mechanism that optimizes operation for typical Internet traffic. We parallelized 8 software NFs and show that they generally scale-up linearly until bottlenecked by PCIe when using small packets or by 100Gbps line-rate with typical Internet traffic. Maestro further outperforms modern hardware-based transactional memory mechanisms, even for challenging parallel-unfriendly workloads. ",
    "url": "https://arxiv.org/abs/2307.14791",
    "authors": [
      "Francisco Pereira",
      "Fernando M. V. Ramos",
      "Luis Pedrosa"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.14823",
    "title": "Fading memory as inductive bias in residual recurrent networks",
    "abstract": "Residual connections have been proposed as architecture-based inductive bias to mitigate the problem of exploding and vanishing gradients and increase task performance in both feed-forward and recurrent networks (RNNs) when trained with the backpropagation algorithm. Yet, little is known about how residual connections in RNNs influence their dynamics and fading memory properties. Here, we introduce weakly coupled residual recurrent networks (WCRNNs) in which residual connections result in well-defined Lyapunov exponents and allow for studying properties of fading memory. We investigate how the residual connections of WCRNNs influence their performance, network dynamics, and memory properties on a set of benchmark tasks. We show that several distinct forms of residual connections yield effective inductive biases that result in increased network expressivity. In particular, residual connections that (i) result in network dynamics at the proximity of the edge of chaos, (ii) allow networks to capitalize on characteristic spectral properties of the data, and (iii) result in heterogeneous memory properties are shown to increase practical expressivity. In addition, we demonstrate how our results can be extended to non-linear residuals and introduce a weakly coupled residual initialization scheme that can be used for Elman RNNs ",
    "url": "https://arxiv.org/abs/2307.14823",
    "authors": [
      "Igor Dubinin",
      "Felix Effenberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14837",
    "title": "DNN-MG: A Hybrid Neural Network/Finite Element Method with Applications  to 3D Simulations of the Navier-Stokes Equations",
    "abstract": "We extend and analyze the deep neural network multigrid solver (DNN-MG) for the Navier-Stokes equations in three dimensions. The idea of the method is to augment of finite element simulations on coarse grids with fine scale information obtained using deep neural networks. This network operates locally on small patches of grid elements. The local approach proves to be highly efficient, since the network can be kept (relatively) small and since it can be applied in parallel on all grid patches. However, the main advantage of the local approach is the inherent good generalizability of the method. Since the network is only ever trained on small sub-areas, it never ``sees'' the global problem and thus does not learn a false bias. We describe the method with a focus on the interplay between finite element method and deep neural networks. Further, we demonstrate with numerical examples the excellent efficiency of the hybrid approach, which allows us to achieve very high accuracies on coarse grids and thus reduce the computation time by orders of magnitude. ",
    "url": "https://arxiv.org/abs/2307.14837",
    "authors": [
      "Nils Margenberg",
      "Robert Jendersie",
      "Christian Lessig",
      "Thomas Richter"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2307.14849",
    "title": "Counterfactual Explanations for Graph Classification Through the Lenses  of Density",
    "abstract": "Counterfactual examples have emerged as an effective approach to produce simple and understandable post-hoc explanations. In the context of graph classification, previous work has focused on generating counterfactual explanations by manipulating the most elementary units of a graph, i.e., removing an existing edge, or adding a non-existing one. In this paper, we claim that such language of explanation might be too fine-grained, and turn our attention to some of the main characterizing features of real-world complex networks, such as the tendency to close triangles, the existence of recurring motifs, and the organization into dense modules. We thus define a general density-based counterfactual search framework to generate instance-level counterfactual explanations for graph classifiers, which can be instantiated with different notions of dense substructures. In particular, we show two specific instantiations of this general framework: a method that searches for counterfactual graphs by opening or closing triangles, and a method driven by maximal cliques. We also discuss how the general method can be instantiated to exploit any other notion of dense substructures, including, for instance, a given taxonomy of nodes. We evaluate the effectiveness of our approaches in 7 brain network datasets and compare the counterfactual statements generated according to several widely-used metrics. Results confirm that adopting a semantic-relevant unit of change like density is essential to define versatile and interpretable counterfactual explanation methods. ",
    "url": "https://arxiv.org/abs/2307.14849",
    "authors": [
      "Carlo Abrate",
      "Giulia Preti",
      "Francesco Bonchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.14856",
    "title": "Exploiting the Potential of Seq2Seq Models as Robust Few-Shot Learners",
    "abstract": "In-context learning, which offers substantial advantages over fine-tuning, is predominantly observed in decoder-only models, while encoder-decoder (i.e., seq2seq) models excel in methods that rely on weight updates. Recently, a few studies have demonstrated the feasibility of few-shot learning with seq2seq models; however, this has been limited to tasks that align well with the seq2seq architecture, such as summarization and translation. Inspired by these initial studies, we provide a first-ever extensive experiment comparing the in-context few-shot learning capabilities of decoder-only and encoder-decoder models on a broad range of tasks. Furthermore, we propose two methods to more effectively elicit in-context learning ability in seq2seq models: objective-aligned prompting and a fusion-based approach. Remarkably, our approach outperforms a decoder-only model that is six times larger and exhibits significant performance improvements compared to conventional seq2seq models across a variety of settings. We posit that, with the right configuration and prompt design, seq2seq models can be highly effective few-shot learners for a wide spectrum of applications. ",
    "url": "https://arxiv.org/abs/2307.14856",
    "authors": [
      "Jihyeon Lee",
      "Dain Kim",
      "Doohae Jung",
      "Boseop Kim",
      "Kyoung-Woon On"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.14897",
    "title": "Mixture of Self-Supervised Learning",
    "abstract": "Self-supervised learning is popular method because of its ability to learn features in images without using its labels and is able to overcome limited labeled datasets used in supervised learning. Self-supervised learning works by using a pretext task which will be trained on the model before being applied to a specific task. There are some examples of pretext tasks used in self-supervised learning in the field of image recognition, namely rotation prediction, solving jigsaw puzzles, and predicting relative positions on image. Previous studies have only used one type of transformation as a pretext task. This raises the question of how it affects if more than one pretext task is used and to use a gating network to combine all pretext tasks. Therefore, we propose the Gated Self-Supervised Learning method to improve image classification which use more than one transformation as pretext task and uses the Mixture of Expert architecture as a gating network in combining each pretext task so that the model automatically can study and focus more on the most useful augmentations for classification. We test performance of the proposed method in several scenarios, namely CIFAR imbalance dataset classification, adversarial perturbations, Tiny-Imagenet dataset classification, and semi-supervised learning. Moreover, there are Grad-CAM and T-SNE analysis that are used to see the proposed method for identifying important features that influence image classification and representing data for each class and separating different classes properly. Our code is in https://github.com/aristorenaldo/G-SSL ",
    "url": "https://arxiv.org/abs/2307.14897",
    "authors": [
      "Aristo Renaldo Ruslim",
      "Novanto Yudistira",
      "Budi Darma Setiawan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14902",
    "title": "CodeLens: An Interactive Tool for Visualizing Code Representations",
    "abstract": "Representing source code in a generic input format is crucial to automate software engineering tasks, e.g., applying machine learning algorithms to extract information. Visualizing code representations can further enable human experts to gain an intuitive insight into the code. Unfortunately, as of today, there is no universal tool that can simultaneously visualise different types of code representations. In this paper, we introduce a tool, CodeLens, which provides a visual interaction environment that supports various representation methods and helps developers understand and explore them. CodeLens is designed to support multiple programming languages, such as Java, Python, and JavaScript, and four types of code representations, including sequence of tokens, abstract syntax tree (AST), data flow graph (DFG), and control flow graph (CFG). By using CodeLens, developers can quickly visualize the specific code representation and also obtain the represented inputs for models of code. The Web-based interface of CodeLens is available at this http URL The demonstration video can be found at this http URL ",
    "url": "https://arxiv.org/abs/2307.14902",
    "authors": [
      "Yuejun Guo",
      "Seifeddine Bettaieb",
      "Qiang Hu",
      "Yves Le Traon",
      "Qiang Tang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14909",
    "title": "Targeted Static Analysis for OCaml C Stubs: eliminating gremlins from  the code",
    "abstract": "Migration to OCaml 5 requires updating a lot of C bindings due to the removal of naked pointer support. Writing OCaml user-defined primitives in C is a necessity, but is unsafe and error-prone. It does not benefit from either OCaml's or C's type checking, and existing C static analysers are not aware of the OCaml GC safety rules, and cannot infer them from existing macros alone.The alternative is automatically generating C stubs, which requires correctly managing value lifetimes. Having a static analyser for OCaml to C interfaces is useful outside the OCaml 5 porting effort too. After some motivating examples of real bugs in C bindings a static analyser is presented that finds these known classes of bugs. The tool works on the OCaml abstract parse and typed trees, and generates a header file and a caller model. Together with a simplified model of the OCaml runtime this is used as input to a static analysis framework, Goblint. An analysis is developed that tracks dereferences of OCaml values, and together with the existing framework reports incorrect dereferences. An example is shown how to extend the analysis to cover more safety properties. The tools and runtime models are generic and could be reused with other static analysis tools. ",
    "url": "https://arxiv.org/abs/2307.14909",
    "authors": [
      "Edwin T\u00f6r\u00f6k"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2307.14912",
    "title": "ARC-NLP at PAN 2023: Hierarchical Long Text Classification for Trigger  Detection",
    "abstract": "Fanfiction, a popular form of creative writing set within established fictional universes, has gained a substantial online following. However, ensuring the well-being and safety of participants has become a critical concern in this community. The detection of triggering content, material that may cause emotional distress or trauma to readers, poses a significant challenge. In this paper, we describe our approach for the Trigger Detection shared task at PAN CLEF 2023, where we want to detect multiple triggering content in a given Fanfiction document. For this, we build a hierarchical model that uses recurrence over Transformer-based language models. In our approach, we first split long documents into smaller sized segments and use them to fine-tune a Transformer model. Then, we extract feature embeddings from the fine-tuned Transformer model, which are used as input in the training of multiple LSTM models for trigger detection in a multi-label setting. Our model achieves an F1-macro score of 0.372 and F1-micro score of 0.736 on the validation set, which are higher than the baseline results shared at PAN CLEF 2023. ",
    "url": "https://arxiv.org/abs/2307.14912",
    "authors": [
      "Umitcan Sahin",
      "Izzet Emre Kucukkaya",
      "Cagri Toraman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2307.14913",
    "title": "ARC-NLP at PAN 2023: Transition-Focused Natural Language Inference for  Writing Style Detection",
    "abstract": "The task of multi-author writing style detection aims at finding any positions of writing style change in a given text document. We formulate the task as a natural language inference problem where two consecutive paragraphs are paired. Our approach focuses on transitions between paragraphs while truncating input tokens for the task. As backbone models, we employ different Transformer-based encoders with warmup phase during training. We submit the model version that outperforms baselines and other proposed model versions in our experiments. For the easy and medium setups, we submit transition-focused natural language inference based on DeBERTa with warmup training, and the same model without transition for the hard setup. ",
    "url": "https://arxiv.org/abs/2307.14913",
    "authors": [
      "Izzet Emre Kucukkaya",
      "Umitcan Sahin",
      "Cagri Toraman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.14917",
    "title": "NSA: Naturalistic Support Artifact to Boost Network Confidence",
    "abstract": "Visual AI systems are vulnerable to natural and synthetic physical corruption in the real-world. Such corruption often arises unexpectedly and alters the model's performance. In recent years, the primary focus has been on adversarial attacks. However, natural corruptions (e.g., snow, fog, dust) are an omnipresent threat to visual AI systems and should be considered equally important. Many existing works propose interesting solutions to train robust models against natural corruption. These works either leverage image augmentations, which come with the additional cost of model training, or place suspicious patches in the scene to design unadversarial examples. In this work, we propose the idea of naturalistic support artifacts (NSA) for robust prediction. The NSAs are shown to be beneficial in scenarios where model parameters are inaccessible and adding artifacts in the scene is feasible. The NSAs are natural looking objects generated through artifact training using DC-GAN to have high visual fidelity in the scene. We test against natural corruptions on the Imagenette dataset and observe the improvement in prediction confidence score by four times. We also demonstrate NSA's capability to increase adversarial accuracy by 8\\% on average. Lastly, we qualitatively analyze NSAs using saliency maps to understand how they help improve prediction confidence. ",
    "url": "https://arxiv.org/abs/2307.14917",
    "authors": [
      "Abhijith Sharma",
      "Phil Munz",
      "Apurva Narayan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14927",
    "title": "Cascaded Code Distributed Computing With Low Complexity and Improved  Flexibility",
    "abstract": "Coded distributed computing, proposed by Li et al., offers significant potential for reducing the communication load in MapReduce computing systems. In the setting of the \\emph{cascaded} coded distributed computing that consisting of $K$ nodes, $N$ input files, and $Q$ output functions, the objective is to compute each output function through $s\\geq 1$ nodes with a computation load $r\\geq 1$, enabling the application of coding techniques during the Shuffle phase to achieve minimum communication load. However, for most existing coded distributed computing schemes, a major limitation lies in their demand for splitting the original data into an exponentially growing number of input files in terms of $N/\\binom{K}{r} \\in\\mathbb{N}$ and requiring an exponentially large number of output functions $Q/\\binom{K}{s} \\in\\mathbb{N}$, which imposes stringent requirements for implementation and results in significant coding complexity when $K$ is large. In this paper, we focus on the cascaded case of $K/s\\in\\mathbb{N} $, deliberately designing the strategy of input files store and output functions assignment based on a grouping method, such that a low-complexity two-round Shuffle phase is available. The main advantages of our proposed scheme contains: 1) the communication load is quilt close to or surprisingly better than the optimal state-of-the-art scheme proposed by Li et al.; 2) our scheme requires significantly less number of input files and output functions; 3) all the operations are implemented over the minimum binary field $\\mathbb{F}_2$. ",
    "url": "https://arxiv.org/abs/2307.14927",
    "authors": [
      "Mingming Zhang",
      "Youlong Wu",
      "Minquan Cheng",
      "Dianhua Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2307.14936",
    "title": "PanGu-Coder2: Boosting Large Language Models for Code with Ranking  Feedback",
    "abstract": "Large Language Models for Code (Code LLM) are flourishing. New and powerful models are released on a weekly basis, demonstrating remarkable performance on the code generation task. Various approaches have been proposed to boost the code generation performance of pre-trained Code LLMs, such as supervised fine-tuning, instruction tuning, reinforcement learning, etc. In this paper, we propose a novel RRTF (Rank Responses to align Test&Teacher Feedback) framework, which can effectively and efficiently boost pre-trained large language models for code generation. Under this framework, we present PanGu-Coder2, which achieves 62.20% pass@1 on the OpenAI HumanEval benchmark. Furthermore, through an extensive evaluation on CoderEval and LeetCode benchmarks, we show that PanGu-Coder2 consistently outperforms all previous Code LLMs. ",
    "url": "https://arxiv.org/abs/2307.14936",
    "authors": [
      "Bo Shen",
      "Jiaxin Zhang",
      "Taihong Chen",
      "Daoguang Zan",
      "Bing Geng",
      "An Fu",
      "Muhan Zeng",
      "Ailun Yu",
      "Jichuan Ji",
      "Jingyang Zhao",
      "Yuenan Guo",
      "Qianxiang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2307.14938",
    "title": "Efficient Interaction-Aware Interval Analysis of Neural Network Feedback  Loops",
    "abstract": "In this paper, we propose a computationally efficient framework for interval reachability of neural network controlled systems. Our approach builds upon inclusion functions for the neural network controller and the open-loop system. We observe that many state-of-the-art neural network verifiers can produce inclusion functions for neural networks. We introduce and analyze a new class of inclusion functions for the open-loop dynamics based on bounds of the function Jacobian that is particularly suitable for capturing the interactions between systems and neural network controllers. Next, for any dynamical system, we use inclusion functions to construct an embedding system with twice the number of states as the original system. We show that a single trajectory of this embedding system provides hyper-rectangular over-approximations of reachable sets. We then propose two approaches for constructing a closed-loop embedding system for a neural network controlled dynamical system that accounts for the interaction between the system and the controller in different ways. The interconnection-based approach accounts for the worst-case evolution of each coordinate separately by substituting the neural network inclusion function into the open-loop embedding system. The interaction-based approach uses the newly introduced class of Jacobian-based inclusion functions to fully capture first-order interactions between the system and the controller. Finally, we implement our approach in a Python framework called \\texttt{ReachMM} and show that on several existing benchmarks, our methods outperform the existing approaches in the literature. We also demonstrate the scalability of our method on a vehicle platooning example with up to $200$ states. ",
    "url": "https://arxiv.org/abs/2307.14938",
    "authors": [
      "Saber Jafarpour",
      "Akash Harapanahalli",
      "Samuel Coogan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.14940",
    "title": "A Self-Adaptive Penalty Method for Integrating Prior Knowledge  Constraints into Neural ODEs",
    "abstract": "The continuous dynamics of natural systems has been effectively modelled using Neural Ordinary Differential Equations (Neural ODEs). However, for accurate and meaningful predictions, it is crucial that the models follow the underlying rules or laws that govern these systems. In this work, we propose a self-adaptive penalty algorithm for Neural ODEs to enable modelling of constrained natural systems. The proposed self-adaptive penalty function can dynamically adjust the penalty parameters. The explicit introduction of prior knowledge helps to increase the interpretability of Neural ODE -based models. We validate the proposed approach by modelling three natural systems with prior knowledge constraints: population growth, chemical reaction evolution, and damped harmonic oscillator motion. The numerical experiments and a comparison with other penalty Neural ODE approaches and \\emph{vanilla} Neural ODE, demonstrate the effectiveness of the proposed self-adaptive penalty algorithm for Neural ODEs in modelling constrained natural systems. Moreover, the self-adaptive penalty approach provides more accurate and robust models with reliable and meaningful predictions. ",
    "url": "https://arxiv.org/abs/2307.14940",
    "authors": [
      "C. Coelho",
      "M. Fernanda P. Costa",
      "L. L. Ferr\u00e1s"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.14949",
    "title": "Visual Analysis of Displacement Processes in Porous Media using  Spatio-Temporal Flow Graphs",
    "abstract": "We developed a new approach comprised of different visualizations for the comparative spatio-temporal analysis of displacement processes in porous media. We aim to analyze and compare ensemble datasets from experiments to gain insight into the influence of different parameters on fluid flow. To capture the displacement of a defending fluid by an invading fluid, we first condense an input image series to a single time map. From this map, we generate a spatio-temporal flow graph covering the whole process. This graph is further simplified to only reflect topological changes in the movement of the invading fluid. Our interactive tools allow the visual analysis of these processes by visualizing the graph structure and the context of the experimental setup, as well as by providing charts for multiple metrics. We apply our approach to analyze and compare ensemble datasets jointly with domain experts, where we vary either fluid properties or the solid structure of the porous medium. We finally report the generated insights from the domain experts and discuss our contribution's advantages, generality, and limitations. ",
    "url": "https://arxiv.org/abs/2307.14949",
    "authors": [
      "Alexander Straub",
      "Nikolaos Karadimitriou",
      "Guido Reina",
      "Steffen Frey",
      "Holger Steeb",
      "Thomas Ertl"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2307.14952",
    "title": "Network Fault-tolerant and Byzantine-resilient Social Learning via  Collaborative Hierarchical Non-Bayesian Learning",
    "abstract": "As the network scale increases, existing fully distributed solutions start to lag behind the real-world challenges such as (1) slow information propagation, (2) network communication failures, and (3) external adversarial attacks. In this paper, we focus on hierarchical system architecture and address the problem of non-Bayesian learning over networks that are vulnerable to communication failures and adversarial attacks. On network communication, we consider packet-dropping link failures. We first propose a hierarchical robust push-sum algorithm that can achieve average consensus despite frequent packet-dropping link failures. We provide a sparse information fusion rule between the parameter server and arbitrarily selected network representatives. Then, interleaving the consensus update step with a dual averaging update with Kullback-Leibler (KL) divergence as the proximal function, we obtain a packet-dropping fault-tolerant non-Bayesian learning algorithm with provable convergence guarantees. On external adversarial attacks, we consider Byzantine attacks in which the compromised agents can send maliciously calibrated messages to others (including both the agents and the parameter server). To avoid the curse of dimensionality of Byzantine consensus, we solve the non-Bayesian learning problem via running multiple dynamics, each of which only involves Byzantine consensus with scalar inputs. To facilitate resilient information propagation across sub-networks, we use a novel Byzantine-resilient gossiping-type rule at the parameter server. ",
    "url": "https://arxiv.org/abs/2307.14952",
    "authors": [
      "Connor Mclaughlin",
      "Matthew Ding",
      "Denis Edogmus",
      "Lili Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.14959",
    "title": "Federated Model Aggregation via Self-Supervised Priors for Highly  Imbalanced Medical Image Classification",
    "abstract": "In the medical field, federated learning commonly deals with highly imbalanced datasets, including skin lesions and gastrointestinal images. Existing federated methods under highly imbalanced datasets primarily focus on optimizing a global model without incorporating the intra-class variations that can arise in medical imaging due to different populations, findings, and scanners. In this paper, we study the inter-client intra-class variations with publicly available self-supervised auxiliary networks. Specifically, we find that employing a shared auxiliary pre-trained model, like MoCo-V2, locally on every client yields consistent divergence measurements. Based on these findings, we derive a dynamic balanced model aggregation via self-supervised priors (MAS) to guide the global model optimization. Fed-MAS can be utilized with different local learning methods for effective model aggregation toward a highly robust and unbiased global model. Our code is available at \\url{https://github.com/xmed-lab/Fed-MAS}. ",
    "url": "https://arxiv.org/abs/2307.14959",
    "authors": [
      "Marawan Elbatel",
      "Hualiang Wang",
      "Robert Mart\u00ed",
      "Huazhu Fu",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14980",
    "title": "Aligning rTWT with 802.1Qbv: a Network Calculus Approach",
    "abstract": "Industry 4.0 applications impose the challenging demand of delivering packets with bounded latencies via a wireless network. This is further complicated if the network is not dedicated to the time critical application. In this paper we use network calculus analysis to derive closed form expressions of latency bounds for time critical traffic when 802.11 Target Wake Time (TWT) and 802.1Qbv work together in a shared 802.11 network. ",
    "url": "https://arxiv.org/abs/2307.14980",
    "authors": [
      "Carlos Barroso-Fern\u00e1ndez",
      "Jorge Mart\u00edn-P\u00e9rez",
      "Constantine Ayimba",
      "Antonio de la Oliva"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.14981",
    "title": "MapNeRF: Incorporating Map Priors into Neural Radiance Fields for  Driving View Simulation",
    "abstract": "Simulating camera sensors is a crucial task in autonomous driving. Although neural radiance fields are exceptional at synthesizing photorealistic views in driving simulations, they still fail in generating extrapolated views. This paper proposes to incorporate map priors into neural radiance fields to synthesize out-of-trajectory driving views with semantic road consistency. The key insight is that map information can be utilized as a prior to guide the training of the radiance fields with uncertainty. Specifically, we utilize the coarse ground surface as uncertain information to supervise the density field and warp depth with uncertainty from unknown camera poses to ensure multi-view consistency. Experimental results demonstrate that our approach can produce semantic consistency in deviated views for vehicle camera simulation. ",
    "url": "https://arxiv.org/abs/2307.14981",
    "authors": [
      "Chenming Wu",
      "Jiadai Sun",
      "Zhelun Shen",
      "Liangjun Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.14988",
    "title": "Incrementally-Computable Neural Networks: Efficient Inference for  Dynamic Inputs",
    "abstract": "Deep learning often faces the challenge of efficiently processing dynamic inputs, such as sensor data or user inputs. For example, an AI writing assistant is required to update its suggestions in real time as a document is edited. Re-running the model each time is expensive, even with compression techniques like knowledge distillation, pruning, or quantization. Instead, we take an incremental computing approach, looking to reuse calculations as the inputs change. However, the dense connectivity of conventional architectures poses a major obstacle to incremental computation, as even minor input changes cascade through the network and restrict information reuse. To address this, we use vector quantization to discretize intermediate values in the network, which filters out noisy and unnecessary modifications to hidden neurons, facilitating the reuse of their values. We apply this approach to the transformers architecture, creating an efficient incremental inference algorithm with complexity proportional to the fraction of the modified inputs. Our experiments with adapting the OPT-125M pre-trained language model demonstrate comparable accuracy on document classification while requiring 12.1X (median) fewer operations for processing sequences of atomic edits. ",
    "url": "https://arxiv.org/abs/2307.14988",
    "authors": [
      "Or Sharir",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.14991",
    "title": "Multilingual Code Co-Evolution Using Large Language Models",
    "abstract": "Many software projects implement APIs and algorithms in multiple programming languages. Maintaining such projects is tiresome, as developers have to ensure that any change (e.g., a bug fix or a new feature) is being propagated, timely and without errors, to implementations in other programming languages. In the world of ever-changing software, using rule-based translation tools (i.e., transpilers) or machine learning models for translating code from one language to another provides limited value. Translating each time the entire codebase from one language to another is not the way developers work. In this paper, we target a novel task: translating code changes from one programming language to another using large language models (LLMs). We design and implement the first LLM, dubbed Codeditor, to tackle this task. Codeditor explicitly models code changes as edit sequences and learns to correlate changes across programming languages. To evaluate Codeditor, we collect a corpus of 6,613 aligned code changes from 8 pairs of open-source software projects implementing similar functionalities in two programming languages (Java and C#). Results show that Codeditor outperforms the state-of-the-art approaches by a large margin on all commonly used automatic metrics. Our work also reveals that Codeditor is complementary to the existing generation-based models, and their combination ensures even greater performance. ",
    "url": "https://arxiv.org/abs/2307.14991",
    "authors": [
      "Jiyang Zhang",
      "Pengyu Nie",
      "Junyi Jessy Li",
      "Milos Gligoric"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.15019",
    "title": "Self-Supervised Graph Transformer for Deepfake Detection",
    "abstract": "Deepfake detection methods have shown promising results in recognizing forgeries within a given dataset, where training and testing take place on the in-distribution dataset. However, their performance deteriorates significantly when presented with unseen samples. As a result, a reliable deepfake detection system must remain impartial to forgery types, appearance, and quality for guaranteed generalizable detection performance. Despite various attempts to enhance cross-dataset generalization, the problem remains challenging, particularly when testing against common post-processing perturbations, such as video compression or blur. Hence, this study introduces a deepfake detection framework, leveraging a self-supervised pre-training model that delivers exceptional generalization ability, withstanding common corruptions and enabling feature explainability. The framework comprises three key components: a feature extractor based on vision Transformer architecture that is pre-trained via self-supervised contrastive learning methodology, a graph convolution network coupled with a Transformer discriminator, and a graph Transformer relevancy map that provides a better understanding of manipulated regions and further explains the model's decision. To assess the effectiveness of the proposed framework, several challenging experiments are conducted, including in-data distribution performance, cross-dataset, cross-manipulation generalization, and robustness against common post-production perturbations. The results achieved demonstrate the remarkable effectiveness of the proposed deepfake detection framework, surpassing the current state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2307.15019",
    "authors": [
      "Aminollah Khormali",
      "Jiann-Shiun Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15029",
    "title": "Adaptive Segmentation Network for Scene Text Detection",
    "abstract": "Inspired by deep convolution segmentation algorithms, scene text detectors break the performance ceiling of datasets steadily. However, these methods often encounter threshold selection bottlenecks and have poor performance on text instances with extreme aspect ratios. In this paper, we propose to automatically learn the discriminate segmentation threshold, which distinguishes text pixels from background pixels for segmentation-based scene text detectors and then further reduces the time-consuming manual parameter adjustment. Besides, we design a Global-information Enhanced Feature Pyramid Network (GE-FPN) for capturing text instances with macro size and extreme aspect ratios. Following the GE-FPN, we introduce a cascade optimization structure to further refine the text instances. Finally, together with the proposed threshold learning strategy and text detection structure, we design an Adaptive Segmentation Network (ASNet) for scene text detection. Extensive experiments are carried out to demonstrate that the proposed ASNet can achieve the state-of-the-art performance on four text detection benchmarks, i.e., ICDAR 2015, MSRA-TD500, ICDAR 2017 MLT and CTW1500. The ablation experiments also verify the effectiveness of our contributions. ",
    "url": "https://arxiv.org/abs/2307.15029",
    "authors": [
      "Guiqin Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.15034",
    "title": "Speeding up Fourier Neural Operators via Mixed Precision",
    "abstract": "The Fourier neural operator (FNO) is a powerful technique for learning surrogate maps for partial differential equation (PDE) solution operators. For many real-world applications, which often require high-resolution data points, training time and memory usage are significant bottlenecks. While there are mixed-precision training techniques for standard neural networks, those work for real-valued datatypes on finite dimensions and therefore cannot be directly applied to FNO, which crucially operates in the (complex-valued) Fourier domain and in function spaces. On the other hand, since the Fourier transform is already an approximation (due to discretization error), we do not need to perform the operation at full precision. In this work, we (i) profile memory and runtime for FNO with full and mixed-precision training, (ii) conduct a study on the numerical stability of mixed-precision training of FNO, and (iii) devise a training routine which substantially decreases training time and memory usage (up to 34%), with little or no reduction in accuracy, on the Navier-Stokes and Darcy flow equations. Combined with the recently proposed tensorized FNO (Kossaifi et al., 2023), the resulting model has far better performance while also being significantly faster than the original FNO. ",
    "url": "https://arxiv.org/abs/2307.15034",
    "authors": [
      "Colin White",
      "Renbo Tu",
      "Jean Kossaifi",
      "Gennady Pekhimenko",
      "Kamyar Azizzadenesheli",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.15036",
    "title": "3-Coloring $C_4$ or $C_3$-free Diameter Two Graphs",
    "abstract": "The question of whether 3-Coloring can be solved in polynomial-time for the diameter two graphs is a well-known open problem in the area of algorithmic graph theory. We study the problem restricted to graph classes that avoid cycles of given lengths as induced subgraphs. Martin et. al. [CIAC 2021] showed that the problem is polynomial-time solvable for $C_5$-free or $C_6$-free graphs, and, $(C_4,C_s)$-free graphs where $s \\in \\{3,7,8,9\\}$. We extend their result proving that it is polynomial-time solvable for $(C_4,C_s)$-free graphs, for any constant $s$, and for $(C_3,C_7)$-free graphs. Our results also hold for the more general problem List 3-Colouring. ",
    "url": "https://arxiv.org/abs/2307.15036",
    "authors": [
      "Tereza Klimo\u0161ov\u00e1",
      "Vibha Sahlot"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2307.15040",
    "title": "A Sparse Quantized Hopfield Network for Online-Continual Memory",
    "abstract": "An important difference between brains and deep neural networks is the way they learn. Nervous systems learn online where a stream of noisy data points are presented in a non-independent, identically distributed (non-i.i.d.) way. Further, synaptic plasticity in the brain depends only on information local to synapses. Deep networks, on the other hand, typically use non-local learning algorithms and are trained in an offline, non-noisy, i.i.d. setting. Understanding how neural networks learn under the same constraints as the brain is an open problem for neuroscience and neuromorphic computing. A standard approach to this problem has yet to be established. In this paper, we propose that discrete graphical models that learn via an online maximum a posteriori learning algorithm could provide such an approach. We implement this kind of model in a novel neural network called the Sparse Quantized Hopfield Network (SQHN). We show that SQHNs outperform state-of-the-art neural networks on associative memory tasks, outperform these models in online, non-i.i.d. settings, learn efficiently with noisy inputs, and are better than baselines on a novel episodic memory task. ",
    "url": "https://arxiv.org/abs/2307.15040",
    "authors": [
      "Nick Alonso",
      "Jeff Krichmar"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2307.15043",
    "title": "Universal and Transferable Adversarial Attacks on Aligned Language  Models",
    "abstract": "Because \"out-of-the-box\" large language models are capable of generating a great deal of objectionable content, recent work has focused on aligning these models in an attempt to prevent undesirable generation. While there has been some success at circumventing these measures -- so-called \"jailbreaks\" against LLMs -- these attacks have required significant human ingenuity and are brittle in practice. In this paper, we propose a simple and effective attack method that causes aligned language models to generate objectionable behaviors. Specifically, our approach finds a suffix that, when attached to a wide range of queries for an LLM to produce objectionable content, aims to maximize the probability that the model produces an affirmative response (rather than refusing to answer). However, instead of relying on manual engineering, our approach automatically produces these adversarial suffixes by a combination of greedy and gradient-based search techniques, and also improves over past automatic prompt generation methods. Surprisingly, we find that the adversarial prompts generated by our approach are quite transferable, including to black-box, publicly released LLMs. Specifically, we train an adversarial attack suffix on multiple prompts (i.e., queries asking for many different types of objectionable content), as well as multiple models (in our case, Vicuna-7B and 13B). When doing so, the resulting attack suffix is able to induce objectionable content in the public interfaces to ChatGPT, Bard, and Claude, as well as open source LLMs such as LLaMA-2-Chat, Pythia, Falcon, and others. In total, this work significantly advances the state-of-the-art in adversarial attacks against aligned language models, raising important questions about how such systems can be prevented from producing objectionable information. Code is available at github.com/llm-attacks/llm-attacks. ",
    "url": "https://arxiv.org/abs/2307.15043",
    "authors": [
      "Andy Zou",
      "Zifan Wang",
      "J. Zico Kolter",
      "Matt Fredrikson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15054",
    "title": "A Geometric Notion of Causal Probing",
    "abstract": "Large language models rely on real-valued representations of text to make their predictions. These representations contain information learned from the data that the model has trained on, including knowledge of linguistic properties and forms of demographic bias, e.g., based on gender. A growing body of work has considered information about concepts such as these using orthogonal projections onto subspaces of the representation space. We contribute to this body of work by proposing a formal definition of intrinsic information in a subspace of a language model's representation space. We propose a counterfactual approach that avoids the failure mode of spurious correlations (Kumar et al., 2022) by treating components in the subspace and its orthogonal complement independently. We show that our counterfactual notion of information in a subspace is optimizing by an causal concept subspace. Furthermore, this intervention allows us to attempt concept controlled generation by manipulating the value of the conceptual component of a representation. Empirically, we find that R-LACE (Ravfogel et al., 2022) returns a one-dimensional subspace containing roughly half of total concept information under our framework. Our causal controlled intervention shows that, for at least one model, the subspace returned by R-LACE can be used to manipulate the concept value of the generated word with precision. ",
    "url": "https://arxiv.org/abs/2307.15054",
    "authors": [
      "Cl\u00e9ment Guerner",
      "Anej Svete",
      "Tianyu Liu",
      "Alexander Warstadt",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.15061",
    "title": "The RoboDepth Challenge: Methods and Advancements Towards Robust Depth  Estimation",
    "abstract": "Accurate depth estimation under out-of-distribution (OoD) scenarios, such as adverse weather conditions, sensor failure, and noise contamination, is desirable for safety-critical applications. Existing depth estimation systems, however, suffer inevitably from real-world corruptions and perturbations and are struggled to provide reliable depth predictions under such cases. In this paper, we summarize the winning solutions from the RoboDepth Challenge -- an academic competition designed to facilitate and advance robust OoD depth estimation. This challenge was developed based on the newly established KITTI-C and NYUDepth2-C benchmarks. We hosted two stand-alone tracks, with an emphasis on robust self-supervised and robust fully-supervised depth estimation, respectively. Out of more than two hundred participants, nine unique and top-performing solutions have appeared, with novel designs ranging from the following aspects: spatial- and frequency-domain augmentations, masked image modeling, image restoration and super-resolution, adversarial training, diffusion-based noise suppression, vision-language pre-training, learned model ensembling, and hierarchical feature enhancement. Extensive experimental analyses along with insightful observations are drawn to better understand the rationale behind each design. We hope this challenge could lay a solid foundation for future research on robust and reliable depth estimation and beyond. The datasets, competition toolkit, workshop recordings, and source code from the winning teams are publicly available on the challenge website. ",
    "url": "https://arxiv.org/abs/2307.15061",
    "authors": [
      "Lingdong Kong",
      "Yaru Niu",
      "Shaoyuan Xie",
      "Hanjiang Hu",
      "Lai Xing Ng",
      "Benoit R. Cottereau",
      "Ding Zhao",
      "Liangjun Zhang",
      "Hesheng Wang",
      "Wei Tsang Ooi",
      "Ruijie Zhu",
      "Ziyang Song",
      "Li Liu",
      "Tianzhu Zhang",
      "Jun Yu",
      "Mohan Jing",
      "Pengwei Li",
      "Xiaohua Qi",
      "Cheng Jin",
      "Yingfeng Chen",
      "Jie Hou",
      "Jie Zhang",
      "Zhen Kan",
      "Qiang Ling",
      "Liang Peng",
      "Minglei Li",
      "Di Xu",
      "Changpeng Yang",
      "Yuanqi Yao",
      "Gang Wu",
      "Jian Kuai",
      "Xianming Liu",
      "Junjun Jiang",
      "Jiamian Huang",
      "Baojun Li",
      "Jiale Chen",
      "Shuang Zhang",
      "Sun Ao",
      "Zhenyu Li",
      "Runze Chen",
      "Haiyong Luo",
      "Fang Zhao",
      "Jingze Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.15064",
    "title": "Self-Supervised Visual Acoustic Matching",
    "abstract": "Acoustic matching aims to re-synthesize an audio clip to sound as if it were recorded in a target acoustic environment. Existing methods assume access to paired training data, where the audio is observed in both source and target environments, but this limits the diversity of training data or requires the use of simulated data or heuristics to create paired samples. We propose a self-supervised approach to visual acoustic matching where training samples include only the target scene image and audio -- without acoustically mismatched source audio for reference. Our approach jointly learns to disentangle room acoustics and re-synthesize audio into the target environment, via a conditional GAN framework and a novel metric that quantifies the level of residual acoustic information in the de-biased audio. Training with either in-the-wild web data or simulated data, we demonstrate it outperforms the state-of-the-art on multiple challenging datasets and a wide variety of real-world audio and environments. ",
    "url": "https://arxiv.org/abs/2307.15064",
    "authors": [
      "Arjun Somayazulu",
      "Changan Chen",
      "Kristen Grauman"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.14362",
    "title": "Learnable wavelet neural networks for cosmological inference",
    "abstract": "Convolutional neural networks (CNNs) have been shown to both extract more information than the traditional two-point statistics from cosmological fields, and marginalise over astrophysical effects extremely well. However, CNNs require large amounts of training data, which is potentially problematic in the domain of expensive cosmological simulations, and it is difficult to interpret the network. In this work we apply the learnable scattering transform, a kind of convolutional neural network that uses trainable wavelets as filters, to the problem of cosmological inference and marginalisation over astrophysical effects. We present two models based on the scattering transform, one constructed for performance, and one constructed for interpretability, and perform a comparison with a CNN. We find that scattering architectures are able to outperform a CNN, significantly in the case of small training data samples. Additionally we present a lightweight scattering network that is highly interpretable. ",
    "url": "https://arxiv.org/abs/2307.14362",
    "authors": [
      "Christian Pedersen",
      "Michael Eickenberg",
      "Shirley Ho"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14363",
    "title": "Unsupervised reconstruction of accelerated cardiac cine MRI using Neural  Fields",
    "abstract": "Cardiac cine MRI is the gold standard for cardiac functional assessment, but the inherently slow acquisition process creates the necessity of reconstruction approaches for accelerated undersampled acquisitions. Several regularization approaches that exploit spatial-temporal redundancy have been proposed to reconstruct undersampled cardiac cine MRI. More recently, methods based on supervised deep learning have been also proposed to further accelerate acquisition and reconstruction. However, these techniques rely on usually large dataset for training, which are not always available. In this work, we propose an unsupervised approach based on implicit neural field representations for cardiac cine MRI (so called NF-cMRI). The proposed method was evaluated in in-vivo undersampled golden-angle radial multi-coil acquisitions for undersampling factors of 26x and 52x, achieving good image quality, and comparable spatial and improved temporal depiction than a state-of-the-art reconstruction technique. ",
    "url": "https://arxiv.org/abs/2307.14363",
    "authors": [
      "Tabita Catal\u00e1n",
      "Mat\u00edas Courdurier",
      "Axel Osses",
      "Ren\u00e9 Botnar",
      "Francisco Sahli Costabal",
      "Claudia Prieto"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14364",
    "title": "Federated Distributionally Robust Optimization with Non-Convex  Objectives: Algorithm and Analysis",
    "abstract": "Distributionally Robust Optimization (DRO), which aims to find an optimal decision that minimizes the worst case cost over the ambiguity set of probability distribution, has been widely applied in diverse applications, e.g., network behavior analysis, risk management, etc. However, existing DRO techniques face three key challenges: 1) how to deal with the asynchronous updating in a distributed environment; 2) how to leverage the prior distribution effectively; 3) how to properly adjust the degree of robustness according to different scenarios. To this end, we propose an asynchronous distributed algorithm, named Asynchronous Single-looP alternatIve gRadient projEction (ASPIRE) algorithm with the itErative Active SEt method (EASE) to tackle the federated distributionally robust optimization (FDRO) problem. Furthermore, a new uncertainty set, i.e., constrained D-norm uncertainty set, is developed to effectively leverage the prior distribution and flexibly control the degree of robustness. Finally, our theoretical analysis elucidates that the proposed algorithm is guaranteed to converge and the iteration complexity is also analyzed. Extensive empirical studies on real-world datasets demonstrate that the proposed method can not only achieve fast convergence, and remain robust against data heterogeneity as well as malicious attacks, but also tradeoff robustness with performance. ",
    "url": "https://arxiv.org/abs/2307.14364",
    "authors": [
      "Yang Jiao",
      "Kai Yang",
      "Dongjin Song"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14398",
    "title": "Non-Linear Self Augmentation Deep Pipeline for Cancer Treatment outcome  Prediction",
    "abstract": "Immunotherapy emerges as promising approach for treating cancer. Encouraging findings have validated the efficacy of immunotherapy medications in addressing tumors, resulting in prolonged survival rates and notable reductions in toxicity compared to conventional chemotherapy methods. However, the pool of eligible patients for immunotherapy remains relatively small, indicating a lack of comprehensive understanding regarding the physiological mechanisms responsible for favorable treatment response in certain individuals while others experience limited benefits. To tackle this issue, the authors present an innovative strategy that harnesses a non-linear cellular architecture in conjunction with a deep downstream classifier. This approach aims to carefully select and enhance 2D features extracted from chest-abdomen CT images, thereby improving the prediction of treatment outcomes. The proposed pipeline has been meticulously designed to seamlessly integrate with an advanced embedded Point of Care system. In this context, the authors present a compelling case study focused on Metastatic Urothelial Carcinoma (mUC), a particularly aggressive form of cancer. Performance evaluation of the proposed approach underscores its effectiveness, with an impressive overall accuracy of approximately 93% ",
    "url": "https://arxiv.org/abs/2307.14398",
    "authors": [
      "Francesco Rundo",
      "Concetto Spampinato",
      "Michael Rundo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.14502",
    "title": "The Effect of Spoken Language on Speech Enhancement using  Self-Supervised Speech Representation Loss Functions",
    "abstract": "Recent work in the field of speech enhancement (SE) has involved the use of self-supervised speech representations (SSSRs) as feature transformations in loss functions. However, in prior work, very little attention has been paid to the relationship between the language of the audio used to train the self-supervised representation and that used to train the SE system. Enhancement models trained using a loss function which incorporates a self-supervised representation that shares exactly the language of the noisy data used to train the SE system show better performance than those which do not match exactly. This may lead to enhancement systems which are language specific and as such do not generalise well to unseen languages, unlike models trained using traditional spectrogram or time domain loss functions. In this work, SE models are trained and tested on a number of different languages, with self-supervised representations which themselves are trained using different language combinations and with differing network structures as loss function representations. These models are then tested across unseen languages and their performances are analysed. It is found that the training language of the self-supervised representation appears to have a minor effect on enhancement performance, the amount of training data of a particular language, however, greatly affects performance. ",
    "url": "https://arxiv.org/abs/2307.14502",
    "authors": [
      "George Close",
      "Thomas Hain",
      "Stefan Goetze"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2307.14520",
    "title": "FocalErrorNet: Uncertainty-aware focal modulation network for  inter-modal registration error estimation in ultrasound-guided neurosurgery",
    "abstract": "In brain tumor resection, accurate removal of cancerous tissues while preserving eloquent regions is crucial to the safety and outcomes of the treatment. However, intra-operative tissue deformation (called brain shift) can move the surgical target and render the pre-surgical plan invalid. Intra-operative ultrasound (iUS) has been adopted to provide real-time images to track brain shift, and inter-modal (i.e., MRI-iUS) registration is often required to update the pre-surgical plan. Quality control for the registration results during surgery is important to avoid adverse outcomes, but manual verification faces great challenges due to difficult 3D visualization and the low contrast of iUS. Automatic algorithms are urgently needed to address this issue, but the problem was rarely attempted. Therefore, we propose a novel deep learning technique based on 3D focal modulation in conjunction with uncertainty estimation to accurately assess MRI-iUS registration errors for brain tumor surgery. Developed and validated with the public RESECT clinical database, the resulting algorithm can achieve an estimation error of 0.59+-0.57 mm. ",
    "url": "https://arxiv.org/abs/2307.14520",
    "authors": [
      "Soorena Salari",
      "Amirhossein Rasoulian",
      "Hassan Rivaz",
      "Yiming Xiao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14547",
    "title": "Mitigating Cross-Database Differences for Learning Unified HRTF  Representation",
    "abstract": "Individualized head-related transfer functions (HRTFs) are crucial for accurate sound positioning in virtual auditory displays. As the acoustic measurement of HRTFs is resource-intensive, predicting individualized HRTFs using machine learning models is a promising approach at scale. Training such models require a unified HRTF representation across multiple databases to utilize their respectively limited samples. However, in addition to differences on the spatial sampling locations, recent studies have shown that, even for the common location, HRTFs across databases manifest consistent differences that make it trivial to tell which databases they come from. This poses a significant challenge for learning a unified HRTF representation across databases. In this work, we first identify the possible causes of these cross-database differences, attributing them to variations in the measurement setup. Then, we propose a novel approach to normalize the frequency responses of HRTFs across databases. We show that HRTFs from different databases cannot be classified by their database after normalization. We further show that these normalized HRTFs can be used to learn a more unified HRTF representation across databases than the prior art. We believe that this normalization approach paves the road to many data-intensive tasks on HRTF modeling. ",
    "url": "https://arxiv.org/abs/2307.14547",
    "authors": [
      "Yutong Wen",
      "You Zhang",
      "Zhiyao Duan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2307.14588",
    "title": "MCPA: Multi-scale Cross Perceptron Attention Network for 2D Medical  Image Segmentation",
    "abstract": "The UNet architecture, based on Convolutional Neural Networks (CNN), has demonstrated its remarkable performance in medical image analysis. However, it faces challenges in capturing long-range dependencies due to the limited receptive fields and inherent bias of convolutional operations. Recently, numerous transformer-based techniques have been incorporated into the UNet architecture to overcome this limitation by effectively capturing global feature correlations. However, the integration of the Transformer modules may result in the loss of local contextual information during the global feature fusion process. To overcome these challenges, we propose a 2D medical image segmentation model called Multi-scale Cross Perceptron Attention Network (MCPA). The MCPA consists of three main components: an encoder, a decoder, and a Cross Perceptron. The Cross Perceptron first captures the local correlations using multiple Multi-scale Cross Perceptron modules, facilitating the fusion of features across scales. The resulting multi-scale feature vectors are then spatially unfolded, concatenated, and fed through a Global Perceptron module to model global dependencies. Furthermore, we introduce a Progressive Dual-branch Structure to address the semantic segmentation of the image involving finer tissue structures. This structure gradually shifts the segmentation focus of MCPA network training from large-scale structural features to more sophisticated pixel-level features. We evaluate our proposed MCPA model on several publicly available medical image datasets from different tasks and devices, including the open large-scale dataset of CT (Synapse), MRI (ACDC), fundus camera (DRIVE, CHASE_DB1, HRF), and OCTA (ROSE). The experimental results show that our MCPA model achieves state-of-the-art performance. The code is available at https://github.com/simonustc/MCPA-for-2D-Medical-Image-Segmentation. ",
    "url": "https://arxiv.org/abs/2307.14588",
    "authors": [
      "Liang Xu",
      "Mingxiao Chen",
      "Yi Cheng",
      "Pengfei Shao",
      "Shuwei Shen",
      "Peng Yao",
      "Ronald X.Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14603",
    "title": "A Weakly Supervised Segmentation Network Embedding Cross-scale Attention  Guidance and Noise-sensitive Constraint for Detecting Tertiary Lymphoid  Structures of Pancreatic Tumors",
    "abstract": "The presence of tertiary lymphoid structures (TLSs) on pancreatic pathological images is an important prognostic indicator of pancreatic tumors. Therefore, TLSs detection on pancreatic pathological images plays a crucial role in diagnosis and treatment for patients with pancreatic tumors. However, fully supervised detection algorithms based on deep learning usually require a large number of manual annotations, which is time-consuming and labor-intensive. In this paper, we aim to detect the TLSs in a manner of few-shot learning by proposing a weakly supervised segmentation network. We firstly obtain the lymphocyte density maps by combining a pretrained model for nuclei segmentation and a domain adversarial network for lymphocyte nuclei recognition. Then, we establish a cross-scale attention guidance mechanism by jointly learning the coarse-scale features from the original histopathology images and fine-scale features from our designed lymphocyte density attention. A noise-sensitive constraint is introduced by an embedding signed distance function loss in the training procedure to reduce tiny prediction errors. Experimental results on two collected datasets demonstrate that our proposed method significantly outperforms the state-of-the-art segmentation-based algorithms in terms of TLSs detection accuracy. Additionally, we apply our method to study the congruent relationship between the density of TLSs and peripancreatic vascular invasion and obtain some clinically statistical results. ",
    "url": "https://arxiv.org/abs/2307.14603",
    "authors": [
      "Bingxue Wang",
      "Liwen Zou",
      "Jun Chen",
      "Yingying Cao",
      "Zhenghua Cai",
      "Yudong Qiu",
      "Liang Mao",
      "Zhongqiu Wang",
      "Jingya Chen",
      "Luying Gui",
      "Xiaoping Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14848",
    "title": "Modeling Interference for the Coexistence of 6G Networks and Passive  Sensing Systems",
    "abstract": "Future wireless networks and sensing systems will benefit from access to large chunks of spectrum above 100 GHz, to achieve terabit-per-second data rates in 6th Generation (6G) cellular systems and improve accuracy and reach of Earth exploration and sensing and radio astronomy applications. These are extremely sensitive to interference from artificial signals, thus the spectrum above 100~GHz features several bands which are protected from active transmissions under current spectrum regulations. To provide more agile access to the spectrum for both services, active and passive users will have to coexist without harming passive sensing operations. In this paper, we provide the first, fundamental analysis of Radio Frequency Interference (RFI) that large-scale terrestrial deployments introduce in different satellite sensing systems now orbiting the Earth. We develop a geometry-based analysis and extend it into a data-driven model which accounts for realistic propagation, building obstruction, ground reflection, for network topology with up to $10^5$ nodes in more than $85$ km$^2$. We show that the presence of harmful RFI depends on several factors, including network load, density and topology, satellite orientation, and building density. The results and methodology provide the foundation for the development of coexistence solutions and spectrum policy towards 6G. ",
    "url": "https://arxiv.org/abs/2307.14848",
    "authors": [
      "Paolo Testolina",
      "Michele Polese",
      "Josep M. Jornet",
      "Tommaso Melodia"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2005.00695",
    "title": "On the Generalization Effects of Linear Transformations in Data  Augmentation",
    "abstract": " Comments: 22 pages. Appeared in ICML 2020 ",
    "url": "https://arxiv.org/abs/2005.00695",
    "authors": [
      "Sen Wu",
      "Hongyang R. Zhang",
      "Gregory Valiant",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2106.02626",
    "title": "Dynamics of specialization in neural modules under resource constraints",
    "abstract": " Title: Dynamics of specialization in neural modules under resource constraints ",
    "url": "https://arxiv.org/abs/2106.02626",
    "authors": [
      "Gabriel B\u00e9na",
      "Dan F. M. Goodman"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2106.03328",
    "title": "Securing Secure Aggregation: Mitigating Multi-Round Privacy Leakage in  Federated Learning",
    "abstract": " Title: Securing Secure Aggregation: Mitigating Multi-Round Privacy Leakage in  Federated Learning ",
    "url": "https://arxiv.org/abs/2106.03328",
    "authors": [
      "Jinhyun So",
      "Ramy E. Ali",
      "Basak Guler",
      "Jiantao Jiao",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2106.11264",
    "title": "Compositional federated learning: Applications in distributionally  robust averaging and meta learning",
    "abstract": " Comments: 10 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2106.11264",
    "authors": [
      "Feihu Huang",
      "Junyi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2201.03622",
    "title": "Graph-Based Recommendation System Enhanced with Community Detection",
    "abstract": " Comments: This is a preprint of an article published in \"Scientific Programming\" ",
    "url": "https://arxiv.org/abs/2201.03622",
    "authors": [
      "Zeinab Shokrzadeh",
      "Mohammad-Reza Feizi-Derakhshi",
      "Mohammad-Ali Balafar",
      "Jamshid Bagherzadeh-Mohasefi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.12481",
    "title": "Analyzing Explainer Robustness via Lipschitzness of Prediction Functions",
    "abstract": " Title: Analyzing Explainer Robustness via Lipschitzness of Prediction Functions ",
    "url": "https://arxiv.org/abs/2206.12481",
    "authors": [
      "Zulqarnain Khan",
      "Davin Hill",
      "Aria Masoomi",
      "Joshua Bone",
      "Jennifer Dy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04045",
    "title": "Runtime Analysis for Permutation-based Evolutionary Algorithms",
    "abstract": " Comments: Journal version of our paper at GECCO 2022, to appear in Algorithmica. 51 pages. arXiv admin note: substantial text overlap with arXiv:2204.07637 ",
    "url": "https://arxiv.org/abs/2207.04045",
    "authors": [
      "Benjamin Doerr",
      "Yassine Ghannane",
      "Marouane Ibn Brahim"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.05776",
    "title": "Neural Networks for Scalar Input and Functional Output",
    "abstract": " Title: Neural Networks for Scalar Input and Functional Output ",
    "url": "https://arxiv.org/abs/2208.05776",
    "authors": [
      "Sidi Wu",
      "C\u00e9dric Beaulac",
      "Jiguo Cao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2209.06589",
    "title": "Towards Better Generalization with Flexible Representation of  Multi-Module Graph Neural Networks",
    "abstract": " Title: Towards Better Generalization with Flexible Representation of  Multi-Module Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2209.06589",
    "authors": [
      "Hyungeun Lee",
      "Kijung Yoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.07436",
    "title": "Statistical process monitoring of artificial neural networks",
    "abstract": " Title: Statistical process monitoring of artificial neural networks ",
    "url": "https://arxiv.org/abs/2209.07436",
    "authors": [
      "Anna Malinovskaya",
      "Pavlo Mozharovskyi",
      "Philipp Otto"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.11405",
    "title": "Quantum Locally Testable Code with Constant Soundness",
    "abstract": " Comments: Updated presentation of the manuscript ",
    "url": "https://arxiv.org/abs/2209.11405",
    "authors": [
      "Andrew Cross",
      "Zhiyang He",
      "Anand Natarajan",
      "Mario Szegedy",
      "Guanyu Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2210.09924",
    "title": "Predicting Winning Regions in Parity Games via Graph Neural Networks  (Extended Abstract)",
    "abstract": " Comments: 4 pages, extended abstract. Presented at DAV'23 ",
    "url": "https://arxiv.org/abs/2210.09924",
    "authors": [
      "Tobias Hecking",
      "Swathy Muthukrishnan",
      "Alexander Weinert"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.17403",
    "title": "Random Walk-based Community Key-members Search over Large Graphs",
    "abstract": " Title: Random Walk-based Community Key-members Search over Large Graphs ",
    "url": "https://arxiv.org/abs/2210.17403",
    "authors": [
      "Yuxiang Wang",
      "Yuyang Zhao",
      "Xiaoliang Xu",
      "Yue Wu",
      "Tianxing Wu",
      "Xiangyu Ke"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.11220",
    "title": "STGlow: A Flow-based Generative Framework with Dual Graphormer for  Pedestrian Trajectory Prediction",
    "abstract": " Comments: 14 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2211.11220",
    "authors": [
      "Rongqin Liang",
      "Yuanman Li",
      "Jiantao Zhou",
      "Xia Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16762",
    "title": "GeoUDF: Surface Reconstruction from 3D Point Clouds via Geometry-guided  Distance Representation",
    "abstract": " Comments: Accepted by ICCV 2023 ",
    "url": "https://arxiv.org/abs/2211.16762",
    "authors": [
      "Siyu Ren",
      "Junhui Hou",
      "Xiaodong Chen",
      "Ying He",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.07959",
    "title": "Scalable Bayesian Uncertainty Quantification for Neural Network  Potentials: Promise and Pitfalls",
    "abstract": " Comments: This is a post-peer-review, pre-copyedit version of an article published in the Journal of Chemical Theory and Computation ",
    "url": "https://arxiv.org/abs/2212.07959",
    "authors": [
      "Stephan Thaler",
      "Gregor Doehner",
      "Julija Zavadlav"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2302.01198",
    "title": "Causal Lifting and Link Prediction",
    "abstract": " Title: Causal Lifting and Link Prediction ",
    "url": "https://arxiv.org/abs/2302.01198",
    "authors": [
      "Leonardo Cotta",
      "Beatrice Bevilacqua",
      "Nesreen Ahmed",
      "Bruno Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.01226",
    "title": "Factor Fields: A Unified Framework for Neural Fields and Beyond",
    "abstract": " Comments: 13 pages, 7 figures; Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2302.01226",
    "authors": [
      "Anpei Chen",
      "Zexiang Xu",
      "Xinyue Wei",
      "Siyu Tang",
      "Hao Su",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.08720",
    "title": "Algorithmic Hallucinations of Near-Surface Winds: Statistical  Downscaling with Generative Adversarial Networks to Convection-Permitting  Scales",
    "abstract": " Comments: 43 pages, including 11 main figures, and 16 supplemental figures ",
    "url": "https://arxiv.org/abs/2302.08720",
    "authors": [
      "Nicolaas J. Annau",
      "Alex J. Cannon",
      "Adam H. Monahan"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12012",
    "title": "Empirical analysis of Different Dimensionality Reduction and  classification Techniques for Epileptic Seizure detection",
    "abstract": " Title: Empirical analysis of Different Dimensionality Reduction and  classification Techniques for Epileptic Seizure detection ",
    "url": "https://arxiv.org/abs/2302.12012",
    "authors": [
      "Rabel Guharoy",
      "Nanda Dulal Jana",
      "Suparna Biswas",
      "Lalit Garg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.12806",
    "title": "Morality in the mundane: Categorizing moral reasoning in real-life  social situations",
    "abstract": " Comments: Accepted by THE 18TH INTERNATIONAL AAAI CONFERENCE ON WEB AND SOCIAL MEDIA (ICWSM2024) ",
    "url": "https://arxiv.org/abs/2302.12806",
    "authors": [
      "Ruijie Xi",
      "Munindar P. Singh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.01669",
    "title": "Learning Common Rationale to Improve Self-Supervised Representation for  Fine-Grained Visual Recognition Problems",
    "abstract": " Comments: CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.01669",
    "authors": [
      "Yangyang Shu",
      "Anton van den Hengel",
      "Lingqiao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.10135",
    "title": "Efficient and Feasible Robotic Assembly Sequence Planning via Graph  Representation Learning",
    "abstract": " Comments: Accepted to IROS 2023. First two authors share equal contribution ",
    "url": "https://arxiv.org/abs/2303.10135",
    "authors": [
      "Matan Atad",
      "Jianxiang Feng",
      "Ismael Rodr\u00edguez",
      "Maximilian Durner",
      "Rudolph Triebel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15986",
    "title": "Clustered Federated Learning Architecture for Network Anomaly Detection  in Large Scale Heterogeneous IoT Networks",
    "abstract": " Comments: Accepted for publication in Computers & Security ",
    "url": "https://arxiv.org/abs/2303.15986",
    "authors": [
      "Xabier S\u00e1ez-de-C\u00e1mara",
      "Jose Luis Flores",
      "Crist\u00f3bal Arellano",
      "Aitor Urbieta",
      "Urko Zurutuza"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.17519",
    "title": "Infinite Horizon Privacy in Networked Control Systems: Utility/Privacy  Tradeoffs and Design Tools",
    "abstract": " Title: Infinite Horizon Privacy in Networked Control Systems: Utility/Privacy  Tradeoffs and Design Tools ",
    "url": "https://arxiv.org/abs/2303.17519",
    "authors": [
      "Haleh Hayati",
      "Nathan van de Wouw",
      "Carlos Murguia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.00570",
    "title": "FedFTN: Personalized Federated Learning with Deep Feature Transformation  Network for Multi-institutional Low-count PET Denoising",
    "abstract": " Title: FedFTN: Personalized Federated Learning with Deep Feature Transformation  Network for Multi-institutional Low-count PET Denoising ",
    "url": "https://arxiv.org/abs/2304.00570",
    "authors": [
      "Bo Zhou",
      "Huidong Xie",
      "Qiong Liu",
      "Xiongchao Chen",
      "Xueqi Guo",
      "Zhicheng Feng",
      "S. Kevin Zhou",
      "Biao Li",
      "Axel Rominger",
      "Kuangyu Shi",
      "James S. Duncan",
      "Chi Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.14031",
    "title": "Boosting Big Brother: Attacking Search Engines with Encodings",
    "abstract": " Comments: To appear in the 26th Symposium on Research in Attacks, Intrusions and Defenses (RAID). Revisions: Adds table summarizing attacks ",
    "url": "https://arxiv.org/abs/2304.14031",
    "authors": [
      "Nicholas Boucher",
      "Luca Pajola",
      "Ilia Shumailov",
      "Ross Anderson",
      "Mauro Conti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2304.14379",
    "title": "Generalized Automorphisms of Channel Codes: Properties, Code Design, and  a Decoder",
    "abstract": " Comments: Accepted for presentation at International Symposium on Topics in Coding 2023 Included reviews: Changed naming of automorphism groups; Corrected typo in def. of GAUT; Preprocessing no longer as theorem; Smaller formatting changes; Results unchanged ",
    "url": "https://arxiv.org/abs/2304.14379",
    "authors": [
      "Jonathan Mandelbaum",
      "Holger J\u00e4kel",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.06716",
    "title": "Distracting Downpour: Adversarial Weather Attacks for Motion Estimation",
    "abstract": " Comments: Acepted by ICCV 2023. This work is a direct extension of our extended abstract from arXiv:2210.11242 ",
    "url": "https://arxiv.org/abs/2305.06716",
    "authors": [
      "Jenny Schmalfuss",
      "Lukas Mehl",
      "Andr\u00e9s Bruhn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08890",
    "title": "Differential Convolutional Fuzzy Time Series Forecasting",
    "abstract": " Title: Differential Convolutional Fuzzy Time Series Forecasting ",
    "url": "https://arxiv.org/abs/2305.08890",
    "authors": [
      "Tianxiang Zhan",
      "Yuanpeng He",
      "Yong Deng",
      "Zhen Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.05697",
    "title": "Group Equivariant Fourier Neural Operators for Partial Differential  Equations",
    "abstract": " Comments: Proceedings of the 40th International Conference on Machine Learning this https URL ",
    "url": "https://arxiv.org/abs/2306.05697",
    "authors": [
      "Jacob Helwig",
      "Xuan Zhang",
      "Cong Fu",
      "Jerry Kurtin",
      "Stephan Wojtowytsch",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.05965",
    "title": "Automating Model Comparison in Factor Graphs",
    "abstract": " Title: Automating Model Comparison in Factor Graphs ",
    "url": "https://arxiv.org/abs/2306.05965",
    "authors": [
      "Bart van Erp",
      "Wouter W. L. Nuijten",
      "Thijs van de Laar",
      "Bert de Vries"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.16958",
    "title": "Identifiability of direct effects from summary causal graphs",
    "abstract": " Title: Identifiability of direct effects from summary causal graphs ",
    "url": "https://arxiv.org/abs/2306.16958",
    "authors": [
      "Simon Ferreira",
      "Charles K. Assaad"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.00866",
    "title": "Mining Clues from Incomplete Utterance: A Query-enhanced Network for  Incomplete Utterance Rewriting",
    "abstract": " Comments: NAACL 2022 ",
    "url": "https://arxiv.org/abs/2307.00866",
    "authors": [
      "Shuzheng Si",
      "Shuang Zeng",
      "Baobao Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.01524",
    "title": "Exploiting Richness of Learned Compressed Representation of Images for  Semantic Segmentation",
    "abstract": " Comments: Accepted at ICME 2023 (Industry Track) ",
    "url": "https://arxiv.org/abs/2307.01524",
    "authors": [
      "Ravi Kakaiya",
      "Rakshith Sathish",
      "Ramanathan Sethuraman",
      "Debdoot Sheet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.01918",
    "title": "Computational Reproducibility in Computational Social Science",
    "abstract": " Comments: Working Paper; fixed missing citation in text; fixed some minor errors and formatting ",
    "url": "https://arxiv.org/abs/2307.01918",
    "authors": [
      "David Schoch",
      "Chung-hong Chan",
      "Claudia Wagner",
      "Arnim Bleier"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2307.03430",
    "title": "Differential Privacy for Clustering Under Continual Observation",
    "abstract": " Title: Differential Privacy for Clustering Under Continual Observation ",
    "url": "https://arxiv.org/abs/2307.03430",
    "authors": [
      "Max Dupr\u00e9 la Tour",
      "Monika Henzinger",
      "David Saulpic"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.03811",
    "title": "Formulation Graphs for Mapping Structure-Composition of Battery  Electrolytes to Device Performance",
    "abstract": " Comments: 35 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2307.03811",
    "authors": [
      "Vidushi Sharma",
      "Maxwell Giammona",
      "Dmitry Zubarev",
      "Andy Tek",
      "Khanh Nugyuen",
      "Linda Sundberg",
      "Daniele Congiu",
      "Young-Hye La"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.04019",
    "title": "GP-guided MPPI for Efficient Navigation in Complex Unknown Cluttered  Environments",
    "abstract": " Comments: This paper has 8 pages, 6 figures, 2 tables. It has been accepted for publication at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Detroit, Michigan, USA, 2023 ",
    "url": "https://arxiv.org/abs/2307.04019",
    "authors": [
      "Ihab S. Mohamed",
      "Mahmoud Ali",
      "Lantao Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.05946",
    "title": "A Bayesian approach to quantifying uncertainties and improving  generalizability in traffic prediction models",
    "abstract": " Title: A Bayesian approach to quantifying uncertainties and improving  generalizability in traffic prediction models ",
    "url": "https://arxiv.org/abs/2307.05946",
    "authors": [
      "Agnimitra Sengupta",
      "Sudeepta Mondal",
      "Adway Das",
      "S. Ilgin Guler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.06732",
    "title": "Learning fixed points of recurrent neural networks by reparameterizing  the network model",
    "abstract": " Title: Learning fixed points of recurrent neural networks by reparameterizing  the network model ",
    "url": "https://arxiv.org/abs/2307.06732",
    "authors": [
      "Vicky Zhu",
      "Robert Rosenbaum"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2307.09751",
    "title": "Information Retrieval Meets Large Language Models: A Strategic Report  from Chinese IR Community",
    "abstract": " Comments: 17 pages ",
    "url": "https://arxiv.org/abs/2307.09751",
    "authors": [
      "Qingyao Ai",
      "Ting Bai",
      "Zhao Cao",
      "Yi Chang",
      "Jiawei Chen",
      "Zhumin Chen",
      "Zhiyong Cheng",
      "Shoubin Dong",
      "Zhicheng Dou",
      "Fuli Feng",
      "Shen Gao",
      "Jiafeng Guo",
      "Xiangnan He",
      "Yanyan Lan",
      "Chenliang Li",
      "Yiqun Liu",
      "Ziyu Lyu",
      "Weizhi Ma",
      "Jun Ma",
      "Zhaochun Ren",
      "Pengjie Ren",
      "Zhiqiang Wang",
      "Mingwen Wang",
      "Ji-Rong Wen",
      "Le Wu",
      "Xin Xin",
      "Jun Xu",
      "Dawei Yin",
      "Peng Zhang",
      "Fan Zhang",
      "Weinan Zhang",
      "Min Zhang",
      "Xiaofei Zhu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.10249",
    "title": "RCM-Fusion: Radar-Camera Multi-Level Fusion for 3D Object Detection",
    "abstract": " Comments: 10 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2307.10249",
    "authors": [
      "Jisong Kim",
      "Minjae Seong",
      "Geonho Bang",
      "Dongsuk Kum",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.10853",
    "title": "Exploring Effective Priors and Efficient Models for Weakly-Supervised  Change Detection",
    "abstract": " Comments: Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence ",
    "url": "https://arxiv.org/abs/2307.10853",
    "authors": [
      "Zhenghui Zhao",
      "Lixiang Ru",
      "Chen Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.11411",
    "title": "Deep Directly-Trained Spiking Neural Networks for Object Detection",
    "abstract": " Comments: Accepted by ICCV2023 ",
    "url": "https://arxiv.org/abs/2307.11411",
    "authors": [
      "Qiaoyi Su",
      "Yuhong Chou",
      "Yifan Hu",
      "Jianing Li",
      "Shijie Mei",
      "Ziyang Zhang",
      "Guoqi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.11892",
    "title": "On the Vulnerability of Fairness Constrained Learning to Malicious Noise",
    "abstract": " Title: On the Vulnerability of Fairness Constrained Learning to Malicious Noise ",
    "url": "https://arxiv.org/abs/2307.11892",
    "authors": [
      "Avrim Blum",
      "Princewill Okoroafor",
      "Aadirupa Saha",
      "Kevin Stangl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2307.12602",
    "title": "Shortest two disjoint paths in conservative graphs",
    "abstract": " Comments: 27 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2307.12602",
    "authors": [
      "Ildik\u00f3 Schlotter"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2307.13494",
    "title": "Duet: efficient and scalable hybriD neUral rElation undersTanding",
    "abstract": " Title: Duet: efficient and scalable hybriD neUral rElation undersTanding ",
    "url": "https://arxiv.org/abs/2307.13494",
    "authors": [
      "Kaixin Zhang",
      "Hongzhi Wang",
      "Yabin Lu",
      "Ziqi Li",
      "Chang Shu",
      "Yu Yan",
      "Donghua Yang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.13925",
    "title": "EasyNet: An Easy Network for 3D Industrial Anomaly Detection",
    "abstract": " Title: EasyNet: An Easy Network for 3D Industrial Anomaly Detection ",
    "url": "https://arxiv.org/abs/2307.13925",
    "authors": [
      "Ruitao Chen",
      "Guoyang Xie",
      "Jiaqi Liu",
      "Jinbao Wang",
      "Ziqi Luo",
      "Jinfan Wang",
      "Feng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.13957",
    "title": "Heterogeneous Embodied Multi-Agent Collaboration",
    "abstract": " Title: Heterogeneous Embodied Multi-Agent Collaboration ",
    "url": "https://arxiv.org/abs/2307.13957",
    "authors": [
      "Xinzhu Liu",
      "Di Guo",
      "Huaping Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14127",
    "title": "Creative Birds: Self-Supervised Single-View 3D Style Transfer",
    "abstract": " Comments: Accepted at ICCV 2023 ",
    "url": "https://arxiv.org/abs/2307.14127",
    "authors": [
      "Renke Wang",
      "Guimin Que",
      "Shuo Chen",
      "Xiang Li",
      "Jun Li",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]