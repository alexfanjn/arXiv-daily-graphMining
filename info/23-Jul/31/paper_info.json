[
  {
    "id": "arXiv:2307.15067",
    "title": "Set-Membership Inference Attacks using Data Watermarking",
    "abstract": "In this work, we propose a set-membership inference attack for generative models using deep image watermarking techniques. In particular, we demonstrate how conditional sampling from a generative model can reveal the watermark that was injected into parts of the training data. Our empirical results demonstrate that the proposed watermarking technique is a principled approach for detecting the non-consensual use of image data in training generative models. ",
    "url": "https://arxiv.org/abs/2307.15067",
    "authors": [
      "Mike Laszkiewicz",
      "Denis Lukovnikov",
      "Johannes Lederer",
      "Asja Fischer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15069",
    "title": "Combining transmission speckle photography and convolutional neural  network for determination of fat content in cow's milk -- an exercise in  classification of parameters of a complex suspension",
    "abstract": "We have combined transmission speckle photography and machine learning for direct classification and recognition of milk fat content classes. Our aim was hinged on the fact that parameters of scattering particles (and the dispersion medium) can be linked to the intensity distribution (speckle) observed when coherent light is transmitted through a scattering medium. For milk, it is primarily the size distribution and concentration of fat globules, which constitutes the total fat content. Consequently, we trained convolutional neural network to recognise and classify laser speckle from different fat content classes (0.5, 1.5, 2.0 and 3.2%). We investigated four exposure-time protocols and obtained the highest performance for shorter exposure times, in which the intensity histograms are kept similar for all images and the most probable intensity in the speckle pattern is close to zero. Our neural network was able to recognize the milk fat content classes unambiguously and we obtained the highest test and independent classification accuracies of 100 and ~99% respectively. It indicates that the parameters of other complex realistic suspensions could be classified with similar methods. ",
    "url": "https://arxiv.org/abs/2307.15069",
    "authors": [
      "Kwasi Nyandey",
      "Daniel Jakubczyk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.15071",
    "title": "Writer adaptation for offline text recognition: An exploration of neural  network-based methods",
    "abstract": "Handwriting recognition has seen significant success with the use of deep learning. However, a persistent shortcoming of neural networks is that they are not well-equipped to deal with shifting data distributions. In the field of handwritten text recognition (HTR), this shows itself in poor recognition accuracy for writers that are not similar to those seen during training. An ideal HTR model should be adaptive to new writing styles in order to handle the vast amount of possible writing styles. In this paper, we explore how HTR models can be made writer adaptive by using only a handful of examples from a new writer (e.g., 16 examples) for adaptation. Two HTR architectures are used as base models, using a ResNet backbone along with either an LSTM or Transformer sequence decoder. Using these base models, two methods are considered to make them writer adaptive: 1) model-agnostic meta-learning (MAML), an algorithm commonly used for tasks such as few-shot classification, and 2) writer codes, an idea originating from automatic speech recognition. Results show that an HTR-specific version of MAML known as MetaHTR improves performance compared to the baseline with a 1.4 to 2.0 improvement in word error rate (WER). The improvement due to writer adaptation is between 0.2 and 0.7 WER, where a deeper model seems to lend itself better to adaptation using MetaHTR than a shallower model. However, applying MetaHTR to larger HTR models or sentence-level HTR may become prohibitive due to its high computational and memory requirements. Lastly, writer codes based on learned features or Hinge statistical features did not lead to improved recognition performance. ",
    "url": "https://arxiv.org/abs/2307.15071",
    "authors": [
      "Tobias van der Werff",
      "Maruf A. Dhali",
      "Lambert Schomaker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.15076",
    "title": "Knowledge Graph Enhanced Intelligent Tutoring System Based on Exercise  Representativeness and Informativeness",
    "abstract": "Presently, knowledge graph-based recommendation algorithms have garnered considerable attention among researchers. However, these algorithms solely consider knowledge graphs with single relationships and do not effectively model exercise-rich features, such as exercise representativeness and informativeness. Consequently, this paper proposes a framework, namely the Knowledge-Graph-Exercise Representativeness and Informativeness Framework, to address these two issues. The framework consists of four intricate components and a novel cognitive diagnosis model called the Neural Attentive cognitive diagnosis model. These components encompass the informativeness component, exercise representation component, knowledge importance component, and exercise representativeness component. The informativeness component evaluates the informational value of each question and identifies the candidate question set that exhibits the highest exercise informativeness. Furthermore, the skill embeddings are employed as input for the knowledge importance component. This component transforms a one-dimensional knowledge graph into a multi-dimensional one through four class relations and calculates skill importance weights based on novelty and popularity. Subsequently, the exercise representativeness component incorporates exercise weight knowledge coverage to select questions from the candidate question set for the tested question set. Lastly, the cognitive diagnosis model leverages exercise representation and skill importance weights to predict student performance on the test set and estimate their knowledge state. To evaluate the effectiveness of our selection strategy, extensive experiments were conducted on two publicly available educational datasets. The experimental results demonstrate that our framework can recommend appropriate exercises to students, leading to improved student performance. ",
    "url": "https://arxiv.org/abs/2307.15076",
    "authors": [
      "Linqing Li",
      "Zhifeng Wang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15090",
    "title": "Understanding Forward Process of Convolutional Neural Network",
    "abstract": "This paper reveal the selective rotation in the CNNs' forward processing. It elucidates the activation function as a discerning mechanism that unifies and quantizes the rotational aspects of the input data. Experiments show how this defined methodology reflects the progress network distinguish inputs based on statistical indicators, which can be comprehended or analyzed by applying structured mathematical tools. Our findings also unveil the consistency between artificial neural networks and the human brain in their data processing pattern. ",
    "url": "https://arxiv.org/abs/2307.15090",
    "authors": [
      "Peixin Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.15097",
    "title": "Cascaded Cross-Modal Transformer for Request and Complaint Detection",
    "abstract": "We propose a novel cascaded cross-modal transformer (CCMT) that combines speech and text transcripts to detect customer requests and complaints in phone conversations. Our approach leverages a multimodal paradigm by transcribing the speech using automatic speech recognition (ASR) models and translating the transcripts into different languages. Subsequently, we combine language-specific BERT-based models with Wav2Vec2.0 audio features in a novel cascaded cross-attention transformer model. We apply our system to the Requests Sub-Challenge of the ACM Multimedia 2023 Computational Paralinguistics Challenge, reaching unweighted average recalls (UAR) of 65.41% and 85.87% for the complaint and request classes, respectively. ",
    "url": "https://arxiv.org/abs/2307.15097",
    "authors": [
      "Nicolae-Catalin Ristea",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.15098",
    "title": "Self-Supervised Learning for Improved Synthetic Aperture Sonar Target  Recognition",
    "abstract": "This study explores the application of self-supervised learning (SSL) for improved target recognition in synthetic aperture sonar (SAS) imagery. The unique challenges of underwater environments make traditional computer vision techniques, which rely heavily on optical camera imagery, less effective. SAS, with its ability to generate high-resolution imagery, emerges as a preferred choice for underwater imaging. However, the voluminous high-resolution SAS data presents a significant challenge for labeling; a crucial step for training deep neural networks (DNNs). SSL, which enables models to learn features in data without the need for labels, is proposed as a potential solution to the data labeling challenge in SAS. The study evaluates the performance of two prominent SSL algorithms, MoCov2 and BYOL, against the well-regarded supervised learning model, ResNet18, for binary image classification tasks. The findings suggest that while both SSL models can outperform a fully supervised model with access to a small number of labels in a few-shot scenario, they do not exceed it when all the labels are used. The results underscore the potential of SSL as a viable alternative to traditional supervised learning, capable of maintaining task performance while reducing the time and costs associated with data labeling. The study also contributes to the growing body of evidence supporting the use of SSL in remote sensing and could stimulate further research in this area. ",
    "url": "https://arxiv.org/abs/2307.15098",
    "authors": [
      "BW Sheffield"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.15105",
    "title": "Detecting Morphing Attacks via Continual Incremental Training",
    "abstract": "Scenarios in which restrictions in data transfer and storage limit the possibility to compose a single dataset -- also exploiting different data sources -- to perform a batch-based training procedure, make the development of robust models particularly challenging. We hypothesize that the recent Continual Learning (CL) paradigm may represent an effective solution to enable incremental training, even through multiple sites. Indeed, a basic assumption of CL is that once a model has been trained, old data can no longer be used in successive training iterations and in principle can be deleted. Therefore, in this paper, we investigate the performance of different Continual Learning methods in this scenario, simulating a learning model that is updated every time a new chunk of data, even of variable size, is available. Experimental results reveal that a particular CL method, namely Learning without Forgetting (LwF), is one of the best-performing algorithms. Then, we investigate its usage and parametrization in Morphing Attack Detection and Object Classification tasks, specifically with respect to the amount of new training data that became available. ",
    "url": "https://arxiv.org/abs/2307.15105",
    "authors": [
      "Lorenzo Pellegrini",
      "Guido Borghi",
      "Annalisa Franco",
      "Davide Maltoni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15128",
    "title": "End-to-end Remote Sensing Change Detection of Unregistered Bi-temporal  Images for Natural Disasters",
    "abstract": "Change detection based on remote sensing images has been a prominent area of interest in the field of remote sensing. Deep networks have demonstrated significant success in detecting changes in bi-temporal remote sensing images and have found applications in various fields. Given the degradation of natural environments and the frequent occurrence of natural disasters, accurately and swiftly identifying damaged buildings in disaster-stricken areas through remote sensing images holds immense significance. This paper aims to investigate change detection specifically for natural disasters. Considering that existing public datasets used in change detection research are registered, which does not align with the practical scenario where bi-temporal images are not matched, this paper introduces an unregistered end-to-end change detection synthetic dataset called xBD-E2ECD. Furthermore, we propose an end-to-end change detection network named E2ECDNet, which takes an unregistered bi-temporal image pair as input and simultaneously generates the flow field prediction result and the change detection prediction result. It is worth noting that our E2ECDNet also supports change detection for registered image pairs, as registration can be seen as a special case of non-registration. Additionally, this paper redefines the criteria for correctly predicting a positive case and introduces neighborhood-based change detection evaluation metrics. The experimental results have demonstrated significant improvements. ",
    "url": "https://arxiv.org/abs/2307.15128",
    "authors": [
      "Guiqin Zhao",
      "Lianlei Shan",
      "Weiqiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.15130",
    "title": "Bounding the Interleaving Distance for Geometric Graphs with a Loss  Function",
    "abstract": "A geometric graph is an abstract graph along with an embedding of the graph into the Euclidean plane which can be used to model a wide range of data sets. The ability to compare and cluster such objects is required in a data analysis pipeline, leading to a need for distances or metrics on these objects. In this work, we study the interleaving distance on geometric graphs, where functor representations of data can be compared by finding pairs of natural transformations between them. However, in many cases, particularly those of the set-valued functor variety, computation of the interleaving distance is NP-hard. For this reason, we take inspiration from the work of Robinson to find quality measures for families of maps that do not rise to the level of a natural transformation. Specifically, we call collections $\\phi = \\{\\phi_U\\mid U\\}$ and $\\psi = \\{\\psi_U\\mid U\\}$ which do not necessarily form a true interleaving an \\textit{assignment}. In the case of embedded graphs, we impose a grid structure on the plane, treat this as a poset endowed with the Alexandroff topology $K$, and encode the embedded graph data as functors $F: \\mathbf{Open}(K) \\to \\mathbf{Set}$ where $F(U)$ is the set of connected components of the graph inside of the geometric realization of the set $U$. We then endow the image with the extra structure of a metric space and define a loss function $L(\\phi,\\psi)$ which measures how far the required diagrams of an interleaving are from commuting. Then for a pair of assignments, we use this loss function to bound the interleaving distance, with an eye toward computation and approximation of the distance. We expect these ideas are not only useful in our particular use case of embedded graphs, but can be extended to a larger class of interleaving distance problems where computational complexity creates a barrier to use in practice. ",
    "url": "https://arxiv.org/abs/2307.15130",
    "authors": [
      "Erin W. Chambers",
      "Elizabeth Munch",
      "Sarah Percival",
      "Bei Wang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "General Topology (math.GN)"
    ]
  },
  {
    "id": "arXiv:2307.15131",
    "title": "Seal-3D: Interactive Pixel-Level Editing for Neural Radiance Fields",
    "abstract": "With the popularity of implicit neural representations, or neural radiance fields (NeRF), there is a pressing need for editing methods to interact with the implicit 3D models for tasks like post-processing reconstructed scenes and 3D content creation. While previous works have explored NeRF editing from various perspectives, they are restricted in editing flexibility, quality, and speed, failing to offer direct editing response and instant preview. The key challenge is to conceive a locally editable neural representation that can directly reflect the editing instructions and update instantly. To bridge the gap, we propose a new interactive editing method and system for implicit representations, called Seal-3D, which allows users to edit NeRF models in a pixel-level and free manner with a wide range of NeRF-like backbone and preview the editing effects instantly. To achieve the effects, the challenges are addressed by our proposed proxy function mapping the editing instructions to the original space of NeRF models and a teacher-student training strategy with local pretraining and global finetuning. A NeRF editing system is built to showcase various editing types. Our system can achieve compelling editing effects with an interactive speed of about 1 second. ",
    "url": "https://arxiv.org/abs/2307.15131",
    "authors": [
      "Xiangyu Wang",
      "Jingsen Zhu",
      "Qi Ye",
      "Yuchi Huo",
      "Yunlong Ran",
      "Zhihua Zhong",
      "Jiming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2307.15150",
    "title": "R-Block: Regularized Block of Dropout for convolutional networks",
    "abstract": "Dropout as a regularization technique is widely used in fully connected layers while is less effective in convolutional layers. Therefore more structured forms of dropout have been proposed to regularize convolutional networks. The disadvantage of these methods is that the randomness introduced causes inconsistency between training and inference. In this paper, we apply a mutual learning training strategy for convolutional layer regularization, namely R-Block, which forces two outputs of the generated difference maximizing sub models to be consistent with each other. Concretely, R-Block minimizes the losses between the output distributions of two sub models with different drop regions for each sample in the training dataset. We design two approaches to construct such sub models. Our experiments demonstrate that R-Block achieves better performance than other existing structured dropout variants. We also demonstrate that our approaches to construct sub models outperforms others. ",
    "url": "https://arxiv.org/abs/2307.15150",
    "authors": [
      "Liqi Wang",
      "Qiya Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15154",
    "title": "A/B Testing and Best-arm Identification for Linear Bandits with  Robustness to Non-stationarity",
    "abstract": "We investigate the fixed-budget best-arm identification (BAI) problem for linear bandits in a potentially non-stationary environment. Given a finite arm set $\\mathcal{X}\\subset\\mathbb{R}^d$, a fixed budget $T$, and an unpredictable sequence of parameters $\\left\\lbrace\\theta_t\\right\\rbrace_{t=1}^{T}$, an algorithm will aim to correctly identify the best arm $x^* := \\arg\\max_{x\\in\\mathcal{X}}x^\\top\\sum_{t=1}^{T}\\theta_t$ with probability as high as possible. Prior work has addressed the stationary setting where $\\theta_t = \\theta_1$ for all $t$ and demonstrated that the error probability decreases as $\\exp(-T /\\rho^*)$ for a problem-dependent constant $\\rho^*$. But in many real-world $A/B/n$ multivariate testing scenarios that motivate our work, the environment is non-stationary and an algorithm expecting a stationary setting can easily fail. For robust identification, it is well-known that if arms are chosen randomly and non-adaptively from a G-optimal design over $\\mathcal{X}$ at each time then the error probability decreases as $\\exp(-T\\Delta^2_{(1)}/d)$, where $\\Delta_{(1)} = \\min_{x \\neq x^*} (x^* - x)^\\top \\frac{1}{T}\\sum_{t=1}^T \\theta_t$. As there exist environments where $\\Delta_{(1)}^2/ d \\ll 1/ \\rho^*$, we are motivated to propose a novel algorithm $\\mathsf{P1}$-$\\mathsf{RAGE}$ that aims to obtain the best of both worlds: robustness to non-stationarity and fast rates of identification in benign settings. We characterize the error probability of $\\mathsf{P1}$-$\\mathsf{RAGE}$ and demonstrate empirically that the algorithm indeed never performs worse than G-optimal design but compares favorably to the best algorithms in the stationary setting. ",
    "url": "https://arxiv.org/abs/2307.15154",
    "authors": [
      "Zhihan Xiong",
      "Romain Camilleri",
      "Maryam Fazel",
      "Lalit Jain",
      "Kevin Jamieson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.15157",
    "title": "R-LPIPS: An Adversarially Robust Perceptual Similarity Metric",
    "abstract": "Similarity metrics have played a significant role in computer vision to capture the underlying semantics of images. In recent years, advanced similarity metrics, such as the Learned Perceptual Image Patch Similarity (LPIPS), have emerged. These metrics leverage deep features extracted from trained neural networks and have demonstrated a remarkable ability to closely align with human perception when evaluating relative image similarity. However, it is now well-known that neural networks are susceptible to adversarial examples, i.e., small perturbations invisible to humans crafted to deliberately mislead the model. Consequently, the LPIPS metric is also sensitive to such adversarial examples. This susceptibility introduces significant security concerns, especially considering the widespread adoption of LPIPS in large-scale applications. In this paper, we propose the Robust Learned Perceptual Image Patch Similarity (R-LPIPS) metric, a new metric that leverages adversarially trained deep features. Through a comprehensive set of experiments, we demonstrate the superiority of R-LPIPS compared to the classical LPIPS metric. The code is available at https://github.com/SaraGhazanfari/R-LPIPS. ",
    "url": "https://arxiv.org/abs/2307.15157",
    "authors": [
      "Sara Ghazanfari",
      "Siddharth Garg",
      "Prashanth Krishnamurthy",
      "Farshad Khorrami",
      "Alexandre Araujo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.15176",
    "title": "RCT Rejection Sampling for Causal Estimation Evaluation",
    "abstract": "Confounding is a significant obstacle to unbiased estimation of causal effects from observational data. For settings with high-dimensional covariates -- such as text data, genomics, or the behavioral social sciences -- researchers have proposed methods to adjust for confounding by adapting machine learning methods to the goal of causal estimation. However, empirical evaluation of these adjustment methods has been challenging and limited. In this work, we build on a promising empirical evaluation strategy that simplifies evaluation design and uses real data: subsampling randomized controlled trials (RCTs) to create confounded observational datasets while using the average causal effects from the RCTs as ground-truth. We contribute a new sampling algorithm, which we call RCT rejection sampling, and provide theoretical guarantees that causal identification holds in the observational data to allow for valid comparisons to the ground-truth RCT. Using synthetic data, we show our algorithm indeed results in low bias when oracle estimators are evaluated on the confounded samples, which is not always the case for a previously proposed algorithm. In addition to this identification result, we highlight several finite data considerations for evaluation designers who plan to use RCT rejection sampling on their own datasets. As a proof of concept, we implement an example evaluation pipeline and walk through these finite data considerations with a novel, real-world RCT -- which we release publicly -- consisting of approximately 70k observations and text data as high-dimensional covariates. Together, these contributions build towards a broader agenda of improved empirical evaluation for causal estimation. ",
    "url": "https://arxiv.org/abs/2307.15176",
    "authors": [
      "Katherine A. Keith",
      "Sergey Feldman",
      "David Jurgens",
      "Jonathan Bragg",
      "Rohit Bhattacharya"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2307.15244",
    "title": "BOURNE: Bootstrapped Self-supervised Learning Framework for Unified  Graph Anomaly Detection",
    "abstract": "Graph anomaly detection (GAD) has gained increasing attention in recent years due to its critical application in a wide range of domains, such as social networks, financial risk management, and traffic analysis. Existing GAD methods can be categorized into node and edge anomaly detection models based on the type of graph objects being detected. However, these methods typically treat node and edge anomalies as separate tasks, overlooking their associations and frequent co-occurrences in real-world graphs. As a result, they fail to leverage the complementary information provided by node and edge anomalies for mutual detection. Additionally, state-of-the-art GAD methods, such as CoLA and SL-GAD, heavily rely on negative pair sampling in contrastive learning, which incurs high computational costs, hindering their scalability to large graphs. To address these limitations, we propose a novel unified graph anomaly detection framework based on bootstrapped self-supervised learning (named BOURNE). We extract a subgraph (graph view) centered on each target node as node context and transform it into a dual hypergraph (hypergraph view) as edge context. These views are encoded using graph and hypergraph neural networks to capture the representations of nodes, edges, and their associated contexts. By swapping the context embeddings between nodes and edges and measuring the agreement in the embedding space, we enable the mutual detection of node and edge anomalies. Furthermore, we adopt a bootstrapped training strategy that eliminates the need for negative sampling, enabling BOURNE to handle large graphs efficiently. Extensive experiments conducted on six benchmark datasets demonstrate the superior effectiveness and efficiency of BOURNE in detecting both node and edge anomalies. ",
    "url": "https://arxiv.org/abs/2307.15244",
    "authors": [
      "Jie Liu",
      "Mengting He",
      "Xuequn Shang",
      "Jieming Shi",
      "Bin Cui",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.15249",
    "title": "A deep transfer learning network for structural condition identification  with limited real-world training data",
    "abstract": "Structural condition identification based on monitoring data is important for automatic civil infrastructure asset management. Nevertheless, the monitoring data is almost always insufficient, because the real-time monitoring data of a structure only reflects a limited number of structural conditions, while the number of possible structural conditions is infinite. With insufficient monitoring data, the identification performance may significantly degrade. This study aims to tackle this challenge by proposing a deep transfer learning (TL) approach for structural condition identification. It effectively integrates physics-based and data-driven methods, by generating various training data based on the calibrated finite element (FE) model, pretraining a deep learning (DL) network, and transferring its embedded knowledge to the real monitoring/testing domain. Its performance is demonstrated in a challenging case, vibration-based condition identification of steel frame structures with bolted connection damage. The results show that even though the training data are from a different domain and with different types of labels, intrinsic physics can be learned through the pretraining process, and the TL results can be clearly improved, with the identification accuracy increasing from 81.8% to 89.1%. The comparative studies show that SHMnet with three convolutional layers stands out as the pretraining DL architecture, with 21.8% and 25.5% higher identification accuracy values over the other two networks, VGGnet-16 and ResNet-18. The findings of this study advance the potential application of the proposed approach towards expert-level condition identification based on limited real-world training data. ",
    "url": "https://arxiv.org/abs/2307.15249",
    "authors": [
      "Nengxin Bao",
      "Tong Zhang",
      "Ruizhi Huang",
      "Suryakanta Biswal",
      "Jingyong Su",
      "Ying Wang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2307.15254",
    "title": "Multiple Instance Learning Framework with Masked Hard Instance Mining  for Whole Slide Image Classification",
    "abstract": "The whole slide image (WSI) classification is often formulated as a multiple instance learning (MIL) problem. Since the positive tissue is only a small fraction of the gigapixel WSI, existing MIL methods intuitively focus on identifying salient instances via attention mechanisms. However, this leads to a bias towards easy-to-classify instances while neglecting hard-to-classify instances. Some literature has revealed that hard examples are beneficial for modeling a discriminative boundary accurately. By applying such an idea at the instance level, we elaborate a novel MIL framework with masked hard instance mining (MHIM-MIL), which uses a Siamese structure (Teacher-Student) with a consistency constraint to explore the potential hard instances. With several instance masking strategies based on attention scores, MHIM-MIL employs a momentum teacher to implicitly mine hard instances for training the student model, which can be any attention-based MIL model. This counter-intuitive strategy essentially enables the student to learn a better discriminating boundary. Moreover, the student is used to update the teacher with an exponential moving average (EMA), which in turn identifies new hard instances for subsequent training iterations and stabilizes the optimization. Experimental results on the CAMELYON-16 and TCGA Lung Cancer datasets demonstrate that MHIM-MIL outperforms other latest methods in terms of performance and training cost. The code is available at: https://github.com/DearCaat/MHIM-MIL. ",
    "url": "https://arxiv.org/abs/2307.15254",
    "authors": [
      "Wenhao Tang",
      "Sheng Huang",
      "Xiaoxian Zhang",
      "Fengtao Zhou",
      "Yi Zhang",
      "Bo Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.15271",
    "title": "Anatomy-Aware Lymph Node Detection in Chest CT using Implicit Station  Stratification",
    "abstract": "Finding abnormal lymph nodes in radiological images is highly important for various medical tasks such as cancer metastasis staging and radiotherapy planning. Lymph nodes (LNs) are small glands scattered throughout the body. They are grouped or defined to various LN stations according to their anatomical locations. The CT imaging appearance and context of LNs in different stations vary significantly, posing challenges for automated detection, especially for pathological LNs. Motivated by this observation, we propose a novel end-to-end framework to improve LN detection performance by leveraging their station information. We design a multi-head detector and make each head focus on differentiating the LN and non-LN structures of certain stations. Pseudo station labels are generated by an LN station classifier as a form of multi-task learning during training, so we do not need another explicit LN station prediction model during inference. Our algorithm is evaluated on 82 patients with lung cancer and 91 patients with esophageal cancer. The proposed implicit station stratification method improves the detection sensitivity of thoracic lymph nodes from 65.1% to 71.4% and from 80.3% to 85.5% at 2 false positives per patient on the two datasets, respectively, which significantly outperforms various existing state-of-the-art baseline techniques such as nnUNet, nnDetection and LENS. ",
    "url": "https://arxiv.org/abs/2307.15271",
    "authors": [
      "Ke Yan",
      "Dakai Jin",
      "Dazhou Guo",
      "Minfeng Xu",
      "Na Shen",
      "Xian-Sheng Hua",
      "Xianghua Ye",
      "Le Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.15284",
    "title": "Task-driven Semantic-aware Green Cooperative Transmission Strategy for  Vehicular Networks",
    "abstract": "Considering the infrastructure deployment cost and energy consumption, it is unrealistic to provide seamless coverage of the vehicular network. The presence of uncovered areas tends to hinder the prevalence of the in-vehicle services with large data volume. To this end, we propose a predictive cooperative multi-relay transmission strategy (PreCMTS) for the intermittently connected vehicular networks, fulfilling the 6G vision of semantic and green communications. Specifically, we introduce a task-driven knowledge graph (KG)-assisted semantic communication system, and model the KG into a weighted directed graph from the viewpoint of transmission. Meanwhile, we identify three predictable parameters about the individual vehicles to perform the following anticipatory analysis. Firstly, to facilitate semantic extraction, we derive the closed-form expression of the achievable throughput within the delay requirement. Then, for the extracted semantic representation, we formulate the mutually coupled problems of semantic unit assignment and predictive relay selection as a combinatorial optimization problem, to jointly optimize the energy efficiency and semantic transmission reliability. To find a favorable solution within limited time, we proposed a low-complexity algorithm based on Markov approximation. The promising performance gains of the PreCMTS are demonstrated by the simulations with realistic vehicle traces generated by the SUMO traffic simulator. ",
    "url": "https://arxiv.org/abs/2307.15284",
    "authors": [
      "Wanting Yang",
      "Xuefen Chi",
      "Linlin Zhao",
      "Zehui Xiong",
      "Wenchao Jiang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.15299",
    "title": "Differential Evolution Algorithm based Hyper-Parameters Selection of  Transformer Neural Network Model for Load Forecasting",
    "abstract": "Accurate load forecasting plays a vital role in numerous sectors, but accurately capturing the complex dynamics of dynamic power systems remains a challenge for traditional statistical models. For these reasons, time-series models (ARIMA) and deep-learning models (ANN, LSTM, GRU, etc.) are commonly deployed and often experience higher success. In this paper, we analyze the efficacy of the recently developed Transformer-based Neural Network model in Load forecasting. Transformer models have the potential to improve Load forecasting because of their ability to learn long-range dependencies derived from their Attention Mechanism. We apply several metaheuristics namely Differential Evolution to find the optimal hyperparameters of the Transformer-based Neural Network to produce accurate forecasts. Differential Evolution provides scalable, robust, global solutions to non-differentiable, multi-objective, or constrained optimization problems. Our work compares the proposed Transformer based Neural Network model integrated with different metaheuristic algorithms by their performance in Load forecasting based on numerical metrics such as Mean Squared Error (MSE) and Mean Absolute Percentage Error (MAPE). Our findings demonstrate the potential of metaheuristic-enhanced Transformer-based Neural Network models in Load forecasting accuracy and provide optimal hyperparameters for each model. ",
    "url": "https://arxiv.org/abs/2307.15299",
    "authors": [
      "Anuvab Sen",
      "Arul Rhik Mazumder",
      "Udayon Sen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15320",
    "title": "Robust Visual Sim-to-Real Transfer for Robotic Manipulation",
    "abstract": "Learning visuomotor policies in simulation is much safer and cheaper than in the real world. However, due to discrepancies between the simulated and real data, simulator-trained policies often fail when transferred to real robots. One common approach to bridge the visual sim-to-real domain gap is domain randomization (DR). While previous work mainly evaluates DR for disembodied tasks, such as pose estimation and object detection, here we systematically explore visual domain randomization methods and benchmark them on a rich set of challenging robotic manipulation tasks. In particular, we propose an off-line proxy task of cube localization to select DR parameters for texture randomization, lighting randomization, variations of object colors and camera parameters. Notably, we demonstrate that DR parameters have similar impact on our off-line proxy task and on-line policies. We, hence, use off-line optimized DR parameters to train visuomotor policies in simulation and directly apply such policies to a real robot. Our approach achieves 93% success rate on average when tested on a diverse set of challenging manipulation tasks. Moreover, we evaluate the robustness of policies to visual variations in real scenes and show that our simulator-trained policies outperform policies learned using real but limited data. Code, simulation environment, real robot datasets and trained models are available at https://www.di.ens.fr/willow/research/robust_s2r/. ",
    "url": "https://arxiv.org/abs/2307.15320",
    "authors": [
      "Ricardo Garcia",
      "Robin Strudel",
      "Shizhe Chen",
      "Etienne Arlaud",
      "Ivan Laptev",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15331",
    "title": "Tutorials on Stance Detection using Pre-trained Language Models:  Fine-tuning BERT and Prompting Large Language Models",
    "abstract": "This paper presents two self-contained tutorials on stance detection in Twitter data using BERT fine-tuning and prompting large language models (LLMs). The first tutorial explains BERT architecture and tokenization, guiding users through training, tuning, and evaluating standard and domain-specific BERT models with HuggingFace transformers. The second focuses on constructing prompts and few-shot examples to elicit stances from ChatGPT and open-source FLAN-T5 without fine-tuning. Various prompting strategies are implemented and evaluated using confusion matrices and macro F1 scores. The tutorials provide code, visualizations, and insights revealing the strengths of few-shot ChatGPT and FLAN-T5 which outperform fine-tuned BERTs. By covering both model fine-tuning and prompting-based techniques in an accessible, hands-on manner, these tutorials enable learners to gain applied experience with cutting-edge methods for stance detection. ",
    "url": "https://arxiv.org/abs/2307.15331",
    "authors": [
      "Yun-Shiuan Chuang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.15362",
    "title": "Prompt Guided Transformer for Multi-Task Dense Prediction",
    "abstract": "Task-conditional architecture offers advantage in parameter efficiency but falls short in performance compared to state-of-the-art multi-decoder methods. How to trade off performance and model parameters is an important and difficult problem. In this paper, we introduce a simple and lightweight task-conditional model called Prompt Guided Transformer (PGT) to optimize this challenge. Our approach designs a Prompt-conditioned Transformer block, which incorporates task-specific prompts in the self-attention mechanism to achieve global dependency modeling and parameter-efficient feature adaptation across multiple tasks. This block is integrated into both the shared encoder and decoder, enhancing the capture of intra- and inter-task features. Moreover, we design a lightweight decoder to further reduce parameter usage, which accounts for only 2.7% of the total model parameters. Extensive experiments on two multi-task dense prediction benchmarks, PASCAL-Context and NYUD-v2, demonstrate that our approach achieves state-of-the-art results among task-conditional methods while using fewer parameters, and maintains a significant balance between performance and parameter size. ",
    "url": "https://arxiv.org/abs/2307.15362",
    "authors": [
      "Yuxiang Lu",
      "Shalayiding Sirejiding",
      "Yue Ding",
      "Chunlin Wang",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.15370",
    "title": "Private-Library-Oriented Code Generation with Large Language Models",
    "abstract": "Large language models (LLMs), such as Codex and GPT-4, have recently showcased their remarkable code generation abilities, facilitating a significant boost in coding efficiency. This paper will delve into utilizing LLMs for code generation in private libraries, as they are widely employed in everyday programming. Despite their remarkable capabilities, generating such private APIs poses a formidable conundrum for LLMs, as they inherently lack exposure to these private libraries during pre-training. To address this challenge, we propose a novel framework that emulates the process of programmers writing private code. This framework comprises two modules: APIFinder first retrieves potentially useful APIs from API documentation; and APICoder then leverages these retrieved APIs to generate private code. Specifically, APIFinder employs vector retrieval techniques and allows user involvement in the retrieval process. For APICoder, it can directly utilize off-the-shelf code generation models. To further cultivate explicit proficiency in invoking APIs from prompts, we continuously pre-train a reinforced version of APICoder, named CodeGenAPI. Our goal is to train the above two modules on vast public libraries, enabling generalization to private ones. Meanwhile, we create four private library benchmarks, including TorchDataEval, TorchDataComplexEval, MonkeyEval, and BeatNumEval, and meticulously handcraft test cases for each benchmark to support comprehensive evaluations. Numerous experiments on the four benchmarks consistently affirm the effectiveness of our approach. Furthermore, deeper analysis is also conducted to glean additional insights. ",
    "url": "https://arxiv.org/abs/2307.15370",
    "authors": [
      "Daoguang Zan",
      "Bei Chen",
      "Yongshun Gong",
      "Junzhi Cao",
      "Fengji Zhang",
      "Bingchao Wu",
      "Bei Guan",
      "Yilong Yin",
      "Yongji Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2307.15374",
    "title": "Leveraging Optical Communication Fiber and AI for Distributed Water Pipe  Leak Detection",
    "abstract": "Detecting leaks in water networks is a costly challenge. This article introduces a practical solution: the integration of optical network with water networks for efficient leak detection. Our approach uses a fiber-optic cable to measure vibrations, enabling accurate leak identification and localization by an intelligent algorithm. We also propose a method to access leak severity for prioritized repairs. Our solution detects even small leaks with flow rates as low as 0.027 L/s. It offers a cost-effective way to improve leak detection, enhance water management, and increase operational efficiency. ",
    "url": "https://arxiv.org/abs/2307.15374",
    "authors": [
      "Huan Wu",
      "Huan-Feng Duan",
      "Wallace W. L. Lai",
      "Kun Zhu",
      "Xin Cheng",
      "Hao Yin",
      "Bin Zhou",
      "Chun-Cheung Lai",
      "Chao Lu",
      "Xiaoli Ding"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.15377",
    "title": "Co-attention Graph Pooling for Efficient Pairwise Graph Interaction  Learning",
    "abstract": "Graph Neural Networks (GNNs) have proven to be effective in processing and learning from graph-structured data. However, previous works mainly focused on understanding single graph inputs while many real-world applications require pair-wise analysis for graph-structured data (e.g., scene graph matching, code searching, and drug-drug interaction prediction). To this end, recent works have shifted their focus to learning the interaction between pairs of graphs. Despite their improved performance, these works were still limited in that the interactions were considered at the node-level, resulting in high computational costs and suboptimal performance. To address this issue, we propose a novel and efficient graph-level approach for extracting interaction representations using co-attention in graph pooling. Our method, Co-Attention Graph Pooling (CAGPool), exhibits competitive performance relative to existing methods in both classification and regression tasks using real-world datasets, while maintaining lower computational complexity. ",
    "url": "https://arxiv.org/abs/2307.15377",
    "authors": [
      "Junhyun Lee",
      "Bumsoo Kim",
      "Minji Jeon",
      "Jaewoo Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.15381",
    "title": "AffineGlue: Joint Matching and Robust Estimation",
    "abstract": "We propose AffineGlue, a method for joint two-view feature matching and robust estimation that reduces the combinatorial complexity of the problem by employing single-point minimal solvers. AffineGlue selects potential matches from one-to-many correspondences to estimate minimal models. Guided matching is then used to find matches consistent with the model, suffering less from the ambiguities of one-to-one matches. Moreover, we derive a new minimal solver for homography estimation, requiring only a single affine correspondence (AC) and a gravity prior. Furthermore, we train a neural network to reject ACs that are unlikely to lead to a good model. AffineGlue is superior to the SOTA on real-world datasets, even when assuming that the gravity direction points downwards. On PhotoTourism, the AUC@10{\\deg} score is improved by 6.6 points compared to the SOTA. On ScanNet, AffineGlue makes SuperPoint and SuperGlue achieve similar accuracy as the detector-free LoFTR. ",
    "url": "https://arxiv.org/abs/2307.15381",
    "authors": [
      "Daniel Barath",
      "Dmytro Mishkin",
      "Luca Cavalli",
      "Paul-Edouard Sarlin",
      "Petr Hruby",
      "Marc Pollefeys"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.15396",
    "title": "Noisy Interpolation Learning with Shallow Univariate ReLU Networks",
    "abstract": "We study the asymptotic overfitting behavior of interpolation with minimum norm ($\\ell_2$ of the weights) two-layer ReLU networks for noisy univariate regression. We show that overfitting is tempered for the $L_1$ loss, and any $L_p$ loss for $p<2$, but catastrophic for $p\\geq 2$. ",
    "url": "https://arxiv.org/abs/2307.15396",
    "authors": [
      "Nirmit Joshi",
      "Gal Vardi",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15413",
    "title": "Improving Social Media Popularity Prediction with Multiple Post  Dependencies",
    "abstract": "Social Media Popularity Prediction has drawn a lot of attention because of its profound impact on many different applications, such as recommendation systems and multimedia advertising. Despite recent efforts to leverage the content of social media posts to improve prediction accuracy, many existing models fail to fully exploit the multiple dependencies between posts, which are important to comprehensively extract content information from posts. To tackle this problem, we propose a novel prediction framework named Dependency-aware Sequence Network (DSN) that exploits both intra- and inter-post dependencies. For intra-post dependency, DSN adopts a multimodal feature extractor with an efficient fine-tuning strategy to obtain task-specific representations from images and textual information of posts. For inter-post dependency, DSN uses a hierarchical information propagation method to learn category representations that could better describe the difference between posts. DSN also exploits recurrent networks with a series of gating layers for more flexible local temporal processing abilities and multi-head attention for long-term dependencies. The experimental results on the Social Media Popularity Dataset demonstrate the superiority of our method compared to existing state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2307.15413",
    "authors": [
      "Zhizhen Zhang",
      "Xiaohui Xie",
      "Mengyu Yang",
      "Ye Tian",
      "Yong Jiang",
      "Yong Cui"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.15428",
    "title": "Implicit neural representation for change detection",
    "abstract": "Detecting changes that occurred in a pair of 3D airborne LiDAR point clouds, acquired at two different times over the same geographical area, is a challenging task because of unmatching spatial supports and acquisition system noise. Most recent attempts to detect changes on point clouds are based on supervised methods, which require large labelled data unavailable in real-world applications. To address these issues, we propose an unsupervised approach that comprises two components: Neural Field (NF) for continuous shape reconstruction and a Gaussian Mixture Model for categorising changes. NF offer a grid-agnostic representation to encode bi-temporal point clouds with unmatched spatial support that can be regularised to increase high-frequency details and reduce noise. The reconstructions at each timestamp are compared at arbitrary spatial scales, leading to a significant increase in detection capabilities. We apply our method to a benchmark dataset of simulated LiDAR point clouds for urban sprawling. The dataset offers different challenging scenarios with different resolutions, input modalities and noise levels, allowing a multi-scenario comparison of our method with the current state-of-the-art. We boast the previous methods on this dataset by a 10% margin in intersection over union metric. In addition, we apply our methods to a real-world scenario to identify illegal excavation (looting) of archaeological sites and confirm that they match findings from field experts. ",
    "url": "https://arxiv.org/abs/2307.15428",
    "authors": [
      "Peter Naylor",
      "Diego Di Carlo",
      "Arianna Traviglia",
      "Makoto Yamada",
      "Marco Fiorucci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.15432",
    "title": "CFN-ESA: A Cross-Modal Fusion Network with Emotion-Shift Awareness for  Dialogue Emotion Recognition",
    "abstract": "Multimodal Emotion Recognition in Conversation (ERC) has garnered growing attention from research communities in various fields. In this paper, we propose a cross-modal fusion network with emotion-shift awareness (CFN-ESA) for ERC. Extant approaches employ each modality equally without distinguishing the amount of emotional information, rendering it hard to adequately extract complementary and associative information from multimodal data. To cope with this problem, in CFN-ESA, textual modalities are treated as the primary source of emotional information, while visual and acoustic modalities are taken as the secondary sources. Besides, most multimodal ERC models ignore emotion-shift information and overfocus on contextual information, leading to the failure of emotion recognition under emotion-shift scenario. We elaborate an emotion-shift module to address this challenge. CFN-ESA mainly consists of the unimodal encoder (RUME), cross-modal encoder (ACME), and emotion-shift module (LESM). RUME is applied to extract conversation-level contextual emotional cues while pulling together the data distributions between modalities; ACME is utilized to perform multimodal interaction centered on textual modality; LESM is used to model emotion shift and capture related information, thereby guide the learning of the main task. Experimental results demonstrate that CFN-ESA can effectively promote performance for ERC and remarkably outperform the state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2307.15432",
    "authors": [
      "Jiang Li",
      "Yingjian Liu",
      "Xiaoping Wang",
      "Zhigang Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.15455",
    "title": "Trie-NLG: Trie Context Augmentation to Improve Personalized Query  Auto-Completion for Short and Unseen Prefixes",
    "abstract": "Query auto-completion (QAC) aims at suggesting plausible completions for a given query prefix. Traditionally, QAC systems have leveraged tries curated from historical query logs to suggest most popular completions. In this context, there are two specific scenarios that are difficult to handle for any QAC system: short prefixes (which are inherently ambiguous) and unseen prefixes. Recently, personalized Natural Language Generation (NLG) models have been proposed to leverage previous session queries as context for addressing these two challenges. However, such NLG models suffer from two drawbacks: (1) some of the previous session queries could be noisy and irrelevant to the user intent for the current prefix, and (2) NLG models cannot directly incorporate historical query popularity. This motivates us to propose a novel NLG model for QAC, Trie-NLG, which jointly leverages popularity signals from trie and personalization signals from previous session queries. We train the Trie-NLG model by augmenting the prefix with rich context comprising of recent session queries and top trie completions. This simple modeling approach overcomes the limitations of trie-based and NLG-based approaches and leads to state-of-the-art performance. We evaluate the Trie-NLG model using two large QAC datasets. On average, our model achieves huge ~57% and ~14% boost in MRR over the popular trie-based lookup and the strong BART-based baseline methods, respectively. We make our code publicly available. ",
    "url": "https://arxiv.org/abs/2307.15455",
    "authors": [
      "Kaushal Kumar Maurya",
      "Maunendra Sankar Desarkar",
      "Manish Gupta",
      "Puneet Agrawal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.15456",
    "title": "Worrisome Properties of Neural Network Controllers and Their Symbolic  Representations",
    "abstract": "We raise concerns about controllers' robustness in simple reinforcement learning benchmark problems. We focus on neural network controllers and their low neuron and symbolic abstractions. A typical controller reaching high mean return values still generates an abundance of persistent low-return solutions, which is a highly undesirable property, easily exploitable by an adversary. We find that the simpler controllers admit more persistent bad solutions. We provide an algorithm for a systematic robustness study and prove existence of persistent solutions and, in some cases, periodic orbits, using a computer-assisted proof methodology. ",
    "url": "https://arxiv.org/abs/2307.15456",
    "authors": [
      "Jacek Cyranka",
      "Kevin E M Church",
      "Jean-Philippe Lessard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.15469",
    "title": "SpaceRIS: LEO Satellite Coverage Maximization in 6G Sub-THz Networks by  MAPPO DRL and Whale Optimization",
    "abstract": "Satellite systems face a significant challenge in effectively utilizing limited communication resources to meet the demands of ground network traffic, characterized by asymmetrical spatial distribution and time-varying characteristics. Moreover, the coverage range and signal transmission distance of low Earth orbit (LEO) satellites are restricted by notable propagation attenuation, molecular absorption, and space losses in sub-terahertz (THz) frequencies. This paper introduces a novel approach to maximize LEO satellite coverage by leveraging reconfigurable intelligent surfaces (RISs) within 6G sub-THz networks. The optimization objectives encompass enhancing the end-to-end data rate, optimizing satellite-remote user equipment (RUE) associations, data packet routing within satellite constellations, RIS phase shift, and ground base station (GBS) transmit power (i.e., active beamforming). The formulated joint optimization problem poses significant challenges owing to its time-varying environment, non-convex characteristics, and NP-hard complexity. To address these challenges, we propose a block coordinate descent (BCD) algorithm that integrates balanced K-means clustering, multi-agent proximal policy optimization (MAPPO) deep reinforcement learning (DRL), and whale optimization (WOA) techniques. The performance of the proposed approach is demonstrated through comprehensive simulation results, exhibiting its superiority over existing baseline methods in the literature. ",
    "url": "https://arxiv.org/abs/2307.15469",
    "authors": [
      "Sheikh Salman Hassan",
      "Yu Min Park",
      "Yan Kyaw Tun",
      "Walid Saad",
      "Zhu Han",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.15478",
    "title": "Local and Global Information in Obstacle Detection on Railway Tracks",
    "abstract": "Reliable obstacle detection on railways could help prevent collisions that result in injuries and potentially damage or derail the train. Unfortunately, generic object detectors do not have enough classes to account for all possible scenarios, and datasets featuring objects on railways are challenging to obtain. We propose utilizing a shallow network to learn railway segmentation from normal railway images. The limited receptive field of the network prevents overconfident predictions and allows the network to focus on the locally very distinct and repetitive patterns of the railway environment. Additionally, we explore the controlled inclusion of global information by learning to hallucinate obstacle-free images. We evaluate our method on a custom dataset featuring railway images with artificially augmented obstacles. Our proposed method outperforms other learning-based baseline methods. ",
    "url": "https://arxiv.org/abs/2307.15478",
    "authors": [
      "Matthias Brucker",
      "Andrei Cramariuc",
      "Cornelius von Einem",
      "Roland Siegwart",
      "Cesar Cadena"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.15480",
    "title": "Non-invasive Diabetes Detection using Gabor Filter: A Comparative  Analysis of Different Cameras",
    "abstract": "This paper compares and explores the performance of both mobile device camera and laptop camera as convenient tool for capturing images for non-invasive detection of Diabetes Mellitus (DM) using facial block texture features. Participants within age bracket 20 to 79 years old were chosen for the dataset. 12mp and 7mp mobile cameras, and a laptop camera were used to take the photo under normal lighting condition. Extracted facial blocks were classified using k-Nearest Neighbors (k-NN) and Support Vector Machine (SVM). 100 images were captured, preprocessed, filtered using Gabor, and iterated. Performance of the system was measured in terms of accuracy, specificity, and sensitivity. Best performance of 96.7% accuracy, 100% sensitivity, and 93% specificity were achieved from 12mp back camera using SVM with 100 images. ",
    "url": "https://arxiv.org/abs/2307.15480",
    "authors": [
      "Christina A. Garcia",
      "Patricia Angela R. Abu",
      "Rosula SJ. Reyes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.15489",
    "title": "Uncertainty Quantification for Scale-Space Blob Detection",
    "abstract": "We consider the problem of blob detection for uncertain images, such as images that have to be inferred from noisy measurements. Extending recent work motivated by astronomical applications, we propose an approach that represents the uncertainty in the position and size of a blob by a region in a three-dimensional scale space. Motivated by classic tube methods such as the taut-string algorithm, these regions are obtained from level sets of the minimizer of a total variation functional within a high-dimensional tube. The resulting non-smooth optimization problem is challenging to solve, and we compare various numerical approaches for its solution and relate them to the literature on constrained total variation denoising. Finally, the proposed methodology is illustrated on numerical experiments for deconvolution and models related to astrophysics, where it is demonstrated that it allows to represent the uncertainty in the detected blobs in a precise and physically interpretable way. ",
    "url": "https://arxiv.org/abs/2307.15489",
    "authors": [
      "Fabian Parzer",
      "Clemens Kirisits",
      "Otmar Scherzer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.15496",
    "title": "From continuous-time formulations to discretization schemes: tensor  trains and robust regression for BSDEs and parabolic PDEs",
    "abstract": "The numerical approximation of partial differential equations (PDEs) poses formidable challenges in high dimensions since classical grid-based methods suffer from the so-called curse of dimensionality. Recent attempts rely on a combination of Monte Carlo methods and variational formulations, using neural networks for function approximation. Extending previous work (Richter et al., 2021), we argue that tensor trains provide an appealing framework for parabolic PDEs: The combination of reformulations in terms of backward stochastic differential equations and regression-type methods holds the promise of leveraging latent low-rank structures, enabling both compression and efficient computation. Emphasizing a continuous-time viewpoint, we develop iterative schemes, which differ in terms of computational efficiency and robustness. We demonstrate both theoretically and numerically that our methods can achieve a favorable trade-off between accuracy and computational efficiency. While previous methods have been either accurate or fast, we have identified a novel numerical strategy that can often combine both of these aspects. ",
    "url": "https://arxiv.org/abs/2307.15496",
    "authors": [
      "Lorenz Richter",
      "Leon Sallandt",
      "Nikolas N\u00fcsken"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.15506",
    "title": "Improving Image Quality of Sparse-view Lung Cancer CT Images with a  Convolutional Neural Network",
    "abstract": "Purpose: To improve the image quality of sparse-view computed tomography (CT) images with a U-Net for lung cancer detection and to determine the best trade-off between number of views, image quality, and diagnostic confidence. Methods: CT images from 41 subjects (34 with lung cancer, seven healthy) were retrospectively selected (01.2016-12.2018) and forward projected onto 2048-view sinograms. Six corresponding sparse-view CT data subsets at varying levels of undersampling were reconstructed from sinograms using filtered backprojection with 16, 32, 64, 128, 256, and 512 views, respectively. A dual-frame U-Net was trained and evaluated for each subsampling level on 8,658 images from 22 diseased subjects. A representative image per scan was selected from 19 subjects (12 diseased, seven healthy) for a single-blinded reader study. The selected slices, for all levels of subsampling, with and without post-processing by the U-Net model, were presented to three readers. Image quality and diagnostic confidence were ranked using pre-defined scales. Subjective nodule segmentation was evaluated utilizing sensitivity (Se) and Dice Similarity Coefficient (DSC) with 95% confidence intervals (CI). Results: The 64-projection sparse-view images resulted in Se = 0.89 and DSC = 0.81 [0.75,0.86] while their counterparts, post-processed with the U-Net, had improved metrics (Se = 0.94, DSC = 0.85 [0.82,0.87]). Fewer views lead to insufficient quality for diagnostic purposes. For increased views, no substantial discrepancies were noted between the sparse-view and post-processed images. Conclusion: Projection views can be reduced from 2048 to 64 while maintaining image quality and the confidence of the radiologists on a satisfactory level. ",
    "url": "https://arxiv.org/abs/2307.15506",
    "authors": [
      "Annika Ries",
      "Tina Dorosti",
      "Johannes Thalhammer",
      "Daniel Sasse",
      "Andreas Sauter",
      "Felix Meurer",
      "Ashley Benne",
      "Franz Pfeiffer",
      "Daniela Pfeiffer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2307.15514",
    "title": "Revisiting Fully Convolutional Geometric Features for Object 6D Pose  Estimation",
    "abstract": "Recent works on 6D object pose estimation focus on learning keypoint correspondences between images and object models, and then determine the object pose through RANSAC-based algorithms or by directly regressing the pose with end-to-end optimisations. We argue that learning point-level discriminative features is overlooked in the literature. To this end, we revisit Fully Convolutional Geometric Features (FCGF) and tailor it for object 6D pose estimation to achieve state-of-the-art performance. FCGF employs sparse convolutions and learns point-level features using a fully-convolutional network by optimising a hardest contrastive loss. We can outperform recent competitors on popular benchmarks by adopting key modifications to the loss and to the input data representations, by carefully tuning the training strategies, and by employing data augmentations suitable for the underlying problem. We carry out a thorough ablation to study the contribution of each modification. ",
    "url": "https://arxiv.org/abs/2307.15514",
    "authors": [
      "Jaime Corsetti",
      "Davide Boscaini",
      "Fabio Poiesi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.15539",
    "title": "Backdoor Defense with Non-Adversarial Backdoor",
    "abstract": "Deep neural networks (DNNs) are vulnerable to backdoor attack, which does not affect the network's performance on clean data but would manipulate the network behavior once a trigger pattern is added. Existing defense methods have greatly reduced attack success rate, but their prediction accuracy on clean data still lags behind a clean model by a large margin. Inspired by the stealthiness and effectiveness of backdoor attack, we propose a simple but highly effective defense framework which injects non-adversarial backdoors targeting poisoned samples. Following the general steps in backdoor attack, we detect a small set of suspected samples and then apply a poisoning strategy to them. The non-adversarial backdoor, once triggered, suppresses the attacker's backdoor on poisoned data, but has limited influence on clean data. The defense can be carried out during data preprocessing, without any modification to the standard end-to-end training pipeline. We conduct extensive experiments on multiple benchmarks with different architectures and representative attacks. Results demonstrate that our method achieves state-of-the-art defense effectiveness with by far the lowest performance drop on clean data. Considering the surprising defense ability displayed by our framework, we call for more attention to utilizing backdoor for backdoor defense. Code is available at https://github.com/damianliumin/non-adversarial_backdoor. ",
    "url": "https://arxiv.org/abs/2307.15539",
    "authors": [
      "Min Liu",
      "Alberto Sangiovanni-Vincentelli",
      "Xiangyu Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.15546",
    "title": "On the Trade-off Between Efficiency and Precision of Neural Abstraction",
    "abstract": "Neural abstractions have been recently introduced as formal approximations of complex, nonlinear dynamical models. They comprise a neural ODE and a certified upper bound on the error between the abstract neural network and the concrete dynamical model. So far neural abstractions have exclusively been obtained as neural networks consisting entirely of $ReLU$ activation functions, resulting in neural ODE models that have piecewise affine dynamics, and which can be equivalently interpreted as linear hybrid automata. In this work, we observe that the utility of an abstraction depends on its use: some scenarios might require coarse abstractions that are easier to analyse, whereas others might require more complex, refined abstractions. We therefore consider neural abstractions of alternative shapes, namely either piecewise constant or nonlinear non-polynomial (specifically, obtained via sigmoidal activations). We employ formal inductive synthesis procedures to generate neural abstractions that result in dynamical models with these semantics. Empirically, we demonstrate the trade-off that these different neural abstraction templates have vis-a-vis their precision and synthesis time, as well as the time required for their safety verification (done via reachability computation). We improve existing synthesis techniques to enable abstraction of higher-dimensional models, and additionally discuss the abstraction of complex neural ODEs to improve the efficiency of reachability analysis for these models. ",
    "url": "https://arxiv.org/abs/2307.15546",
    "authors": [
      "Alec Edwards",
      "Mirco Giacobbe",
      "Alessandro Abate"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.15555",
    "title": "All-for-One and One-For-All: Deep learning-based feature fusion for  Synthetic Speech Detection",
    "abstract": "Recent advances in deep learning and computer vision have made the synthesis and counterfeiting of multimedia content more accessible than ever, leading to possible threats and dangers from malicious users. In the audio field, we are witnessing the growth of speech deepfake generation techniques, which solicit the development of synthetic speech detection algorithms to counter possible mischievous uses such as frauds or identity thefts. In this paper, we consider three different feature sets proposed in the literature for the synthetic speech detection task and present a model that fuses them, achieving overall better performances with respect to the state-of-the-art solutions. The system was tested on different scenarios and datasets to prove its robustness to anti-forensic attacks and its generalization capabilities. ",
    "url": "https://arxiv.org/abs/2307.15555",
    "authors": [
      "Daniele Mari",
      "Davide Salvi",
      "Paolo Bestagini",
      "Simone Milani"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.15557",
    "title": "Dynamic algorithms for k-center on graphs",
    "abstract": "In this paper we give the first efficient algorithms for the $k$-center problem on dynamic graphs undergoing edge updates. In this problem, the goal is to partition the input into $k$ sets by choosing $k$ centers such that the maximum distance from any data point to the closest center is minimized. It is known that it is NP-hard to get a better than $2$ approximation for this problem. While in many applications the input may naturally be modeled as a graph, all prior works on $k$-center problem in dynamic settings are on metrics. In this paper, we give a deterministic decremental $(2+\\epsilon)$-approximation algorithm and a randomized incremental $(4+\\epsilon)$-approximation algorithm, both with amortized update time $kn^{o(1)}$ for weighted graphs. Moreover, we show a reduction that leads to a fully dynamic $(2+\\epsilon)$-approximation algorithm for the $k$-center problem, with worst-case update time that is within a factor $k$ of the state-of-the-art upper bound for maintaining $(1+\\epsilon)$-approximate single-source distances in graphs. Matching this bound is a natural goalpost because the approximate distances of each vertex to its center can be used to maintain a $(2+\\epsilon)$-approximation of the graph diameter and the fastest known algorithms for such a diameter approximation also rely on maintaining approximate single-source distances. ",
    "url": "https://arxiv.org/abs/2307.15557",
    "authors": [
      "Emilio Cruciani",
      "Sebastian Forster",
      "Gramoz Goranci",
      "Yasamin Nazari",
      "Antonis Skarlatos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15567",
    "title": "Panoptic Scene Graph Generation with Semantics-prototype Learning",
    "abstract": "Panoptic Scene Graph Generation (PSG) parses objects and predicts their relationships (predicate) to connect human language and visual scenes. However, different language preferences of annotators and semantic overlaps between predicates lead to biased predicate annotations in the dataset, i.e. different predicates for same object pairs. Biased predicate annotations make PSG models struggle in constructing a clear decision plane among predicates, which greatly hinders the real application of PSG models. To address the intrinsic bias above, we propose a novel framework named ADTrans to adaptively transfer biased predicate annotations to informative and unified ones. To promise consistency and accuracy during the transfer process, we propose to measure the invariance of representations in each predicate class, and learn unbiased prototypes of predicates with different intensities. Meanwhile, we continuously measure the distribution changes between each presentation and its prototype, and constantly screen potential biased data. Finally, with the unbiased predicate-prototype representation embedding space, biased annotations are easily identified. Experiments show that ADTrans significantly improves the performance of benchmark models, achieving a new state-of-the-art performance, and shows great generalization and effectiveness on multiple datasets. ",
    "url": "https://arxiv.org/abs/2307.15567",
    "authors": [
      "Li Li",
      "Wei Ji",
      "Yiming Wu",
      "Mengze Li",
      "You Qin",
      "Lina Wei",
      "Roger Zimmermann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.15593",
    "title": "Robust Distortion-free Watermarks for Language Models",
    "abstract": "We propose a methodology for planting watermarks in text from an autoregressive language model that are robust to perturbations without changing the distribution over text up to a certain maximum generation budget. We generate watermarked text by mapping a sequence of random numbers -- which we compute using a randomized watermark key -- to a sample from the language model. To detect watermarked text, any party who knows the key can align the text to the random number sequence. We instantiate our watermark methodology with two sampling schemes: inverse transform sampling and exponential minimum sampling. We apply these watermarks to three language models -- OPT-1.3B, LLaMA-7B and Alpaca-7B -- to experimentally validate their statistical power and robustness to various paraphrasing attacks. Notably, for both the OPT-1.3B and LLaMA-7B models, we find we can reliably detect watermarked text ($p \\leq 0.01$) from $35$ tokens even after corrupting between $40$-$50$\\% of the tokens via random edits (i.e., substitutions, insertions or deletions). For the Alpaca-7B model, we conduct a case study on the feasibility of watermarking responses to typical user instructions. Due to the lower entropy of the responses, detection is more difficult: around $25\\%$ of the responses -- whose median length is around $100$ tokens -- are detectable with $p \\leq 0.01$, and the watermark is also less robust to certain automated paraphrasing attacks we implement. ",
    "url": "https://arxiv.org/abs/2307.15593",
    "authors": [
      "Rohith Kuditipudi",
      "John Thickstun",
      "Tatsunori Hashimoto",
      "Percy Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.15604",
    "title": "Integrated Digital Reconstruction of Welded Components: Supporting  Improved Fatigue Life Prediction",
    "abstract": "In the design of offshore jacket foundations, fatigue life is crucial. Post-weld treatment has been proposed to enhance the fatigue performance of welded joints, where particularly high-frequency mechanical impact (HFMI) treatment has been shown to improve fatigue performance significantly. Automated HFMI treatment has improved quality assurance and can lead to cost-effective design when combined with accurate fatigue life prediction. However, the finite element method (FEM), commonly used for predicting fatigue life in complex or multi-axial joints, relies on a basic CAD depiction of the weld, failing to consider the actual weld geometry and defects. Including the actual weld geometry in the FE model improves fatigue life prediction and possible crack location prediction but requires a digital reconstruction of the weld. Current digital reconstruction methods are time-consuming or require specialised scanning equipment and potential component relocation. The proposed framework instead uses an industrial manipulator combined with a line scanner to integrate digital reconstruction as part of the automated HFMI treatment setup. This approach applies standard image processing, simple filtering techniques, and non-linear optimisation for aligning and merging overlapping scans. A screened Poisson surface reconstruction finalises the 3D model to create a meshed surface. The outcome is a generic, cost-effective, flexible, and rapid method that enables generic digital reconstruction of welded parts, aiding in component design, overall quality assurance, and documentation of the HFMI treatment. ",
    "url": "https://arxiv.org/abs/2307.15604",
    "authors": [
      "Anders Faarb\u00e6k Mikkelstrup",
      "Morten Kristiansen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.15621",
    "title": "Shrink-Perturb Improves Architecture Mixing during Population Based  Training for Neural Architecture Search",
    "abstract": "In this work, we show that simultaneously training and mixing neural networks is a promising way to conduct Neural Architecture Search (NAS). For hyperparameter optimization, reusing the partially trained weights allows for efficient search, as was previously demonstrated by the Population Based Training (PBT) algorithm. We propose PBT-NAS, an adaptation of PBT to NAS where architectures are improved during training by replacing poorly-performing networks in a population with the result of mixing well-performing ones and inheriting the weights using the shrink-perturb technique. After PBT-NAS terminates, the created networks can be directly used without retraining. PBT-NAS is highly parallelizable and effective: on challenging tasks (image generation and reinforcement learning) PBT-NAS achieves superior performance compared to baselines (random search and mutation-based PBT). ",
    "url": "https://arxiv.org/abs/2307.15621",
    "authors": [
      "Alexander Chebykin",
      "Arkadiy Dushatskiy",
      "Tanja Alderliesten",
      "Peter A. N. Bosman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15647",
    "title": "Multi-layer Aggregation as a key to feature-based OOD detection",
    "abstract": "Deep Learning models are easily disturbed by variations in the input images that were not observed during the training stage, resulting in unpredictable predictions. Detecting such Out-of-Distribution (OOD) images is particularly crucial in the context of medical image analysis, where the range of possible abnormalities is extremely wide. Recently, a new category of methods has emerged, based on the analysis of the intermediate features of a trained model. These methods can be divided into 2 groups: single-layer methods that consider the feature map obtained at a fixed, carefully chosen layer, and multi-layer methods that consider the ensemble of the feature maps generated by the model. While promising, a proper comparison of these algorithms is still lacking. In this work, we compared various feature-based OOD detection methods on a large spectra of OOD (20 types), representing approximately 7800 3D MRIs. Our experiments shed the light on two phenomenons. First, multi-layer methods consistently outperform single-layer approaches, which tend to have inconsistent behaviour depending on the type of anomaly. Second, the OOD detection performance highly depends on the architecture of the underlying neural network. ",
    "url": "https://arxiv.org/abs/2307.15647",
    "authors": [
      "Benjamin Lambert",
      "Florence Forbes",
      "Senan Doyle",
      "Michel Dojat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.15662",
    "title": "Robust data-driven learning and control of nonlinear systems. A Sontag's  formula approach",
    "abstract": "An interlaced method to learn and control nonlinear system dynamics from a set of demonstrations is proposed, under a constrained optimization framework for the unsupervised learning process. The nonlinear system is modelled as a mixture of Gaussians and the Sontag's formula together with its associated Control Lyapunov Function is proposed for learning and control. Lyapunov stability and robustness in noisy data environments are guaranteed, as a result of the inclusion of control in the learning-optimization problem. The performances are validated through a well-known dataset of demonstrations with handwriting complex trajectories, succeeding in all of them and outperforming previous methods under bounded disturbances, possibly coming from inaccuracies, imperfect demonstrations or noisy datasets. As a result, the proposed interlaced solution yields a good performance trade-off between reproductions and robustness. The proposed method can be used to program nonlinear trajectories in robotic systems through human demonstrations. ",
    "url": "https://arxiv.org/abs/2307.15662",
    "authors": [
      "Yeyson A. Becerra-Mora",
      "Jos\u00e9 \u00c1ngel Acosta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2307.15672",
    "title": "Bayesian Time-Series Classifier for Decoding Simple Visual Stimuli from  Intracranial Neural Activity",
    "abstract": "Understanding how external stimuli are encoded in distributed neural activity is of significant interest in clinical and basic neuroscience. To address this need, it is essential to develop analytical tools capable of handling limited data and the intrinsic stochasticity present in neural data. In this study, we propose a straightforward Bayesian time series classifier (BTsC) model that tackles these challenges whilst maintaining a high level of interpretability. We demonstrate the classification capabilities of this approach by utilizing neural data to decode colors in a visual task. The model exhibits consistent and reliable average performance of 75.55% on 4 patients' dataset, improving upon state-of-the-art machine learning techniques by about 3.0 percent. In addition to its high classification accuracy, the proposed BTsC model provides interpretable results, making the technique a valuable tool to study neural activity in various tasks and categories. The proposed solution can be applied to neural data recorded in various tasks, where there is a need for interpretable results and accurate classification accuracy. ",
    "url": "https://arxiv.org/abs/2307.15672",
    "authors": [
      "Navid Ziaei",
      "Reza Saadatifard",
      "Ali Yousefi",
      "Behzad Nazari",
      "Sydney S. Cash",
      "Angelique C. Paulk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2307.15677",
    "title": "Adversarial training for tabular data with attack propagation",
    "abstract": "Adversarial attacks are a major concern in security-centered applications, where malicious actors continuously try to mislead Machine Learning (ML) models into wrongly classifying fraudulent activity as legitimate, whereas system maintainers try to stop them. Adversarially training ML models that are robust against such attacks can prevent business losses and reduce the work load of system maintainers. In such applications data is often tabular and the space available for attackers to manipulate undergoes complex feature engineering transformations, to provide useful signals for model training, to a space attackers cannot access. Thus, we propose a new form of adversarial training where attacks are propagated between the two spaces in the training loop. We then test this method empirically on a real world dataset in the domain of credit card fraud detection. We show that our method can prevent about 30% performance drops under moderate attacks and is essential under very aggressive attacks, with a trade-off loss in performance under no attacks smaller than 7%. ",
    "url": "https://arxiv.org/abs/2307.15677",
    "authors": [
      "Tiago Leon Melo",
      "Jo\u00e3o Bravo",
      "Marco O. P. Sampaio",
      "Paolo Romano",
      "Hugo Ferreira",
      "Jo\u00e3o Tiago Ascens\u00e3o",
      "Pedro Bizarro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.15678",
    "title": "Case Studies of Causal Discovery from IT Monitoring Time Series",
    "abstract": "Information technology (IT) systems are vital for modern businesses, handling data storage, communication, and process automation. Monitoring these systems is crucial for their proper functioning and efficiency, as it allows collecting extensive observational time series data for analysis. The interest in causal discovery is growing in IT monitoring systems as knowing causal relations between different components of the IT system helps in reducing downtime, enhancing system performance and identifying root causes of anomalies and incidents. It also allows proactive prediction of future issues through historical data analysis. Despite its potential benefits, applying causal discovery algorithms on IT monitoring data poses challenges, due to the complexity of the data. For instance, IT monitoring data often contains misaligned time series, sleeping time series, timestamp errors and missing values. This paper presents case studies on applying causal discovery algorithms to different IT monitoring datasets, highlighting benefits and ongoing challenges. ",
    "url": "https://arxiv.org/abs/2307.15678",
    "authors": [
      "Ali A\u00eft-Bachir",
      "Charles K. Assaad",
      "Christophe de Bignicourt",
      "Emilie Devijver",
      "Simon Ferreira",
      "Eric Gaussier",
      "Hosein Mohanna",
      "Lei Zan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2307.15679",
    "title": "Dynamic Analysis and an Eigen Initializer for Recurrent Neural Networks",
    "abstract": "In recurrent neural networks, learning long-term dependency is the main difficulty due to the vanishing and exploding gradient problem. Many researchers are dedicated to solving this issue and they proposed many algorithms. Although these algorithms have achieved great success, understanding how the information decays remains an open problem. In this paper, we study the dynamics of the hidden state in recurrent neural networks. We propose a new perspective to analyze the hidden state space based on an eigen decomposition of the weight matrix. We start the analysis by linear state space model and explain the function of preserving information in activation functions. We provide an explanation for long-term dependency based on the eigen analysis. We also point out the different behavior of eigenvalues for regression tasks and classification tasks. From the observations on well-trained recurrent neural networks, we proposed a new initialization method for recurrent neural networks, which improves consistently performance. It can be applied to vanilla-RNN, LSTM, and GRU. We test on many datasets, such as Tomita Grammars, pixel-by-pixel MNIST datasets, and machine translation datasets (Multi30k). It outperforms the Xavier initializer and kaiming initializer as well as other RNN-only initializers like IRNN and sp-RNN in several tasks. ",
    "url": "https://arxiv.org/abs/2307.15679",
    "authors": [
      "Ran Dou",
      "Jose Principe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15692",
    "title": "PatchMixer: Rethinking network design to boost generalization for 3D  point cloud understanding",
    "abstract": "The recent trend in deep learning methods for 3D point cloud understanding is to propose increasingly sophisticated architectures either to better capture 3D geometries or by introducing possibly undesired inductive biases. Moreover, prior works introducing novel architectures compared their performance on the same domain, devoting less attention to their generalization to other domains. We argue that the ability of a model to transfer the learnt knowledge to different domains is an important feature that should be evaluated to exhaustively assess the quality of a deep network architecture. In this work we propose PatchMixer, a simple yet effective architecture that extends the ideas behind the recent MLP-Mixer paper to 3D point clouds. The novelties of our approach are the processing of local patches instead of the whole shape to promote robustness to partial point clouds, and the aggregation of patch-wise features using an MLP as a simpler alternative to the graph convolutions or the attention mechanisms that are used in prior works. We evaluated our method on the shape classification and part segmentation tasks, achieving superior generalization performance compared to a selection of the most relevant deep architectures. ",
    "url": "https://arxiv.org/abs/2307.15692",
    "authors": [
      "Davide Boscaini",
      "Fabio Poiesi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.15697",
    "title": "SimDETR: Simplifying self-supervised pretraining for DETR",
    "abstract": "DETR-based object detectors have achieved remarkable performance but are sample-inefficient and exhibit slow convergence. Unsupervised pretraining has been found to be helpful to alleviate these impediments, allowing training with large amounts of unlabeled data to improve the detector's performance. However, existing methods have their own limitations, like keeping the detector's backbone frozen in order to avoid performance degradation and utilizing pretraining objectives misaligned with the downstream task. To overcome these limitations, we propose a simple pretraining framework for DETR-based detectors that consists of three simple yet key ingredients: (i) richer, semantics-based initial proposals derived from high-level feature maps, (ii) discriminative training using object pseudo-labels produced via clustering, (iii) self-training to take advantage of the improved object proposals learned by the detector. We report two main findings: (1) Our pretraining outperforms prior DETR pretraining works on both the full and low data regimes by significant margins. (2) We show we can pretrain DETR from scratch (including the backbone) directly on complex image datasets like COCO, paving the path for unsupervised representation learning directly using DETR. ",
    "url": "https://arxiv.org/abs/2307.15697",
    "authors": [
      "Ioannis Maniadis Metaxas",
      "Adrian Bulat",
      "Ioannis Patras",
      "Brais Martinez",
      "Georgios Tzimiropoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.15710",
    "title": "Semi-Supervised Object Detection in the Open World",
    "abstract": "Existing approaches for semi-supervised object detection assume a fixed set of classes present in training and unlabeled datasets, i.e., in-distribution (ID) data. The performance of these techniques significantly degrades when these techniques are deployed in the open-world, due to the fact that the unlabeled and test data may contain objects that were not seen during training, i.e., out-of-distribution (OOD) data. The two key questions that we explore in this paper are: can we detect these OOD samples and if so, can we learn from them? With these considerations in mind, we propose the Open World Semi-supervised Detection framework (OWSSD) that effectively detects OOD data along with a semi-supervised learning pipeline that learns from both ID and OOD data. We introduce an ensemble based OOD detector consisting of lightweight auto-encoder networks trained only on ID data. Through extensive evalulation, we demonstrate that our method performs competitively against state-of-the-art OOD detection algorithms and also significantly boosts the semi-supervised learning performance in open-world scenarios. ",
    "url": "https://arxiv.org/abs/2307.15710",
    "authors": [
      "Garvita Allabadi",
      "Ana Lucic",
      "Peter Pao-Huang",
      "Yu-Xiong Wang",
      "Vikram Adve"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14442",
    "title": "Neural Schr\u00f6dinger Bridge with Sinkhorn Losses: Application to  Data-driven Minimum Effort Control of Colloidal Self-assembly",
    "abstract": "We show that the minimum effort control of colloidal self-assembly can be naturally formulated in the order-parameter space as a generalized Schr\\\"odinger bridge problem -- a class of fixed-horizon stochastic optimal control problems that originated in the works of Erwin Schr\\\"odinger in the early 1930s. In recent years, this class of problems has seen a resurgence of research activities in control and machine learning communities. Different from the existing literature on the theory and computation for such problems, the controlled drift and diffusion coefficients for colloidal self-assembly are typically non-affine in control, and are difficult to obtain from physics-based modeling. We deduce the conditions of optimality for such generalized problems, and show that the resulting system of equations is structurally very different from the existing results in a way that standard computational approaches no longer apply. Thus motivated, we propose a data-driven learning and control framework, named `neural Schr\\\"odinger bridge', to solve such generalized Schr\\\"odinger bridge problems by innovating on recent advances in neural networks. We illustrate the effectiveness of the proposed framework using a numerical case study of colloidal self-assembly. We learn the controlled drift and diffusion coefficients as two neural networks using molecular dynamics simulation data, and then use these two to train a third network with Sinkhorn losses designed for distributional endpoint constraints, specific for this class of control problems. ",
    "url": "https://arxiv.org/abs/2307.14442",
    "authors": [
      "Iman Nodozi",
      "Charlie Yan",
      "Mira Khare",
      "Abhishek Halder",
      "Ali Mesbah"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.15079",
    "title": "Heterogeneous Vulnerability of Zero-Carbon Power Grids under  Climate-Technological Changes",
    "abstract": "The transition to decarbonized energy systems has become a priority at regional, national and global levels as a critical strategy to mitigate carbon emissions and therefore climate change. However, the vulnerabilities of the proposed zero-carbon power grid under climatic and technological changes have not been thoroughly examined. In this study, we focus on modeling the zero-carbon grid using a dataset that captures a broad variety of future climatic-technological scenarios, with New York State (NYS) as a case study. By accurately capturing the topology and operational constraints of the power grid, we identify spatiotemporal heterogeneity in vulnerabilities arising from the interplay of renewable resource availability, high load, and severe transmission line congestion. Our findings reveal a need for 30-65\\% more firm, zero-emission capacity to ensure system reliability. Merely increasing wind and solar capacity is ineffective in improving reliability due to the spatial and temporal variations in vulnerabilities. This underscores the importance of considering spatiotemporal dynamics and operational constraints when making decisions regarding additional investments in renewable resources. ",
    "url": "https://arxiv.org/abs/2307.15079",
    "authors": [
      "M.Vivienne Liu",
      "Vivek Srikrishnan",
      "Kenji Doering",
      "Scott Steinschneider",
      "Elnaz Kabir",
      "C. Lindsay Anderson"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.15101",
    "title": "Detection of Children Abuse by Voice and Audio Classification by  Short-Time Fourier Transform Machine Learning implemented on Nvidia Edge GPU  device",
    "abstract": "The safety of children in children home has become an increasing social concern, and the purpose of this experiment is to use machine learning applied to detect the scenarios of child abuse to increase the safety of children. This experiment uses machine learning to classify and recognize a child's voice and predict whether the current sound made by the child is crying, screaming or laughing. If a child is found to be crying or screaming, an alert is immediately sent to the relevant personnel so that they can perceive what the child may be experiencing in a surveillance blind spot and respond in a timely manner. Together with a hybrid use of video image classification, the accuracy of child abuse detection can be significantly increased. This greatly reduces the likelihood that a child will receive violent abuse in the nursery and allows personnel to stop an imminent or incipient child abuse incident in time. The datasets collected from this experiment is entirely from sounds recorded on site at the children home, including crying, laughing, screaming sound and background noises. These sound files are transformed into spectrograms using Short-Time Fourier Transform, and then these image data are imported into a CNN neural network for classification, and the final trained model can achieve an accuracy of about 92% for sound detection. ",
    "url": "https://arxiv.org/abs/2307.15101",
    "authors": [
      "Jiuqi Yan",
      "Yingxian Chen",
      "W.W.T.Fok"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2307.15243",
    "title": "TROPHY: A Topologically Robust Physics-Informed Tracking Framework for  Tropical Cyclones",
    "abstract": "Tropical cyclones (TCs) are among the most destructive weather systems. Realistically and efficiently detecting and tracking TCs are critical for assessing their impacts and risks. Recently, a multilevel robustness framework has been introduced to study the critical points of time-varying vector fields. The framework quantifies the robustness of critical points across varying neighborhoods. By relating the multilevel robustness with critical point tracking, the framework has demonstrated its potential in cyclone tracking. An advantage is that it identifies cyclonic features using only 2D wind vector fields, which is encouraging as most tracking algorithms require multiple dynamic and thermodynamic variables at different altitudes. A disadvantage is that the framework does not scale well computationally for datasets containing a large number of cyclones. This paper introduces a topologically robust physics-informed tracking framework (TROPHY) for TC tracking. The main idea is to integrate physical knowledge of TC to drastically improve the computational efficiency of multilevel robustness framework for large-scale climate datasets. First, during preprocessing, we propose a physics-informed feature selection strategy to filter 90% of critical points that are short-lived and have low stability, thus preserving good candidates for TC tracking. Second, during in-processing, we impose constraints during the multilevel robustness computation to focus only on physics-informed neighborhoods of TCs. We apply TROPHY to 30 years of 2D wind fields from reanalysis data in ERA5 and generate a number of TC tracks. In comparison with the observed tracks, we demonstrate that TROPHY can capture TC characteristics that are comparable to and sometimes even better than a well-validated TC tracking algorithm that requires multiple dynamic and thermodynamic scalar fields. ",
    "url": "https://arxiv.org/abs/2307.15243",
    "authors": [
      "Lin Yan",
      "Hanqi Guo",
      "Thomas Peterka",
      "Bei Wang",
      "Jiali Wang"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.15251",
    "title": "PCNN: A Lightweight Parallel Conformer Neural Network for Efficient  Monaural Speech Enhancement",
    "abstract": "Convolutional neural networks (CNN) and Transformer have wildly succeeded in multimedia applications. However, more effort needs to be made to harmonize these two architectures effectively to satisfy speech enhancement. This paper aims to unify these two architectures and presents a Parallel Conformer for speech enhancement. In particular, the CNN and the self-attention (SA) in the Transformer are fully exploited for local format patterns and global structure representations. Based on the small receptive field size of CNN and the high computational complexity of SA, we specially designed a multi-branch dilated convolution (MBDC) and a self-channel-time-frequency attention (Self-CTFA) module. MBDC contains three convolutional layers with different dilation rates for the feature from local to non-local processing. Experimental results show that our method performs better than state-of-the-art methods in most evaluation criteria while maintaining the lowest model parameters. ",
    "url": "https://arxiv.org/abs/2307.15251",
    "authors": [
      "Xinmeng Xu",
      "Weiping Tu",
      "Yuhong Yang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2307.15285",
    "title": "Optimal Approximation of Zonoids and Uniform Approximation by Shallow  Neural Networks",
    "abstract": "We study the following two related problems. The first is to determine to what error an arbitrary zonoid in $\\mathbb{R}^{d+1}$ can be approximated in the Hausdorff distance by a sum of $n$ line segments. The second is to determine optimal approximation rates in the uniform norm for shallow ReLU$^k$ neural networks on their variation spaces. The first of these problems has been solved for $d\\neq 2,3$, but when $d=2,3$ a logarithmic gap between the best upper and lower bounds remains. We close this gap, which completes the solution in all dimensions. For the second problem, our techniques significantly improve upon existing approximation rates when $k\\geq 1$, and enable uniform approximation of both the target function and its derivatives. ",
    "url": "https://arxiv.org/abs/2307.15285",
    "authors": [
      "Jonathan W. Siegel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.15373",
    "title": "Conflict-free joint decision by lag and zero-lag synchronization in  laser network",
    "abstract": "With the end of Moore's Law and the increasing demand for computing, photonic accelerators are garnering considerable attention. This is due to the physical characteristics of light, such as high bandwidth and multiplicity, and the various synchronization phenomena that emerge in the realm of laser physics. These factors come into play as computer performance approaches its limits. In this study, we explore the application of a laser network, acting as a photonic accelerator, to the competitive multi-armed bandit problem. In this context, conflict avoidance is key to maximizing environmental rewards. We experimentally demonstrate cooperative decision-making using zero-lag and lag synchronization within a network of four semiconductor lasers. Lag synchronization of chaos realizes effective decision-making and zero-delay synchronization is responsible for the realization of the collision avoidance function. We experimentally verified a low collision rate and high reward in a fundamental 2-player, 2-slot scenario, and showed the scalability of this system. This system architecture opens up new possibilities for intelligent functionalities in laser dynamics. ",
    "url": "https://arxiv.org/abs/2307.15373",
    "authors": [
      "Hisako Ito",
      "Takatomo Mihana",
      "Ryoichi Horisaki",
      "Makoto Naruse"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2307.15573",
    "title": "Three remarks on $\\mathbf{W_2}$ graphs",
    "abstract": "Let $k \\geq 1$. A graph $G$ is $\\mathbf{W_k}$ if for any $k$ pairwise disjoint independent vertex subsets $A_1, \\dots, A_k$ in $G$, there exist $k$ pairwise disjoint maximum independent sets $S_1, \\dots, S_k$ in $G$ such that $A_i \\subseteq S_i$ for $i \\in [k]$. Recognizing $\\mathbf{W_1}$ graphs is co-NP-hard, as shown by Chv\\'atal and Hartnell (1993) and, independently, by Sankaranarayana and Stewart (1992). Extending this result and answering a recent question of Levit and Tankus, we show that recognizing $\\mathbf{W_k}$ graphs is co-NP-hard for $k \\geq 2$. On the positive side, we show that recognizing $\\mathbf{W_k}$ graphs is, for each $k\\geq 2$, FPT parameterized by clique-width and by tree-width. Finally, we construct graphs $G$ that are not $\\mathbf{W_2}$ such that, for every vertex $v$ in $G$ and every maximal independent set $S$ in $G - N[v]$, the largest independent set in $N(v) \\setminus S$ consists of a single vertex, thereby refuting a conjecture of Levit and Tankus. ",
    "url": "https://arxiv.org/abs/2307.15573",
    "authors": [
      "Carl Feghali",
      "Malory Marin"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2307.15691",
    "title": "ODTlearn: A Package for Learning Optimal Decision Trees for Prediction  and Prescription",
    "abstract": "ODTLearn is an open-source Python package that provides methods for learning optimal decision trees for high-stakes predictive and prescriptive tasks based on the mixed-integer optimization (MIO) framework proposed in Aghaei et al. (2019) and several of its extensions. The current version of the package provides implementations for learning optimal classification trees, optimal fair classification trees, optimal classification trees robust to distribution shifts, and optimal prescriptive trees from observational data. We have designed the package to be easy to maintain and extend as new optimal decision tree problem classes, reformulation strategies, and solution algorithms are introduced. To this end, the package follows object-oriented design principles and supports both commercial (Gurobi) and open source (COIN-OR branch and cut) solvers. The package documentation and an extensive user guide can be found at https://d3m-research-group.github.io/odtlearn/. Additionally, users can view the package source code and submit feature requests and bug reports by visiting https://github.com/D3M-Research-Group/odtlearn. ",
    "url": "https://arxiv.org/abs/2307.15691",
    "authors": [
      "Patrick Vossler",
      "Sina Aghaei",
      "Nathan Justin",
      "Nathanael Jo",
      "Andr\u00e9s G\u00f3mez",
      "Phebe Vayanos"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.15696",
    "title": "Development of a Boston-area 50-km fiber quantum network testbed",
    "abstract": "Distributing quantum information between remote systems will necessitate the integration of emerging quantum components with existing communication infrastructure. This requires understanding the channel-induced degradations of the transmitted quantum signals, beyond the typical characterization methods for classical communication systems. Here we report on a comprehensive characterization of a Boston-Area Quantum Network (BARQNET) telecom fiber testbed, measuring the time-of-flight, polarization, and phase noise imparted on transmitted signals. We further design and demonstrate a compensation system that is both resilient to these noise sources and compatible with integration of emerging quantum memory components on the deployed link. These results have utility for future work on the BARQNET as well as other quantum network testbeds in development, enabling near-term quantum networking demonstrations and informing what areas of technology development will be most impactful in advancing future system capabilities. ",
    "url": "https://arxiv.org/abs/2307.15696",
    "authors": [
      "Eric Bersin",
      "Matthew Grein",
      "Madison Sutula",
      "Ryan Murphy",
      "Yan Qi Huan",
      "Mark Stevens",
      "Aziza Suleymanzade",
      "Catherine Lee",
      "Ralf Riedinger",
      "David J. Starling",
      "Pieter-Jan Stas",
      "Can M. Knaut",
      "Neil Sinclair",
      "Daniel R. Assumpcao",
      "Yan-Cheng Wei",
      "Erik N. Knall",
      "Bartholomeus Machielse",
      "Denis D. Sukachev",
      "David S. Levonian",
      "Mihir K. Bhaskar",
      "Marko Lon\u010dar",
      "Scott Hamilton",
      "Mikhail Lukin",
      "Dirk Englund",
      "P. Benjamin Dixon"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2307.15712",
    "title": "Quantum-noise-limited optical neural networks operating at a few quanta  per activation",
    "abstract": "Analog physical neural networks, which hold promise for improved energy efficiency and speed compared to digital electronic neural networks, are nevertheless typically operated in a relatively high-power regime so that the signal-to-noise ratio (SNR) is large (>10). What happens if an analog system is instead operated in an ultra-low-power regime, in which the behavior of the system becomes highly stochastic and the noise is no longer a small perturbation on the signal? In this paper, we study this question in the setting of optical neural networks operated in the limit where some layers use only a single photon to cause a neuron activation. Neuron activations in this limit are dominated by quantum noise from the fundamentally probabilistic nature of single-photon detection of weak optical signals. We show that it is possible to train stochastic optical neural networks to perform deterministic image-classification tasks with high accuracy in spite of the extremely high noise (SNR ~ 1) by using a training procedure that directly models the stochastic behavior of photodetection. We experimentally demonstrated MNIST classification with a test accuracy of 98% using an optical neural network with a hidden layer operating in the single-photon regime; the optical energy used to perform the classification corresponds to 0.008 photons per multiply-accumulate (MAC) operation, which is equivalent to 0.003 attojoules of optical energy per MAC. Our experiment used >40x fewer photons per inference than previous state-of-the-art low-optical-energy demonstrations, to achieve the same accuracy of >90%. Our work shows that some extremely stochastic analog systems, including those operating in the limit where quantum noise dominates, can nevertheless be used as layers in neural networks that deterministically perform classification tasks with high accuracy if they are appropriately trained. ",
    "url": "https://arxiv.org/abs/2307.15712",
    "authors": [
      "Shi-Yuan Ma",
      "Tianyu Wang",
      "J\u00e9r\u00e9mie Laydevant",
      "Logan G. Wright",
      "Peter L. McMahon"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2111.13555",
    "title": "Hypergraph Representation via Axis-Aligned Point-Subspace Cover",
    "abstract": " Comments: A preliminary version of this work has appeared in Proc. 16th International Conference and Workshops on Algorithms and Computation (WALCOM'22) ",
    "url": "https://arxiv.org/abs/2111.13555",
    "authors": [
      "Oksana Firman",
      "Joachim Spoerhase"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2112.03906",
    "title": "Cross-modal Manifold Cutmix for Self-supervised Video Representation  Learning",
    "abstract": " Comments: Accepted at MVA 2023 ",
    "url": "https://arxiv.org/abs/2112.03906",
    "authors": [
      "Srijan Das",
      "Michael S. Ryoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01696",
    "title": "Fail-Safe Adversarial Generative Imitation Learning",
    "abstract": " Title: Fail-Safe Adversarial Generative Imitation Learning ",
    "url": "https://arxiv.org/abs/2203.01696",
    "authors": [
      "Philipp Geiger",
      "Christoph-Nikolas Straehle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.05606",
    "title": "Multi-fidelity wavelet neural operator with application to uncertainty  quantification",
    "abstract": " Title: Multi-fidelity wavelet neural operator with application to uncertainty  quantification ",
    "url": "https://arxiv.org/abs/2208.05606",
    "authors": [
      "Akshay Thakur",
      "Tapas Tripura",
      "Souvik Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2209.05193",
    "title": "Robust parallel nonlinear solvers for implicit time discretizations of  the Bidomain equations",
    "abstract": " Title: Robust parallel nonlinear solvers for implicit time discretizations of  the Bidomain equations ",
    "url": "https://arxiv.org/abs/2209.05193",
    "authors": [
      "Nicol\u00e1s A. Barnafi",
      "Ngoc Mai Monica Huynh",
      "Luca F. Pavarino",
      "Simone Scacchi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2209.14272",
    "title": "Towards Multimodal Prediction of Spontaneous Humour: A Novel Dataset and  First Results",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible (Major Revision) ",
    "url": "https://arxiv.org/abs/2209.14272",
    "authors": [
      "Lukas Christ",
      "Shahin Amiriparian",
      "Alexander Kathan",
      "Niklas M\u00fcller",
      "Andreas K\u00f6nig",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.05304",
    "title": "Learning Provably Stabilizing Neural Controllers for Discrete-Time  Stochastic Systems",
    "abstract": " Comments: Accepted at ATVA 2023. Follow-up work of arXiv:2112.09495 ",
    "url": "https://arxiv.org/abs/2210.05304",
    "authors": [
      "Matin Ansaripour",
      "Krishnendu Chatterjee",
      "Thomas A. Henzinger",
      "Mathias Lechner",
      "\u0110or\u0111e \u017dikeli\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.14710",
    "title": "3DPPE: 3D Point Positional Encoding for Multi-Camera 3D Object Detection  Transformers",
    "abstract": " Comments: 10 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2211.14710",
    "authors": [
      "Changyong Shu",
      "JIajun Deng",
      "Fisher Yu",
      "Yifan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16335",
    "title": "X-ICP: Localizability-Aware LiDAR Registration for Robust Localization  in Extreme Environments",
    "abstract": " Comments: 20 Pages, 20 Figures Submitted to IEEE Transactions On Robotics. Supplementary Video: this https URL Project Website: this https URL ",
    "url": "https://arxiv.org/abs/2211.16335",
    "authors": [
      "Turcan Tuna",
      "Julian Nubert",
      "Yoshua Nava",
      "Shehryar Khattak",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2212.14197",
    "title": "Self-Supervised Pre-training for 3D Point Clouds via View-Specific  Point-to-Image Translation",
    "abstract": " Title: Self-Supervised Pre-training for 3D Point Clouds via View-Specific  Point-to-Image Translation ",
    "url": "https://arxiv.org/abs/2212.14197",
    "authors": [
      "Qijian Zhang",
      "Junhui Hou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12717",
    "title": "Automatic Intersection Management in Mixed Traffic Using Reinforcement  Learning and Graph Neural Networks",
    "abstract": " Comments: 8 pages, 7 figures, 34th IEEE Intelligent Vehicles Symposium (IV), updated to accepted version ",
    "url": "https://arxiv.org/abs/2301.12717",
    "authors": [
      "Marvin Klimke",
      "Benjamin V\u00f6lz",
      "Michael Buchholz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.08231",
    "title": "3M3D: Multi-view, Multi-path, Multi-representation for 3D Object  Detection",
    "abstract": " Title: 3M3D: Multi-view, Multi-path, Multi-representation for 3D Object  Detection ",
    "url": "https://arxiv.org/abs/2302.08231",
    "authors": [
      "Jongwoo Park",
      "Apoorv Singh",
      "Varun Bankiti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.09394",
    "title": "Deep Neural Networks based Meta-Learning for Network Intrusion Detection",
    "abstract": " Comments: Pages: 15, Figures: 10 and Tables: 9 ",
    "url": "https://arxiv.org/abs/2302.09394",
    "authors": [
      "Anabia Sohail",
      "Bibi Ayisha",
      "Irfan Hameed",
      "Muhammad Mohsin Zafar",
      "Hani Alquhayz",
      "Asifullah Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07148",
    "title": "The Topology of Causality",
    "abstract": " Comments: Originally Part 2 of arXiv:2206.08911v2, now extended and published as a stand-alone paper. Introduction shares some material with Part 1 of the trilogy, \"The Combinatorics of Causality\" ",
    "url": "https://arxiv.org/abs/2303.07148",
    "authors": [
      "Stefano Gogioso",
      "Nicola Pinzani"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ]
  },
  {
    "id": "arXiv:2303.07189",
    "title": "Optimizing Convolutional Neural Networks for Chronic Obstructive  Pulmonary Disease Detection in Clinical Computed Tomography Imaging",
    "abstract": " Title: Optimizing Convolutional Neural Networks for Chronic Obstructive  Pulmonary Disease Detection in Clinical Computed Tomography Imaging ",
    "url": "https://arxiv.org/abs/2303.07189",
    "authors": [
      "Tina Dorosti",
      "Manuel Schultheiss",
      "Felix Hofmann",
      "Johannes Thalhammer",
      "Luisa Kirchner",
      "Theresa Urban",
      "Franz Pfeiffer",
      "Florian Schaff",
      "Tobias Lasser",
      "Daniela Pfeiffer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09017",
    "title": "The Geometry of Causality",
    "abstract": " Comments: Originally Part 3 of arXiv:2206.08911v2, now extended and published as a stand-alone paper. Introduction shares some material with Part 1 of the trilogy, \"The Combinatorics of Causality\" [arXiv:2206.08911], and Part 2 of the trilogy, \"The Topology of Causality\" [arXiv:2303.07148] ",
    "url": "https://arxiv.org/abs/2303.09017",
    "authors": [
      "Stefano Gogioso",
      "Nicola Pinzani"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Logic in Computer Science (cs.LO)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ]
  },
  {
    "id": "arXiv:2304.09507",
    "title": "Self-supervised Image Denoising with Downsampled Invariance Loss and  Conditional Blind-Spot Network",
    "abstract": " Comments: Accepted to ICCV 2023 ",
    "url": "https://arxiv.org/abs/2304.09507",
    "authors": [
      "Yeong Il Jang",
      "Keuntek Lee",
      "Gu Yong Park",
      "Seyun Kim",
      "Nam Ik Cho"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.10266",
    "title": "OOD-CV-v2: An extended Benchmark for Robustness to Out-of-Distribution  Shifts of Individual Nuisances in Natural Images",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2111.14341 ",
    "url": "https://arxiv.org/abs/2304.10266",
    "authors": [
      "Bingchen Zhao",
      "Jiahao Wang",
      "Wufei Ma",
      "Artur Jesslen",
      "Siwei Yang",
      "Shaozuo Yu",
      "Oliver Zendel",
      "Christian Theobalt",
      "Alan Yuille",
      "Adam Kortylewski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.10712",
    "title": "Adversarial Infrared Blocks: A Multi-view Black-box Attack to Thermal  Infrared Detectors in Physical World",
    "abstract": " Title: Adversarial Infrared Blocks: A Multi-view Black-box Attack to Thermal  Infrared Detectors in Physical World ",
    "url": "https://arxiv.org/abs/2304.10712",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi",
      "Tingsong Jiang",
      "Wen Yao",
      "Ling Tian",
      "Xiaoqian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.05966",
    "title": "Graph Neural Networks and 3-Dimensional Topology",
    "abstract": " Comments: 12 pages and appendix, 9 figures ",
    "url": "https://arxiv.org/abs/2305.05966",
    "authors": [
      "Pavel Putrov",
      "Song Jin Ri"
    ],
    "subjectives": [
      "Geometric Topology (math.GT)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)"
    ]
  },
  {
    "id": "arXiv:2305.11164",
    "title": "Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository  Mining Study",
    "abstract": " Comments: Accepted at the 2023 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM) ",
    "url": "https://arxiv.org/abs/2305.11164",
    "authors": [
      "Joel Casta\u00f1o",
      "Silverio Mart\u00ednez-Fern\u00e1ndez",
      "Xavier Franch",
      "Justus Bogner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.00607",
    "title": "FACT: Federated Adversarial Cross Training",
    "abstract": " Title: FACT: Federated Adversarial Cross Training ",
    "url": "https://arxiv.org/abs/2306.00607",
    "authors": [
      "Stefan Schrod",
      "Jonas Lippl",
      "Andreas Sch\u00e4fer",
      "Michael Altenbuchinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01874",
    "title": "SACSoN: Scalable Autonomous Control for Social Navigation",
    "abstract": " Comments: 10 pages, 14 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2306.01874",
    "authors": [
      "Noriaki Hirose",
      "Dhruv Shah",
      "Ajay Sridhar",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.05965",
    "title": "Automating Model Comparison in Factor Graphs",
    "abstract": " Title: Automating Model Comparison in Factor Graphs ",
    "url": "https://arxiv.org/abs/2306.05965",
    "authors": [
      "Bart van Erp",
      "Wouter W. L. Nuijten",
      "Thijs van de Laar",
      "Bert de Vries"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.12794",
    "title": "Overview of Robust and Multilingual Automatic Evaluation Metrics\\\\for  Open-Domain Dialogue Systems at DSTC 11 Track 4",
    "abstract": " Title: Overview of Robust and Multilingual Automatic Evaluation Metrics\\\\for  Open-Domain Dialogue Systems at DSTC 11 Track 4 ",
    "url": "https://arxiv.org/abs/2306.12794",
    "authors": [
      "Mario Rodr\u00edguez-Cantelar",
      "Chen Zhang",
      "Chengguang Tang",
      "Ke Shi",
      "Sarik Ghazarian",
      "Jo\u00e3o Sedoc",
      "Luis Fernando D'Haro",
      "Alexander Rudnicky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.01515",
    "title": "LPN: Language-guided Prototypical Network for few-shot classification",
    "abstract": " Comments: results error in table 1, the last line ",
    "url": "https://arxiv.org/abs/2307.01515",
    "authors": [
      "Kaihui Cheng",
      "Chule Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07686",
    "title": "Creating a Dataset for High-Performance Computing Code Translation: A  Bridge Between HPC Fortran and C++",
    "abstract": " Title: Creating a Dataset for High-Performance Computing Code Translation: A  Bridge Between HPC Fortran and C++ ",
    "url": "https://arxiv.org/abs/2307.07686",
    "authors": [
      "Bin Lei",
      "Caiwen Ding",
      "Le Chen",
      "Pei-Hung Lin",
      "Chunhua Liao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08381",
    "title": "2P-BFT-Log: 2-Phase Single-Author Append-Only Log for Adversarial  Environments",
    "abstract": " Comments: Fixed 'two-phase' typo ",
    "url": "https://arxiv.org/abs/2307.08381",
    "authors": [
      "Erick Lavoie"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2307.09763",
    "title": "Towards Building More Robust Models with Frequency Bias",
    "abstract": " Comments: Accepted by ICCV23 ",
    "url": "https://arxiv.org/abs/2307.09763",
    "authors": [
      "Qingwen Bu",
      "Dong Huang",
      "Heming Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.11465",
    "title": "A Deep Learning Approach for Overall Survival Prediction in Lung Cancer  with Missing Values",
    "abstract": " Comments: 20 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2307.11465",
    "authors": [
      "Camillo Maria Caruso",
      "Valerio Guarrasi",
      "Sara Ramella",
      "Paolo Soda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2307.12239",
    "title": "Learning Dynamic Query Combinations for Transformer-based Object  Detection and Segmentation",
    "abstract": " Comments: 12 pages, 4 figures, ICML 2023, code is available at this https URL ",
    "url": "https://arxiv.org/abs/2307.12239",
    "authors": [
      "Yiming Cui",
      "Linjie Yang",
      "Haichao Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12534",
    "title": "Towards Generalizable Deepfake Detection by Primary Region  Regularization",
    "abstract": " Comments: 12 pages. v2 corrected one minor citation error. Code and Dataset: this https URL ",
    "url": "https://arxiv.org/abs/2307.12534",
    "authors": [
      "Harry Cheng",
      "Yangyang Guo",
      "Tianyi Wang",
      "Liqiang Nie",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12717",
    "title": "Dense Transformer based Enhanced Coding Network for Unsupervised Metal  Artifact Reduction",
    "abstract": " Title: Dense Transformer based Enhanced Coding Network for Unsupervised Metal  Artifact Reduction ",
    "url": "https://arxiv.org/abs/2307.12717",
    "authors": [
      "Wangduo Xie",
      "Matthew B.Blaschko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.12721",
    "title": "AMAE: Adaptation of Pre-Trained Masked Autoencoder for Dual-Distribution  Anomaly Detection in Chest X-Rays",
    "abstract": " Comments: To be presented at MICCAI 2023 ",
    "url": "https://arxiv.org/abs/2307.12721",
    "authors": [
      "Behzad Bozorgtabar",
      "Dwarikanath Mahapatra",
      "Jean-Philippe Thiran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.13124",
    "title": "Conformal prediction for frequency-severity modeling",
    "abstract": " Title: Conformal prediction for frequency-severity modeling ",
    "url": "https://arxiv.org/abs/2307.13124",
    "authors": [
      "Helton Graziadei",
      "Paulo C. Marques F.",
      "Eduardo F. L. de Melo",
      "Rodrigo S. Targino"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.13131",
    "title": "Why Don't You Clean Your Glasses? Perception Attacks with Dynamic  Optical Perturbations",
    "abstract": " Comments: 15 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2307.13131",
    "authors": [
      "Yi Han",
      "Matthew Chan",
      "Eric Wengrowski",
      "Zhuohuan Li",
      "Nils Ole Tippenhauer",
      "Mani Srivastava",
      "Saman Zonouz",
      "Luis Garcia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.13494",
    "title": "Duet: efficient and scalable hybriD neUral rElation undersTanding",
    "abstract": " Title: Duet: efficient and scalable hybriD neUral rElation undersTanding ",
    "url": "https://arxiv.org/abs/2307.13494",
    "authors": [
      "Kaixin Zhang",
      "Hongzhi Wang",
      "Yabin Lu",
      "Ziqi Li",
      "Chang Shu",
      "Yu Yan",
      "Donghua Yang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14848",
    "title": "Modeling Interference for the Coexistence of 6G Networks and Passive  Sensing Systems",
    "abstract": " Title: Modeling Interference for the Coexistence of 6G Networks and Passive  Sensing Systems ",
    "url": "https://arxiv.org/abs/2307.14848",
    "authors": [
      "Paolo Testolina",
      "Michele Polese",
      "Josep M. Jornet",
      "Tommaso Melodia",
      "Michele Zorzi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.14909",
    "title": "Targeted Static Analysis for OCaml C Stubs: eliminating gremlins from  the code",
    "abstract": " Comments: submitted to the OCaml 2023 workshop added references about OCaml/Rust interop and XenServer origins ",
    "url": "https://arxiv.org/abs/2307.14909",
    "authors": [
      "Edwin T\u00f6r\u00f6k"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2307.14940",
    "title": "A Self-Adaptive Penalty Method for Integrating Prior Knowledge  Constraints into Neural ODEs",
    "abstract": " Title: A Self-Adaptive Penalty Method for Integrating Prior Knowledge  Constraints into Neural ODEs ",
    "url": "https://arxiv.org/abs/2307.14940",
    "authors": [
      "C. Coelho",
      "M. Fernanda P. Costa",
      "L. L. Ferr\u00e1s"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  }
]