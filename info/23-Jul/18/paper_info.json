[
  {
    "id": "arXiv:2307.07513",
    "title": "An empirical study of using radiology reports and images to improve ICU  mortality prediction",
    "abstract": "Background: The predictive Intensive Care Unit (ICU) scoring system plays an important role in ICU management because it predicts important outcomes, especially mortality. Many scoring systems have been developed and used in the ICU. These scoring systems are primarily based on the structured clinical data in the electronic health record (EHR), which may suffer the loss of important clinical information in the narratives and images. Methods: In this work, we build a deep learning based survival prediction model with multi-modality data to predict ICU mortality. Four sets of features are investigated: (1) physiological measurements of Simplified Acute Physiology Score (SAPS) II, (2) common thorax diseases pre-defined by radiologists, (3) BERT-based text representations, and (4) chest X-ray image features. We use the Medical Information Mart for Intensive Care IV (MIMIC-IV) dataset to evaluate the proposed model. Results: Our model achieves the average C-index of 0.7829 (95% confidence interval, 0.7620-0.8038), which substantially exceeds that of the baseline with SAPS-II features (0.7470 (0.7263-0.7676)). Ablation studies further demonstrate the contributions of pre-defined labels (2.00%), text features (2.44%), and image features (2.82%). ",
    "url": "https://arxiv.org/abs/2307.07513",
    "authors": [
      "Mingquan Lin",
      "Song Wang",
      "Ying Ding",
      "Lihui Zhao",
      "Fei Wang",
      "Yifan Peng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.07516",
    "title": "Voting-based Multimodal Automatic Deception Detection",
    "abstract": "Automatic Deception Detection has been a hot research topic for a long time, using machine learning and deep learning to automatically detect deception, brings new light to this old field. In this paper, we proposed a voting-based method for automatic deception detection from videos using audio, visual and lexical features. Experiments were done on two datasets, the Real-life trial dataset by Michigan University and the Miami University deception detection dataset. Video samples were split into frames of images, audio, and manuscripts. Our Voting-based Multimodal proposed solution consists of three models. The first model is CNN for detecting deception from images, the second model is Support Vector Machine (SVM) on Mel spectrograms for detecting deception from audio and the third model is Word2Vec on Support Vector Machine (SVM) for detecting deception from manuscripts. Our proposed solution outperforms state of the art. Best results achieved on images, audio and text were 97%, 96%, 92% respectively on Real-Life Trial Dataset, and 97%, 82%, 73% on video, audio and text respectively on Miami University Deception Detection. ",
    "url": "https://arxiv.org/abs/2307.07516",
    "authors": [
      "Lana Touma",
      "Mohammad Al Horani",
      "Manar Tailouni",
      "Anas Dahabiah",
      "Khloud Al Jallad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2307.07521",
    "title": "Artistic Strategies to Guide Neural Networks",
    "abstract": "Artificial Intelligence is present in the generation and distribution of culture. How do artists exploit neural networks? What impact do these algorithms have on artistic practice? Through a practice-based research methodology, this paper explores the potentials and limits of current AI technology, more precisely deep neural networks, in the context of image, text, form and translation of semiotic spaces. In a relatively short time, the generation of high-resolution images and 3D objects has been achieved. There are models, like CLIP and text2mesh, that do not need the same kind of media input as the output; we call them translation models. Such a twist contributes toward creativity arousal, which manifests itself in art practice and feeds back to the developers' pipeline. Yet again, we see how artworks act as catalysts for technology development. Those creative scenarios and processes are enabled not solely by AI models, but by the hard work behind implementing these new technologies. AI does not create a 'push-a-button' masterpiece but requires a deep understanding of the technology behind it, and a creative and critical mindset. Thus, AI opens new avenues for inspiration and offers novel tool sets, and yet again the question of authorship is asked. ",
    "url": "https://arxiv.org/abs/2307.07521",
    "authors": [
      "Varvara Guljajeva",
      "Mar Canet Sola",
      "Isaac Joseph Clarke"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2307.07524",
    "title": "Reducing Causality to Functions with Structural Models",
    "abstract": "The precise definition of causality is currently an open problem in philosophy and statistics. We believe causality should be defined as functions (in mathematics) that map causes to effects. We propose a reductive definition of causality based on Structural Functional Model (SFM). Using delta compression and contrastive forward inference, SFM can produce causal utterances like \"X causes Y\" and \"X is the cause of Y\" that match our intuitions. We compile a dataset of causal scenarios and use SFM in all of them. SFM is compatible with but not reducible to probability theory. We also compare SFM with other theories of causation and apply SFM to downstream problems like free will, causal explanation, and mental causation. ",
    "url": "https://arxiv.org/abs/2307.07524",
    "authors": [
      "Tianyi Miao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.07529",
    "title": "Learning Multiple Coordinated Agents under Directed Acyclic Graph  Constraints",
    "abstract": "This paper proposes a novel multi-agent reinforcement learning (MARL) method to learn multiple coordinated agents under directed acyclic graph (DAG) constraints. Unlike existing MARL approaches, our method explicitly exploits the DAG structure between agents to achieve more effective learning performance. Theoretically, we propose a novel surrogate value function based on a MARL model with synthetic rewards (MARLM-SR) and prove that it serves as a lower bound of the optimal value function. Computationally, we propose a practical training algorithm that exploits new notion of leader agent and reward generator and distributor agent to guide the decomposed follower agents to better explore the parameter space in environments with DAG constraints. Empirically, we exploit four DAG environments including a real-world scheduling for one of Intel's high volume packaging and test factory to benchmark our methods and show it outperforms the other non-DAG approaches. ",
    "url": "https://arxiv.org/abs/2307.07529",
    "authors": [
      "Jaeyeon Jang",
      "Diego Klabjan",
      "Han Liu",
      "Nital S. Patel",
      "Xiuqi Li",
      "Balakrishnan Ananthanarayanan",
      "Husam Dauod",
      "Tzung-Han Juang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2307.07568",
    "title": "Variational Prediction",
    "abstract": "Bayesian inference offers benefits over maximum likelihood, but it also comes with computational costs. Computing the posterior is typically intractable, as is marginalizing that posterior to form the posterior predictive distribution. In this paper, we present variational prediction, a technique for directly learning a variational approximation to the posterior predictive distribution using a variational bound. This approach can provide good predictive distributions without test time marginalization costs. We demonstrate Variational Prediction on an illustrative toy example. ",
    "url": "https://arxiv.org/abs/2307.07568",
    "authors": [
      "Alexander A. Alemi",
      "Ben Poole"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.07575",
    "title": "A Quantitative Approach to Predicting Representational Learning and  Performance in Neural Networks",
    "abstract": "A key property of neural networks (both biological and artificial) is how they learn to represent and manipulate input information in order to solve a task. Different types of representations may be suited to different types of tasks, making identifying and understanding learned representations a critical part of understanding and designing useful networks. In this paper, we introduce a new pseudo-kernel based tool for analyzing and predicting learned representations, based only on the initial conditions of the network and the training curriculum. We validate the method on a simple test case, before demonstrating its use on a question about the effects of representational learning on sequential single versus concurrent multitask performance. We show that our method can be used to predict the effects of the scale of weight initialization and training curriculum on representational learning and downstream concurrent multitasking performance. ",
    "url": "https://arxiv.org/abs/2307.07575",
    "authors": [
      "Ryan Pyle",
      "Sebastian Musslick",
      "Jonathan D. Cohen",
      "Ankit B. Patel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2307.07577",
    "title": "Decomposition Based Refinement for the Network Interdiction Problem",
    "abstract": "The shortest path network interdiction (SPNI) problem poses significant computational challenges due to its NP-hardness. Current solutions, primarily based on integer programming methods, are inefficient for large-scale instances. In this paper, we introduce a novel hybrid algorithm that can utilize Ising Processing Units (IPUs) alongside classical solvers. This approach decomposes the problem into manageable sub-problems, which are then offloaded to the slow but high-quality classical solvers or IPU. Results are subsequently recombined to form a global solution. Our method demonstrates comparable quality to existing whole problem solvers while reducing computational time for large-scale instances. Furthermore, our approach is amenable to parallelization, allowing for simultaneous processing of decomposed sub-problems. ",
    "url": "https://arxiv.org/abs/2307.07577",
    "authors": [
      "Krish Matta",
      "Xiaoyuan Liu",
      "Ilya Safro"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2307.07583",
    "title": "On Diameter Approximation in Directed Graphs",
    "abstract": "Computing the diameter of a graph, i.e. the largest distance, is a fundamental problem that is central in fine-grained complexity. In undirected graphs, the Strong Exponential Time Hypothesis (SETH) yields a lower bound on the time vs. approximation trade-off that is quite close to the upper bounds. In \\emph{directed} graphs, however, where only some of the upper bounds apply, much larger gaps remain. Since $d(u,v)$ may not be the same as $d(v,u)$, there are multiple ways to define the problem, the two most natural being the \\emph{(one-way) diameter} ($\\max_{(u,v)} d(u,v)$) and the \\emph{roundtrip diameter} ($\\max_{u,v} d(u,v)+d(v,u)$). In this paper we make progress on the outstanding open question for each of them. -- We design the first algorithm for diameter in sparse directed graphs to achieve $n^{1.5-\\varepsilon}$ time with an approximation factor better than $2$. The new upper bound trade-off makes the directed case appear more similar to the undirected case. Notably, this is the first algorithm for diameter in sparse graphs that benefits from fast matrix multiplication. -- We design new hardness reductions separating roundtrip diameter from directed and undirected diameter. In particular, a $1.5$-approximation in subquadratic time would refute the All-Nodes $k$-Cycle hypothesis, and any $(2-\\varepsilon)$-approximation would imply a breakthrough algorithm for approximate $\\ell_{\\infty}$-Closest-Pair. Notably, these are the first conditional lower bounds for diameter that are not based on SETH. ",
    "url": "https://arxiv.org/abs/2307.07583",
    "authors": [
      "Amir Abboud",
      "Mina Dalirrooyfard",
      "Ray Li",
      "Virginia Vassilevska-Williams"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2307.07597",
    "title": "Power consumption prediction for steel industry",
    "abstract": "The use of steel is essential in many industries, including infrastructure, transportation, and modern architecture. Predicting power consumption in the steel industry is crucial to meet the rising demand for steel and promoting city development. However, predicting energy consumption in the steel industry is challenging due to several factors, such as the type of steel produced, the manufacturing process, and the efficiency of the manufacturing facility. This research aims to contribute by creating a predictive model that estimates power consumption in the steel industry. The unique approach combines linear regression to predict a continuous variable related to power consumption and the KNN clustering method to identify the demanding load type. This study's novelty lies in the development of a model that accurately predicts energy consumption in the steel industry, leading to more sustainable and efficient practices. This research contributes to enabling industries to anticipate and optimize their energy consumption, leading to more sustainable practices and economic development. ",
    "url": "https://arxiv.org/abs/2307.07597",
    "authors": [
      "WT Al-shaibani",
      "Tareq Babaqi",
      "Abdulraqeeb Alsarori"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.07601",
    "title": "Generalized Weighted Type Graphs for Termination of Graph Transformation  Systems",
    "abstract": "We refine a technique by Bruggink et al. that uses weighted type graphs for proving termination of double pushout (DPO) graph transformation systems. We increase the power of the approach for graphs, we generalize the technique to other categories, and we allow for variations of DPO that occur in the literature. ",
    "url": "https://arxiv.org/abs/2307.07601",
    "authors": [
      "J\u00f6rg Endrullis",
      "Roy Overbeek"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2307.07602",
    "title": "Collision Detection for Multi-Robot Motion Planning with Efficient  Quad-Tree Update and Skipping",
    "abstract": "This paper presents a novel and efficient collision checking approach called Updating and Collision Check Skipping Quad-tree (USQ) for multi-robot motion planning. USQ extends the standard quad-tree data structure through a time-efficient update mechanism, which significantly reduces the total number of collision checks and the collision checking time. In addition, it handles transitions at the quad-tree quadrant boundaries based on worst-case trajectories of agents. These extensions make quad-trees suitable for efficient collision checking in multi-robot motion planning of large robot teams. We evaluate the efficiency of USQ in comparison with Regenerating Quad-tree (RQ) from scratch at each timestep and naive pairwise collision checking across a variety of randomized environments. The results indicate that USQ significantly reduces the number of collision checks and the collision checking time compared to other baselines for different numbers of robots and map sizes. In a 50-robot experiment, USQ accurately detected all collisions, outperforming RQ which has longer run-times and/or misses up to 25% of collisions. ",
    "url": "https://arxiv.org/abs/2307.07602",
    "authors": [
      "Abdel Zaro",
      "Ardalan Tajbakhsh",
      "Aaron M. Johnson"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2307.07603",
    "title": "Gastrointestinal Disease Classification through Explainable and  Cost-Sensitive Deep Neural Networks with Supervised Contrastive Learning",
    "abstract": "Gastrointestinal diseases pose significant healthcare chall-enges as they manifest in diverse ways and can lead to potential complications. Ensuring precise and timely classification of these diseases is pivotal in guiding treatment choices and enhancing patient outcomes. This paper introduces a novel approach on classifying gastrointestinal diseases by leveraging cost-sensitive pre-trained deep convolutional neural network (CNN) architectures with supervised contrastive learning. Our approach enables the network to learn representations that capture vital disease-related features, while also considering the relationships of similarity between samples. To tackle the challenges posed by imbalanced datasets and the cost-sensitive nature of misclassification errors in healthcare, we incorporate cost-sensitive learning. By assigning distinct costs to misclassifications based on the disease class, we prioritize accurate classification of critical conditions. Furthermore, we enhance the interpretability of our model by integrating gradient-based techniques from explainable artificial intelligence (AI). This inclusion provides valuable insights into the decision-making process of the network, aiding in understanding the features that contribute to disease classification. To assess the effectiveness of our proposed approach, we perform extensive experiments on a comprehensive gastrointestinal disease dataset, such as the Hyper-Kvasir dataset. Through thorough comparisons with existing works, we demonstrate the strong classification accuracy, robustness and interpretability of our model. We have made the implementation of our proposed approach publicly available at https://github.com/dibya404/Gastrointestinal-Disease-Classification-through-Explainable-and-Cost-Sensitive-DNN-with-SCL ",
    "url": "https://arxiv.org/abs/2307.07603",
    "authors": [
      "Dibya Nath",
      "G. M. Shahariar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07607",
    "title": "SubT-MRS: A Subterranean, Multi-Robot, Multi-Spectral and Multi-Degraded  Dataset for Robust SLAM",
    "abstract": "In recent years, significant progress has been made in the field of simultaneous localization and mapping (SLAM) research. However, current state-of-the-art solutions still struggle with limited accuracy and robustness in real-world applications. One major reason is the lack of datasets that fully capture the conditions faced by robots in the wild. To address this problem, we present SubT-MRS, an extremely challenging real-world dataset designed to push the limits of SLAM and perception algorithms. SubT-MRS is a multi-modal, multi-robot dataset collected mainly from subterranean environments having multi-degraded conditions including structureless corridors, varying lighting conditions, and perceptual obscurants such as smoke and dust. Furthermore, the dataset packages information from a diverse range of time-synchronized sensors, including LiDAR, visual cameras, thermal cameras, and IMUs captured using varied vehicular motions like aerial, legged, and wheeled, to support research in sensor fusion, which is essential for achieving accurate and robust robotic perception in complex environments. To evaluate the accuracy of SLAM systems, we also provide a dense 3D model with sub-centimeter-level accuracy, as well as accurate 6DoF ground truth. Our benchmarking approach includes several state-of-the-art methods to demonstrate the challenges our datasets introduce, particularly in the case of multi-degraded environments. ",
    "url": "https://arxiv.org/abs/2307.07607",
    "authors": [
      "Shibo Zhao",
      "Damanpreet Singh",
      "Haoxiang Sun",
      "Rushan Jiang",
      "YuanJun Gao",
      "Tianhao Wu",
      "Jay Karhade",
      "Chuck Whittaker",
      "Ian Higgins",
      "Jiahe Xu",
      "Yuheng Qiu",
      "Sourojit Saha",
      "Chen Wang",
      "Wenshan Wang",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.07614",
    "title": "Towards Generalizable Detection of Urgency of Discussion Forum Posts",
    "abstract": "Students who take an online course, such as a MOOC, use the course's discussion forum to ask questions or reach out to instructors when encountering an issue. However, reading and responding to students' questions is difficult to scale because of the time needed to consider each message. As a result, critical issues may be left unresolved, and students may lose the motivation to continue in the course. To help address this problem, we build predictive models that automatically determine the urgency of each forum post, so that these posts can be brought to instructors' attention. This paper goes beyond previous work by predicting not just a binary decision cut-off but a post's level of urgency on a 7-point scale. First, we train and cross-validate several models on an original data set of 3,503 posts from MOOCs at University of Pennsylvania. Second, to determine the generalizability of our models, we test their performance on a separate, previously published data set of 29,604 posts from MOOCs at Stanford University. While the previous work on post urgency used only one data set, we evaluated the prediction across different data sets and courses. The best-performing model was a support vector regressor trained on the Universal Sentence Encoder embeddings of the posts, achieving an RMSE of 1.1 on the training set and 1.4 on the test set. Understanding the urgency of forum posts enables instructors to focus their time more effectively and, as a result, better support student learning. ",
    "url": "https://arxiv.org/abs/2307.07614",
    "authors": [
      "Valdemar \u0160v\u00e1bensk\u00fd",
      "Ryan S. Baker",
      "Andr\u00e9s Zambrano",
      "Yishan Zou",
      "Stefan Slater"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.07643",
    "title": "ACF-Net: An Attention-enhanced Co-interactive Fusion Network for  Automated Structural Condition Assessment in Visual Inspection",
    "abstract": "Efficiently monitoring the condition of civil infrastructures necessitates automating the structural condition assessment in visual inspection. This paper proposes an Attention-enhanced Co-interactive Fusion Network (ACF-Net) for automatic structural condition assessment in visual bridge inspection. The ACF-Net can simultaneously parse structural elements and segment surface defects on the elements in inspection images. It integrates two task-specific relearning subnets to extract task-specific features from an overall feature embedding and a co-interactive feature fusion module to capture the spatial correlation and facilitate information sharing between tasks. Experimental results demonstrate that the proposed ACF-Net outperforms the current state-of-the-art approaches, achieving promising performance with 92.11% mIoU for element parsing and 87.16% mIoU for corrosion segmentation on the new benchmark dataset Steel Bridge Condition Inspection Visual (SBCIV) testing set. An ablation study reveals the strengths of ACF-Net, and a case study showcases its capability to automate structural condition assessment. The code will be open-source after acceptance. ",
    "url": "https://arxiv.org/abs/2307.07643",
    "authors": [
      "Chenyu Zhang",
      "Zhaozheng Yin",
      "Ruwen Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07647",
    "title": "Physics Informed Neural Networks with strong and weak residuals for  advection-dominated diffusion problems",
    "abstract": "This paper deals with the following important research questions. Is it possible to solve challenging advection-dominated diffusion problems in one and two dimensions using Physics Informed Neural Networks (PINN) and Variational Physics Informed Neural Networks (VPINN)? How does it compare to the higher-order and continuity Finite Element Method (FEM)? How to define the loss functions for PINN and VPINN so they converge to the correct solutions? How to select points or test functions for training of PINN and VPINN? We focus on the one-dimensional advection-dominated diffusion problem and the two-dimensional Eriksson-Johnson model problem. We show that the standard Galerkin method for FEM cannot solve this problem. We discuss the stabilization of the advection-dominated diffusion problem with the Petrov-Galerkin (PG) formulation and present the FEM solution obtained with the PG method. We employ PINN and VPINN methods, defining several strong and weak loss functions. We compare the training and solutions of PINN and VPINN methods with higher-order FEM methods. ",
    "url": "https://arxiv.org/abs/2307.07647",
    "authors": [
      "Maciej Sikora",
      "Patryk Krukowski",
      "Anna Paszynska",
      "Maciej Paszynski"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.07649",
    "title": "DistTGL: Distributed Memory-Based Temporal Graph Neural Network Training",
    "abstract": "Memory-based Temporal Graph Neural Networks are powerful tools in dynamic graph representation learning and have demonstrated superior performance in many real-world applications. However, their node memory favors smaller batch sizes to capture more dependencies in graph events and needs to be maintained synchronously across all trainers. As a result, existing frameworks suffer from accuracy loss when scaling to multiple GPUs. Evenworse, the tremendous overhead to synchronize the node memory make it impractical to be deployed to distributed GPU clusters. In this work, we propose DistTGL -- an efficient and scalable solution to train memory-based TGNNs on distributed GPU clusters. DistTGL has three improvements over existing solutions: an enhanced TGNN model, a novel training algorithm, and an optimized system. In experiments, DistTGL achieves near-linear convergence speedup, outperforming state-of-the-art single-machine method by 14.5% in accuracy and 10.17x in training throughput. ",
    "url": "https://arxiv.org/abs/2307.07649",
    "authors": [
      "Hongkuan Zhou",
      "Da Zheng",
      "Xiang Song",
      "George Karypis",
      "Viktor Prasanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.07653",
    "title": "RFLA: A Stealthy Reflected Light Adversarial Attack in the Physical  World",
    "abstract": "Physical adversarial attacks against deep neural networks (DNNs) have recently gained increasing attention. The current mainstream physical attacks use printed adversarial patches or camouflage to alter the appearance of the target object. However, these approaches generate conspicuous adversarial patterns that show poor stealthiness. Another physical deployable attack is the optical attack, featuring stealthiness while exhibiting weakly in the daytime with sunlight. In this paper, we propose a novel Reflected Light Attack (RFLA), featuring effective and stealthy in both the digital and physical world, which is implemented by placing the color transparent plastic sheet and a paper cut of a specific shape in front of the mirror to create different colored geometries on the target object. To achieve these goals, we devise a general framework based on the circle to model the reflected light on the target object. Specifically, we optimize a circle (composed of a coordinate and radius) to carry various geometrical shapes determined by the optimized angle. The fill color of the geometry shape and its corresponding transparency are also optimized. We extensively evaluate the effectiveness of RFLA on different datasets and models. Experiment results suggest that the proposed method achieves over 99% success rate on different datasets and models in the digital world. Additionally, we verify the effectiveness of the proposed method in different physical environments by using sunlight or a flashlight. ",
    "url": "https://arxiv.org/abs/2307.07653",
    "authors": [
      "Donghua Wang",
      "Wen Yao",
      "Tingsong Jiang",
      "Chao Li",
      "Xiaoqian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07656",
    "title": "On weighted two-mode network projections",
    "abstract": "The standard and fractional projections are extended from binary two-mode networks to weighted two-mode networks. Some interesting properties of the extended projections are proved. ",
    "url": "https://arxiv.org/abs/2307.07656",
    "authors": [
      "Vladimir Batagelj"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2307.07663",
    "title": "INVE: Interactive Neural Video Editing",
    "abstract": "We present Interactive Neural Video Editing (INVE), a real-time video editing solution, which can assist the video editing process by consistently propagating sparse frame edits to the entire video clip. Our method is inspired by the recent work on Layered Neural Atlas (LNA). LNA, however, suffers from two major drawbacks: (1) the method is too slow for interactive editing, and (2) it offers insufficient support for some editing use cases, including direct frame editing and rigid texture tracking. To address these challenges we leverage and adopt highly efficient network architectures, powered by hash-grids encoding, to substantially improve processing speed. In addition, we learn bi-directional functions between image-atlas and introduce vectorized editing, which collectively enables a much greater variety of edits in both the atlas and the frames directly. Compared to LNA, our INVE reduces the learning and inference time by a factor of 5, and supports various video editing operations that LNA cannot. We showcase the superiority of INVE over LNA in interactive video editing through a comprehensive quantitative and qualitative analysis, highlighting its numerous advantages and improved performance. For video results, please see https://gabriel-huang.github.io/inve/ ",
    "url": "https://arxiv.org/abs/2307.07663",
    "authors": [
      "Jiahui Huang",
      "Leonid Sigal",
      "Kwang Moo Yi",
      "Oliver Wang",
      "Joon-Young Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07666",
    "title": "Efficient Action Robust Reinforcement Learning with Probabilistic Policy  Execution Uncertainty",
    "abstract": "Robust reinforcement learning (RL) aims to find a policy that optimizes the worst-case performance in the face of uncertainties. In this paper, we focus on action robust RL with the probabilistic policy execution uncertainty, in which, instead of always carrying out the action specified by the policy, the agent will take the action specified by the policy with probability $1-\\rho$ and an alternative adversarial action with probability $\\rho$. We establish the existence of an optimal policy on the action robust MDPs with probabilistic policy execution uncertainty and provide the action robust Bellman optimality equation for its solution. Furthermore, we develop Action Robust Reinforcement Learning with Certificates (ARRLC) algorithm that achieves minimax optimal regret and sample complexity. Furthermore, we conduct numerical experiments to validate our approach's robustness, demonstrating that ARRLC outperforms non-robust RL algorithms and converges faster than the robust TD algorithm in the presence of action perturbations. ",
    "url": "https://arxiv.org/abs/2307.07666",
    "authors": [
      "Guanin Liu",
      "Zhihan Zhou",
      "Han Liu",
      "Lifeng Lai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.07670",
    "title": "Efficient Adversarial Attacks on Online Multi-agent Reinforcement  Learning",
    "abstract": "Due to the broad range of applications of multi-agent reinforcement learning (MARL), understanding the effects of adversarial attacks against MARL model is essential for the safe applications of this model. Motivated by this, we investigate the impact of adversarial attacks on MARL. In the considered setup, there is an exogenous attacker who is able to modify the rewards before the agents receive them or manipulate the actions before the environment receives them. The attacker aims to guide each agent into a target policy or maximize the cumulative rewards under some specific reward function chosen by the attacker, while minimizing the amount of manipulation on feedback and action. We first show the limitations of the action poisoning only attacks and the reward poisoning only attacks. We then introduce a mixed attack strategy with both the action poisoning and the reward poisoning. We show that the mixed attack strategy can efficiently attack MARL agents even if the attacker has no prior information about the underlying environment and the agents' algorithms. ",
    "url": "https://arxiv.org/abs/2307.07670",
    "authors": [
      "Guanlin Liu",
      "Lifeng Lai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.07675",
    "title": "On the Robustness of Epoch-Greedy in Multi-Agent Contextual Bandit  Mechanisms",
    "abstract": "Efficient learning in multi-armed bandit mechanisms such as pay-per-click (PPC) auctions typically involves three challenges: 1) inducing truthful bidding behavior (incentives), 2) using personalization in the users (context), and 3) circumventing manipulations in click patterns (corruptions). Each of these challenges has been studied orthogonally in the literature; incentives have been addressed by a line of work on truthful multi-armed bandit mechanisms, context has been extensively tackled by contextual bandit algorithms, while corruptions have been discussed via a recent line of work on bandits with adversarial corruptions. Since these challenges co-exist, it is important to understand the robustness of each of these approaches in addressing the other challenges, provide algorithms that can handle all simultaneously, and highlight inherent limitations in this combination. In this work, we show that the most prominent contextual bandit algorithm, $\\epsilon$-greedy can be extended to handle the challenges introduced by strategic arms in the contextual multi-arm bandit mechanism setting. We further show that $\\epsilon$-greedy is inherently robust to adversarial data corruption attacks and achieves performance that degrades linearly with the amount of corruption. ",
    "url": "https://arxiv.org/abs/2307.07675",
    "authors": [
      "Yinglun Xu",
      "Bhuvesh Kumar",
      "Jacob Abernethy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.07676",
    "title": "Computing SEQ-IC-LCS of Labeled Graphs",
    "abstract": "We consider labeled directed graphs where each vertex is labeled with a non-empty string. Such labeled graphs are also known as non-linear texts in the literature. In this paper, we introduce a new problem of comparing two given labeled graphs, called the SEQ-IC-LCS problem on labeled graphs. The goal of SEQ-IC-LCS is to compute the the length of the longest common subsequence (LCS) $Z$ of two target labeled graphs $G_1 = (V_1, E_1)$ and $G_2 = (V_2, E_2)$ that includes some string in the constraint labeled graph $G_3 = (V_3, E_3)$ as its subsequence. Firstly, we consider the case where $G_1$, $G_2$ and $G_3$ are all acyclic, and present algorithms for computing their SEQ-IC-LCS in $O(|E_1||E_2||E_3|)$ time and $O(|V_1||V_2||V_3|)$ space. Secondly, we consider the case where $G_1$ and $G_2$ can be cyclic and $G_3$ is acyclic, and present algorithms for computing their SEQ-IC-LCS in $O(|E_1||E_2||E_3| + |V_1||V_2||V_3|\\log|\\Sigma|)$ time and $O(|V_1||V_2||V_3|)$ space, where $\\Sigma$ is the alphabet. ",
    "url": "https://arxiv.org/abs/2307.07676",
    "authors": [
      "Yuki Yonemoto",
      "Yuto Nakashima",
      "Shunsuke Inenaga"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2307.07686",
    "title": "Creating a Dataset Supporting Translation Between OpenMP Fortran and C++  Code",
    "abstract": "In this study, we present a novel dataset for training machine learning models translating between OpenMP Fortran and C++ code. To ensure reliability and applicability, the dataset is initially refined using a meticulous code similarity test. The effectiveness of our dataset is assessed using both quantitative (CodeBLEU) and qualitative (human evaluation) methods. We demonstrate how this dataset can significantly improve the translation capabilities of large-scale language models, with improvements of \\times 5.1 for models with no prior coding knowledge and \\times 9.9 for models with some coding familiarity. Our work highlights the potential of this dataset to advance the field of code translation for high-performance computing. ",
    "url": "https://arxiv.org/abs/2307.07686",
    "authors": [
      "Bin Lei",
      "Caiwen Ding",
      "Le Chen",
      "Pei-Hung Lin",
      "Chunhua Liao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.07688",
    "title": "DRM-IR: Task-Adaptive Deep Unfolding Network for All-In-One Image  Restoration",
    "abstract": "Existing All-In-One image restoration (IR) methods usually lack flexible modeling on various types of degradation, thus impeding the restoration performance. To achieve All-In-One IR with higher task dexterity, this work proposes an efficient Dynamic Reference Modeling paradigm (DRM-IR), which consists of task-adaptive degradation modeling and model-based image restoring. Specifically, these two subtasks are formalized as a pair of entangled reference-based maximum a posteriori (MAP) inferences, which are optimized synchronously in an unfolding-based manner. With the two cascaded subtasks, DRM-IR first dynamically models the task-specific degradation based on a reference image pair and further restores the image with the collected degradation statistics. Besides, to bridge the semantic gap between the reference and target degraded images, we further devise a Degradation Prior Transmitter (DPT) that restrains the instance-specific feature differences. DRM-IR explicitly provides superior flexibility for All-in-One IR while being interpretable. Extensive experiments on multiple benchmark datasets show that our DRM-IR achieves state-of-the-art in All-In-One IR. ",
    "url": "https://arxiv.org/abs/2307.07688",
    "authors": [
      "Yuanshuo Cheng",
      "Mingwen Shao",
      "Yecong Wan",
      "Chao Wang",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.07691",
    "title": "A Survey on Change Detection Techniques in Document Images",
    "abstract": "The problem of change detection in images finds application in different domains like diagnosis of diseases in the medical field, detecting growth patterns of cities through remote sensing, and finding changes in legal documents and contracts. However, this paper presents a survey on core techniques and rules to detect changes in different versions of a document image. Our discussions on change detection focus on two categories -- content-based and layout-based. The content-based techniques intelligently extract and analyze the image contents (text or non-text) to show the possible differences, whereas the layout-based techniques use structural information to predict document changes. We also summarize the existing datasets and evaluation metrics used in change detection experiments. The shortcomings and challenges the existing methods face are reported, along with some pointers for future research work. ",
    "url": "https://arxiv.org/abs/2307.07691",
    "authors": [
      "Abhinandan Kumar Pun",
      "Mohammed Javed",
      "David S. Doermann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.07693",
    "title": "Neural Deformable Models for 3D Bi-Ventricular Heart Shape  Reconstruction and Modeling from 2D Sparse Cardiac Magnetic Resonance Imaging",
    "abstract": "We propose a novel neural deformable model (NDM) targeting at the reconstruction and modeling of 3D bi-ventricular shape of the heart from 2D sparse cardiac magnetic resonance (CMR) imaging data. We model the bi-ventricular shape using blended deformable superquadrics, which are parameterized by a set of geometric parameter functions and are capable of deforming globally and locally. While global geometric parameter functions and deformations capture gross shape features from visual data, local deformations, parameterized as neural diffeomorphic point flows, can be learned to recover the detailed heart shape.Different from iterative optimization methods used in conventional deformable model formulations, NDMs can be trained to learn such geometric parameter functions, global and local deformations from a shape distribution manifold. Our NDM can learn to densify a sparse cardiac point cloud with arbitrary scales and generate high-quality triangular meshes automatically. It also enables the implicit learning of dense correspondences among different heart shape instances for accurate cardiac shape registration. Furthermore, the parameters of NDM are intuitive, and can be used by a physician without sophisticated post-processing. Experimental results on a large CMR dataset demonstrate the improved performance of NDM over conventional methods. ",
    "url": "https://arxiv.org/abs/2307.07693",
    "authors": [
      "Meng Ye",
      "Dong Yang",
      "Mikael Kanski",
      "Leon Axel",
      "Dimitris Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07696",
    "title": "Coupling Large Language Models with Logic Programming for Robust and  General Reasoning from Text",
    "abstract": "While large language models (LLMs), such as GPT-3, appear to be robust and general, their reasoning ability is not at a level to compete with the best models trained for specific natural language reasoning problems. In this study, we observe that a large language model can serve as a highly effective few-shot semantic parser. It can convert natural language sentences into a logical form that serves as input for answer set programs, a logic-based declarative knowledge representation formalism. The combination results in a robust and general system that can handle multiple question-answering tasks without requiring retraining for each new task. It only needs a few examples to guide the LLM's adaptation to a specific task, along with reusable ASP knowledge modules that can be applied to multiple tasks. We demonstrate that this method achieves state-of-the-art performance on several NLP benchmarks, including bAbI, StepGame, CLUTRR, and gSCAN. Additionally, it successfully tackles robot planning tasks that an LLM alone fails to solve. ",
    "url": "https://arxiv.org/abs/2307.07696",
    "authors": [
      "Zhun Yang",
      "Adam Ishay",
      "Joohyung Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2307.07697",
    "title": "Think-on-Graph: Deep and Responsible Reasoning of Large Language Model  with Knowledge Graph",
    "abstract": "Large language models (LLMs) have made significant strides in various tasks, yet they often struggle with complex reasoning and exhibit poor performance in scenarios where knowledge traceability, timeliness, and accuracy are crucial. To address these limitations, we present Think-on-Graph (ToG), a novel framework that leverages knowledge graphs to enhance LLMs' ability for deep and responsible reasoning. By employing ToG, we can identify entities relevant to a given question and conduct exploration and reasoning to retrieve related triples from an external knowledge database. This iterative procedure generates multiple reasoning pathways consisting of sequentially connected triplets until sufficient information is gathered to answer the question or the maximum depth is reached. Through experiments on complex multi-hop reasoning question-answering tasks, we demonstrate that ToG outperforms existing methods, effectively addressing the aforementioned limitations of LLMs without incurring additional training costs. ",
    "url": "https://arxiv.org/abs/2307.07697",
    "authors": [
      "Jiashuo Sun",
      "Chengjin Xu",
      "Lumingyuan Tang",
      "Saizhuo Wang",
      "Chen Lin",
      "Yeyun Gong",
      "Heung-Yeung Shum",
      "Jian Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.07700",
    "title": "NeurASP: Embracing Neural Networks into Answer Set Programming",
    "abstract": "We present NeurASP, a simple extension of answer set programs by embracing neural networks. By treating the neural network output as the probability distribution over atomic facts in answer set programs, NeurASP provides a simple and effective way to integrate sub-symbolic and symbolic computation. We demonstrate how NeurASP can make use of a pre-trained neural network in symbolic computation and how it can improve the neural network's perception result by applying symbolic reasoning in answer set programming. Also, NeurASP can be used to train a neural network better by training with ASP rules so that a neural network not only learns from implicit correlations from the data but also from the explicit complex semantic constraints expressed by the rules. ",
    "url": "https://arxiv.org/abs/2307.07700",
    "authors": [
      "Zhun Yang",
      "Adam Ishay",
      "Joohyung Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2307.07711",
    "title": "Sandpile Prediction on Structured Undirected Graphs",
    "abstract": "We present algorithms that compute the terminal configurations for sandpile instances in $O(n \\log n)$ time on trees and $O(n)$ time on paths, where $n$ is the number of vertices. The Abelian Sandpile model is a well-known model used in exploring self-organized criticality. Despite a large amount of work on other aspects of sandpiles, there have been limited results in efficiently computing the terminal state, known as the sandpile prediction problem. Our algorithm improves the previous best runtime of $O(n \\log^5 n)$ on trees [Ramachandran-Schild SODA '17] and $O(n \\log n)$ on paths [Moore-Nilsson '99]. To do so, we move beyond the simulation of individual events by directly computing the number of firings for each vertex. The computation is accelerated using splittable binary search trees. We also generalize our algorithm to adapt at most three sink vertices, which is the first prediction algorithm faster than mere simulation on a sandpile model with sinks. We provide a general reduction that transforms the prediction problem on an arbitrary graph into problems on its subgraphs separated by any vertex set $P$. The reduction gives a time complexity of $O(\\log^{|P|} n \\cdot T)$ where $T$ denotes the total time for solving on each subgraph. In addition, we give algorithms in $O(n)$ time on cliques and $O(n \\log^2 n)$ time on pseudotrees. ",
    "url": "https://arxiv.org/abs/2307.07711",
    "authors": [
      "Jingbang Chen",
      "Ruinian Chang",
      "Qingyu Shi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2307.07725",
    "title": "Improving Translation Invariance in Convolutional Neural Networks with  Peripheral Prediction Padding",
    "abstract": "Zero padding is often used in convolutional neural networks to prevent the feature map size from decreasing with each layer. However, recent studies have shown that zero padding promotes encoding of absolute positional information, which may adversely affect the performance of some tasks. In this work, a novel padding method called Peripheral Prediction Padding (PP-Pad) method is proposed, which enables end-to-end training of padding values suitable for each task instead of zero padding. Moreover, novel metrics to quantitatively evaluate the translation invariance of the model are presented. By evaluating with these metrics, it was confirmed that the proposed method achieved higher accuracy and translation invariance than the previous methods in a semantic segmentation task. ",
    "url": "https://arxiv.org/abs/2307.07725",
    "authors": [
      "Kensuke Mukai",
      "Takao Yamanaka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07742",
    "title": "SINC: Self-Supervised In-Context Learning for Vision-Language Tasks",
    "abstract": "Large Pre-trained Transformers exhibit an intriguing capacity for in-context learning. Without gradient updates, these models can rapidly construct new predictors from demonstrations presented in the inputs. Recent works promote this ability in the vision-language domain by incorporating visual information into large language models that can already make in-context predictions. However, these methods could inherit issues in the language domain, such as template sensitivity and hallucination. Also, the scale of these language models raises a significant demand for computations, making learning and operating these models resource-intensive. To this end, we raise a question: ``How can we enable in-context learning for general models without being constrained on large language models?\". To answer it, we propose a succinct and general framework, Self-supervised IN-Context learning (SINC), that introduces a meta-model to learn on self-supervised prompts consisting of tailored demonstrations. The learned models can be transferred to downstream tasks for making in-context predictions on-the-fly. Extensive experiments show that SINC outperforms gradient-based methods in various vision-language tasks under few-shot settings. Furthermore, the designs of SINC help us investigate the benefits of in-context learning across different tasks, and the analysis further reveals the essential components for the emergence of in-context learning in the vision-language domain. ",
    "url": "https://arxiv.org/abs/2307.07742",
    "authors": [
      "Yi-Syuan Chen",
      "Yun-Zhu Song",
      "Cheng Yu Yeo",
      "Bei Liu",
      "Jianlong Fu",
      "Hong-Han Shuai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.07753",
    "title": "Learning Expressive Priors for Generalization and Uncertainty Estimation  in Neural Networks",
    "abstract": "In this work, we propose a novel prior learning method for advancing generalization and uncertainty estimation in deep neural networks. The key idea is to exploit scalable and structured posteriors of neural networks as informative priors with generalization guarantees. Our learned priors provide expressive probabilistic representations at large scale, like Bayesian counterparts of pre-trained models on ImageNet, and further produce non-vacuous generalization bounds. We also extend this idea to a continual learning framework, where the favorable properties of our priors are desirable. Major enablers are our technical contributions: (1) the sums-of-Kronecker-product computations, and (2) the derivations and optimizations of tractable objectives that lead to improved generalization bounds. Empirically, we exhaustively show the effectiveness of this method for uncertainty estimation and generalization. ",
    "url": "https://arxiv.org/abs/2307.07753",
    "authors": [
      "Dominik Schnaus",
      "Jongseok Lee",
      "Daniel Cremers",
      "Rudolph Triebel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.07781",
    "title": "Improving Trace Link Recommendation by Using Non-Isotropic Distances and  Combinations",
    "abstract": "The existence of trace links between artifacts of the software development life cycle can improve the efficiency of many activities during software development, maintenance and operations. Unfortunately, the creation and maintenance of trace links is time-consuming and error-prone. Research efforts have been spent to automatically compute trace links and lately gained momentum, e.g., due to the availability of powerful tools in the area of natural language processing. In this paper, we report on some observations that we made during studying non-linear similarity measures for computing trace links. We argue, that taking a geometric viewpoint on semantic similarity can be helpful for future traceability research. We evaluated our observations on a dataset of four open source projects and two industrial projects. We furthermore point out that our findings are more general and can build the basis for other information retrieval problems as well. ",
    "url": "https://arxiv.org/abs/2307.07781",
    "authors": [
      "Christof Tinnes"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Differential Geometry (math.DG)"
    ]
  },
  {
    "id": "arXiv:2307.07791",
    "title": "Joint Adversarial and Collaborative Learning for Self-Supervised Action  Recognition",
    "abstract": "Considering the instance-level discriminative ability, contrastive learning methods, including MoCo and SimCLR, have been adapted from the original image representation learning task to solve the self-supervised skeleton-based action recognition task. These methods usually use multiple data streams (i.e., joint, motion, and bone) for ensemble learning, meanwhile, how to construct a discriminative feature space within a single stream and effectively aggregate the information from multiple streams remains an open problem. To this end, we first apply a new contrastive learning method called BYOL to learn from skeleton data and formulate SkeletonBYOL as a simple yet effective baseline for self-supervised skeleton-based action recognition. Inspired by SkeletonBYOL, we further present a joint Adversarial and Collaborative Learning (ACL) framework, which combines Cross-Model Adversarial Learning (CMAL) and Cross-Stream Collaborative Learning (CSCL). Specifically, CMAL learns single-stream representation by cross-model adversarial loss to obtain more discriminative features. To aggregate and interact with multi-stream information, CSCL is designed by generating similarity pseudo label of ensemble learning as supervision and guiding feature generation for individual streams. Exhaustive experiments on three datasets verify the complementary properties between CMAL and CSCL and also verify that our method can perform favorably against state-of-the-art methods using various evaluation protocols. Our code and models are publicly available at \\url{https://github.com/Levigty/ACL}. ",
    "url": "https://arxiv.org/abs/2307.07791",
    "authors": [
      "Tianyu Guo",
      "Mengyuan Liu",
      "Hong Liu",
      "Wenhao Li",
      "Jingwen Guo",
      "Tao Wang",
      "Yidi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07798",
    "title": "Opinion mining using Double Channel CNN for Recommender System",
    "abstract": "Much unstructured data has been produced with the growth of the Internet and social media. A significant volume of textual data includes users' opinions about products in online stores and social media. By exploring and categorizing them, helpful information can be acquired, including customer satisfaction, user feedback about a particular event, predicting the sale of a specific product, and other similar cases. In this paper, we present an approach for sentiment analysis with a deep learning model and use it to recommend products. A two-channel convolutional neural network model has been used for opinion mining, which has five layers and extracts essential features from the data. We increased the number of comments by applying the SMOTE algorithm to the initial dataset and balanced the data. Then we proceed to cluster the aspects. We also assign a weight to each cluster using tensor decomposition algorithms that improve the recommender system's performance. Our proposed method has reached 91.6% accuracy, significantly improved compared to previous aspect-based approaches. ",
    "url": "https://arxiv.org/abs/2307.07798",
    "authors": [
      "Minoo Sayyadpour",
      "Ali Nazarizadeh"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.07810",
    "title": "Graph Automorphism Group Equivariant Neural Networks",
    "abstract": "For any graph $G$ having $n$ vertices and its automorphism group $\\textrm{Aut}(G)$, we provide a full characterisation of all of the possible $\\textrm{Aut}(G)$-equivariant neural networks whose layers are some tensor power of $\\mathbb{R}^{n}$. In particular, we find a spanning set of matrices for the learnable, linear, $\\textrm{Aut}(G)$-equivariant layer functions between such tensor power spaces in the standard basis of $\\mathbb{R}^{n}$. ",
    "url": "https://arxiv.org/abs/2307.07810",
    "authors": [
      "Edward Pearce-Crump"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)",
      "Representation Theory (math.RT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.07811",
    "title": "Generative Meta-Learning Robust Quality-Diversity Portfolio",
    "abstract": "This paper proposes a novel meta-learning approach to optimize a robust portfolio ensemble. The method uses a deep generative model to generate diverse and high-quality sub-portfolios combined to form the ensemble portfolio. The generative model consists of a convolutional layer, a stateful LSTM module, and a dense network. During training, the model takes a randomly sampled batch of Gaussian noise and outputs a population of solutions, which are then evaluated using the objective function of the problem. The weights of the model are updated using a gradient-based optimizer. The convolutional layer transforms the noise into a desired distribution in latent space, while the LSTM module adds dependence between generations. The dense network decodes the population of solutions. The proposed method balances maximizing the performance of the sub-portfolios with minimizing their maximum correlation, resulting in a robust ensemble portfolio against systematic shocks. The approach was effective in experiments where stochastic rewards were present. Moreover, the results (Fig. 1) demonstrated that the ensemble portfolio obtained by taking the average of the generated sub-portfolio weights was robust and generalized well. The proposed method can be applied to problems where diversity is desired among co-optimized solutions for a robust ensemble. The source-codes and the dataset are in the supplementary material. ",
    "url": "https://arxiv.org/abs/2307.07811",
    "authors": [
      "Kamer Ali Yuksel"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Portfolio Management (q-fin.PM)"
    ]
  },
  {
    "id": "arXiv:2307.07816",
    "title": "Minimal Random Code Learning with Mean-KL Parameterization",
    "abstract": "This paper studies the qualitative behavior and robustness of two variants of Minimal Random Code Learning (MIRACLE) used to compress variational Bayesian neural networks. MIRACLE implements a powerful, conditionally Gaussian variational approximation for the weight posterior $Q_{\\mathbf{w}}$ and uses relative entropy coding to compress a weight sample from the posterior using a Gaussian coding distribution $P_{\\mathbf{w}}$. To achieve the desired compression rate, $D_{\\mathrm{KL}}[Q_{\\mathbf{w}} \\Vert P_{\\mathbf{w}}]$ must be constrained, which requires a computationally expensive annealing procedure under the conventional mean-variance (Mean-Var) parameterization for $Q_{\\mathbf{w}}$. Instead, we parameterize $Q_{\\mathbf{w}}$ by its mean and KL divergence from $P_{\\mathbf{w}}$ to constrain the compression cost to the desired value by construction. We demonstrate that variational training with Mean-KL parameterization converges twice as fast and maintains predictive performance after compression. Furthermore, we show that Mean-KL leads to more meaningful variational distributions with heavier tails and compressed weight samples which are more robust to pruning. ",
    "url": "https://arxiv.org/abs/2307.07816",
    "authors": [
      "Jihao Andreas Lin",
      "Gergely Flamich",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.07832",
    "title": "MixupExplainer: Generalizing Explanations for Graph Neural Networks with  Data Augmentation",
    "abstract": "Graph Neural Networks (GNNs) have received increasing attention due to their ability to learn from graph-structured data. However, their predictions are often not interpretable. Post-hoc instance-level explanation methods have been proposed to understand GNN predictions. These methods seek to discover substructures that explain the prediction behavior of a trained GNN. In this paper, we shed light on the existence of the distribution shifting issue in existing methods, which affects explanation quality, particularly in applications on real-life datasets with tight decision boundaries. To address this issue, we introduce a generalized Graph Information Bottleneck (GIB) form that includes a label-independent graph variable, which is equivalent to the vanilla GIB. Driven by the generalized GIB, we propose a graph mixup method, MixupExplainer, with a theoretical guarantee to resolve the distribution shifting issue. We conduct extensive experiments on both synthetic and real-world datasets to validate the effectiveness of our proposed mixup approach over existing approaches. We also provide a detailed analysis of how our proposed approach alleviates the distribution shifting issue. ",
    "url": "https://arxiv.org/abs/2307.07832",
    "authors": [
      "Jiaxing Zhang",
      "Dongsheng Luo",
      "Hua Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.07840",
    "title": "RegExplainer: Generating Explanations for Graph Neural Networks in  Regression Task",
    "abstract": "Graph regression is a fundamental task and has received increasing attention in a wide range of graph learning tasks. However, the inference process is often not interpretable. Most existing explanation techniques are limited to understanding GNN behaviors in classification tasks. In this work, we seek an explanation to interpret the graph regression models (XAIG-R). We show that existing methods overlook the distribution shifting and continuously ordered decision boundary, which hinders them away from being applied in the regression tasks. To address these challenges, we propose a novel objective based on the information bottleneck theory and introduce a new mix-up framework, which could support various GNNs in a model-agnostic manner. We further present a contrastive learning strategy to tackle the continuously ordered labels in regression task. To empirically verify the effectiveness of the proposed method, we introduce three benchmark datasets and a real-life dataset for evaluation. Extensive experiments show the effectiveness of the proposed method in interpreting GNN models in regression tasks. ",
    "url": "https://arxiv.org/abs/2307.07840",
    "authors": [
      "Jiaxing Zhang",
      "Zhuomin Chen",
      "Hao Mei",
      "Dongsheng Luo",
      "Hua Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.07847",
    "title": "Neural Video Recovery for Cloud Gaming",
    "abstract": "Cloud gaming is a multi-billion dollar industry. A client in cloud gaming sends its movement to the game server on the Internet, which renders and transmits the resulting video back. In order to provide a good gaming experience, a latency below 80 ms is required. This means that video rendering, encoding, transmission, decoding, and display have to finish within that time frame, which is especially challenging to achieve due to server overload, network congestion, and losses. In this paper, we propose a new method for recovering lost or corrupted video frames in cloud gaming. Unlike traditional video frame recovery, our approach uses game states to significantly enhance recovery accuracy and utilizes partially decoded frames to recover lost portions. We develop a holistic system that consists of (i) efficiently extracting game states, (ii) modifying H.264 video decoder to generate a mask to indicate which portions of video frames need recovery, and (iii) designing a novel neural network to recover either complete or partial video frames. Our approach is extensively evaluated using iPhone 12 and laptop implementations, and we demonstrate the utility of game states in the game video recovery and the effectiveness of our overall design. ",
    "url": "https://arxiv.org/abs/2307.07847",
    "authors": [
      "Zhaoyuan He",
      "Yifan Yang",
      "Shuozhe Li",
      "Diyuan Dai",
      "Lili Qiu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2307.07854",
    "title": "Multilingual Adapter-based Knowledge Aggregation on Code Summarization  for Low-Resource Languages",
    "abstract": "Multilingual fine-tuning (of a multilingual Pre-trained Language Model) has shown to improve performance of downstream tasks. However, it was observed that different programming languages may have different structural properties, and thus the learning or fine-tuning of a model may be sub-optimal or even degrade the intended performance by using a multilingual dataset. In this study, we proposed a new modular component architecture, AdvFusion, that leverages the different aspects of programming languages for a target popular low-resource programming language, Ruby. Our result shows that AdvFusion can extract useful features from different programming languages efficiently, and it outperforms the existing state-of-the-art multilingual fine-tuning by 12% on the Code Summarization task. ",
    "url": "https://arxiv.org/abs/2307.07854",
    "authors": [
      "Iman Saberi",
      "Fatemeh Fard",
      "Fuxiang Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2307.07859",
    "title": "Unified Adversarial Patch for Cross-modal Attacks in the Physical World",
    "abstract": "Recently, physical adversarial attacks have been presented to evade DNNs-based object detectors. To ensure the security, many scenarios are simultaneously deployed with visible sensors and infrared sensors, leading to the failures of these single-modal physical attacks. To show the potential risks under such scenes, we propose a unified adversarial patch to perform cross-modal physical attacks, i.e., fooling visible and infrared object detectors at the same time via a single patch. Considering different imaging mechanisms of visible and infrared sensors, our work focuses on modeling the shapes of adversarial patches, which can be captured in different modalities when they change. To this end, we design a novel boundary-limited shape optimization to achieve the compact and smooth shapes, and thus they can be easily implemented in the physical world. In addition, to balance the fooling degree between visible detector and infrared detector during the optimization process, we propose a score-aware iterative evaluation, which can guide the adversarial patch to iteratively reduce the predicted scores of the multi-modal sensors. We finally test our method against the one-stage detector: YOLOv3 and the two-stage detector: Faster RCNN. Results show that our unified patch achieves an Attack Success Rate (ASR) of 73.33% and 69.17%, respectively. More importantly, we verify the effective attacks in the physical world when visible and infrared sensors shoot the objects under various settings like different angles, distances, postures, and scenes. ",
    "url": "https://arxiv.org/abs/2307.07859",
    "authors": [
      "Xingxing Wei",
      "Yao Huang",
      "Yitong Sun",
      "Jie Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07872",
    "title": "Does Double Descent Occur in Self-Supervised Learning?",
    "abstract": "Most investigations into double descent have focused on supervised models while the few works studying self-supervised settings find a surprising lack of the phenomenon. These results imply that double descent may not exist in self-supervised models. We show this empirically using a standard and linear autoencoder, two previously unstudied settings. The test loss is found to have either a classical U-shape or to monotonically decrease instead of exhibiting a double-descent curve. We hope that further work on this will help elucidate the theoretical underpinnings of this phenomenon. ",
    "url": "https://arxiv.org/abs/2307.07872",
    "authors": [
      "Alisia Lupidi",
      "Yonatan Gideoni",
      "Dulhan Jayalath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.07873",
    "title": "Towards Understanding Adversarial Transferability From Surrogate  Training",
    "abstract": "Adversarial examples (AEs) for DNNs have been shown to be transferable: AEs that successfully fool white-box surrogate models can also deceive other black-box models with different architectures. Although a bunch of empirical studies have provided guidance on generating highly transferable AEs, many of these findings lack explanations and even lead to inconsistent advice. In this paper, we take a further step towards understanding adversarial transferability, with a particular focus on surrogate aspects. Starting from the intriguing little robustness phenomenon, where models adversarially trained with mildly perturbed adversarial samples can serve as better surrogates, we attribute it to a trade-off between two predominant factors: model smoothness and gradient similarity. Our investigations focus on their joint effects, rather than their separate correlations with transferability. Through a series of theoretical and empirical analyses, we conjecture that the data distribution shift in adversarial training explains the degradation of gradient similarity. Building on these insights, we explore the impacts of data augmentation and gradient regularization on transferability and identify that the trade-off generally exists in the various training mechanisms, thus building a comprehensive blueprint for the regulation mechanism behind transferability. Finally, we provide a general route for constructing better surrogates to boost transferability which optimizes both model smoothness and gradient similarity simultaneously, e.g., the combination of input gradient regularization and sharpness-aware minimization (SAM), validated by extensive experiments. In summary, we call for attention to the united impacts of these two factors for launching effective transfer attacks, rather than optimizing one while ignoring the other, and emphasize the crucial role of manipulating surrogate models. ",
    "url": "https://arxiv.org/abs/2307.07873",
    "authors": [
      "Yechao Zhang",
      "Shengshan Hu",
      "Leo Yu Zhang",
      "Junyu Shi",
      "Minghui Li",
      "Xiaogeng Liu",
      "Wei Wan",
      "Hai Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07876",
    "title": "Online Goal Recognition in Discrete and Continuous Domains Using a  Vectorial Representation",
    "abstract": "While recent work on online goal recognition efficiently infers goals under low observability, comparatively less work focuses on online goal recognition that works in both discrete and continuous domains. Online goal recognition approaches often rely on repeated calls to the planner at each new observation, incurring high computational costs. Recognizing goals online in continuous space quickly and reliably is critical for any trajectory planning problem since the real physical world is fast-moving, e.g. robot applications. We develop an efficient method for goal recognition that relies either on a single call to the planner for each possible goal in discrete domains or a simplified motion model that reduces the computational burden in continuous ones. The resulting approach performs the online component of recognition orders of magnitude faster than the current state of the art, making it the first online method effectively usable for robotics applications that require sub-second recognition. ",
    "url": "https://arxiv.org/abs/2307.07876",
    "authors": [
      "Douglas Tesch",
      "Leonardo Rosa Amado",
      "Felipe Meneguzzi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.07881",
    "title": "Graph Embedded Intuitionistic Fuzzy RVFL for Class Imbalance Learning",
    "abstract": "The domain of machine learning is confronted with a crucial research area known as class imbalance learning, which presents considerable hurdles in the precise classification of minority classes. This issue can result in biased models where the majority class takes precedence in the training process, leading to the underrepresentation of the minority class. The random vector functional link (RVFL) network is a widely-used and effective learning model for classification due to its speed and efficiency. However, it suffers from low accuracy when dealing with imbalanced datasets. To overcome this limitation, we propose a novel graph embedded intuitionistic fuzzy RVFL for class imbalance learning (GE-IFRVFL-CIL) model incorporating a weighting mechanism to handle imbalanced datasets. The proposed GE-IFRVFL-CIL model has a plethora of benefits, such as $(i)$ it leverages graph embedding to extract semantically rich information from the dataset, $(ii)$ it uses intuitionistic fuzzy sets to handle uncertainty and imprecision in the data, $(iii)$ and the most important, it tackles class imbalance learning. The amalgamation of a weighting scheme, graph embedding, and intuitionistic fuzzy sets leads to the superior performance of the proposed model on various benchmark imbalanced datasets, including UCI and KEEL. Furthermore, we implement the proposed GE-IFRVFL-CIL on the ADNI dataset and achieved promising results, demonstrating the model's effectiveness in real-world applications. The proposed method provides a promising solution for handling class imbalance in machine learning and has the potential to be applied to other classification problems. ",
    "url": "https://arxiv.org/abs/2307.07881",
    "authors": [
      "M.A. Ganaie",
      "M. Sajid",
      "A.K. Malik",
      "M. Tanveer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.07882",
    "title": "Gradient-free training of neural ODEs for system identification and  control using ensemble Kalman inversion",
    "abstract": "Ensemble Kalman inversion (EKI) is a sequential Monte Carlo method used to solve inverse problems within a Bayesian framework. Unlike backpropagation, EKI is a gradient-free optimization method that only necessitates the evaluation of artificial neural networks in forward passes. In this study, we examine the effectiveness of EKI in training neural ordinary differential equations (neural ODEs) for system identification and control tasks. To apply EKI to optimal control problems, we formulate inverse problems that incorporate a Tikhonov-type regularization term. Our numerical results demonstrate that EKI is an efficient method for training neural ODEs in system identification and optimal control problems, with runtime and quality of solutions that are competitive with commonly used gradient-based optimizers. ",
    "url": "https://arxiv.org/abs/2307.07882",
    "authors": [
      "Lucas B\u00f6ttcher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2307.07892",
    "title": "Multitemporal SAR images change detection and visualization using  RABASAR and simplified GLR",
    "abstract": "Understanding the state of changed areas requires that precise information be given about the changes. Thus, detecting different kinds of changes is important for land surface monitoring. SAR sensors are ideal to fulfil this task, because of their all-time and all-weather capabilities, with good accuracy of the acquisition geometry and without effects of atmospheric constituents for amplitude data. In this study, we propose a simplified generalized likelihood ratio ($S_{GLR}$) method assuming that corresponding temporal pixels have the same equivalent number of looks (ENL). Thanks to the denoised data provided by a ratio-based multitemporal SAR image denoising method (RABASAR), we successfully applied this similarity test approach to compute the change areas. A new change magnitude index method and an improved spectral clustering-based change classification method are also developed. In addition, we apply the simplified generalized likelihood ratio to detect the maximum change magnitude time, and the change starting and ending times. Then, we propose to use an adaptation of the REACTIV method to visualize the detection results vividly. The effectiveness of the proposed methods is demonstrated through the processing of simulated and SAR images, and the comparison with classical techniques. In particular, numerical experiments proved that the developed method has good performances in detecting farmland area changes, building area changes, harbour area changes and flooding area changes. ",
    "url": "https://arxiv.org/abs/2307.07892",
    "authors": [
      "Weiying Zhao",
      "Charles-Alban Deledalle",
      "Lo\u00efc Denis",
      "Henri Ma\u00eetre",
      "Jean-Marie Nicolas",
      "Florence Tupin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.07893",
    "title": "Anomaly Detection in Automated Fibre Placement: Learning with Data  Limitations",
    "abstract": "Current defect detection systems for Automated Fibre Placement (AFP) are mostly based on end-to-end supervised learning methods requiring abundant labelled defective samples, which are not easily generated in sufficient numbers. To address this data scarcity problem, we introduce an autoencoder-based approach compatible with small datasets. Fortunately, the problem from a foundational point of view can be simplified as a binary classification between normal and abnormal samples. The proposed approach uses a depth map of the fibre layup surface, split into small windows aligned to each composite strip (tow). A subset of these windows that do not contain anomalies is passed to an autoencoder to reconstruct the input. Because the autoencoder is trained with normal samples, it produces more accurate reconstructions for these samples than for abnormal ones. Therefore, the value of reconstruction error is used as a quantitative metric for whether there are potential anomalies. These values are combined to produce an anomaly map, which can localize the manufacturing defects in the depth map. The results show that although the autoencoder is trained with a very limited number of scans, the proposed approach can produce sufficient binary classification accuracy and specify the location of the defects. ",
    "url": "https://arxiv.org/abs/2307.07893",
    "authors": [
      "Assef Ghamisi",
      "Todd Charter",
      "Li Ji",
      "Maxime Rivard",
      "Gil Lund",
      "Homayoun Najjaran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.07907",
    "title": "Seeing is not Believing: Robust Reinforcement Learning against Spurious  Correlation",
    "abstract": "Robustness has been extensively studied in reinforcement learning (RL) to handle various forms of uncertainty such as random perturbations, rare events, and malicious attacks. In this work, we consider one critical type of robustness against spurious correlation, where different portions of the state do not have causality but have correlations induced by unobserved confounders. These spurious correlations are ubiquitous in real-world tasks, for instance, a self-driving car usually observes heavy traffic in the daytime and light traffic at night due to unobservable human activity. A model that learns such useless or even harmful correlation could catastrophically fail when the confounder in the test case deviates from the training one. Although motivated, enabling robustness against spurious correlation poses significant challenges since the uncertainty set, shaped by the unobserved confounder and sequential structure of RL, is difficult to characterize and identify. Existing robust algorithms that assume simple and unstructured uncertainty sets are therefore inadequate to address this challenge. To solve this issue, we propose Robust State-Confounded Markov Decision Processes (RSC-MDPs) and theoretically demonstrate its superiority in breaking spurious correlations compared with other robust RL counterparts. We also design an empirical algorithm to learn the robust optimal policy for RSC-MDPs, which outperforms all baselines in eight realistic self-driving and manipulation tasks. ",
    "url": "https://arxiv.org/abs/2307.07907",
    "authors": [
      "Wenhao Ding",
      "Laixi Shi",
      "Yuejie Chi",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.07911",
    "title": "MESOB: Balancing Equilibria & Social Optimality",
    "abstract": "Motivated by bid recommendation in online ad auctions, this paper considers a general class of multi-level and multi-agent games, with two major characteristics: one is a large number of anonymous agents, and the other is the intricate interplay between competition and cooperation. To model such complex systems, we propose a novel and tractable bi-objective optimization formulation with mean-field approximation, called MESOB (Mean-field Equilibria & Social Optimality Balancing), as well as an associated occupation measure optimization (OMO) method called MESOB-OMO to solve it. MESOB-OMO enables obtaining approximately Pareto efficient solutions in terms of the dual objectives of competition and cooperation in MESOB, and in particular allows for Nash equilibrium selection and social equalization in an asymptotic manner. We apply MESOB-OMO to bid recommendation in a simulated pay-per-click ad auction. Experiments demonstrate its efficacy in balancing the interests of different parties and in handling the competitive nature of bidders, as well as its advantages over baselines that only consider either the competitive or the cooperative aspects. ",
    "url": "https://arxiv.org/abs/2307.07911",
    "authors": [
      "Xin Guo",
      "Lihong Li",
      "Sareh Nabi",
      "Rabih Salhab",
      "Junzi Zhang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.07916",
    "title": "On the Robustness of Split Learning against Adversarial Attacks",
    "abstract": "Split learning enables collaborative deep learning model training while preserving data privacy and model security by avoiding direct sharing of raw data and model details (i.e., sever and clients only hold partial sub-networks and exchange intermediate computations). However, existing research has mainly focused on examining its reliability for privacy protection, with little investigation into model security. Specifically, by exploring full models, attackers can launch adversarial attacks, and split learning can mitigate this severe threat by only disclosing part of models to untrusted servers.This paper aims to evaluate the robustness of split learning against adversarial attacks, particularly in the most challenging setting where untrusted servers only have access to the intermediate layers of the model.Existing adversarial attacks mostly focus on the centralized setting instead of the collaborative setting, thus, to better evaluate the robustness of split learning, we develop a tailored attack called SPADV, which comprises two stages: 1) shadow model training that addresses the issue of lacking part of the model and 2) local adversarial attack that produces adversarial examples to evaluate.The first stage only requires a few unlabeled non-IID data, and, in the second stage, SPADV perturbs the intermediate output of natural samples to craft the adversarial ones. The overall cost of the proposed attack process is relatively low, yet the empirical attack effectiveness is significantly high, demonstrating the surprising vulnerability of split learning to adversarial attacks. ",
    "url": "https://arxiv.org/abs/2307.07916",
    "authors": [
      "Mingyuan Fan",
      "Cen Chen",
      "Chengyu Wang",
      "Wenmeng Zhou",
      "Jun Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07919",
    "title": "Neural Architecture Retrieval",
    "abstract": "With the increasing number of new neural architecture designs and substantial existing neural architectures, it becomes difficult for the researchers to situate their contributions compared with existing neural architectures or establish the connections between their designs and other relevant ones. To discover similar neural architectures in an efficient and automatic manner, we define a new problem Neural Architecture Retrieval which retrieves a set of existing neural architectures which have similar designs to the query neural architecture. Existing graph pre-training strategies cannot address the computational graph in neural architectures due to the graph size and motifs. To fulfill this potential, we propose to divide the graph into motifs which are used to rebuild the macro graph to tackle these issues, and introduce multi-level contrastive learning to achieve accurate graph representation learning. Extensive evaluations on both human-designed and synthesized neural architectures demonstrate the superiority of our algorithm. Such a dataset which contains 12k real-world network architectures, as well as their embedding, is built for neural architecture retrieval. ",
    "url": "https://arxiv.org/abs/2307.07919",
    "authors": [
      "Xiaohuan Pei",
      "Yanxi Li",
      "Minjing Dong",
      "Chang Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.07933",
    "title": "Holistic Prototype Attention Network for Few-Shot VOS",
    "abstract": "Few-shot video object segmentation (FSVOS) aims to segment dynamic objects of unseen classes by resorting to a small set of support images that contain pixel-level object annotations. Existing methods have demonstrated that the domain agent-based attention mechanism is effective in FSVOS by learning the correlation between support images and query frames. However, the agent frame contains redundant pixel information and background noise, resulting in inferior segmentation performance. Moreover, existing methods tend to ignore inter-frame correlations in query videos. To alleviate the above dilemma, we propose a holistic prototype attention network (HPAN) for advancing FSVOS. Specifically, HPAN introduces a prototype graph attention module (PGAM) and a bidirectional prototype attention module (BPAM), transferring informative knowledge from seen to unseen classes. PGAM generates local prototypes from all foreground features and then utilizes their internal correlations to enhance the representation of the holistic prototypes. BPAM exploits the holistic information from support images and video frames by fusing co-attention and self-attention to achieve support-query semantic consistency and inner-frame temporal consistency. Extensive experiments on YouTube-FSVOS have been provided to demonstrate the effectiveness and superiority of our proposed HPAN method. ",
    "url": "https://arxiv.org/abs/2307.07933",
    "authors": [
      "Yin Tang",
      "Tao Chen",
      "Xiruo Jiang",
      "Yazhou Yao",
      "Guo-Sen Xie",
      "Heng-Tao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07934",
    "title": "Contrastive Multi-Task Dense Prediction",
    "abstract": "This paper targets the problem of multi-task dense prediction which aims to achieve simultaneous learning and inference on a bunch of multiple dense prediction tasks in a single framework. A core objective in design is how to effectively model cross-task interactions to achieve a comprehensive improvement on different tasks based on their inherent complementarity and consistency. Existing works typically design extra expensive distillation modules to perform explicit interaction computations among different task-specific features in both training and inference, bringing difficulty in adaptation for different task sets, and reducing efficiency due to clearly increased size of multi-task models. In contrast, we introduce feature-wise contrastive consistency into modeling the cross-task interactions for multi-task dense prediction. We propose a novel multi-task contrastive regularization method based on the consistency to effectively boost the representation learning of the different sub-tasks, which can also be easily generalized to different multi-task dense prediction frameworks, and costs no additional computation in the inference. Extensive experiments on two challenging datasets (i.e. NYUD-v2 and Pascal-Context) clearly demonstrate the superiority of the proposed multi-task contrastive learning approach for dense predictions, establishing new state-of-the-art performances. ",
    "url": "https://arxiv.org/abs/2307.07934",
    "authors": [
      "Siwei Yang",
      "Hanrong Ye",
      "Dan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07942",
    "title": "KECOR: Kernel Coding Rate Maximization for Active 3D Object Detection",
    "abstract": "Achieving a reliable LiDAR-based object detector in autonomous driving is paramount, but its success hinges on obtaining large amounts of precise 3D annotations. Active learning (AL) seeks to mitigate the annotation burden through algorithms that use fewer labels and can attain performance comparable to fully supervised learning. Although AL has shown promise, current approaches prioritize the selection of unlabeled point clouds with high uncertainty and/or diversity, leading to the selection of more instances for labeling and reduced computational efficiency. In this paper, we resort to a novel kernel coding rate maximization (KECOR) strategy which aims to identify the most informative point clouds to acquire labels through the lens of information theory. Greedy search is applied to seek desired point clouds that can maximize the minimal number of bits required to encode the latent features. To determine the uniqueness and informativeness of the selected samples from the model perspective, we construct a proxy network of the 3D detector head and compute the outer product of Jacobians from all proxy layers to form the empirical neural tangent kernel (NTK) matrix. To accommodate both one-stage (i.e., SECOND) and two-stage detectors (i.e., PVRCNN), we further incorporate the classification entropy maximization and well trade-off between detection performance and the total number of bounding boxes selected for annotation. Extensive experiments conducted on two 3D benchmarks and a 2D detection dataset evidence the superiority and versatility of the proposed approach. Our results show that approximately 44% box-level annotation costs and 26% computational time are reduced compared to the state-of-the-art AL method, without compromising detection performance. ",
    "url": "https://arxiv.org/abs/2307.07942",
    "authors": [
      "Yadan Luo",
      "Zhuoxiao Chen",
      "Zhen Fang",
      "Zheng Zhang",
      "Zi Huang",
      "Mahsa Baktashmotlagh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.07944",
    "title": "Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and  Class-balanced Pseudo-Labeling",
    "abstract": "Unsupervised domain adaptation (DA) with the aid of pseudo labeling techniques has emerged as a crucial approach for domain-adaptive 3D object detection. While effective, existing DA methods suffer from a substantial drop in performance when applied to a multi-class training setting, due to the co-existence of low-quality pseudo labels and class imbalance issues. In this paper, we address this challenge by proposing a novel ReDB framework tailored for learning to detect all classes at once. Our approach produces Reliable, Diverse, and class-Balanced pseudo 3D boxes to iteratively guide the self-training on a distributionally different target domain. To alleviate disruptions caused by the environmental discrepancy (e.g., beam numbers), the proposed cross-domain examination (CDE) assesses the correctness of pseudo labels by copy-pasting target instances into a source environment and measuring the prediction consistency. To reduce computational overhead and mitigate the object shift (e.g., scales and point densities), we design an overlapped boxes counting (OBC) metric that allows to uniformly downsample pseudo-labeled objects across different geometric characteristics. To confront the issue of inter-class imbalance, we progressively augment the target point clouds with a class-balanced set of pseudo-labeled target instances and source objects, which boosts recognition accuracies on both frequently appearing and rare classes. Experimental results on three benchmark datasets using both voxel-based (i.e., SECOND) and point-based 3D detectors (i.e., PointRCNN) demonstrate that our proposed ReDB approach outperforms existing 3D domain adaptation methods by a large margin, improving 23.15% mAP on the nuScenes $\\rightarrow$ KITTI task. ",
    "url": "https://arxiv.org/abs/2307.07944",
    "authors": [
      "Zhuoxiao Chen",
      "Yadan Luo",
      "Zi Huang",
      "Zheng Wang",
      "Mahsa Baktashmotlagh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.07945",
    "title": "Surface Geometry Processing: An Efficient Normal-based Detail  Representation",
    "abstract": "With the rapid development of high-resolution 3D vision applications, the traditional way of manipulating surface detail requires considerable memory and computing time. To address these problems, we introduce an efficient surface detail processing framework in 2D normal domain, which extracts new normal feature representations as the carrier of micro geometry structures that are illustrated both theoretically and empirically in this article. Compared with the existing state of the arts, we verify and demonstrate that the proposed normal-based representation has three important properties, including detail separability, detail transferability and detail idempotence. Finally, three new schemes are further designed for geometric surface detail processing applications, including geometric texture synthesis, geometry detail transfer, and 3D surface super-resolution. Theoretical analysis and experimental results on the latest benchmark dataset verify the effectiveness and versatility of our normal-based representation, which accepts 30 times of the input surface vertices but at the same time only takes 6.5% memory cost and 14.0% running time in comparison with existing competing algorithms. ",
    "url": "https://arxiv.org/abs/2307.07945",
    "authors": [
      "Wuyuan Xie",
      "Miaohui Wang",
      "Di Lin",
      "Boxin Shi",
      "Jianmin Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2307.07953",
    "title": "Accurate 3D Prediction of Missing Teeth in Diverse Patterns for Precise  Dental Implant Planning",
    "abstract": "In recent years, the demand for dental implants has surged, driven by their high success rates and esthetic advantages. However, accurate prediction of missing teeth for precise digital implant planning remains a challenge due to the intricate nature of dental structures and the variability in tooth loss patterns. This study presents a novel framework for accurate prediction of missing teeth in different patterns, facilitating digital implant planning. The proposed framework begins by estimating point-to-point correspondence among a dataset of dental mesh models reconstructed from CBCT images of healthy subjects. Subsequently, tooth dictionaries are constructed for each tooth type, encoding their position and shape information based on the established point-to-point correspondence. To predict missing teeth in a given dental mesh model, sparse coefficients are learned by sparsely representing adjacent teeth of the missing teeth using the corresponding tooth dictionaries. These coefficients are then applied to the dictionaries of the missing teeth to generate accurate predictions of their positions and shapes. The evaluation results on real subjects shows that our proposed framework achieves an average prediction error of 1.04mm for predictions of single missing tooth and an average prediction error of 1.33mm for the prediction of 14 missing teeth, which demonstrates its capability of accurately predicting missing teeth in various patterns. By accurately predicting missing teeth, dental professionals can improve the planning and placement of dental implants, leading to better esthetic and functional outcomes for patients undergoing dental implant procedures. ",
    "url": "https://arxiv.org/abs/2307.07953",
    "authors": [
      "Lei Ma",
      "Peng Xue",
      "Yuning Gu",
      "Yue Zhao",
      "Min Zhu",
      "Zhongxiang Ding",
      "Dinggang Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07956",
    "title": "Automated Polynomial Filter Learning for Graph Neural Networks",
    "abstract": "Polynomial graph filters have been widely used as guiding principles in the design of Graph Neural Networks (GNNs). Recently, the adaptive learning of the polynomial graph filters has demonstrated promising performance for modeling graph signals on both homophilic and heterophilic graphs, owning to their flexibility and expressiveness. In this work, we conduct a novel preliminary study to explore the potential and limitations of polynomial graph filter learning approaches, revealing a severe overfitting issue. To improve the effectiveness of polynomial graph filters, we propose Auto-Polynomial, a novel and general automated polynomial graph filter learning framework that efficiently learns better filters capable of adapting to various complex graph signals. Comprehensive experiments and ablation studies demonstrate significant and consistent performance improvements on both homophilic and heterophilic graphs across multiple learning settings considering various labeling ratios, which unleashes the potential of polynomial filter learning. ",
    "url": "https://arxiv.org/abs/2307.07956",
    "authors": [
      "Wendi Yu",
      "Zhichao Hou",
      "Xiaorui Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.07957",
    "title": "Generalizable prediction of potential miRNA-disease associations based  on heterogeneous graph learning",
    "abstract": "Biomedical studies have revealed the crucial role of miRNAs in the progression of many diseases, and computational prediction methods are increasingly proposed for assisting biological experiments to verify miRNA-disease associations (MDAs). The generalizability is a significant issue, the prediction ought to be available for entities with fewer or without existing MDAs, while it is previously underemphasized. In this study, we work on the stages of data, model, and result analysis. First, we integrate multi-source data into a miRNA-PCG-disease graph, embracing all authoritative recorded human miRNAs and diseases, and the verified MDAs are split by time and known degree as a benchmark. Second, we propose an end-to-end data-driven model that avoids taking the existing MDAs as an input feature. It performs node feature encoding, graph structure learning, and binary prediction centered on a heterogeneous graph transformer. Finally, computational experiments indicate that our method achieves state-of-the-art performance on basic metrics and effectively alleviates the neglect of less and zero known miRNAs and diseases. Predictions are conducted on all human miRNA-disease pairs, case studies further demonstrate that we can make reliable MDA detections on unseen diseases, and the prediction basis is instance-level explainable. ",
    "url": "https://arxiv.org/abs/2307.07957",
    "authors": [
      "Yi Zhou",
      "Meixuan Wu",
      "Chengzhou Ouyang",
      "Xinyi Wang",
      "Min Zhu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2307.07960",
    "title": "The Roll-Out of Community Notes Did Not Reduce Engagement With  Misinformation on Twitter",
    "abstract": "Developing interventions that successfully reduce engagement with misinformation on social media is challenging. One intervention that has recently gained great attention is Twitter's Community Notes (previously known as \"Birdwatch\"). Community Notes is a crowdsourced fact-checking approach that allows users to write textual notes to inform others about potentially misleading posts on Twitter. Yet, empirical evidence regarding its effectiveness in reducing engagement with misinformation on social media is missing. In this paper, we perform a large-scale empirical study to analyze whether the introduction of the Community Notes feature and its roll-out to users in the U. S. and around the world have reduced engagement with misinformation on Twitter in terms of retweet volume and likes. We employ Difference-in-Difference (DiD) models and Regression Discontinuity Design (RDD) to analyze a comprehensive dataset consisting of all fact-checking notes and corresponding source tweets since the launch of Community Notes in early 2021. Although we observe a significant increase in the volume of fact-checks carried out via Community Notes, particularly for tweets from verified users with many followers, we find no evidence that the introduction of Community Notes significantly reduced engagement with misleading tweets on Twitter. Rather, our findings suggest that Community Notes might be too slow to effectively reduce engagement with misinformation in the early (and most viral) stage of diffusion. Our work emphasizes the importance of evaluating fact-checking interventions in the field and offers important implications to enhance crowdsourced fact-checking strategies on social media. ",
    "url": "https://arxiv.org/abs/2307.07960",
    "authors": [
      "Yuwei Chuai",
      "Haoye Tian",
      "Nicolas Pr\u00f6llochs",
      "Gabriele Lenzini"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2307.07973",
    "title": "Heteroscedastic Causal Structure Learning",
    "abstract": "Heretofore, learning the directed acyclic graphs (DAGs) that encode the cause-effect relationships embedded in observational data is a computationally challenging problem. A recent trend of studies has shown that it is possible to recover the DAGs with polynomial time complexity under the equal variances assumption. However, this prohibits the heteroscedasticity of the noise, which allows for more flexible modeling capabilities, but at the same time is substantially more challenging to handle. In this study, we tackle the heteroscedastic causal structure learning problem under Gaussian noises. By exploiting the normality of the causal mechanisms, we can recover a valid causal ordering, which can uniquely identify the causal DAG using a series of conditional independence tests. The result is HOST (Heteroscedastic causal STructure learning), a simple yet effective causal structure learning algorithm that scales polynomially in both sample size and dimensionality. In addition, via extensive empirical evaluations on a wide range of both controlled and real datasets, we show that the proposed HOST method is competitive with state-of-the-art approaches in both the causal order learning and structure learning problems. ",
    "url": "https://arxiv.org/abs/2307.07973",
    "authors": [
      "Bao Duong",
      "Thin Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2307.07977",
    "title": "Integrating Human Parsing and Pose Network for Human Action Recognition",
    "abstract": "Human skeletons and RGB sequences are both widely-adopted input modalities for human action recognition. However, skeletons lack appearance features and color data suffer large amount of irrelevant depiction. To address this, we introduce human parsing feature map as a novel modality, since it can selectively retain spatiotemporal features of the body parts, while filtering out noises regarding outfits, backgrounds, etc. We propose an Integrating Human Parsing and Pose Network (IPP-Net) for action recognition, which is the first to leverage both skeletons and human parsing feature maps in dual-branch approach. The human pose branch feeds compact skeletal representations of different modalities in graph convolutional network to model pose features. In human parsing branch, multi-frame body-part parsing features are extracted with human detector and parser, which is later learnt using a convolutional backbone. A late ensemble of two branches is adopted to get final predictions, considering both robust keypoints and rich semantic body-part features. Extensive experiments on NTU RGB+D and NTU RGB+D 120 benchmarks consistently verify the effectiveness of the proposed IPP-Net, which outperforms the existing action recognition methods. Our code is publicly available at https://github.com/liujf69/IPP-Net-Parsing . ",
    "url": "https://arxiv.org/abs/2307.07977",
    "authors": [
      "Runwei Ding",
      "Yuhang Wen",
      "Jinfu Liu",
      "Nan Dai",
      "Fanyang Meng",
      "Mengyuan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07980",
    "title": "Byzantine-Robust Distributed Online Learning: Taming Adversarial  Participants in An Adversarial Environment",
    "abstract": "This paper studies distributed online learning under Byzantine attacks. The performance of an online learning algorithm is often characterized by (adversarial) regret, which evaluates the quality of one-step-ahead decision-making when an environment provides adversarial losses, and a sublinear bound is preferred. But we prove that, even with a class of state-of-the-art robust aggregation rules, in an adversarial environment and in the presence of Byzantine participants, distributed online gradient descent can only achieve a linear adversarial regret bound, which is tight. This is the inevitable consequence of Byzantine attacks, even though we can control the constant of the linear adversarial regret to a reasonable level. Interestingly, when the environment is not fully adversarial so that the losses of the honest participants are i.i.d. (independent and identically distributed), we show that sublinear stochastic regret, in contrast to the aforementioned adversarial regret, is possible. We develop a Byzantine-robust distributed online momentum algorithm to attain such a sublinear stochastic regret bound. Extensive numerical experiments corroborate our theoretical analysis. ",
    "url": "https://arxiv.org/abs/2307.07980",
    "authors": [
      "Xingrong Dong",
      "Zhaoxian Wu",
      "Qing Ling",
      "Zhi Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2307.07998",
    "title": "LUCYD: A Feature-Driven Richardson-Lucy Deconvolution Network",
    "abstract": "The process of acquiring microscopic images in life sciences often results in image degradation and corruption, characterised by the presence of noise and blur, which poses significant challenges in accurately analysing and interpreting the obtained data. This paper proposes LUCYD, a novel method for the restoration of volumetric microscopy images that combines the Richardson-Lucy deconvolution formula and the fusion of deep features obtained by a fully convolutional network. By integrating the image formation process into a feature-driven restoration model, the proposed approach aims to enhance the quality of the restored images whilst reducing computational costs and maintaining a high degree of interpretability. Our results demonstrate that LUCYD outperforms the state-of-the-art methods in both synthetic and real microscopy images, achieving superior performance in terms of image quality and generalisability. We show that the model can handle various microscopy modalities and different imaging conditions by evaluating it on two different microscopy datasets, including volumetric widefield and light-sheet microscopy. Our experiments indicate that LUCYD can significantly improve resolution, contrast, and overall quality of microscopy images. Therefore, it can be a valuable tool for microscopy image restoration and can facilitate further research in various microscopy applications. We made the source code for the model accessible under https://github.com/ctom2/lucyd-deconvolution. ",
    "url": "https://arxiv.org/abs/2307.07998",
    "authors": [
      "Tom\u00e1\u0161 Chobola",
      "Gesine M\u00fcller",
      "Veit Dausmann",
      "Anton Theileis",
      "Jan Taucher",
      "Jan Huisken",
      "Tingying Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08007",
    "title": "NoiseBandNet: Controllable Time-Varying Neural Synthesis of Sound  Effects Using Filterbanks",
    "abstract": "Controllable neural audio synthesis of sound effects is a challenging task due to the potential scarcity and spectro-temporal variance of the data. Differentiable digital signal processing (DDSP) synthesisers have been successfully employed to model and control musical and harmonic signals using relatively limited data and computational resources. Here we propose NoiseBandNet, an architecture capable of synthesising and controlling sound effects by filtering white noise through a filterbank, thus going further than previous systems that make assumptions about the harmonic nature of sounds. We evaluate our approach via a series of experiments, modelling footsteps, thunderstorm, pottery, knocking, and metal sound effects. Comparing NoiseBandNet audio reconstruction capabilities to four variants of the DDSP-filtered noise synthesiser, NoiseBandNet scores higher in nine out of ten evaluation categories, establishing a flexible DDSP method for generating time-varying, inharmonic sound effects of arbitrary length with both good time and frequency resolution. Finally, we introduce some potential creative uses of NoiseBandNet, by generating variations, performing loudness transfer, and by training it on user-defined control curves. ",
    "url": "https://arxiv.org/abs/2307.08007",
    "authors": [
      "Adri\u00e1n Barahona-R\u00edos",
      "Tom Collins"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.08025",
    "title": "Analysing Gender Bias in Text-to-Image Models using Object Detection",
    "abstract": "This work presents a novel strategy to measure bias in text-to-image models. Using paired prompts that specify gender and vaguely reference an object (e.g. \"a man/woman holding an item\") we can examine whether certain objects are associated with a certain gender. In analysing results from Stable Diffusion, we observed that male prompts generated objects such as ties, knives, trucks, baseball bats, and bicycles more frequently. On the other hand, female prompts were more likely to generate objects such as handbags, umbrellas, bowls, bottles, and cups. We hope that the method outlined here will be a useful tool for examining bias in text-to-image models. ",
    "url": "https://arxiv.org/abs/2307.08025",
    "authors": [
      "Harvey Mannering"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08026",
    "title": "Weighted Graph Coloring for Quantized Computing",
    "abstract": "We consider the problem of distributed lossless computation of a function of two sources by one common user. To do so, we first build a bipartite graph, where two disjoint parts denote the individual source outcomes. We then project the bipartite graph onto each source to obtain an edge-weighted characteristic graph (EWCG), where edge weights capture the function's structure, by how much the source outcomes are to be distinguished, generalizing the classical notion of characteristic graphs. Via exploiting the notions of characteristic graphs, the fractional coloring of such graphs, and edge weights, the sources separately build multi-fold graphs that capture vector-valued source sequences, determine vertex colorings for such graphs, encode these colorings, and send them to the user that performs minimum-entropy decoding on its received information to recover the desired function in an asymptotically lossless manner. For the proposed EWCG compression setup, we characterize the fundamental limits of distributed compression, verify the communication complexity through an example, contrast it with traditional coloring schemes, and demonstrate that we can attain compression gains higher than $\\% 30$ over traditional coloring. ",
    "url": "https://arxiv.org/abs/2307.08026",
    "authors": [
      "Derya Malak"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2307.08044",
    "title": "Towards Flexible Time-to-event Modeling: Optimizing Neural Networks via  Rank Regression",
    "abstract": "Time-to-event analysis, also known as survival analysis, aims to predict the time of occurrence of an event, given a set of features. One of the major challenges in this area is dealing with censored data, which can make learning algorithms more complex. Traditional methods such as Cox's proportional hazards model and the accelerated failure time (AFT) model have been popular in this field, but they often require assumptions such as proportional hazards and linearity. In particular, the AFT models often require pre-specified parametric distributional assumptions. To improve predictive performance and alleviate strict assumptions, there have been many deep learning approaches for hazard-based models in recent years. However, representation learning for AFT has not been widely explored in the neural network literature, despite its simplicity and interpretability in comparison to hazard-focused methods. In this work, we introduce the Deep AFT Rank-regression model for Time-to-event prediction (DART). This model uses an objective function based on Gehan's rank statistic, which is efficient and reliable for representation learning. On top of eliminating the requirement to establish a baseline event time distribution, DART retains the advantages of directly predicting event time in standard AFT models. The proposed method is a semiparametric approach to AFT modeling that does not impose any distributional assumptions on the survival time distribution. This also eliminates the need for additional hyperparameters or complex model architectures, unlike existing neural network-based AFT models. Through quantitative analysis on various benchmark datasets, we have shown that DART has significant potential for modeling high-throughput censored time-to-event data. ",
    "url": "https://arxiv.org/abs/2307.08044",
    "authors": [
      "Hyunjun Lee",
      "Junhyun Lee",
      "Taehwa Choi",
      "Jaewoo Kang",
      "Sangbum Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.08059",
    "title": "LafitE: Latent Diffusion Model with Feature Editing for Unsupervised  Multi-class Anomaly Detection",
    "abstract": "In the context of flexible manufacturing systems that are required to produce different types and quantities of products with minimal reconfiguration, this paper addresses the problem of unsupervised multi-class anomaly detection: develop a unified model to detect anomalies from objects belonging to multiple classes when only normal data is accessible. We first explore the generative-based approach and investigate latent diffusion models for reconstruction to mitigate the notorious ``identity shortcut'' issue in auto-encoder based methods. We then introduce a feature editing strategy that modifies the input feature space of the diffusion model to further alleviate ``identity shortcuts'' and meanwhile improve the reconstruction quality of normal regions, leading to fewer false positive predictions. Moreover, we are the first who pose the problem of hyperparameter selection in unsupervised anomaly detection, and propose a solution of synthesizing anomaly data for a pseudo validation set to address this problem. Extensive experiments on benchmark datasets MVTec-AD and MPDD show that the proposed LafitE, \\ie, Latent Diffusion Model with Feature Editing, outperforms state-of-art methods by a significant margin in terms of average AUROC. The hyperparamters selected via our pseudo validation set are well-matched to the real test set. ",
    "url": "https://arxiv.org/abs/2307.08059",
    "authors": [
      "Haonan Yin",
      "Guanlong Jiao",
      "Qianhui Wu",
      "Borje F. Karlsson",
      "Biqing Huang",
      "Chin Yew Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08065",
    "title": "MaGNAS: A Mapping-Aware Graph Neural Architecture Search Framework for  Heterogeneous MPSoC Deployment",
    "abstract": "Graph Neural Networks (GNNs) are becoming increasingly popular for vision-based applications due to their intrinsic capacity in modeling structural and contextual relations between various parts of an image frame. On another front, the rising popularity of deep vision-based applications at the edge has been facilitated by the recent advancements in heterogeneous multi-processor Systems on Chips (MPSoCs) that enable inference under real-time, stringent execution requirements. By extension, GNNs employed for vision-based applications must adhere to the same execution requirements. Yet contrary to typical deep neural networks, the irregular flow of graph learning operations poses a challenge to running GNNs on such heterogeneous MPSoC platforms. In this paper, we propose a novel unified design-mapping approach for efficient processing of vision GNN workloads on heterogeneous MPSoC platforms. Particularly, we develop MaGNAS, a mapping-aware Graph Neural Architecture Search framework. MaGNAS proposes a GNN architectural design space coupled with prospective mapping options on a heterogeneous SoC to identify model architectures that maximize on-device resource efficiency. To achieve this, MaGNAS employs a two-tier evolutionary search to identify optimal GNNs and mapping pairings that yield the best performance trade-offs. Through designing a supernet derived from the recent Vision GNN (ViG) architecture, we conducted experiments on four (04) state-of-the-art vision datasets using both (i) a real hardware SoC platform (NVIDIA Xavier AGX) and (ii) a performance/cost model simulator for DNN accelerators. Our experimental results demonstrate that MaGNAS is able to provide 1.57x latency speedup and is 3.38x more energy-efficient for several vision datasets executed on the Xavier MPSoC vs. the GPU-only deployment while sustaining an average 0.11% accuracy reduction from the baseline. ",
    "url": "https://arxiv.org/abs/2307.08065",
    "authors": [
      "Mohanad Odema",
      "Halima Bouzidi",
      "Hamza Ouarnoughi",
      "Smail Niar",
      "Mohammad Abdullah Al Faruque"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08076",
    "title": "Diffusion to Confusion: Naturalistic Adversarial Patch Generation Based  on Diffusion Model for Object Detector",
    "abstract": "Many physical adversarial patch generation methods are widely proposed to protect personal privacy from malicious monitoring using object detectors. However, they usually fail to generate satisfactory patch images in terms of both stealthiness and attack performance without making huge efforts on careful hyperparameter tuning. To address this issue, we propose a novel naturalistic adversarial patch generation method based on the diffusion models (DM). Through sampling the optimal image from the DM model pretrained upon natural images, it allows us to stably craft high-quality and naturalistic physical adversarial patches to humans without suffering from serious mode collapse problems as other deep generative models. To the best of our knowledge, we are the first to propose DM-based naturalistic adversarial patch generation for object detectors. With extensive quantitative, qualitative, and subjective experiments, the results demonstrate the effectiveness of the proposed approach to generate better-quality and more naturalistic adversarial patches while achieving acceptable attack performance than other state-of-the-art patch generation methods. We also show various generation trade-offs under different conditions. ",
    "url": "https://arxiv.org/abs/2307.08076",
    "authors": [
      "Shuo-Yen Lin",
      "Ernie Chu",
      "Che-Hsien Lin",
      "Jun-Cheng Chen",
      "Jia-Ching Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08080",
    "title": "Sampling Proper Colorings on Line Graphs Using $(1+o(1))\u0394$ Colors",
    "abstract": "We prove that the single-site Glauber dynamics for sampling proper $q$-colorings mixes in $O_\\Delta(n\\log n)$ time on line graphs with $n$ vertices and maximum degree $\\Delta$ when $q>(1+o(1))\\Delta$. The main tool in our proof is the matrix trickle-down theorem developed by Abdolazimi, Liu and Oveis Gharan (FOCS, 2021). ",
    "url": "https://arxiv.org/abs/2307.08080",
    "authors": [
      "Yulin Wang",
      "Chihao Zhang",
      "Zihan Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2307.08082",
    "title": "POMDP inference and robust solution via deep reinforcement learning: An  application to railway optimal maintenance",
    "abstract": "Partially Observable Markov Decision Processes (POMDPs) can model complex sequential decision-making problems under stochastic and uncertain environments. A main reason hindering their broad adoption in real-world applications is the lack of availability of a suitable POMDP model or a simulator thereof. Available solution algorithms, such as Reinforcement Learning (RL), require the knowledge of the transition dynamics and the observation generating process, which are often unknown and non-trivial to infer. In this work, we propose a combined framework for inference and robust solution of POMDPs via deep RL. First, all transition and observation model parameters are jointly inferred via Markov Chain Monte Carlo sampling of a hidden Markov model, which is conditioned on actions, in order to recover full posterior distributions from the available data. The POMDP with uncertain parameters is then solved via deep RL techniques with the parameter distributions incorporated into the solution via domain randomization, in order to develop solutions that are robust to model uncertainty. As a further contribution, we compare the use of transformers and long short-term memory networks, which constitute model-free RL solutions, with a model-based/model-free hybrid approach. We apply these methods to the real-world problem of optimal maintenance planning for railway assets. ",
    "url": "https://arxiv.org/abs/2307.08082",
    "authors": [
      "Giacomo Arcieri",
      "Cyprien Hoelzl",
      "Oliver Schwery",
      "Daniel Straub",
      "Konstantinos G. Papakonstantinou",
      "Eleni Chatzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.08092",
    "title": "Gait Data Augmentation using Physics-Based Biomechanical Simulation",
    "abstract": "This paper focuses on addressing the problem of data scarcity for gait analysis. Standard augmentation methods may produce gait sequences that are not consistent with the biomechanical constraints of human walking. To address this issue, we propose a novel framework for gait data augmentation by using OpenSIM, a physics-based simulator, to synthesize biomechanically plausible walking sequences. The proposed approach is validated by augmenting the WBDS and CASIA-B datasets and then training gait-based classifiers for 3D gender gait classification and 2D gait person identification respectively. Experimental results indicate that our augmentation approach can improve the performance of model-based gait classifiers and deliver state-of-the-art results for gait-based person identification with an accuracy of up to 96.11% on the CASIA-B dataset. ",
    "url": "https://arxiv.org/abs/2307.08092",
    "authors": [
      "Mritula Chandrasekaran",
      "Jarek Francik",
      "Dimitrios Makris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08093",
    "title": "Cross-Ray Neural Radiance Fields for Novel-view Synthesis from  Unconstrained Image Collections",
    "abstract": "Neural Radiance Fields (NeRF) is a revolutionary approach for rendering scenes by sampling a single ray per pixel and it has demonstrated impressive capabilities in novel-view synthesis from static scene images. However, in practice, we usually need to recover NeRF from unconstrained image collections, which poses two challenges: 1) the images often have dynamic changes in appearance because of different capturing time and camera settings; 2) the images may contain transient objects such as humans and cars, leading to occlusion and ghosting artifacts. Conventional approaches seek to address these challenges by locally utilizing a single ray to synthesize a color of a pixel. In contrast, humans typically perceive appearance and objects by globally utilizing information across multiple pixels. To mimic the perception process of humans, in this paper, we propose Cross-Ray NeRF (CR-NeRF) that leverages interactive information across multiple rays to synthesize occlusion-free novel views with the same appearances as the images. Specifically, to model varying appearances, we first propose to represent multiple rays with a novel cross-ray feature and then recover the appearance by fusing global statistics, i.e., feature covariance of the rays and the image appearance. Moreover, to avoid occlusion introduced by transient objects, we propose a transient objects handler and introduce a grid sampling strategy for masking out the transient objects. We theoretically find that leveraging correlation across multiple rays promotes capturing more global information. Moreover, extensive experimental results on large real-world datasets verify the effectiveness of CR-NeRF. ",
    "url": "https://arxiv.org/abs/2307.08093",
    "authors": [
      "Yifan Yang",
      "Shuhai Zhang",
      "Zixiong Huang",
      "Yubing Zhang",
      "Mingkui Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08095",
    "title": "Semi-DETR: Semi-Supervised Object Detection with Detection Transformers",
    "abstract": "We analyze the DETR-based framework on semi-supervised object detection (SSOD) and observe that (1) the one-to-one assignment strategy generates incorrect matching when the pseudo ground-truth bounding box is inaccurate, leading to training inefficiency; (2) DETR-based detectors lack deterministic correspondence between the input query and its prediction output, which hinders the applicability of the consistency-based regularization widely used in current SSOD methods. We present Semi-DETR, the first transformer-based end-to-end semi-supervised object detector, to tackle these problems. Specifically, we propose a Stage-wise Hybrid Matching strategy that combines the one-to-many assignment and one-to-one assignment strategies to improve the training efficiency of the first stage and thus provide high-quality pseudo labels for the training of the second stage. Besides, we introduce a Crossview Query Consistency method to learn the semantic feature invariance of object queries from different views while avoiding the need to find deterministic query correspondence. Furthermore, we propose a Cost-based Pseudo Label Mining module to dynamically mine more pseudo boxes based on the matching cost of pseudo ground truth bounding boxes for consistency training. Extensive experiments on all SSOD settings of both COCO and Pascal VOC benchmark datasets show that our Semi-DETR method outperforms all state-of-the-art methods by clear margins. The PaddlePaddle version code1 is at https://github.com/PaddlePaddle/PaddleDetection/tree/develop/configs/semi_det/semi_detr. ",
    "url": "https://arxiv.org/abs/2307.08095",
    "authors": [
      "Jiacheng Zhang",
      "Xiangru Lin",
      "Wei Zhang",
      "Kuo Wang",
      "Xiao Tan",
      "Junyu Han",
      "Errui Ding",
      "Jingdong Wang",
      "Guanbin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08096",
    "title": "Flux-corrected transport stabilization of an evolutionary  cross-diffusion cancer invasion model",
    "abstract": "In the present work, we investigate a model of the invasion of healthy tissue by cancer cells which is described by a system of nonlinear PDEs consisting of a cross-diffusion-reaction equation and two additional nonlinear ordinary differential equations. We show that when the convective part of the system, the chemotactic term, is dominant, then straightforward numerical methods for the studied system may be unstable. We present an implicit finite element method using conforming $P_1$ or $Q_1$ finite elements to discretize the model in space and the $\\theta$-method for discretization in time. The discrete problem is stabilized using a nonlinear flux-corrected transport approach. It is proved that both the nonlinear scheme and the linearized problems used in fixed-point iterations are solvable and positivity preserving. Several numerical experiments are presented in 2D using the deal.II library to demonstrate the performance of the proposed method. ",
    "url": "https://arxiv.org/abs/2307.08096",
    "authors": [
      "Shahin Heydari",
      "Petr Knobloch",
      "Thoma Wick"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2307.08100",
    "title": "FourierHandFlow: Neural 4D Hand Representation Using Fourier Query Flow",
    "abstract": "Recent 4D shape representations model continuous temporal evolution of implicit shapes by (1) learning query flows without leveraging shape and articulation priors or (2) decoding shape occupancies separately for each time value. Thus, they do not effectively capture implicit correspondences between articulated shapes or regularize jittery temporal deformations. In this work, we present FourierHandFlow, which is a spatio-temporally continuous representation for human hands that combines a 3D occupancy field with articulation-aware query flows represented as Fourier series. Given an input RGB sequence, we aim to learn a fixed number of Fourier coefficients for each query flow to guarantee smooth and continuous temporal shape dynamics. To effectively model spatio-temporal deformations of articulated hands, we compose our 4D representation based on two types of Fourier query flow: (1) pose flow that models query dynamics influenced by hand articulation changes via implicit linear blend skinning and (2) shape flow that models query-wise displacement flow. In the experiments, our method achieves state-of-the-art results on video-based 4D reconstruction while being computationally more efficient than the existing 3D/4D implicit shape representations. We additionally show our results on motion inter- and extrapolation and texture transfer using the learned correspondences of implicit shapes. To the best of our knowledge, FourierHandFlow is the first neural 4D continuous hand representation learned from RGB videos. The code will be publicly accessible. ",
    "url": "https://arxiv.org/abs/2307.08100",
    "authors": [
      "Jihyun Lee",
      "Junbong Jang",
      "Donghwan Kim",
      "Minhyuk Sung",
      "Tae-Kyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08122",
    "title": "Tangent Transformers for Composition, Privacy and Removal",
    "abstract": "We introduce Tangent Attention Fine-Tuning (TAFT), a method for fine-tuning linearized transformers obtained by computing a First-order Taylor Expansion around a pre-trained initialization. We show that the Jacobian-Vector Product resulting from linearization can be computed efficiently in a single forward pass, reducing training and inference cost to the same order of magnitude as its original non-linear counterpart, while using the same number of parameters. Furthermore, we show that, when applied to various downstream visual classification tasks, the resulting Tangent Transformer fine-tuned with TAFT can perform comparably with fine-tuning the original non-linear network. Since Tangent Transformers are linear with respect to the new set of weights, and the resulting fine-tuning loss is convex, we show that TAFT enjoys several advantages compared to non-linear fine-tuning when it comes to model composition, parallel training, machine unlearning, and differential privacy. ",
    "url": "https://arxiv.org/abs/2307.08122",
    "authors": [
      "Tian Yu Liu",
      "Aditya Golatkar",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08131",
    "title": "INFLECT-DGNN: Influencer Prediction with Dynamic Graph Neural Networks",
    "abstract": "Leveraging network information for predictive modeling has become widespread in many domains. Within the realm of referral and targeted marketing, influencer detection stands out as an area that could greatly benefit from the incorporation of dynamic network representation due to the ongoing development of customer-brand relationships. To elaborate this idea, we introduce INFLECT-DGNN, a new framework for INFLuencer prEdiCTion with Dynamic Graph Neural Networks that combines Graph Neural Networks (GNN) and Recurrent Neural Networks (RNN) with weighted loss functions, the Synthetic Minority Oversampling TEchnique (SMOTE) adapted for graph data, and a carefully crafted rolling-window strategy. To evaluate predictive performance, we utilize a unique corporate data set with networks of three cities and derive a profit-driven evaluation methodology for influencer prediction. Our results show how using RNN to encode temporal attributes alongside GNNs significantly improves predictive performance. We compare the results of various models to demonstrate the importance of capturing graph representation, temporal dependencies, and using a profit-driven methodology for evaluation. ",
    "url": "https://arxiv.org/abs/2307.08131",
    "authors": [
      "Elena Tiukhova",
      "Emiliano Penaloza",
      "Mar\u00eda \u00d3skarsd\u00f3ttir",
      "Bart Baesens",
      "Monique Snoeck",
      "Cristi\u00e1n Bravo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08132",
    "title": "Heterogeneous graphs model spatial relationships between biological  entities for breast cancer diagnosis",
    "abstract": "The heterogeneity of breast cancer presents considerable challenges for its early detection, prognosis, and treatment selection. Convolutional neural networks often neglect the spatial relationships within histopathological images, which can limit their accuracy. Graph neural networks (GNNs) offer a promising solution by coding the spatial relationships within images. Prior studies have investigated the modeling of histopathological images as cell and tissue graphs, but they have not fully tapped into the potential of extracting interrelationships between these biological entities. In this paper, we present a novel approach using a heterogeneous GNN that captures the spatial and hierarchical relations between cell and tissue graphs to enhance the extraction of useful information from histopathological images. We also compare the performance of a cross-attention-based network and a transformer architecture for modeling the intricate relationships within tissue and cell graphs. Our model demonstrates superior efficiency in terms of parameter count and achieves higher accuracy compared to the transformer-based state-of-the-art approach on three publicly available breast cancer datasets -- BRIGHT, BreakHis, and BACH. ",
    "url": "https://arxiv.org/abs/2307.08132",
    "authors": [
      "Akhila Krishna K",
      "Ravi Kant Gupta",
      "Nikhil Cherian Kurian",
      "Pranav Jeevan",
      "Amit Sethi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08142",
    "title": "Neural Stream Functions",
    "abstract": "We present a neural network approach to compute stream functions, which are scalar functions with gradients orthogonal to a given vector field. As a result, isosurfaces of the stream function extract stream surfaces, which can be visualized to analyze flow features. Our approach takes a vector field as input and trains an implicit neural representation to learn a stream function for that vector field. The network learns to map input coordinates to a stream function value by minimizing the inner product of the gradient of the neural network's output and the vector field. Since stream function solutions may not be unique, we give optional constraints for the network to learn particular stream functions of interest. Specifically, we introduce regularizing loss functions that can optionally be used to generate stream function solutions whose stream surfaces follow the flow field's curvature, or that can learn a stream function that includes a stream surface passing through a seeding rake. We also discuss considerations for properly visualizing the trained implicit network and extracting artifact-free surfaces. We compare our results with other implicit solutions and present qualitative and quantitative results for several synthetic and simulated vector fields. ",
    "url": "https://arxiv.org/abs/2307.08142",
    "authors": [
      "Skylar Wolfgang Wurster",
      "Hanqi Guo",
      "Tom Peterka",
      "Han-Wei Shen"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08145",
    "title": "Self-Attention Based Generative Adversarial Networks For Unsupervised  Video Summarization",
    "abstract": "In this paper, we study the problem of producing a comprehensive video summary following an unsupervised approach that relies on adversarial learning. We build on a popular method where a Generative Adversarial Network (GAN) is trained to create representative summaries, indistinguishable from the originals. The introduction of the attention mechanism into the architecture for the selection, encoding and decoding of video frames, shows the efficacy of self-attention and transformer in modeling temporal relationships for video summarization. We propose the SUM-GAN-AED model that uses a self-attention mechanism for frame selection, combined with LSTMs for encoding and decoding. We evaluate the performance of the SUM-GAN-AED model on the SumMe, TVSum and COGNIMUSE datasets. Experimental results indicate that using a self-attention mechanism as the frame selection mechanism outperforms the state-of-the-art on SumMe and leads to comparable to state-of-the-art performance on TVSum and COGNIMUSE. ",
    "url": "https://arxiv.org/abs/2307.08145",
    "authors": [
      "Maria Nektaria Minaidi",
      "Charilaos Papaioannou",
      "Alexandros Potamianos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08159",
    "title": "Knowledge Gain as Privacy Loss in Local Differential Privacy Accounting",
    "abstract": "This paper establishes the equivalence between Local Differential Privacy (LDP) and a global limit on learning any knowledge about an object. However, an output from an LDP query is not necessarily required to provide exact amount of knowledge equal to the upper bound of the learning limit. Since the amount of knowledge gain should be proportional to the incurred privacy loss, the traditional approach of using DP guarantee to measure privacy loss can occasionally overestimate the actual privacy loss. This is especially problematic in privacy accounting in LDP, where privacy loss is computed by summing the DP guarantees (basic composition). To address this issue, this paper introduces the concept of realized privacy loss, which measures the actual knowledge gained by the analyst after a query, as a more accurate measure of privacy loss. The realized privacy loss is then integrated into the privacy accounting of fully adaptive composition, where an adversary adaptively selects queries based on previous results. The Bayesian Privacy Filter is implemented to ensure that the realized privacy loss of the composed queries eventually reaches the DP guarantee, allowing the full utilization of the privacy budget assigned to a queried object. Furthermore, this paper introduces the Bayesian Privacy Odometer to measure realized privacy loss in fully adaptive composition. Experimental evaluations are conducted to assess the efficiency of the Bayesian Privacy Filter, demonstrating that the corresponding composition can accept arbitrarily more queries than the basic composition when the composed queries have sufficiently small DP guarantees. Conversely, this paper concludes, through experiments, that when estimating the histogram of a group of objects with the same privacy budget, an analyst should prefer using a single randomized response over a composition managed by the Bayesian Privacy Filter. ",
    "url": "https://arxiv.org/abs/2307.08159",
    "authors": [
      "Mingen Pan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.08162",
    "title": "Better Diameter Algorithms for Bounded VC-dimension Graphs and Geometric  Intersection Graphs",
    "abstract": "We develop a framework for algorithms finding diameter in graphs of bounded distance Vapnik-Chervonenkis dimension, in (parametrized) sub-quadratic time complexity. The class of bounded distance VC-dimension graphs is wide, including, e.g. all minor-free graphs. We build on the work of Ducoffe et al., improving their technique. With our approach the algorithms become simpler and faster, working in $\\widetilde{\\mathcal{O}}(k \\cdot V^{1-1/d} \\cdot E)$ time complexity, where $k$ is the diameter, $d$ is the VC-dimension. Furthermore, it allows us to use the technique in more general setting. In particular, we use this framework for geometric intersection graphs, i.e. graphs where vertices are identical geometric objects on a plane and the adjacency is defined by intersection. Applying our approach for these graphs, we answer a question posed by Bringmann et al., finding a $\\widetilde{\\mathcal{O}}(n^{7/4})$ parametrized diameter algorithm for unit square intersection graph of size $n$, as well as a more general algorithm for convex polygon intersection graphs. ",
    "url": "https://arxiv.org/abs/2307.08162",
    "authors": [
      "Lech Duraj",
      "Filip Konieczny",
      "Krzysztof Pot\u0119pa"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2307.08163",
    "title": "Boundary-weighted logit consistency improves calibration of segmentation  networks",
    "abstract": "Neural network prediction probabilities and accuracy are often only weakly-correlated. Inherent label ambiguity in training data for image segmentation aggravates such miscalibration. We show that logit consistency across stochastic transformations acts as a spatially varying regularizer that prevents overconfident predictions at pixels with ambiguous labels. Our boundary-weighted extension of this regularizer provides state-of-the-art calibration for prostate and heart MRI segmentation. ",
    "url": "https://arxiv.org/abs/2307.08163",
    "authors": [
      "Neerav Karani",
      "Neel Dey",
      "Polina Golland"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08178",
    "title": "Robot motor learning shows emergence of frequency-modulated, robust  swimming with an invariant Strouhal-number",
    "abstract": "Fish locomotion emerges from a diversity of interactions among deformable structures, surrounding fluids and neuromuscular activations, i.e., fluid-structure interactions (FSI) controlled by fish's motor systems. Previous studies suggested that such motor-controlled FSI may possess embodied traits. However, their implications in motor learning, neuromuscular control, gait generation, and swimming performance remain to be uncovered. Using robot models, we studied how swimming behaviours emerged from the FSI and the embodied traits. We developed modular robots with various designs and used Central Pattern Generators (CPGs) to control the torque acting on robot body. We used reinforcement learning to learn CPG parameters to maximize the swimming speed. The results showed that motor frequency converged faster than other parameters, and the emergent swimming gaits were robust against disruptions applied to motor control. For all robots and frequencies tested, swimming speed was proportional to the mean undulation velocity of body and caudal-fin combined, yielding an invariant, undulation-based Strouhal number. The Strouhal number also revealed two fundamental classes of undulatory swimming in both biological and robotic fishes. The robot actuators also demonstrated diverse functions as motors, virtual springs, and virtual masses. These results provide novel insights into the embodied traits of motor-controlled FSI for fish-inspired locomotion. ",
    "url": "https://arxiv.org/abs/2307.08178",
    "authors": [
      "Hankun Deng",
      "Donghao Li",
      "Colin Nitroy",
      "Andrew Wertz",
      "Shashank Priya",
      "Bo Cheng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.08192",
    "title": "HOPE: High-order Polynomial Expansion of Black-box Neural Networks",
    "abstract": "Despite their remarkable performance, deep neural networks remain mostly ``black boxes'', suggesting inexplicability and hindering their wide applications in fields requiring making rational decisions. Here we introduce HOPE (High-order Polynomial Expansion), a method for expanding a network into a high-order Taylor polynomial on a reference input. Specifically, we derive the high-order derivative rule for composite functions and extend the rule to neural networks to obtain their high-order derivatives quickly and accurately. From these derivatives, we can then derive the Taylor polynomial of the neural network, which provides an explicit expression of the network's local interpretations. Numerical analysis confirms the high accuracy, low computational complexity, and good convergence of the proposed method. Moreover, we demonstrate HOPE's wide applications built on deep learning, including function discovery, fast inference, and feature selection. The code is available at https://github.com/HarryPotterXTX/HOPE.git. ",
    "url": "https://arxiv.org/abs/2307.08192",
    "authors": [
      "Tingxiong Xiao",
      "Weihang Zhang",
      "Yuxiao Cheng",
      "Jinli Suo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.08197",
    "title": "Towards Self-Assembling Artificial Neural Networks through Neural  Developmental Programs",
    "abstract": "Biological nervous systems are created in a fundamentally different way than current artificial neural networks. Despite its impressive results in a variety of different domains, deep learning often requires considerable engineering effort to design high-performing neural architectures. By contrast, biological nervous systems are grown through a dynamic self-organizing process. In this paper, we take initial steps toward neural networks that grow through a developmental process that mirrors key properties of embryonic development in biological organisms. The growth process is guided by another neural network, which we call a Neural Developmental Program (NDP) and which operates through local communication alone. We investigate the role of neural growth on different machine learning benchmarks and different optimization methods (evolutionary training, online RL, offline RL, and supervised learning). Additionally, we highlight future research directions and opportunities enabled by having self-organization driving the growth of neural networks. ",
    "url": "https://arxiv.org/abs/2307.08197",
    "authors": [
      "Elias Najarro",
      "Shyam Sudhakaran",
      "Sebastian Risi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.08202",
    "title": "Joint Beamforming and User Association Design for Integrated  HAPS-Terrestrial Networks",
    "abstract": "Located in the stratospheric layer of Earth's atmosphere, the high altitude platform station (HAPS) is a promising network infrastructure, which can bring significant advantages to sixth-generation (6G) and beyond wireless communications systems by forming vertical heterogeneous networks (vHetNets). However, if not dealt with properly, integrated networks suffer from a number of performance challenges compared to standalone networks. In harmonized integrated networks, where different tiers share the same frequency spectrum, interference is an important challenge to be addressed. This work focuses on an integrated HAPS-terrestrial network, serving users in an overlapped urban geographic area, and formulates a fairness optimization problem, aiming to maximize the minimum spectral efficiency (SE) of the network. Due to the highly nonconvex nature of the formulated problem, we develop a fast converging iterative algorithm that designs the massive multiple-input multiple-output (mMIMO) beamforming weights and the user association scheme such that the propagated inter- and intra-tier interference is managed. Simulation results demonstrate the proposed algorithm's superiority over standalone terrestrial networks and baseline algorithms. ",
    "url": "https://arxiv.org/abs/2307.08202",
    "authors": [
      "Afsoon Alidadi Shamsabadi",
      "Animesh Yadav",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.08208",
    "title": "Towards Stealthy Backdoor Attacks against Speech Recognition via  Elements of Sound",
    "abstract": "Deep neural networks (DNNs) have been widely and successfully adopted and deployed in various applications of speech recognition. Recently, a few works revealed that these models are vulnerable to backdoor attacks, where the adversaries can implant malicious prediction behaviors into victim models by poisoning their training process. In this paper, we revisit poison-only backdoor attacks against speech recognition. We reveal that existing methods are not stealthy since their trigger patterns are perceptible to humans or machine detection. This limitation is mostly because their trigger patterns are simple noises or separable and distinctive clips. Motivated by these findings, we propose to exploit elements of sound ($e.g.$, pitch and timbre) to design more stealthy yet effective poison-only backdoor attacks. Specifically, we insert a short-duration high-pitched signal as the trigger and increase the pitch of remaining audio clips to `mask' it for designing stealthy pitch-based triggers. We manipulate timbre features of victim audios to design the stealthy timbre-based attack and design a voiceprint selection module to facilitate the multi-backdoor attack. Our attacks can generate more `natural' poisoned samples and therefore are more stealthy. Extensive experiments are conducted on benchmark datasets, which verify the effectiveness of our attacks under different settings ($e.g.$, all-to-one, all-to-all, clean-label, physical, and multi-backdoor settings) and their stealthiness. The code for reproducing main experiments are available at \\url{https://github.com/HanboCai/BadSpeech_SoE}. ",
    "url": "https://arxiv.org/abs/2307.08208",
    "authors": [
      "Hanbo Cai",
      "Pengcheng Zhang",
      "Hai Dong",
      "Yan Xiao",
      "Stefanos Koffas",
      "Yiming Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.08209",
    "title": "Ada3D : Exploiting the Spatial Redundancy with Adaptive Inference for  Efficient 3D Object Detection",
    "abstract": "Voxel-based methods have achieved state-of-the-art performance for 3D object detection in autonomous driving. However, their significant computational and memory costs pose a challenge for their application to resource-constrained vehicles. One reason for this high resource consumption is the presence of a large number of redundant background points in Lidar point clouds, resulting in spatial redundancy in both 3D voxel and dense BEV map representations. To address this issue, we propose an adaptive inference framework called Ada3D, which focuses on exploiting the input-level spatial redundancy. Ada3D adaptively filters the redundant input, guided by a lightweight importance predictor and the unique properties of the Lidar point cloud. Additionally, we utilize the BEV features' intrinsic sparsity by introducing the Sparsity Preserving Batch Normalization. With Ada3D, we achieve 40% reduction for 3D voxels and decrease the density of 2D BEV feature maps from 100% to 20% without sacrificing accuracy. Ada3D reduces the model computational and memory cost by 5x, and achieves 1.52x/1.45x end-to-end GPU latency and 1.5x/4.5x GPU peak memory optimization for the 3D and 2D backbone respectively. ",
    "url": "https://arxiv.org/abs/2307.08209",
    "authors": [
      "Tianchen Zhao",
      "Xuefei Ning",
      "Ke Hong",
      "Zhongyuan Qiu",
      "Pu Lu",
      "Yali Zhao",
      "Linfeng Zhang",
      "Lipu Zhou",
      "Guohao Dai",
      "Huazhong Yang",
      "Yu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08220",
    "title": "A Lightweight Framework for High-Quality Code Generation",
    "abstract": "In recent years, the use of automated source code generation utilizing transformer-based generative models has expanded, and these models can generate functional code according to the requirements of the developers. However, recent research revealed that these automatically generated source codes can contain vulnerabilities and other quality issues. Despite researchers' and practitioners' attempts to enhance code generation models, retraining and fine-tuning large language models is time-consuming and resource-intensive. Thus, we describe FRANC, a lightweight framework for recommending more secure and high-quality source code derived from transformer-based code generation models. FRANC includes a static filter to make the generated code compilable with heuristics and a quality-aware ranker to sort the code snippets based on a quality score. Moreover, the framework uses prompt engineering to fix persistent quality issues. We evaluated the framework with five Python and Java code generation models and six prompt datasets, including a newly created one in this work (SOEval). The static filter improves 9% to 46% Java suggestions and 10% to 43% Python suggestions regarding compilability. The average improvement over the NDCG@10 score for the ranking system is 0.0763, and the repairing techniques repair the highest 80% of prompts. FRANC takes, on average, 1.98 seconds for Java; for Python, it takes 0.08 seconds. ",
    "url": "https://arxiv.org/abs/2307.08220",
    "authors": [
      "Mohammed Latif Siddiq",
      "Beatrice Casey",
      "Joanna C. S. Santos"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08221",
    "title": "NDT-Map-Code: A 3D global descriptor for real-time loop closure  detection in lidar SLAM",
    "abstract": "Loop-closure detection, also known as place recognition, aiming to identify previously visited locations, is an essential component of a SLAM system. Existing research on lidar-based loop closure heavily relies on dense point cloud and 360 FOV lidars. This paper proposes an out-of-the-box NDT (Normal Distribution Transform) based global descriptor, NDT-Map-Code, designed for both on-road driving and underground valet parking scenarios. NDT-Map-Code can be directly extracted from the NDT map without the need for a dense point cloud, resulting in excellent scalability and low maintenance cost. The NDT representation is leveraged to identify representative patterns, which are further encoded according to their spatial location (bearing, range, and height). Experimental results on the NIO underground parking lot dataset and the KITTI dataset demonstrate that our method achieves significantly better performance compared to the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2307.08221",
    "authors": [
      "Lizhou Liao",
      "Li Sun",
      "Xinhui Bai",
      "Zhenxing You",
      "Hongyuan Yuan",
      "Chunyun Fu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.08233",
    "title": "ROFusion: Efficient Object Detection using Hybrid Point-wise  Radar-Optical Fusion",
    "abstract": "Radars, due to their robustness to adverse weather conditions and ability to measure object motions, have served in autonomous driving and intelligent agents for years. However, Radar-based perception suffers from its unintuitive sensing data, which lack of semantic and structural information of scenes. To tackle this problem, camera and Radar sensor fusion has been investigated as a trending strategy with low cost, high reliability and strong maintenance. While most recent works explore how to explore Radar point clouds and images, rich contextual information within Radar observation are discarded. In this paper, we propose a hybrid point-wise Radar-Optical fusion approach for object detection in autonomous driving scenarios. The framework benefits from dense contextual information from both the range-doppler spectrum and images which are integrated to learn a multi-modal feature representation. Furthermore, we propose a novel local coordinate formulation, tackling the object detection task in an object-centric coordinate. Extensive results show that with the information gained from optical images, we could achieve leading performance in object detection (97.69\\% recall) compared to recent state-of-the-art methods FFT-RadNet (82.86\\% recall). Ablation studies verify the key design choices and practicability of our approach given machine generated imperfect detections. The code will be available at https://github.com/LiuLiu-55/ROFusion. ",
    "url": "https://arxiv.org/abs/2307.08233",
    "authors": [
      "Liu Liu",
      "Shuaifeng Zhi",
      "Zhenhua Du",
      "Li Liu",
      "Xinyu Zhang",
      "Kai Huo",
      "Weidong Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.08235",
    "title": "HeroLT: Benchmarking Heterogeneous Long-Tailed Learning",
    "abstract": "Long-tailed data distributions are prevalent in a variety of domains, including finance, e-commerce, biomedical science, and cyber security. In such scenarios, the performance of machine learning models is often dominated by the head categories, while the learning of tail categories is significantly inadequate. Given abundant studies conducted to alleviate the issue, this work aims to provide a systematic view of long-tailed learning with regard to three pivotal angles: (A1) the characterization of data long-tailedness, (A2) the data complexity of various domains, and (A3) the heterogeneity of emerging tasks. To achieve this, we develop the most comprehensive (to the best of our knowledge) long-tailed learning benchmark named HeroLT, which integrates 13 state-of-the-art algorithms and 6 evaluation metrics on 14 real-world benchmark datasets across 4 tasks from 3 domains. HeroLT with novel angles and extensive experiments (264 in total) enables researchers and practitioners to effectively and fairly evaluate newly proposed methods compared with existing baselines on varying types of datasets. Finally, we conclude by highlighting the significant applications of long-tailed learning and identifying several promising future directions. For accessibility and reproducibility, we open-source our benchmark HeroLT and corresponding results at https://github.com/SSSKJ/HeroLT. ",
    "url": "https://arxiv.org/abs/2307.08235",
    "authors": [
      "Haohui Wang",
      "Weijie Guan",
      "Jianpeng Chen",
      "Zi Wang",
      "Dawei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08237",
    "title": "A Look into Causal Effects under Entangled Treatment in Graphs:  Investigating the Impact of Contact on MRSA Infection",
    "abstract": "Methicillin-resistant Staphylococcus aureus (MRSA) is a type of bacteria resistant to certain antibiotics, making it difficult to prevent MRSA infections. Among decades of efforts to conquer infectious diseases caused by MRSA, many studies have been proposed to estimate the causal effects of close contact (treatment) on MRSA infection (outcome) from observational data. In this problem, the treatment assignment mechanism plays a key role as it determines the patterns of missing counterfactuals -- the fundamental challenge of causal effect estimation. Most existing observational studies for causal effect learning assume that the treatment is assigned individually for each unit. However, on many occasions, the treatments are pairwisely assigned for units that are connected in graphs, i.e., the treatments of different units are entangled. Neglecting the entangled treatments can impede the causal effect estimation. In this paper, we study the problem of causal effect estimation with treatment entangled in a graph. Despite a few explorations for entangled treatments, this problem still remains challenging due to the following challenges: (1) the entanglement brings difficulties in modeling and leveraging the unknown treatment assignment mechanism; (2) there may exist hidden confounders which lead to confounding biases in causal effect estimation; (3) the observational data is often time-varying. To tackle these challenges, we propose a novel method NEAT, which explicitly leverages the graph structure to model the treatment assignment mechanism, and mitigates confounding biases based on the treatment assignment modeling. We also extend our method into a dynamic setting to handle time-varying observational data. Experiments on both synthetic datasets and a real-world MRSA dataset validate the effectiveness of the proposed method, and provide insights for future applications. ",
    "url": "https://arxiv.org/abs/2307.08237",
    "authors": [
      "Jing Ma",
      "Chen Chen",
      "Anil Vullikanti",
      "Ritwick Mishra",
      "Gregory Madden",
      "Daniel Borrajo",
      "Jundong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.08238",
    "title": "Unified Open-Vocabulary Dense Visual Prediction",
    "abstract": "In recent years, open-vocabulary (OV) dense visual prediction (such as OV object detection, semantic, instance and panoptic segmentations) has attracted increasing research attention. However, most of existing approaches are task-specific and individually tackle each task. In this paper, we propose a Unified Open-Vocabulary Network (UOVN) to jointly address four common dense prediction tasks. Compared with separate models, a unified network is more desirable for diverse industrial applications. Moreover, OV dense prediction training data is relatively less. Separate networks can only leverage task-relevant training data, while a unified approach can integrate diverse training data to boost individual tasks. We address two major challenges in unified OV prediction. Firstly, unlike unified methods for fixed-set predictions, OV networks are usually trained with multi-modal data. Therefore, we propose a multi-modal, multi-scale and multi-task (MMM) decoding mechanism to better leverage multi-modal data. Secondly, because UOVN uses data from different tasks for training, there are significant domain and task gaps. We present a UOVN training mechanism to reduce such gaps. Experiments on four datasets demonstrate the effectiveness of our UOVN. ",
    "url": "https://arxiv.org/abs/2307.08238",
    "authors": [
      "Hengcan Shi",
      "Munawar Hayat",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08252",
    "title": "Large-Scale Person Detection and Localization using Overhead Fisheye  Cameras",
    "abstract": "Location determination finds wide applications in daily life. Instead of existing efforts devoted to localizing tourist photos captured by perspective cameras, in this article, we focus on devising person positioning solutions using overhead fisheye cameras. Such solutions are advantageous in large field of view (FOV), low cost, anti-occlusion, and unaggressive work mode (without the necessity of cameras carried by persons). However, related studies are quite scarce, due to the paucity of data. To stimulate research in this exciting area, we present LOAF, the first large-scale overhead fisheye dataset for person detection and localization. LOAF is built with many essential features, e.g., i) the data cover abundant diversities in scenes, human pose, density, and location; ii) it contains currently the largest number of annotated pedestrian, i.e., 457K bounding boxes with groundtruth location information; iii) the body-boxes are labeled as radius-aligned so as to fully address the positioning challenge. To approach localization, we build a fisheye person detection network, which exploits the fisheye distortions by a rotation-equivariant training strategy and predict radius-aligned human boxes end-to-end. Then, the actual locations of the detected persons are calculated by a numerical solution on the fisheye model and camera altitude data. Extensive experiments on LOAF validate the superiority of our fisheye detector w.r.t. previous methods, and show that our whole fisheye positioning solution is able to locate all persons in FOV with an accuracy of 0.5 m, within 0.1 s. ",
    "url": "https://arxiv.org/abs/2307.08252",
    "authors": [
      "Lu Yang",
      "Liulei Li",
      "Xueshi Xin",
      "Yifan Sun",
      "Qing Song",
      "Wenguan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08260",
    "title": "Extending the Frontier of ChatGPT: Code Generation and Debugging",
    "abstract": "Large-scale language models (LLMs) have emerged as a groundbreaking innovation in the realm of question-answering and conversational agents. These models, leveraging different deep learning architectures such as Transformers, are trained on vast corpora to predict sentences based on given queries. Among these LLMs, ChatGPT, developed by OpenAI, has ushered in a new era by utilizing artificial intelligence (AI) to tackle diverse problem domains, ranging from composing essays and biographies to solving intricate mathematical integrals. The versatile applications enabled by ChatGPT offer immense value to users. However, assessing the performance of ChatGPT's output poses a challenge, particularly in scenarios where queries lack clear objective criteria for correctness. For instance, evaluating the quality of generated essays becomes arduous and relies heavily on manual labor, in stark contrast to evaluating solutions to well-defined, closed-ended questions such as mathematical problems. This research paper delves into the efficacy of ChatGPT in solving programming problems, examining both the correctness and the efficiency of its solution in terms of time and memory complexity. The research reveals a commendable overall success rate of 71.875\\%, denoting the proportion of problems for which ChatGPT was able to provide correct solutions that successfully satisfied all the test cases present in Leetcode. It exhibits strengths in structured problems and shows a linear correlation between its success rate and problem acceptance rates. However, it struggles to improve solutions based on feedback, pointing to potential shortcomings in debugging tasks. These findings provide a compact yet insightful glimpse into ChatGPT's capabilities and areas for improvement. ",
    "url": "https://arxiv.org/abs/2307.08260",
    "authors": [
      "Fardin Ahsan Sakib",
      "Saadat Hasan Khan",
      "A. H. M. Rezaul Karim"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.08262",
    "title": "Team Badminseok at IJCAI CoachAI Badminton Challenge 2023: Multi-Layer  Multi-Input Transformer Network (MuLMINet) with Weighted Loss",
    "abstract": "The increasing use of artificial intelligence (AI) technology in turn-based sports, such as badminton, has sparked significant interest in evaluating strategies through the analysis of match video data. Predicting future shots based on past ones plays a vital role in coaching and strategic planning. In this study, we present a Multi-Layer Multi-Input Transformer Network (MuLMINet) that leverages professional badminton player match data to accurately predict future shot types and area coordinates. Our approach resulted in achieving the runner-up (2nd place) in the IJCAI CoachAI Badminton Challenge 2023, Track 2. To facilitate further research, we have made our code publicly accessible online, contributing to the broader research community's knowledge and advancements in the field of AI-assisted sports analysis. ",
    "url": "https://arxiv.org/abs/2307.08262",
    "authors": [
      "Minwoo Seong",
      "Jeongseok Oh",
      "SeungJun Kim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.08278",
    "title": "Adversarial Attacks on Traffic Sign Recognition: A Survey",
    "abstract": "Traffic sign recognition is an essential component of perception in autonomous vehicles, which is currently performed almost exclusively with deep neural networks (DNNs). However, DNNs are known to be vulnerable to adversarial attacks. Several previous works have demonstrated the feasibility of adversarial attacks on traffic sign recognition models. Traffic signs are particularly promising for adversarial attack research due to the ease of performing real-world attacks using printed signs or stickers. In this work, we survey existing works performing either digital or real-world attacks on traffic sign detection and classification models. We provide an overview of the latest advancements and highlight the existing research areas that require further investigation. ",
    "url": "https://arxiv.org/abs/2307.08278",
    "authors": [
      "Svetlana Pavlitska",
      "Nico Lambing",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08287",
    "title": "Drawing non-planar graphs with rotation systems on the Klein bottle",
    "abstract": "This paper provides a linear time algorithm in the number of edges that, given a simple 3-connected non-planar graph G with a Klein bottle rotation system, outputs a straight line drawing of G with no crossings on the flat Klein bottle. ",
    "url": "https://arxiv.org/abs/2307.08287",
    "authors": [
      "Fran\u00e7ois Dor\u00e9",
      "Enrico Formenti"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2307.08288",
    "title": "Systematic Testing of the Data-Poisoning Robustness of KNN",
    "abstract": "Data poisoning aims to compromise a machine learning based software component by contaminating its training set to change its prediction results for test inputs. Existing methods for deciding data-poisoning robustness have either poor accuracy or long running time and, more importantly, they can only certify some of the truly-robust cases, but remain inconclusive when certification fails. In other words, they cannot falsify the truly-non-robust cases. To overcome this limitation, we propose a systematic testing based method, which can falsify as well as certify data-poisoning robustness for a widely used supervised-learning technique named k-nearest neighbors (KNN). Our method is faster and more accurate than the baseline enumeration method, due to a novel over-approximate analysis in the abstract domain, to quickly narrow down the search space, and systematic testing in the concrete domain, to find the actual violations. We have evaluated our method on a set of supervised-learning datasets. Our results show that the method significantly outperforms state-of-the-art techniques, and can decide data-poisoning robustness of KNN prediction results for most of the test inputs. ",
    "url": "https://arxiv.org/abs/2307.08288",
    "authors": [
      "Yannan Li",
      "Jingbo Wang",
      "Chao Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08296",
    "title": "1 JCAS-Enabled Sensing as a Service in 6th-Generation Mobile  Communication Networks",
    "abstract": "The introduction of new types of frequency spectrum in 6G technology facilitates the convergence of conventional mobile communications and radar functions. Thus, the mobile network itself becomes a versatile sensor system. This enables mobile network operators to offer a sensing service in addition to conventional data and telephony services. The potential benefits are expected to accrue to various stakeholders, including individuals, the environment, and society in general. The paper discusses technological development, possible integration, and use cases, as well as future development areas. ",
    "url": "https://arxiv.org/abs/2307.08296",
    "authors": [
      "Christof A. O. Rauber",
      "Lukas Brechtel",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.08301",
    "title": "Environment Knowledge Supported RAN Control for 6G Campus Networks",
    "abstract": "In this paper, the authors present a Radio Access Network (RAN) concept for future mobile communication systems beyond 5G. The concept is based on knowledge of the environment. The three conceptual applications RAN authentication, beam steering, and channel estimation are presented and their added value with respect to 6G development goals is outlined. The concept is explained by means of an intralogistic use case of a fully automated warehouse. Based on this, the concrete steps for implementation in a laboratory setup are described and further research steps are shown. ",
    "url": "https://arxiv.org/abs/2307.08301",
    "authors": [
      "Lukas Brechtel",
      "Christof A. O. Rauber",
      "Christoph Fischer"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.08317",
    "title": "AltFreezing for More General Video Face Forgery Detection",
    "abstract": "Existing face forgery detection models try to discriminate fake images by detecting only spatial artifacts (e.g., generative artifacts, blending) or mainly temporal artifacts (e.g., flickering, discontinuity). They may experience significant performance degradation when facing out-domain artifacts. In this paper, we propose to capture both spatial and temporal artifacts in one model for face forgery detection. A simple idea is to leverage a spatiotemporal model (3D ConvNet). However, we find that it may easily rely on one type of artifact and ignore the other. To address this issue, we present a novel training strategy called AltFreezing for more general face forgery detection. The AltFreezing aims to encourage the model to detect both spatial and temporal artifacts. It divides the weights of a spatiotemporal network into two groups: spatial-related and temporal-related. Then the two groups of weights are alternately frozen during the training process so that the model can learn spatial and temporal features to distinguish real or fake videos. Furthermore, we introduce various video-level data augmentation methods to improve the generalization capability of the forgery detection model. Extensive experiments show that our framework outperforms existing methods in terms of generalization to unseen manipulations and datasets. Code is available at https: //github.com/ZhendongWang6/AltFreezing. ",
    "url": "https://arxiv.org/abs/2307.08317",
    "authors": [
      "Zhendong Wang",
      "Jianmin Bao",
      "Wengang Zhou",
      "Weilun Wang",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08318",
    "title": "Airway Label Prediction in Video Bronchoscopy: Capturing Temporal  Dependencies Utilizing Anatomical Knowledge",
    "abstract": "Purpose: Navigation guidance is a key requirement for a multitude of lung interventions using video bronchoscopy. State-of-the-art solutions focus on lung biopsies using electromagnetic tracking and intraoperative image registration w.r.t. preoperative CT scans for guidance. The requirement of patient-specific CT scans hampers the utilisation of navigation guidance for other applications such as intensive care units. Methods: This paper addresses navigation guidance solely incorporating bronchosopy video data. In contrast to state-of-the-art approaches we entirely omit the use of electromagnetic tracking and patient-specific CT scans. Guidance is enabled by means of topological bronchoscope localization w.r.t. an interpatient airway model. Particularly, we take maximally advantage of anatomical constraints of airway trees being sequentially traversed. This is realized by incorporating sequences of CNN-based airway likelihoods into a Hidden Markov Model. Results: Our approach is evaluated based on multiple experiments inside a lung phantom model. With the consideration of temporal context and use of anatomical knowledge for regularization, we are able to improve the accuracy up to to 0.98 compared to 0.81 (weighted F1: 0.98 compared to 0.81) for a classification based on individual frames. Conclusion: We combine CNN-based single image classification of airway segments with anatomical constraints and temporal HMM-based inference for the first time. Our approach renders vision-only guidance for bronchoscopy interventions in the absence of electromagnetic tracking and patient-specific CT scans possible. ",
    "url": "https://arxiv.org/abs/2307.08318",
    "authors": [
      "Ron Keuth",
      "Mattias Heinrich",
      "Martin Eichenlaub",
      "Marian Himstedt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08321",
    "title": "Legal Syllogism Prompting: Teaching Large Language Models for Legal  Judgment Prediction",
    "abstract": "Legal syllogism is a form of deductive reasoning commonly used by legal professionals to analyze cases. In this paper, we propose legal syllogism prompting (LoT), a simple prompting method to teach large language models (LLMs) for legal judgment prediction. LoT teaches only that in the legal syllogism the major premise is law, the minor premise is the fact, and the conclusion is judgment. Then the models can produce a syllogism reasoning of the case and give the judgment without any learning, fine-tuning, or examples. On CAIL2018, a Chinese criminal case dataset, we performed zero-shot judgment prediction experiments with GPT-3 models. Our results show that LLMs with LoT achieve better performance than the baseline and chain of thought prompting, the state-of-art prompting method on diverse reasoning tasks. LoT enables the model to concentrate on the key information relevant to the judgment and to correctly understand the legal meaning of acts, as compared to other methods. Our method enables LLMs to predict judgment along with law articles and justification, which significantly enhances the explainability of models. ",
    "url": "https://arxiv.org/abs/2307.08321",
    "authors": [
      "Cong Jiang",
      "Xiaolei Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.08327",
    "title": "Analyzing the Impact of Adversarial Examples on Explainable Machine  Learning",
    "abstract": "Adversarial attacks are a type of attack on machine learning models where an attacker deliberately modifies the inputs to cause the model to make incorrect predictions. Adversarial attacks can have serious consequences, particularly in applications such as autonomous vehicles, medical diagnosis, and security systems. Work on the vulnerability of deep learning models to adversarial attacks has shown that it is very easy to make samples that make a model predict things that it doesn't want to. In this work, we analyze the impact of model interpretability due to adversarial attacks on text classification problems. We develop an ML-based classification model for text data. Then, we introduce the adversarial perturbations on the text data to understand the classification performance after the attack. Subsequently, we analyze and interpret the model's explainability before and after the attack ",
    "url": "https://arxiv.org/abs/2307.08327",
    "authors": [
      "Prathyusha Devabhakthini",
      "Sasmita Parida",
      "Raj Mani Shukla",
      "Suvendu Chandan Nayak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.08336",
    "title": "RAYEN: Imposition of Hard Convex Constraints on Neural Networks",
    "abstract": "This paper presents RAYEN, a framework to impose hard convex constraints on the output or latent variable of a neural network. RAYEN guarantees that, for any input or any weights of the network, the constraints are satisfied at all times. Compared to other approaches, RAYEN does not perform a computationally-expensive orthogonal projection step onto the feasible set, does not rely on soft constraints (which do not guarantee the satisfaction of the constraints at test time), does not use conservative approximations of the feasible set, and does not perform a potentially slow inner gradient descent correction to enforce the constraints. RAYEN supports any combination of linear, convex quadratic, second-order cone (SOC), and linear matrix inequality (LMI) constraints, achieving a very small computational overhead compared to unconstrained networks. For example, it is able to impose 1K quadratic constraints on a 1K-dimensional variable with an overhead of less than 8 ms, and an LMI constraint with 300x300 dense matrices on a 10K-dimensional variable in less than 12 ms. When used in neural networks that approximate the solution of constrained optimization problems, RAYEN achieves computation times between 20 and 7468 times faster than state-of-the-art algorithms, while guaranteeing the satisfaction of the constraints at all times and obtaining a cost very close to the optimal one. ",
    "url": "https://arxiv.org/abs/2307.08336",
    "authors": [
      "Jesus Tordesillas",
      "Jonathan P. How",
      "Marco Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.08339",
    "title": "Multi-Task Cross-Modality Attention-Fusion for 2D Object Detection",
    "abstract": "Accurate and robust object detection is critical for autonomous driving. Image-based detectors face difficulties caused by low visibility in adverse weather conditions. Thus, radar-camera fusion is of particular interest but presents challenges in optimally fusing heterogeneous data sources. To approach this issue, we propose two new radar preprocessing techniques to better align radar and camera data. In addition, we introduce a Multi-Task Cross-Modality Attention-Fusion Network (MCAF-Net) for object detection, which includes two new fusion blocks. These allow for exploiting information from the feature maps more comprehensively. The proposed algorithm jointly detects objects and segments free space, which guides the model to focus on the more relevant part of the scene, namely, the occupied space. Our approach outperforms current state-of-the-art radar-camera fusion-based object detectors in the nuScenes dataset and achieves more robust results in adverse weather conditions and nighttime scenarios. ",
    "url": "https://arxiv.org/abs/2307.08339",
    "authors": [
      "Huawei Sun",
      "Hao Feng",
      "Georg Stettinger",
      "Lorenzo Servadei",
      "Robert Wille"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2307.08349",
    "title": "Are we there yet? An Industrial Viewpoint on Provenance-based Endpoint  Detection and Response Tools",
    "abstract": "Provenance-Based Endpoint Detection and Response (P-EDR) systems are deemed crucial for future APT defenses. Despite the fact that numerous new techniques to improve P-EDR systems have been proposed in academia, it is still unclear whether the industry will adopt P-EDR systems and what improvements the industry desires for P-EDR systems. To this end, we conduct the first set of systematic studies on the effectiveness and the limitations of P-EDR systems. Our study consists of four components: a one-to-one interview, an online questionnaire study, a survey of the relevant literature, and a systematic measurement study. Our research indicates that all industry experts consider P-EDR systems to be more effective than conventional Endpoint Detection and Response (EDR) systems. However, industry experts are concerned about the operating cost of P-EDR systems. In addition, our research reveals three significant gaps between academia and industry: (1) overlooking client-side overhead; (2) imbalanced alarm triage cost and interpretation cost; and (3) excessive server-side memory consumption. This paper's findings provide objective data on the effectiveness of P-EDR systems and how much improvements are needed to adopt P-EDR systems in industry. ",
    "url": "https://arxiv.org/abs/2307.08349",
    "authors": [
      "Feng Dong",
      "Shaofei Li",
      "Peng Jiang",
      "Ding Li",
      "Haoyu Wang",
      "Liangyi Huang",
      "Xusheng Xiao",
      "Jiedong Chen",
      "Xiapu Luo",
      "Yao Guo",
      "Xiangqun Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.08357",
    "title": "Self-supervised Monocular Depth Estimation: Let's Talk About The Weather",
    "abstract": "Current, self-supervised depth estimation architectures rely on clear and sunny weather scenes to train deep neural networks. However, in many locations, this assumption is too strong. For example in the UK (2021), 149 days consisted of rain. For these architectures to be effective in real-world applications, we must create models that can generalise to all weather conditions, times of the day and image qualities. Using a combination of computer graphics and generative models, one can augment existing sunny-weather data in a variety of ways that simulate adverse weather effects. While it is tempting to use such data augmentations for self-supervised depth, in the past this was shown to degrade performance instead of improving it. In this paper, we put forward a method that uses augmentations to remedy this problem. By exploiting the correspondence between unaugmented and augmented data we introduce a pseudo-supervised loss for both depth and pose estimation. This brings back some of the benefits of supervised learning while still not requiring any labels. We also make a series of practical recommendations which collectively offer a reliable, efficient framework for weather-related augmentation of self-supervised depth from monocular video. We present extensive testing to show that our method, Robust-Depth, achieves SotA performance on the KITTI dataset while significantly surpassing SotA on challenging, adverse condition data such as DrivingStereo, Foggy CityScape and NuScenes-Night. The project website can be found here https://kieran514.github.io/Robust-Depth-Project/. ",
    "url": "https://arxiv.org/abs/2307.08357",
    "authors": [
      "Kieran Saunders",
      "George Vogiatzis",
      "Luis Manso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08359",
    "title": "Human Emergency Detection during Autonomous Hospital Transports",
    "abstract": "Human transports in hospitals are labor-intensive and primarily performed in beds to save time. This transfer method does not promote the mobility or autonomy of the patient. To relieve the caregivers from this time-consuming task, a mobile robot is developed to autonomously transport humans around the hospital. It provides different transfer modes including walking and sitting in a wheelchair. The problem that this paper focuses on is to detect emergencies and ensure the well-being of the patient during the transport. For this purpose, the patient is tracked and monitored with a camera system. OpenPose is used for Human Pose Estimation and a trained classifier for emergency detection. We collected and published a dataset of 18,000 images in lab and hospital environments. It differs from related work because we have a moving robot with different transfer modes in a highly dynamic environment with multiple people in the scene using only RGB-D data. To improve the critical recall metric, we apply threshold moving and a time delay. We compare different models with an AutoML approach. This paper shows that emergencies while walking are best detected by a SVM with a recall of 95.8% on single frames. In the case of sitting transport, the best model achieves a recall of 62.2%. The contribution is to establish a baseline on this new dataset and to provide a proof of concept for the human emergency detection in this use case. ",
    "url": "https://arxiv.org/abs/2307.08359",
    "authors": [
      "Andreas Zachariae",
      "Julia Widera",
      "Frederik Plahl",
      "Bj\u00f6rn Hein",
      "Christian Wurll"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.08371",
    "title": "Quantum Graph Drawing",
    "abstract": "In this paper, we initiate the study of quantum algorithms in the Graph Drawing research area. We focus on two foundational drawing standards: 2-level drawings and book layouts. Concerning $2$-level drawings, we consider the problems of obtaining drawings with the minimum number of crossings, $k$-planar drawings, quasi-planar drawings, and the problem of removing the minimum number of edges to obtain a $2$-level planar graph. Concerning book layouts, we consider the problems of obtaining $1$-page book layouts with the minimum number of crossings, book embeddings with the minimum number of pages, and the problem of removing the minimum number of edges to obtain an outerplanar graph. We explore both the quantum circuit and the quantum annealing models of computation. In the quantum circuit model, we provide an algorithmic framework based on Grover's quantum search, which allows us to obtain, at least, a quadratic speedup on the best classical exact algorithms for all the considered problems. In the quantum annealing model, we perform experiments on the quantum processing unit provided by D-Wave, focusing on the classical $2$-level crossing minimization problem, demonstrating that quantum annealing is competitive with respect to classical algorithms. ",
    "url": "https://arxiv.org/abs/2307.08371",
    "authors": [
      "Susanna Caroppo",
      "Giordano Da Lozzo",
      "Giuseppe Di Battista"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2307.08381",
    "title": "2P-BFT-Log: 2-Phases Single-Author Append-Only Log for Adversarial  Environments",
    "abstract": "Replicated append-only logs sequentially order messages from the same author such that their ordering can be eventually recovered even with out-of-order and unreliable dissemination of individual messages. They are widely used for implementing replicated services in both clouds and peer-to-peer environments because they provide simple and efficient incremental reconciliation. However, existing designs of replicated append-only logs assume replicas faithfully maintain the sequential properties of logs and do not provide eventual consistency when malicious participants fork their logs by disseminating different messages to different replicas for the same index, which may result in partitioning of replicas according to which branch was first replicated. In this paper, we present 2P-BFT-Log, a two-phases replicated append-only log that provides eventual consistency in the presence of forks from malicious participants such that all correct replicas will eventually agree either on the most recent message of a valid log (first phase) or on the earliest point at which a fork occurred as well as on an irrefutable proof that it happened (second phase). We provide definitions, algorithms, and proofs of the key properties of the design, and explain one way to implement the design onto Git, an eventually consistent replicated database originally designed for distributed version control. Our design enables correct replicas to faithfully implement the happens-before relationship first introduced by Lamport that underpins most existing distributed algorithms, with eventual detection of forks from malicious participants to exclude the latter from further progress. This opens the door to adaptations of existing distributed algorithms to a cheaper detect and repair paradigm, rather than the more common and expensive systematic prevention of incorrect behaviour. ",
    "url": "https://arxiv.org/abs/2307.08381",
    "authors": [
      "Erick Lavoie"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2307.08390",
    "title": "Correlation-aware Spatial-Temporal Graph Learning for Multivariate  Time-series Anomaly Detection",
    "abstract": "Multivariate time-series anomaly detection is critically important in many applications, including retail, transportation, power grid, and water treatment plants. Existing approaches for this problem mostly employ either statistical models which cannot capture the non-linear relations well or conventional deep learning models (e.g., CNN and LSTM) that do not explicitly learn the pairwise correlations among variables. To overcome these limitations, we propose a novel method, correlation-aware spatial-temporal graph learning (termed CST-GL), for time series anomaly detection. CST-GL explicitly captures the pairwise correlations via a multivariate time series correlation learning module based on which a spatial-temporal graph neural network (STGNN) can be developed. Then, by employing a graph convolution network that exploits one- and multi-hop neighbor information, our STGNN component can encode rich spatial information from complex pairwise dependencies between variables. With a temporal module that consists of dilated convolutional functions, the STGNN can further capture long-range dependence over time. A novel anomaly scoring component is further integrated into CST-GL to estimate the degree of an anomaly in a purely unsupervised manner. Experimental results demonstrate that CST-GL can detect anomalies effectively in general settings as well as enable early detection across different time delays. ",
    "url": "https://arxiv.org/abs/2307.08390",
    "authors": [
      "Yu Zheng",
      "Huan Yee Koh",
      "Ming Jin",
      "Lianhua Chi",
      "Khoa T. Phan",
      "Shirui Pan",
      "Yi-Ping Phoebe Chen",
      "Wei Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08411",
    "title": "Neurosymbolic AI for Reasoning on Biomedical Knowledge Graphs",
    "abstract": "Biomedical datasets are often modeled as knowledge graphs (KGs) because they capture the multi-relational, heterogeneous, and dynamic natures of biomedical systems. KG completion (KGC), can, therefore, help researchers make predictions to inform tasks like drug repositioning. While previous approaches for KGC were either rule-based or embedding-based, hybrid approaches based on neurosymbolic artificial intelligence are becoming more popular. Many of these methods possess unique characteristics which make them even better suited toward biomedical challenges. Here, we survey such approaches with an emphasis on their utilities and prospective benefits for biomedicine. ",
    "url": "https://arxiv.org/abs/2307.08411",
    "authors": [
      "Lauren Nicole DeLong",
      "Ramon Fern\u00e1ndez Mir",
      "Zonglin Ji",
      "Fiona Niamh Coulter Smith",
      "Jacques D. Fleuriot"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2307.08414",
    "title": "Active Learning for Object Detection with Non-Redundant Informative  Sampling",
    "abstract": "Curating an informative and representative dataset is essential for enhancing the performance of 2D object detectors. We present a novel active learning sampling strategy that addresses both the informativeness and diversity of the selections. Our strategy integrates uncertainty and diversity-based selection principles into a joint selection objective by measuring the collective information score of the selected samples. Specifically, our proposed NORIS algorithm quantifies the impact of training with a sample on the informativeness of other similar samples. By exclusively selecting samples that are simultaneously informative and distant from other highly informative samples, we effectively avoid redundancy while maintaining a high level of informativeness. Moreover, instead of utilizing whole image features to calculate distances between samples, we leverage features extracted from detected object regions within images to define object features. This allows us to construct a dataset encompassing diverse object types, shapes, and angles. Extensive experiments on object detection and image classification tasks demonstrate the effectiveness of our strategy over the state-of-the-art baselines. Specifically, our selection strategy achieves a 20% and 30% reduction in labeling costs compared to random selection for PASCAL-VOC and KITTI, respectively. ",
    "url": "https://arxiv.org/abs/2307.08414",
    "authors": [
      "Aral Hekimoglu",
      "Adrian Brucker",
      "Alper Kagan Kayali",
      "Michael Schmidt",
      "Alvaro Marcos-Ramiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08415",
    "title": "Monocular 3D Object Detection with LiDAR Guided Semi Supervised Active  Learning",
    "abstract": "We propose a novel semi-supervised active learning (SSAL) framework for monocular 3D object detection with LiDAR guidance (MonoLiG), which leverages all modalities of collected data during model development. We utilize LiDAR to guide the data selection and training of monocular 3D detectors without introducing any overhead in the inference phase. During training, we leverage the LiDAR teacher, monocular student cross-modal framework from semi-supervised learning to distill information from unlabeled data as pseudo-labels. To handle the differences in sensor characteristics, we propose a data noise-based weighting mechanism to reduce the effect of propagating noise from LiDAR modality to monocular. For selecting which samples to label to improve the model performance, we propose a sensor consistency-based selection score that is also coherent with the training objective. Extensive experimental results on KITTI and Waymo datasets verify the effectiveness of our proposed framework. In particular, our selection strategy consistently outperforms state-of-the-art active learning baselines, yielding up to 17% better saving rate in labeling costs. Our training strategy attains the top place in KITTI 3D and birds-eye-view (BEV) monocular object detection official benchmarks by improving the BEV Average Precision (AP) by 2.02. ",
    "url": "https://arxiv.org/abs/2307.08415",
    "authors": [
      "Aral Hekimoglu",
      "Michael Schmidt",
      "Alvaro Marcos-Ramiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08416",
    "title": "Enhancing Supervised Learning with Contrastive Markings in Neural  Machine Translation Training",
    "abstract": "Supervised learning in Neural Machine Translation (NMT) typically follows a teacher forcing paradigm where reference tokens constitute the conditioning context in the model's prediction, instead of its own previous predictions. In order to alleviate this lack of exploration in the space of translations, we present a simple extension of standard maximum likelihood estimation by a contrastive marking objective. The additional training signals are extracted automatically from reference translations by comparing the system hypothesis against the reference, and used for up/down-weighting correct/incorrect tokens. The proposed new training procedure requires one additional translation pass over the training set per epoch, and does not alter the standard inference setup. We show that training with contrastive markings yields improvements on top of supervised learning, and is especially useful when learning from postedits where contrastive markings indicate human error corrections to the original hypotheses. Code is publicly released. ",
    "url": "https://arxiv.org/abs/2307.08416",
    "authors": [
      "Nathaniel Berger",
      "Miriam Exel",
      "Matthias Huck",
      "Stefan Riezler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.08420",
    "title": "Maximum Flows in Parametric Graph Templates",
    "abstract": "Execution graphs of parallel loop programs exhibit a nested, repeating structure. We show how such graphs that are the result of nested repetition can be represented by succinct parametric structures. This parametric graph template representation allows us to reason about the execution graph of a parallel program at a cost that only depends on the program size. We develop structurally-parametric polynomial-time algorithm variants of maximum flows. When the graph models a parallel loop program, the maximum flow provides a bound on the data movement during an execution of the program. By reasoning about the structure of the repeating subgraphs, we avoid explicit construction of the instantiation (e.g., the execution graph), potentially saving an exponential amount of memory and computation. Hence, our approach enables graph-based dataflow analysis in previously intractable settings. ",
    "url": "https://arxiv.org/abs/2307.08420",
    "authors": [
      "Tal Ben-Nun",
      "Lukas Gianinazzi",
      "Torsten Hoefler",
      "Yishai Oltchik"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2307.08430",
    "title": "Long-range Dependency based Multi-Layer Perceptron for Heterogeneous  Information Networks",
    "abstract": "Existing heterogeneous graph neural networks (HGNNs) have achieved great success in utilizing the rich semantic information in heterogeneous information networks (HINs). However, few works have delved into the utilization of long-range dependencies in HINs, which is extremely valuable as many real-world HINs are sparse, and each node has only a few directly connected neighbors. Although some HGNNs can utilize distant neighbors by stacking multiple layers or leveraging long meta-paths, the exponentially increased number of nodes in the receptive field or the number of meta-paths incurs high computation and memory costs. To address these issues, we investigate the importance of different meta-paths and propose Long-range Dependency based Multi-Layer Perceptron (LDMLP). Specifically, to solve the high-cost problem of leveraging long-range dependencies, LDMLP adopts a search stage to discover effective meta-paths automatically, reducing the exponentially increased number of meta-paths to a constant. To avoid the influence of specific modules on search results, LDMLP utilizes a simple architecture with only multi-layer perceptions in the search stage, improving the generalization of searched meta-paths. As a result, the searched meta-paths not only perform well in LDMLP but also enable other HGNNs like HAN and SeHGNN to perform better. Extensive experiments on eight heterogeneous datasets demonstrate that LDMLP achieves state-of-the-art performance while enjoying high efficiency and generalization, especially on sparse HINs. ",
    "url": "https://arxiv.org/abs/2307.08430",
    "authors": [
      "Chao Li",
      "Zijie Guo",
      "Qiuting He",
      "Hao Xu",
      "Kun He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.08431",
    "title": "Robust Preconditioning of mixed-dimensional PDEs on 3d-1d domains  coupled with Lagrange multipliers",
    "abstract": "In the context of micro-circulation, the coexistence of two distinct length scales - the vascular radius and the tissue/organ scale - with a substantial difference in magnitude, poses significant challenges. To handle slender inclusions and simplify the geometry involved, a technique called topological dimensionality reduction is employed, which suppresses manifold dimensions associated with the smaller characteristic length. However, the resulting discretized system's algebraic structure presents a challenge in constructing efficient solution algorithms. This chapter addresses this challenge by developing a robust preconditioner for the 3d-1d problem using the operator preconditioning technique. Robustness of the preconditioner is demonstrated with respect to problem parameters, except for the vascular radius. The vascular radius, as demonstrated, plays a fundamental role in mathematical well-posedness of the problem and the preconditioner's effectiveness. ",
    "url": "https://arxiv.org/abs/2307.08431",
    "authors": [
      "Nunzio Dimola",
      "Miroslav Kuchta",
      "Kent-Andre Mardal",
      "Paolo Zunino"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.08433",
    "title": "From random-walks to graph-sprints: a low-latency node embedding  framework on continuous-time dynamic graphs",
    "abstract": "Many real-world datasets have an underlying dynamic graph structure, where entities and their interactions evolve over time. Machine learning models should consider these dynamics in order to harness their full potential in downstream tasks. Previous approaches for graph representation learning have focused on either sampling k-hop neighborhoods, akin to breadth-first search, or random walks, akin to depth-first search. However, these methods are computationally expensive and unsuitable for real-time, low-latency inference on dynamic graphs. To overcome these limitations, we propose graph-sprints a general purpose feature extraction framework for continuous-time-dynamic-graphs (CTDGs) that has low latency and is competitive with state-of-the-art, higher latency models. To achieve this, a streaming, low latency approximation to the random-walk based features is proposed. In our framework, time-aware node embeddings summarizing multi-hop information are computed using only single-hop operations on the incoming edges. We evaluate our proposed approach on three open-source datasets and two in-house datasets, and compare with three state-of-the-art algorithms (TGN-attn, TGN-ID, Jodie). We demonstrate that our graph-sprints features, combined with a machine learning classifier, achieve competitive performance (outperforming all baselines for the node classification tasks in five datasets). Simultaneously, graph-sprints significantly reduce inference latencies, achieving close to an order of magnitude speed-up in our experimental setting. ",
    "url": "https://arxiv.org/abs/2307.08433",
    "authors": [
      "Ahmad Naser Eddin",
      "Jacopo Bono",
      "David Apar\u00edcio",
      "Hugo Ferreira",
      "Jo\u00e3o Ascens\u00e3o",
      "Pedro Ribeiro",
      "Pedro Bizarro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08466",
    "title": "Classification of UHF Partial Discharge Signals in Gas-Insulated HVDC  Systems Using Neural Networks",
    "abstract": "Undetected partial discharges (PDs) are a safety critical issue in high voltage (HV) gas insulated systems (GIS). While the diagnosis of PDs under AC voltage is well-established, the analysis of PDs under DC voltage remains an active research field. A key focus of these investigations is the classification of different PD sources to enable subsequent sophisticated analysis. In this paper, we propose and analyze a neural network-based approach for classifying PD signals caused by metallic protrusions and conductive particles on the insulator of HVDC GIS, without relying on pulse sequence analysis features. In contrast to previous approaches, our proposed model can discriminate the studied PD signals obtained at negative and positive potentials, while also generalizing to unseen operating voltage multiples. Additionally, we compare the performance of time- and frequency-domain input signals and explore the impact of different normalization schemes to mitigate the influence of free-space path loss between the sensor and defect location. ",
    "url": "https://arxiv.org/abs/2307.08466",
    "authors": [
      "Steffen Seitz",
      "Thomas G\u00f6tz",
      "Christopher Lindenberg",
      "Ronald Tetzlaff",
      "Stephan Schlegel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08467",
    "title": "Riesz feature representation: scale equivariant scattering network for  classification tasks",
    "abstract": "Scattering networks yield powerful and robust hierarchical image descriptors which do not require lengthy training and which work well with very few training data. However, they rely on sampling the scale dimension. Hence, they become sensitive to scale variations and are unable to generalize to unseen scales. In this work, we define an alternative feature representation based on the Riesz transform. We detail and analyze the mathematical foundations behind this representation. In particular, it inherits scale equivariance from the Riesz transform and completely avoids sampling of the scale dimension. Additionally, the number of features in the representation is reduced by a factor four compared to scattering networks. Nevertheless, our representation performs comparably well for texture classification with an interesting addition: scale equivariance. Our method yields superior performance when dealing with scales outside of those covered by the training dataset. The usefulness of the equivariance property is demonstrated on the digit classification task, where accuracy remains stable even for scales four times larger than the one chosen for training. As a second example, we consider classification of textures. ",
    "url": "https://arxiv.org/abs/2307.08467",
    "authors": [
      "Tin Barisin",
      "Jesus Angulo",
      "Katja Schladitz",
      "Claudia Redenbach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08487",
    "title": "Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output  Robustness of Large Language Models",
    "abstract": "Researchers have invested considerable effort into ensuring that large language models (LLMs) align with human values, using various training techniques, such as instruction tuning and Reinforcement Learning from Human or AI Feedback (RLHF/RLAIF), to guard against text unsafety. However, these defenses remain incredibly vulnerable to some jailbreak attacks, which can cause the model to become overly defensive to sensitive topics or still generate harmful content, leaving the model performance particularly fragile. Therefore, to comprehensively study text safety and output robustness, we propose a latent jailbreak prompt dataset, each involving malicious instruction embedding. Specifically, we instruct the model to complete a regular task, such as translation, where the text to be translated contains malicious instructions. To further analyze the safety and robustness, we design a hierarchical annotation framework. We present a systematic analysis of the safety and robustness of LLMs concerning the position of explicit normal instructions, word replacement (verbs in explicit normal instructions, target groups in malicious instructions, cue words in malicious instructions), and instruction replacement (different explicit normal instructions). Our results show that current LLMs not only have a preference for certain instruction verbs, but also exhibit different jailbreak rates for different instruction verbs in explicit normal instructions. In other words, the probability of generating unsafe content by the model will be reinforced to varying degrees depending on the instruction verb in explicit normal instructions. Code and data are available at https://github.com/qiuhuachuan/latent-jailbreak. ",
    "url": "https://arxiv.org/abs/2307.08487",
    "authors": [
      "Huachuan Qiu",
      "Shuai Zhang",
      "Anqi Li",
      "Hongliang He",
      "Zhenzhong Lan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.08492",
    "title": "SVDFormer: Complementing Point Cloud via Self-view Augmentation and  Self-structure Dual-generator",
    "abstract": "In this paper, we propose a novel network, SVDFormer, to tackle two specific challenges in point cloud completion: understanding faithful global shapes from incomplete point clouds and generating high-accuracy local structures. Current methods either perceive shape patterns using only 3D coordinates or import extra images with well-calibrated intrinsic parameters to guide the geometry estimation of the missing parts. However, these approaches do not always fully leverage the cross-modal self-structures available for accurate and high-quality point cloud completion. To this end, we first design a Self-view Fusion Network that leverages multiple-view depth image information to observe incomplete self-shape and generate a compact global shape. To reveal highly detailed structures, we then introduce a refinement module, called Self-structure Dual-generator, in which we incorporate learned shape priors and geometric self-similarities for producing new points. By perceiving the incompleteness of each point, the dual-path design disentangles refinement strategies conditioned on the structural type of each point. SVDFormer absorbs the wisdom of self-structures, avoiding any additional paired information such as color images with precisely calibrated camera intrinsic parameters. Comprehensive experiments indicate that our method achieves state-of-the-art performance on widely-used benchmarks. Code will be available at https://github.com/czvvd/SVDFormer. ",
    "url": "https://arxiv.org/abs/2307.08492",
    "authors": [
      "Zhe Zhu",
      "Honghua Chen",
      "Xing He",
      "Weiming Wang",
      "Jing Qin",
      "Mingqiang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08505",
    "title": "Approximation Algorithms for the Graph Burning on Cactus and Directed  Trees",
    "abstract": "Given a graph $G=(V, E)$, the problem of Graph Burning is to find a sequence of nodes from $V$, called a burning sequence, to burn the whole graph. This is a discrete-step process, and at each step, an unburned vertex is selected as an agent to spread fire to its neighbors by marking it as a burnt node. A burnt node spreads the fire to its neighbors at the next consecutive step. The goal is to find the burning sequence of minimum length. The Graph Burning problem is NP-Hard for general graphs and even for binary trees. A few approximation results are known, including a $ 3$-approximation algorithm for general graphs and a $ 2$-approximation algorithm for trees. The Graph Burning on directed graphs is more challenging than on undirected graphs. In this paper, we propose 1) A $2.75$-approximation algorithm for a cactus graph (undirected), 2) A $3$-approximation algorithm for multi-rooted directed trees (polytree) and 3) A $1.905$-approximation algorithm for single-rooted directed tree (arborescence). We implement all the three approximation algorithms and the results are shown for randomly generated cactus graphs and directed trees. ",
    "url": "https://arxiv.org/abs/2307.08505",
    "authors": [
      "Rahul Kumar Gautam",
      "Anjeneya Swami Kare",
      "S. Durga Bhavani"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2307.08536",
    "title": "Variational Probabilistic Fusion Network for RGB-T Semantic Segmentation",
    "abstract": "RGB-T semantic segmentation has been widely adopted to handle hard scenes with poor lighting conditions by fusing different modality features of RGB and thermal images. Existing methods try to find an optimal fusion feature for segmentation, resulting in sensitivity to modality noise, class-imbalance, and modality bias. To overcome the problems, this paper proposes a novel Variational Probabilistic Fusion Network (VPFNet), which regards fusion features as random variables and obtains robust segmentation by averaging segmentation results under multiple samples of fusion features. The random samples generation of fusion features in VPFNet is realized by a novel Variational Feature Fusion Module (VFFM) designed based on variation attention. To further avoid class-imbalance and modality bias, we employ the weighted cross-entropy loss and introduce prior information of illumination and category to control the proposed VFFM. Experimental results on MFNet and PST900 datasets demonstrate that the proposed VPFNet can achieve state-of-the-art segmentation performance. ",
    "url": "https://arxiv.org/abs/2307.08536",
    "authors": [
      "Baihong Lin",
      "Zengrong Lin",
      "Yulan Guo",
      "Yulan Zhang",
      "Jianxiao Zou",
      "Shicai Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08539",
    "title": "Image-Based Abnormal Data Detection and Cleaning Algorithm via Wind  Power Curve",
    "abstract": "This paper proposes an image-based algorithm for detecting and cleaning the wind turbine abnormal data based on wind power curve (WPC) images. The abnormal data are categorized into three types, negative points, scattered points, and stacked points. The proposed algorithm includes three steps, data pre-cleaning, normal data extraction, and data marking. The negative abnormal points, whose wind speed is greater than cut-in speed and power is below zero, are first filtered in the data pre-cleaning step. The scatter figure of the rest wind power data forms the WPC image and corresponding binary image. In the normal data extraction step, the principle part of the WPC binary image, representing the normal data, is extracted by the mathematical morphology operation (MMO). The optimal parameter setting of MMO is determined by minimizing the dissimilarity between the extracted principle part and the reference WPC image based on Hu moments. In the data mark step, the pixel points of scattered and stacked abnormal data are successively identified. The mapping relationship between the wind power points and image pixel points is built to mark the wind turbine normal and abnormal data. The proposed image-based algorithm is compared with k-means, local outlier factor, combined algorithm based on change point grouping algorithm and quartile algorithm (CA). Numerous experiments based on 33 wind turbines from two wind farms are conducted to validate the effectiveness, efficiency, and universality of the proposed method. ",
    "url": "https://arxiv.org/abs/2307.08539",
    "authors": [
      "Huan Long",
      "Linwei Sang",
      "Zaijun Wu",
      "Wei Gu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.08547",
    "title": "Metadata-based Malware Detection on Android using Machine Learning",
    "abstract": "In the digitized world, smartphones and their apps play an important role. To name just a few examples, some apps offer possibilities for entertainment, others for online banking, and others offer support for two-factor authentication. Therefore, with smartphones also, sensitive information is shared; thus, they are a desirable target for malware. The following technical report gives an overview of how machine learning, especially neural networks, can be employed to detect malicious Android apps based on their metadata. Detection based on the metadata is necessary since not all of an app's information is readable from another app due to the security layout of Android. To do so, a comparable big dataset of metadata of apps has been collected for learning and evaluation in this work. The first section, after the introduction, presents the related work, followed by the description of the sources of the dataset and the selection of the features used for machine learning, in this case, only the app permissions. Afterward, a free available dataset is used to find an efficient and effective neural network model for learning and evaluation. Here, the fully connected network type consisting of dense layers is chosen. Then this model is trained and evaluated on the new, more extensive dataset to obtain a representative result. It turns out that this model detects malware with an accuracy of 92.93% based on an app's permissions. ",
    "url": "https://arxiv.org/abs/2307.08547",
    "authors": [
      "Alexander Hefter",
      "Christoph Sendner",
      "Alexandra Dmitrienko"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.08549",
    "title": "G-Scan: Graph Neural Networks for Line-Level Vulnerability  Identification in Smart Contracts",
    "abstract": "Due to the immutable and decentralized nature of Ethereum (ETH) platform, smart contracts are prone to security risks that can result in financial loss. While existing machine learning-based vulnerability detection algorithms achieve high accuracy at the contract level, they require developers to manually inspect source code to locate bugs. To this end, we present G-Scan, the first end-to-end fine-grained line-level vulnerability detection system evaluated on the first-of-its-kind real world dataset. G-Scan first converts smart contracts to code graphs in a dependency and hierarchy preserving manner. Next, we train a graph neural network to identify vulnerable nodes and assess security risks. Finally, the code graphs with node vulnerability predictions are mapped back to the smart contracts for line-level localization. We train and evaluate G-Scan on a collected real world smart contracts dataset with line-level annotations on reentrancy vulnerability, one of the most common and severe types of smart contract vulnerabilities. With the well-designed graph representation and high-quality dataset, G-Scan achieves 93.02% F1-score in contract-level vulnerability detection and 93.69% F1-score in line-level vulnerability localization. Additionally, the lightweight graph neural network enables G-Scan to localize vulnerabilities in 6.1k lines of code smart contract within 1.2 seconds. ",
    "url": "https://arxiv.org/abs/2307.08549",
    "authors": [
      "Christoph Sendner",
      "Ruisi Zhang",
      "Alexander Hefter",
      "Alexandra Dmitrienko",
      "Farinaz Koushanfar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.08550",
    "title": "TorMult: Introducing a Novel Tor Bandwidth Inflation Attack",
    "abstract": "The Tor network is the most prominent system for providing anonymous communication to web users, with a daily user base of 2 million users. However, since its inception, it has been constantly targeted by various traffic fingerprinting and correlation attacks aiming at deanonymizing its users. A critical requirement for these attacks is to attract as much user traffic to adversarial relays as possible, which is typically accomplished by means of bandwidth inflation attacks. This paper proposes a new inflation attack vector in Tor, referred to as TorMult, which enables inflation of measured bandwidth. The underlying attack technique exploits resource sharing among Tor relay nodes and employs a cluster of attacker-controlled relays with coordinated resource allocation within the cluster to deceive bandwidth measurers into believing that each relay node in the cluster possesses ample resources. We propose two attack variants, C-TorMult and D-TorMult, and test both versions in a private Tor test network. Our evaluation demonstrates that an attacker can inflate the measured bandwidth by a factor close to n using C-TorMult and nearly half n*N using D-TorMult, where n is the size of the cluster hosted on one server and N is the number of servers. Furthermore, our theoretical analysis reveals that gaining control over half of the Tor network's traffic can be achieved by employing just 10 dedicated servers with a cluster size of 109 relays running the TorMult attack, each with a bandwidth of 100MB/s. The problem is further exacerbated by the fact that Tor not only allows resource sharing but, according to recent reports, even promotes it. ",
    "url": "https://arxiv.org/abs/2307.08550",
    "authors": [
      "Christoph Sendner",
      "Jasper Stang",
      "Alexandra Dmitrienko",
      "Raveen Wijewickrama",
      "Murtuza Jadliwala"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.08551",
    "title": "On the Fly Neural Style Smoothing for Risk-Averse Domain Generalization",
    "abstract": "Achieving high accuracy on data from domains unseen during training is a fundamental challenge in domain generalization (DG). While state-of-the-art DG classifiers have demonstrated impressive performance across various tasks, they have shown a bias towards domain-dependent information, such as image styles, rather than domain-invariant information, such as image content. This bias renders them unreliable for deployment in risk-sensitive scenarios such as autonomous driving where a misclassification could lead to catastrophic consequences. To enable risk-averse predictions from a DG classifier, we propose a novel inference procedure, Test-Time Neural Style Smoothing (TT-NSS), that uses a \"style-smoothed\" version of the DG classifier for prediction at test time. Specifically, the style-smoothed classifier classifies a test image as the most probable class predicted by the DG classifier on random re-stylizations of the test image. TT-NSS uses a neural style transfer module to stylize a test image on the fly, requires only black-box access to the DG classifier, and crucially, abstains when predictions of the DG classifier on the stylized test images lack consensus. Additionally, we propose a neural style smoothing (NSS) based training procedure that can be seamlessly integrated with existing DG methods. This procedure enhances prediction consistency, improving the performance of TT-NSS on non-abstained samples. Our empirical results demonstrate the effectiveness of TT-NSS and NSS at producing and improving risk-averse predictions on unseen domains from DG classifiers trained with SOTA training methods on various benchmark datasets and their variations. ",
    "url": "https://arxiv.org/abs/2307.08551",
    "authors": [
      "Akshay Mehra",
      "Yunbei Zhang",
      "Bhavya Kailkhura",
      "Jihun Hamm"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08559",
    "title": "Improving Data Efficiency for Plant Cover Prediction with Label  Interpolation and Monte-Carlo Cropping",
    "abstract": "The plant community composition is an essential indicator of environmental changes and is, for this reason, usually analyzed in ecological field studies in terms of the so-called plant cover. The manual acquisition of this kind of data is time-consuming, laborious, and prone to human error. Automated camera systems can collect high-resolution images of the surveyed vegetation plots at a high frequency. In combination with subsequent algorithmic analysis, it is possible to objectively extract information on plant community composition quickly and with little human effort. An automated camera system can easily collect the large amounts of image data necessary to train a Deep Learning system for automatic analysis. However, due to the amount of work required to annotate vegetation images with plant cover data, only few labeled samples are available. As automated camera systems can collect many pictures without labels, we introduce an approach to interpolate the sparse labels in the collected vegetation plot time series down to the intermediate dense and unlabeled images to artificially increase our training dataset to seven times its original size. Moreover, we introduce a new method we call Monte-Carlo Cropping. This approach trains on a collection of cropped parts of the training images to deal with high-resolution images efficiently, implicitly augment the training images, and speed up training. We evaluate both approaches on a plant cover dataset containing images of herbaceous plant communities and find that our methods lead to improvements in the species, community, and segmentation metrics investigated. ",
    "url": "https://arxiv.org/abs/2307.08559",
    "authors": [
      "Matthias K\u00f6rschens",
      "Solveig Franziska Bucher",
      "Christine R\u00f6mermann",
      "Joachim Denzler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08572",
    "title": "Revisiting the Robustness of the Minimum Error Entropy Criterion: A  Transfer Learning Case Study",
    "abstract": "Coping with distributional shifts is an important part of transfer learning methods in order to perform well in real-life tasks. However, most of the existing approaches in this area either focus on an ideal scenario in which the data does not contain noises or employ a complicated training paradigm or model design to deal with distributional shifts. In this paper, we revisit the robustness of the minimum error entropy (MEE) criterion, a widely used objective in statistical signal processing to deal with non-Gaussian noises, and investigate its feasibility and usefulness in real-life transfer learning regression tasks, where distributional shifts are common. Specifically, we put forward a new theoretical result showing the robustness of MEE against covariate shift. We also show that by simply replacing the mean squared error (MSE) loss with the MEE on basic transfer learning algorithms such as fine-tuning and linear probing, we can achieve competitive performance with respect to state-of-the-art transfer learning algorithms. We justify our arguments on both synthetic data and 5 real-world time-series data. ",
    "url": "https://arxiv.org/abs/2307.08572",
    "authors": [
      "Luis Pedro Silvestrin",
      "Shujian Yu",
      "Mark Hoogendoorn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08582",
    "title": "Applications of Educational Data Mining and Learning Analytics on Data  From Cybersecurity Training",
    "abstract": "Cybersecurity professionals need hands-on training to prepare for managing the current advanced cyber threats. To practice cybersecurity skills, training participants use numerous software tools in computer-supported interactive learning environments to perform offensive or defensive actions. The interaction involves typing commands, communicating over the network, and engaging with the training environment. The training artifacts (data resulting from this interaction) can be highly beneficial in educational research. For example, in cybersecurity education, they provide insights into the trainees' learning processes and support effective learning interventions. However, this research area is not yet well-understood. Therefore, this paper surveys publications that enhance cybersecurity education by leveraging trainee-generated data from interactive learning environments. We identified and examined 3021 papers, ultimately selecting 35 articles for a detailed review. First, we investigated which data are employed in which areas of cybersecurity training, how, and why. Second, we examined the applications and impact of research in this area, and third, we explored the community of researchers. Our contribution is a systematic literature review of relevant papers and their categorization according to the collected data, analysis methods, and application contexts. These results provide researchers, developers, and educators with an original perspective on this emerging topic. To motivate further research, we identify trends and gaps, propose ideas for future work, and present practical recommendations. Overall, this paper provides in-depth insight into the recently growing research on collecting and analyzing data from hands-on training in security contexts. ",
    "url": "https://arxiv.org/abs/2307.08582",
    "authors": [
      "Valdemar \u0160v\u00e1bensk\u00fd",
      "Jan Vykopal",
      "Pavel \u010celeda",
      "Lydia Kraus"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.08586",
    "title": "Syntax-Aware Complex-Valued Neural Machine Translation",
    "abstract": "Syntax has been proven to be remarkably effective in neural machine translation (NMT). Previous models obtained syntax information from syntactic parsing tools and integrated it into NMT models to improve translation performance. In this work, we propose a method to incorporate syntax information into a complex-valued Encoder-Decoder architecture. The proposed model jointly learns word-level and syntax-level attention scores from the source side to the target side using an attention mechanism. Importantly, it is not dependent on specific network architectures and can be directly integrated into any existing sequence-to-sequence (Seq2Seq) framework. The experimental results demonstrate that the proposed method can bring significant improvements in BLEU scores on two datasets. In particular, the proposed method achieves a greater improvement in BLEU scores in translation tasks involving language pairs with significant syntactic differences. ",
    "url": "https://arxiv.org/abs/2307.08586",
    "authors": [
      "Yang Liu",
      "Yuexian Hou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.08592",
    "title": "Tight Bounds for Budgeted Maximum Weight Independent Set in Bipartite  and Perfect Graphs",
    "abstract": "We consider the classic budgeted maximum weight independent set (BMWIS) problem. The input is a graph $G = (V,E)$, a weight function $w:V \\rightarrow \\mathbb{R}_{\\geq 0}$, a cost function $c:V \\rightarrow \\mathbb{R}_{\\geq 0}$, and a budget $B \\in \\mathbb{R}_{\\geq 0}$. The goal is to find an independent set $S \\subseteq V$ in $G$ such that $\\sum_{v \\in S} c(v) \\leq B$, which maximizes the total weight $\\sum_{v \\in S} w(v)$. Since the problem on general graphs cannot be approximated within ratio $|V|^{1-\\varepsilon}$ for any $\\varepsilon>0$, BMWIS has attracted significant attention on graph families for which a maximum weight independent set can be computed in polynomial time. Two notable such graph families are bipartite and perfect graphs. BMWIS is known to be NP-hard on both of these graph families; however, the best possible approximation guarantees for these graphs are wide open. In this paper, we give a tight $2$-approximation for BMWIS on perfect graphs and bipartite graphs. In particular, we give We a $(2-\\varepsilon)$ lower bound for BMWIS on bipartite graphs, already for the special case where the budget is replaced by a cardinality constraint, based on the Small Set Expansion Hypothesis (SSEH). For the upper bound, we design a $2$-approximation for BMWIS on perfect graphs using a Lagrangian relaxation based technique. Finally, we obtain a tight lower bound for the capacitated maximum weight independent set (CMWIS) problem, the special case of BMWIS where $w(v) = c(v)~\\forall v \\in V$. We show that CMWIS on bipartite and perfect graphs is unlikely to admit an efficient polynomial-time approximation scheme (EPTAS). Thus, the existing PTAS for CMWIS is essentially the best we can expect. ",
    "url": "https://arxiv.org/abs/2307.08592",
    "authors": [
      "Ilan Doron-Arad",
      "Hadas Shachnai"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2307.08596",
    "title": "Omnipotent Adversarial Training for Unknown Label-noisy and Imbalanced  Datasets",
    "abstract": "Adversarial training is an important topic in robust deep learning, but the community lacks attention to its practical usage. In this paper, we aim to resolve a real-world application challenge, i.e., training a model on an imbalanced and noisy dataset to achieve high clean accuracy and robustness, with our proposed Omnipotent Adversarial Training (OAT). Our strategy consists of two innovative methodologies to address the label noise and data imbalance in the training set. We first introduce an oracle into the adversarial training process to help the model learn a correct data-label conditional distribution. This carefully-designed oracle can provide correct label annotations for adversarial training. We further propose logits adjustment adversarial training to overcome the data imbalance challenge, which can help the model learn a Bayes-optimal distribution. Our comprehensive evaluation results show that OAT outperforms other baselines by more than 20% clean accuracy improvement and 10% robust accuracy improvement under the complex combinations of data imbalance and label noise scenarios. The code can be found in https://github.com/GuanlinLee/OAT. ",
    "url": "https://arxiv.org/abs/2307.08596",
    "authors": [
      "Guanlin Li",
      "Kangjie Chen",
      "Yuan Xu",
      "Han Qiu",
      "Tianwei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08602",
    "title": "CART: Collision Avoidance and Robust Tracking Augmentation in  Learning-based Motion Planning for Multi-Agent Systems",
    "abstract": "This paper presents CART, an analytical method to augment a learning-based, distributed motion planning policy of a nonlinear multi-agent system with real-time collision avoidance and robust tracking guarantees, independently of learning errors. We first derive an analytical form of an optimal safety filter for Lagrangian systems, which formally ensures a collision-free operation in a multi-agent setting in a disturbance-free environment, while allowing for its distributed implementation with minimal deviation from the learned policy. We then propose an analytical form of an optimal robust filter for Lagrangian systems to be used hierarchically with the learned collision-free target trajectory, which also enables distributed implementation and guarantees exponential boundedness of the trajectory tracking error for safety, even under the presence of deterministic and stochastic disturbance. These results are shown to extend further to general control-affine nonlinear systems using contraction theory. Our key contribution is to enhance the performance of the learned motion planning policy with collision avoidance and tracking-based robustness guarantees, independently of its original performance such as approximation errors and regret bounds in machine learning. We demonstrate the effectiveness of CART in motion planning and control of several examples of nonlinear systems, including spacecraft formation flying and rotor-failed UAV swarms. ",
    "url": "https://arxiv.org/abs/2307.08602",
    "authors": [
      "Hiroyasu Tsukamoto",
      "Benjamin Rivi\u00e8re",
      "Changrak Choi",
      "Amir Rahmani",
      "Soon-Jo Chung"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.08615",
    "title": "Benchmarking fixed-length Fingerprint Representations across different  Embedding Sizes and Sensor Types",
    "abstract": "Traditional minutiae-based fingerprint representations consist of a variable-length set of minutiae. This necessitates a more complex comparison causing the drawback of high computational cost in one-to-many comparison. Recently, deep neural networks have been proposed to extract fixed-length embeddings from fingerprints. In this paper, we explore to what extent fingerprint texture information contained in such embeddings can be reduced in terms of dimension while preserving high biometric performance. This is of particular interest since it would allow to reduce the number of operations incurred at comparisons. We also study the impact in terms of recognition performance of the fingerprint textural information for two sensor types, i.e. optical and capacitive. Furthermore, the impact of rotation and translation of fingerprint images on the extraction of fingerprint embeddings is analysed. Experimental results conducted on a publicly available database reveal an optimal embedding size of 512 feature elements for the texture-based embedding part of fixed-length fingerprint representations. In addition, differences in performance between sensor types can be perceived. ",
    "url": "https://arxiv.org/abs/2307.08615",
    "authors": [
      "Tim Rohwedder",
      "Daile Osorio-Roig",
      "Christian Rathgeb",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08623",
    "title": "HYTREL: Hypergraph-enhanced Tabular Data Representation Learning",
    "abstract": "Language models pretrained on large collections of tabular data have demonstrated their effectiveness in several downstream tasks. However, many of these models do not take into account the row/column permutation invariances, hierarchical structure, etc. that exist in tabular data. To alleviate these limitations, we propose HYTREL, a tabular language model, that captures the permutation invariances and three more structural properties of tabular data by using hypergraphs - where the table cells make up the nodes and the cells occurring jointly together in each row, column, and the entire table are used to form three different types of hyperedges. We show that HYTREL is maximally invariant under certain conditions for tabular data, i.e., two tables obtain the same representations via HYTREL iff the two tables are identical up to permutations. Our empirical results demonstrate that HYTREL consistently outperforms other competitive baselines on four downstream tasks with minimal pretraining, illustrating the advantages of incorporating the inductive biases associated with tabular data into the representations. Finally, our qualitative analyses showcase that HYTREL can assimilate the table structures to generate robust representations for the cells, rows, columns, and the entire table. ",
    "url": "https://arxiv.org/abs/2307.08623",
    "authors": [
      "Pei Chen",
      "Soumajyoti Sarkar",
      "Leonard Lausen",
      "Balasubramaniam Srinivasan",
      "Sheng Zha",
      "Ruihong Huang",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.08636",
    "title": "PolyGNN: Polyhedron-based Graph Neural Network for 3D Building  Reconstruction from Point Clouds",
    "abstract": "We present PolyGNN, a polyhedron-based graph neural network for 3D building reconstruction from point clouds. PolyGNN learns to assemble primitives obtained by polyhedral decomposition via graph node classification, achieving a watertight, compact, and weakly semantic reconstruction. To effectively represent arbitrary-shaped polyhedra in the neural network, we propose three different sampling strategies to select representative points as polyhedron-wise queries, enabling efficient occupancy inference. Furthermore, we incorporate the inter-polyhedron adjacency to enhance the classification of the graph nodes. We also observe that existing city-building models are abstractions of the underlying instances. To address this abstraction gap and provide a fair evaluation of the proposed method, we develop our method on a large-scale synthetic dataset covering 500k+ buildings with well-defined ground truths of polyhedral class labels. We further conduct a transferability analysis across cities and on real-world point clouds. Both qualitative and quantitative results demonstrate the effectiveness of our method, particularly its efficiency for large-scale reconstructions. The source code and data of our work are available at https://github.com/chenzhaiyu/polygnn. ",
    "url": "https://arxiv.org/abs/2307.08636",
    "authors": [
      "Zhaiyu Chen",
      "Yilei Shi",
      "Liangliang Nan",
      "Zhitong Xiong",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08652",
    "title": "Search Me Knot, Render Me Knot: Embedding Search and Differentiable  Rendering of Knots in 3D",
    "abstract": "We introduce the problem of knot-based inverse perceptual art. Given multiple target images and their corresponding viewing configurations, the objective is to find a 3D knot-based tubular structure whose appearance resembles the target images when viewed from the specified viewing configurations. To solve this problem, we first design a differentiable rendering algorithm for rendering tubular knots embedded in 3D for arbitrary perspective camera configurations. Utilizing this he's doctodifferentiable rendering algorithm, we search over the space of knot configurations to find the ideal knot embedding. We represent the knot embeddings via homeomorphisms of the desired template knot, where the homeomorphisms are parametrized by the weights of an invertible neural network. Our approach is fully differentiable, making it possible to find the ideal 3D tubular structure for the desired perceptual art using gradient-based optimization. We propose several loss functions that impose additional physical constraints, ensuring that the tube is free of self-intersection, lies within a predefined region in space, satisfies the physical bending limits of the tube material and the material cost is within a specified budget. We demonstrate through results that our knot representation is highly expressive and gives impressive results even for challenging target images in both single view as well as multiple view constraints. Through extensive ablation study we show that each of the proposed loss function is effective in ensuring physical realizability. To the best of our knowledge, we are the first to propose a fully differentiable optimization framework for knot-based inverse perceptual art. ",
    "url": "https://arxiv.org/abs/2307.08652",
    "authors": [
      "Aalok Gangopadhyay",
      "Paras Gupta",
      "Tarun Sharma",
      "Prajwal Singh",
      "Shanmuganathan Raman"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2307.08663",
    "title": "Quaternion Convolutional Neural Networks: Current Advances and Future  Directions",
    "abstract": "Since their first applications, Convolutional Neural Networks (CNNs) have solved problems that have advanced the state-of-the-art in several domains. CNNs represent information using real numbers. Despite encouraging results, theoretical analysis shows that representations such as hyper-complex numbers can achieve richer representational capacities than real numbers, and that Hamilton products can capture intrinsic interchannel relationships. Moreover, in the last few years, experimental research has shown that Quaternion-Valued CNNs (QCNNs) can achieve similar performance with fewer parameters than their real-valued counterparts. This paper condenses research in the development of QCNNs from its very beginnings. We propose a conceptual organization of current trends and analyze the main building blocks used in the design of QCNN models. Based on this conceptual organization, we propose future directions of research. ",
    "url": "https://arxiv.org/abs/2307.08663",
    "authors": [
      "Gerardo Altamirano-Gomez",
      "Carlos Gershenson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08671",
    "title": "Deep Cross-Modal Steganography Using Neural Representations",
    "abstract": "Steganography is the process of embedding secret data into another message or data, in such a way that it is not easily noticeable. With the advancement of deep learning, Deep Neural Networks (DNNs) have recently been utilized in steganography. However, existing deep steganography techniques are limited in scope, as they focus on specific data types and are not effective for cross-modal steganography. Therefore, We propose a deep cross-modal steganography framework using Implicit Neural Representations (INRs) to hide secret data of various formats in cover images. The proposed framework employs INRs to represent the secret data, which can handle data of various modalities and resolutions. Experiments on various secret datasets of diverse types demonstrate that the proposed approach is expandable and capable of accommodating different modalities. ",
    "url": "https://arxiv.org/abs/2307.08671",
    "authors": [
      "Gyojin Han",
      "Dong-Jae Lee",
      "Jiwan Hur",
      "Jaehyun Choi",
      "Junmo Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.08672",
    "title": "FedDefender: Backdoor Attack Defense in Federated Learning",
    "abstract": "Federated Learning (FL) is a privacy-preserving distributed machine learning technique that enables individual clients (e.g., user participants, edge devices, or organizations) to train a model on their local data in a secure environment and then share the trained model with an aggregator to build a global model collaboratively. In this work, we propose FedDefender, a defense mechanism against targeted poisoning attacks in FL by leveraging differential testing. Our proposed method fingerprints the neuron activations of clients' models on the same input and uses differential testing to identify a potentially malicious client containing a backdoor. We evaluate FedDefender using MNIST and FashionMNIST datasets with 20 and 30 clients, and our results demonstrate that FedDefender effectively mitigates such attacks, reducing the attack success rate (ASR) to 10\\% without deteriorating the global model performance. ",
    "url": "https://arxiv.org/abs/2307.08672",
    "authors": [
      "Waris Gill",
      "Ali Anwar",
      "Muhammad Ali Gulzar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08673",
    "title": "CohortFinder: an open-source tool for data-driven partitioning of  biomedical image cohorts to yield robust machine learning models",
    "abstract": "Batch effects (BEs) refer to systematic technical differences in data collection unrelated to biological variations whose noise is shown to negatively impact machine learning (ML) model generalizability. Here we release CohortFinder, an open-source tool aimed at mitigating BEs via data-driven cohort partitioning. We demonstrate CohortFinder improves ML model performance in downstream medical image processing tasks. CohortFinder is freely available for download at cohortfinder.com. ",
    "url": "https://arxiv.org/abs/2307.08673",
    "authors": [
      "Fan Fan",
      "Georgia Martinez",
      "Thomas Desilvio",
      "John Shin",
      "Yijiang Chen",
      "Bangchen Wang",
      "Takaya Ozeki",
      "Maxime W. Lafarge",
      "Viktor H. Koelzer",
      "Laura Barisoni",
      "Anant Madabhushi",
      "Satish E. Viswanath",
      "Andrew Janowczyk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08680",
    "title": "Optimal storage codes on graphs with fixed locality",
    "abstract": "Storage codes on graphs are an instance of \\emph{codes with locality}, which are used in distributed storage schemes to provide local repairability. Specifically, the nodes of the graph correspond to storage servers, and the neighbourhood of each server constitute the set of servers it can query to repair its stored data in the event of a failure. A storage code on a graph with $n$-vertices is a set of $n$-length codewords over $\\field_q$ where the $i$th codeword symbol is stored in server $i$, and it can be recovered by querying the neighbours of server $i$ according to the underlying graph. In this work, we look at binary storage codes whose repair function is the parity check, and characterise the tradeoff between the locality of the code and its rate. Specifically, we show that the maximum rate of a code on $n$ vertices with locality $r$ is bounded between $1-1/n\\lceil n/(r+1)\\rceil$ and $1-1/n\\lceil n/(r+1)\\rceil$. The lower bound on the rate is derived by constructing an explicit family of graphs with locality $r$, while the upper bound is obtained via a lower bound on the binary-field rank of a class of symmetric binary matrices. Our upper bound on maximal rate of a storage code matches the upper bound on the larger class of codes with locality derived by Tamo and Barg. As a corollary to our result, we obtain the following asymptotic separation result: given a sequence $r(n), n\\geq 1$, there exists a sequence of graphs on $n$-vertices with storage codes of rate $1-o(1)$ if and only if $r(n)=\\omega(1)$. ",
    "url": "https://arxiv.org/abs/2307.08680",
    "authors": [
      "Sabyasachi Basu",
      "Manuj Mukherjee"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2307.08681",
    "title": "Secure Composition of Robust and Optimising Compilers",
    "abstract": "To ensure that secure applications do not leak their secrets, they are required to uphold several security properties such as spatial and temporal memory safety as well as cryptographic constant time. Existing work shows how to enforce these properties individually, in an architecture-independent way, by using secure compiler passes that each focus on an individual property. Unfortunately, given two secure compiler passes that each preserve a possibly different security property, it is unclear what kind of security property is preserved by the composition of those secure compiler passes. This paper is the first to study what security properties are preserved across the composition of different secure compiler passes. Starting from a general theory of property composition for security-relevant properties (such as the aforementioned ones), this paper formalises a theory of composition of secure compilers. Then, it showcases this theory a secure multi-pass compiler that preserves the aforementioned security-relevant properties. Crucially, this paper derives the security of the multi-pass compiler from the composition of the security properties preserved by its individual passes, which include security-preserving as well as optimisation passes. From an engineering perspective, this is the desirable approach to building secure compilers. ",
    "url": "https://arxiv.org/abs/2307.08681",
    "authors": [
      "Matthis Kruse",
      "Michael Backes",
      "Marco Patrignani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2307.08682",
    "title": "Implementation of a perception system for autonomous vehicles using a  detection-segmentation network in SoC FPGA",
    "abstract": "Perception and control systems for autonomous vehicles are an active area of scientific and industrial research. These solutions should be characterised by high efficiency in recognising obstacles and other environmental elements in different road conditions, real-time capability, and energy efficiency. Achieving such functionality requires an appropriate algorithm and a suitable computing platform. In this paper, we have used the MultiTaskV3 detection-segmentation network as the basis for a perception system that can perform both functionalities within a single architecture. It was appropriately trained, quantised, and implemented on the AMD Xilinx Kria KV260 Vision AI embedded platform. By using this device, it was possible to parallelise and accelerate the computations. Furthermore, the whole system consumes relatively little power compared to a CPU-based implementation (an average of 5 watts, compared to the minimum of 55 watts for weaker CPUs, and the small size (119mm x 140mm x 36mm) of the platform allows it to be used in devices where the amount of space available is limited. It also achieves an accuracy higher than 97% of the mAP (mean average precision) for object detection and above 90% of the mIoU (mean intersection over union) for image segmentation. The article also details the design of the Mecanum wheel vehicle, which was used to test the proposed solution in a mock-up city. ",
    "url": "https://arxiv.org/abs/2307.08682",
    "authors": [
      "Maciej Baczmanski",
      "Mateusz Wasala",
      "Tomasz Kryjak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.08695",
    "title": "Neural Video Depth Stabilizer",
    "abstract": "Video depth estimation aims to infer temporally consistent depth. Some methods achieve temporal consistency by finetuning a single-image depth model during test time using geometry and re-projection constraints, which is inefficient and not robust. An alternative approach is to learn how to enforce temporal consistency from data, but this requires well-designed models and sufficient video depth data. To address these challenges, we propose a plug-and-play framework called Neural Video Depth Stabilizer (NVDS) that stabilizes inconsistent depth estimations and can be applied to different single-image depth models without extra effort. We also introduce a large-scale dataset, Video Depth in the Wild (VDW), which consists of 14,203 videos with over two million frames, making it the largest natural-scene video depth dataset to our knowledge. We evaluate our method on the VDW dataset as well as two public benchmarks and demonstrate significant improvements in consistency, accuracy, and efficiency compared to previous approaches. Our work serves as a solid baseline and provides a data foundation for learning-based video depth models. We will release our dataset and code for future research. ",
    "url": "https://arxiv.org/abs/2307.08695",
    "authors": [
      "Yiran Wang",
      "Min Shi",
      "Jiaqi Li",
      "Zihao Huang",
      "Zhiguo Cao",
      "Jianming Zhang",
      "Ke Xian",
      "Guosheng Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08699",
    "title": "Pair then Relation: Pair-Net for Panoptic Scene Graph Generation",
    "abstract": "Panoptic Scene Graph (PSG) is a challenging task in Scene Graph Generation (SGG) that aims to create a more comprehensive scene graph representation using panoptic segmentation instead of boxes. However, current PSG methods have limited performance, which can hinder downstream task development. To improve PSG methods, we conducted an in-depth analysis to identify the bottleneck of the current PSG models, finding that inter-object pair-wise recall is a crucial factor which was ignored by previous PSG methods. Based on this, we present a novel framework: Pair then Relation (Pair-Net), which uses a Pair Proposal Network (PPN) to learn and filter sparse pair-wise relationships between subjects and objects. We also observed the sparse nature of object pairs and used this insight to design a lightweight Matrix Learner within the PPN. Through extensive ablation and analysis, our approach significantly improves upon leveraging the strong segmenter baseline. Notably, our approach achieves new state-of-the-art results on the PSG benchmark, with over 10% absolute gains compared to PSGFormer. The code of this paper is publicly available at https://github.com/king159/Pair-Net. ",
    "url": "https://arxiv.org/abs/2307.08699",
    "authors": [
      "Jinghao Wang",
      "Zhengyu Wen",
      "Xiangtai Li",
      "Zujin Guo",
      "Jingkang Yang",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.07534",
    "title": "Masked Autoencoders for Unsupervised Anomaly Detection in Medical Images",
    "abstract": "Pathological anomalies exhibit diverse appearances in medical imaging, making it difficult to collect and annotate a representative amount of data required to train deep learning models in a supervised setting. Therefore, in this work, we tackle anomaly detection in medical images training our framework using only healthy samples. We propose to use the Masked Autoencoder model to learn the structure of the normal samples, then train an anomaly classifier on top of the difference between the original image and the reconstruction provided by the masked autoencoder. We train the anomaly classifier in a supervised manner using as negative samples the reconstruction of the healthy scans, while as positive samples, we use pseudo-abnormal scans obtained via our novel pseudo-abnormal module. The pseudo-abnormal module alters the reconstruction of the normal samples by changing the intensity of several regions. We conduct experiments on two medical image data sets, namely BRATS2020 and LUNA16 and compare our method with four state-of-the-art anomaly detection frameworks, namely AST, RD4AD, AnoVAEGAN and f-AnoGAN. ",
    "url": "https://arxiv.org/abs/2307.07534",
    "authors": [
      "Mariana-Iuliana Georgescu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07566",
    "title": "Reconstruction of 3-Axis Seismocardiogram from Right-to-left and  Head-to-foot Components Using A Long Short-Term Memory Network",
    "abstract": "This pilot study aims to develop a deep learning model for predicting seismocardiogram (SCG) signals in the dorsoventral direction from the SCG signals in the right-to-left and head-to-foot directions ($\\textrm{SCG}_x$ and $\\textrm{SCG}_y$). The dataset used for the training and validation of the model was obtained from 15 healthy adult subjects. The SCG signals were recorded using tri-axial accelerometers placed on the chest of each subject. The signals were then segmented using electrocardiogram R waves, and the segments were downsampled, normalized, and centered around zero. The resulting dataset was used to train and validate a long short-term memory (LSTM) network with two layers and a dropout layer to prevent overfitting. The network took as input 100-time steps of $\\textrm{SCG}_x$ and $\\textrm{SCG}_y$, representing one cardiac cycle, and outputted a vector that mapped to the target variable being predicted. The results showed that the LSTM model had a mean square error of 0.09 between the predicted and actual SCG segments in the dorsoventral direction. The study demonstrates the potential of deep learning models for reconstructing 3-axis SCG signals using the data obtained from dual-axis accelerometers. ",
    "url": "https://arxiv.org/abs/2307.07566",
    "authors": [
      "Mohammad Muntasir Rahman",
      "Amirtah\u00e0 Taebi"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.07572",
    "title": "Harpa: High-Rate Phase Association with Travel Time Neural Fields",
    "abstract": "Phase association groups seismic wave arrivals according to their originating earthquakes. It is a fundamental task in a seismic data processing pipeline, but challenging to perform for smaller, high-rate seismic events which carry fundamental information about earthquake dynamics, especially with a commonly assumed inaccurate wave speed model. As a consequence, most association methods focus on larger events that occur at a lower rate and are thus easier to associate, even though microseismicity provides a valuable description of the elastic medium properties in the subsurface. In this paper, we show that association is possible at rates much higher than previously reported even when the wave speed is unknown. We propose Harpa, a high-rate seismic phase association method which leverages deep neural fields to build generative models of wave speeds and associated travel times, and first solves a joint spatio--temporal source localization and wave speed recovery problem, followed by association. We obviate the need for associated phases by interpreting arrival time data as probability measures and using an optimal transport loss to enforce data fidelity. The joint recovery problem is known to admit a unique solution under certain conditions but due to the non-convexity of the corresponding loss a simple gradient scheme converges to poor local minima. We show that this is effectively mitigated by stochastic gradient Langevin dynamics (SGLD). Numerical experiments show that \\harpa~efficiently associates high-rate seismicity clouds over complex, unknown wave speeds and graciously handles noisy and missing picks. ",
    "url": "https://arxiv.org/abs/2307.07572",
    "authors": [
      "Cheng Shi",
      "Maarten V. de Hoop",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.07657",
    "title": "Machine learning for option pricing: an empirical investigation of  network architectures",
    "abstract": "We consider the supervised learning problem of learning the price of an option or the implied volatility given appropriate input data (model parameters) and corresponding output data (option prices or implied volatilities). The majority of articles in this literature considers a (plain) feed forward neural network architecture in order to connect the neurons used for learning the function mapping inputs to outputs. In this article, motivated by methods in image classification and recent advances in machine learning methods for PDEs, we investigate empirically whether and how the choice of network architecture affects the accuracy and training time of a machine learning algorithm. We find that for option pricing problems, where we focus on the Black--Scholes and the Heston model, the generalized highway network architecture outperforms all other variants, when considering the mean squared error and the training time as criteria. Moreover, for the computation of the implied volatility, after a necessary transformation, a variant of the DGM architecture outperforms all other variants, when considering again the mean squared error and the training time as criteria. ",
    "url": "https://arxiv.org/abs/2307.07657",
    "authors": [
      "Laurens Van Mieghem",
      "Antonis Papapantoleon",
      "Jonas Papazoglou-Hennig"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.07726",
    "title": "Towards Optimal Neural Networks: the Role of Sample Splitting in  Hyperparameter Selection",
    "abstract": "When artificial neural networks have demonstrated exceptional practical success in a variety of domains, investigations into their theoretical characteristics, such as their approximation power, statistical properties, and generalization performance, have made significant strides. In this paper, we construct a novel theory for understanding the effectiveness of neural networks by discovering the mystery underlying a common practice during neural network model construction: sample splitting. Our theory demonstrates that, the optimal hyperparameters derived from sample splitting can enable a neural network model that asymptotically minimizes the prediction risk. We conduct extensive experiments across different application scenarios and network architectures, and the results manifest our theory's effectiveness. ",
    "url": "https://arxiv.org/abs/2307.07726",
    "authors": [
      "Shijin Gong",
      "Xinyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.07738",
    "title": "Negative probabilities in Gene Regulatory Networks",
    "abstract": "We introduce a natural framework to identify sign-indefinite co-expressions between genes based on the known expressions and given the sign of their respective correlations. Specifically, given information concerning the affinity among genes (i.e., connectivity in the gene regulatory network) and knowledge whether they promote/inhibit co-expression of the respective protein production, we seek rates that may explain the observed stationary distributions at the level of proteins. We propose to encapsulate their ``promotion vs.\\ inhibition'' functionality in a sign-indefinite probability transition matrix--a matrix whose row-sums equal to one, but is otherwise sign indefinite. The purpose of constructing such a representation for the interaction network with sign-indefinite contributions in protein regulation, is to quantify the structure and significance of various links, and to explain how these may affect the geometry of the network, highlighting the significance of the regulatory functions of certain genes. We cast the problem of finding the interaction (sign-indefinite) transition matrix as a solution to a convex optimization problem from which all the relevant geometric properties may be easily derived. ",
    "url": "https://arxiv.org/abs/2307.07738",
    "authors": [
      "Anqi Dong",
      "Tryphon T. Georgiou",
      "Allen Tannenbaum"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.07807",
    "title": "MUVF-YOLOX: A Multi-modal Ultrasound Video Fusion Network for Renal  Tumor Diagnosis",
    "abstract": "Early diagnosis of renal cancer can greatly improve the survival rate of patients. Contrast-enhanced ultrasound (CEUS) is a cost-effective and non-invasive imaging technique and has become more and more frequently used for renal tumor diagnosis. However, the classification of benign and malignant renal tumors can still be very challenging due to the highly heterogeneous appearance of cancer and imaging artifacts. Our aim is to detect and classify renal tumors by integrating B-mode and CEUS-mode ultrasound videos. To this end, we propose a novel multi-modal ultrasound video fusion network that can effectively perform multi-modal feature fusion and video classification for renal tumor diagnosis. The attention-based multi-modal fusion module uses cross-attention and self-attention to extract modality-invariant features and modality-specific features in parallel. In addition, we design an object-level temporal aggregation (OTA) module that can automatically filter low-quality features and efficiently integrate temporal information from multiple frames to improve the accuracy of tumor diagnosis. Experimental results on a multicenter dataset show that the proposed framework outperforms the single-modal models and the competing methods. Furthermore, our OTA module achieves higher classification accuracy than the frame-level predictions. Our code is available at \\url{https://github.com/JeunyuLi/MUAF}. ",
    "url": "https://arxiv.org/abs/2307.07807",
    "authors": [
      "Junyu Li",
      "Han Huang",
      "Dong Ni",
      "Wufeng Xue",
      "Dongmei Zhu",
      "Jun Cheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07868",
    "title": "Contrasting the efficiency of stock price prediction models using  various types of LSTM models aided with sentiment analysis",
    "abstract": "Our research aims to find the best model that uses companies projections and sector performances and how the given company fares accordingly to correctly predict equity share prices for both short and long term goals. ",
    "url": "https://arxiv.org/abs/2307.07868",
    "authors": [
      "Varun Sangwan",
      "Vishesh Kumar Singh",
      "Bibin Christopher V"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08140",
    "title": "GastroVision: A Multi-class Endoscopy Image Dataset for Computer Aided  Gastrointestinal Disease Detection",
    "abstract": "Integrating real-time artificial intelligence (AI) systems in clinical practices faces challenges such as scalability and acceptance. These challenges include data availability, biased outcomes, data quality, lack of transparency, and underperformance on unseen datasets from different distributions. The scarcity of large-scale, precisely labeled, and diverse datasets are the major challenge for clinical integration. This scarcity is also due to the legal restrictions and extensive manual efforts required for accurate annotations from clinicians. To address these challenges, we present GastroVision, a multi-center open-access gastrointestinal (GI) endoscopy dataset that includes different anatomical landmarks, pathological abnormalities, polyp removal cases and normal findings (a total of 24 classes) from the GI tract. The dataset comprises 8,000 images acquired from B{\\ae}rum Hospital in Norway and Karolinska University in Sweden and was annotated and verified by experienced GI endoscopists. Furthermore, we validate the significance of our dataset with extensive benchmarking based on the popular deep learning based baseline models. We believe our dataset can facilitate the development of AI-based algorithms for GI disease detection and classification. Our dataset is available at https://osf.io/84e7f/. ",
    "url": "https://arxiv.org/abs/2307.08140",
    "authors": [
      "Debesh Jha",
      "Vanshali Sharma",
      "Neethi Dasu",
      "Nikhil Kumar Tomar",
      "Steven Hicks",
      "M.K. Bhuyan",
      "Pradip K. Das",
      "Michael A. Riegler",
      "P\u00e5l Halvorsen",
      "Thomas de Lange",
      "Ulas Bagci"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08165",
    "title": "Short edges and noncrossing paths in complete topological graphs",
    "abstract": "Let $h(n)$ be the minimum integer such that every complete $n$-vertex simple topological graph contains an edge that crosses at most $h(n)$ other edges. In 2009, Kyn\\v{c}l and Valtr showed that $h(n) = O(n^2/\\log^{1/4} n)$, and in the other direction, gave constructions showing that $h(n) = \\Omega(n^{3/2})$. In this paper, we prove that $h(n) = O(n^{7/4})$. Along the way, we establish a new variant of Chazelle and Welzl's matching theorem for set systems with bounded VC-dimension, which we believe to be of independent interest. We also show that every complete $n$-vertex simple topological graph contains a noncrossing path on $\\Omega(n^{1/9})$ vertices. This improves the previously best known bound of $(\\log n)^{1 - o(1)}$ due to Aichholzer et al., and independently, the author and Zeng. ",
    "url": "https://arxiv.org/abs/2307.08165",
    "authors": [
      "Andrew Suk"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2307.08167",
    "title": "Computing the gradients with respect to all parameters of a quantum  neural network using a single circuit",
    "abstract": "When computing the gradients of a quantum neural network using the parameter-shift rule, the cost function needs to be calculated twice for the gradient with respect to a single adjustable parameter of the network. When the total number of parameters is high, the quantum circuit for the computation has to be adjusted and run for many times. Here we propose an approach to compute all the gradients using a single circuit only, with a much reduced circuit depth and less classical registers. We also demonstrate experimentally, on both real quantum hardware and simulator, that our approach has the advantages that the circuit takes a significantly shorter time to compile than the conventional approach, resulting in a speedup on the total runtime. ",
    "url": "https://arxiv.org/abs/2307.08167",
    "authors": [
      "Guang Ping He"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08204",
    "title": "A Quantum Convolutional Neural Network Approach for Object Detection and  Classification",
    "abstract": "This paper presents a comprehensive evaluation of the potential of Quantum Convolutional Neural Networks (QCNNs) in comparison to classical Convolutional Neural Networks (CNNs) and Artificial / Classical Neural Network (ANN) models. With the increasing amount of data, utilizing computing methods like CNN in real-time has become challenging. QCNNs overcome this challenge by utilizing qubits to represent data in a quantum environment and applying CNN structures to quantum computers. The time and accuracy of QCNNs are compared with classical CNNs and ANN models under different conditions such as batch size and input size. The maximum complexity level that QCNNs can handle in terms of these parameters is also investigated. The analysis shows that QCNNs have the potential to outperform both classical CNNs and ANN models in terms of accuracy and efficiency for certain applications, demonstrating their promise as a powerful tool in the field of machine learning. ",
    "url": "https://arxiv.org/abs/2307.08204",
    "authors": [
      "Gowri Namratha Meedinti",
      "Kandukuri Sai Srirekha",
      "Radhakrishnan Delhibabu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08214",
    "title": "Forward Laplacian: A New Computational Framework for Neural  Network-based Variational Monte Carlo",
    "abstract": "Neural network-based variational Monte Carlo (NN-VMC) has emerged as a promising cutting-edge technique of ab initio quantum chemistry. However, the high computational cost of existing approaches hinders their applications in realistic chemistry problems. Here, we report the development of a new NN-VMC method that achieves a remarkable speed-up by more than one order of magnitude, thereby greatly extending the applicability of NN-VMC to larger systems. Our key design is a novel computational framework named Forward Laplacian, which computes the Laplacian associated with neural networks, the bottleneck of NN-VMC, through an efficient forward propagation process. We then demonstrate that Forward Laplacian is not only versatile but also facilitates more developments of acceleration methods across various aspects, including optimization for sparse derivative matrix and efficient neural network design. Empirically, our approach enables NN-VMC to investigate a broader range of atoms, molecules and chemical reactions for the first time, providing valuable references to other ab initio methods. The results demonstrate a great potential in applying deep learning methods to solve general quantum mechanical problems. ",
    "url": "https://arxiv.org/abs/2307.08214",
    "authors": [
      "Ruichen Li",
      "Haotian Ye",
      "Du Jiang",
      "Xuelan Wen",
      "Chuwei Wang",
      "Zhe Li",
      "Xiang Li",
      "Di He",
      "Ji Chen",
      "Weiluo Ren",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2307.08266",
    "title": "Phase Transitions of Structured Codes of Graphs",
    "abstract": "We consider the symmetric difference of two graphs on the same vertex set $[n]$, which is the graph on $[n]$ whose edge set consists of all edges that belong to exactly one of the two graphs. Let $\\mathcal{F}$ be a class of graphs, and let $M_{\\mathcal{F}}(n)$ denote the maximum possible cardinality of a family $\\mathcal{G}$ of graphs on $[n]$ such that the symmetric difference of any two members in $\\mathcal{G}$ belongs to $\\mathcal{F}$. These concepts are recently investigated by Alon, Gujgiczer, K\\\"{o}rner, Milojevi\\'{c}, and Simonyi, with the aim of providing a new graphic approach to coding theory. In particular, $M_{\\mathcal{F}}(n)$ denotes the maximum possible size of this code. Existing results show that as the graph class $\\mathcal{F}$ changes, $M_{\\mathcal{F}}(n)$ can vary from $n$ to $2^{(1+o(1))\\binom{n}{2}}$. We study several phase transition problems related to $M_{\\mathcal{F}}(n)$ in general settings and present a partial solution to a recent problem posed by Alon et. al. ",
    "url": "https://arxiv.org/abs/2307.08266",
    "authors": [
      "Bo Bai",
      "Yu Gao",
      "Jie Ma",
      "Yuze Wu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2307.08268",
    "title": "Liver Tumor Screening and Diagnosis in CT with Pixel-Lesion-Patient  Network",
    "abstract": "Liver tumor segmentation and classification are important tasks in computer aided diagnosis. We aim to address three problems: liver tumor screening and preliminary diagnosis in non-contrast computed tomography (CT), and differential diagnosis in dynamic contrast-enhanced CT. A novel framework named Pixel-Lesion-pAtient Network (PLAN) is proposed. It uses a mask transformer to jointly segment and classify each lesion with improved anchor queries and a foreground-enhanced sampling loss. It also has an image-wise classifier to effectively aggregate global information and predict patient-level diagnosis. A large-scale multi-phase dataset is collected containing 939 tumor patients and 810 normal subjects. 4010 tumor instances of eight types are extensively annotated. On the non-contrast tumor screening task, PLAN achieves 95% and 96% in patient-level sensitivity and specificity. On contrast-enhanced CT, our lesion-level detection precision, recall, and classification accuracy are 92%, 89%, and 86%, outperforming widely used CNN and transformers for lesion segmentation. We also conduct a reader study on a holdout set of 250 cases. PLAN is on par with a senior human radiologist, showing the clinical significance of our results. ",
    "url": "https://arxiv.org/abs/2307.08268",
    "authors": [
      "Ke Yan",
      "Xiaoli Yin",
      "Yingda Xia",
      "Fakai Wang",
      "Shu Wang",
      "Yuan Gao",
      "Jiawen Yao",
      "Chunli Li",
      "Xiaoyu Bai",
      "Jingren Zhou",
      "Ling Zhang",
      "Le Lu",
      "Yu Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08351",
    "title": "Neural Modulation Fields for Conditional Cone Beam Neural Tomography",
    "abstract": "Conventional Computed Tomography (CT) methods require large numbers of noise-free projections for accurate density reconstructions, limiting their applicability to the more complex class of Cone Beam Geometry CT (CBCT) reconstruction. Recently, deep learning methods have been proposed to overcome these limitations, with methods based on neural fields (NF) showing strong performance, by approximating the reconstructed density through a continuous-in-space coordinate based neural network. Our focus is on improving such methods, however, unlike previous work, which requires training an NF from scratch for each new set of projections, we instead propose to leverage anatomical consistencies over different scans by training a single conditional NF on a dataset of projections. We propose a novel conditioning method where local modulations are modeled per patient as a field over the input domain through a Neural Modulation Field (NMF). The resulting Conditional Cone Beam Neural Tomography (CondCBNT) shows improved performance for both high and low numbers of available projections on noise-free and noisy data. ",
    "url": "https://arxiv.org/abs/2307.08351",
    "authors": [
      "Samuele Papa",
      "David M. Knigge",
      "Riccardo Valperga",
      "Nikita Moriakov",
      "Miltos Kofinas",
      "Jan-Jakob Sonke",
      "Efstratios Gavves"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08501",
    "title": "Corticomorphic Hybrid CNN-SNN Architecture for EEG-based Low-footprint  Low-latency Auditory Attention Detection",
    "abstract": "In a multi-speaker \"cocktail party\" scenario, a listener can selectively attend to a speaker of interest. Studies into the human auditory attention network demonstrate cortical entrainment to speech envelopes resulting in highly correlated Electroencephalography (EEG) measurements. Current trends in EEG-based auditory attention detection (AAD) using artificial neural networks (ANN) are not practical for edge-computing platforms due to longer decision windows using several EEG channels, with higher power consumption and larger memory footprint requirements. Nor are ANNs capable of accurately modeling the brain's top-down attention network since the cortical organization is complex and layer. In this paper, we propose a hybrid convolutional neural network-spiking neural network (CNN-SNN) corticomorphic architecture, inspired by the auditory cortex, which uses EEG data along with multi-speaker speech envelopes to successfully decode auditory attention with low latency down to 1 second, using only 8 EEG electrodes strategically placed close to the auditory cortex, at a significantly higher accuracy of 91.03%, compared to the state-of-the-art. Simultaneously, when compared to a traditional CNN reference model, our model uses ~15% fewer parameters at a lower bit precision resulting in ~57% memory footprint reduction. The results show great promise for edge-computing in brain-embedded devices, like smart hearing aids. ",
    "url": "https://arxiv.org/abs/2307.08501",
    "authors": [
      "Richard Gall",
      "Deniz Kocanaogullari",
      "Murat Akcakaya",
      "Deniz Erdogmus",
      "Rajkumar Kubendran"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.08535",
    "title": "Multi-class point cloud completion networks for 3D cardiac anatomy  reconstruction from cine magnetic resonance images",
    "abstract": "Cine magnetic resonance imaging (MRI) is the current gold standard for the assessment of cardiac anatomy and function. However, it typically only acquires a set of two-dimensional (2D) slices of the underlying three-dimensional (3D) anatomy of the heart, thus limiting the understanding and analysis of both healthy and pathological cardiac morphology and physiology. In this paper, we propose a novel fully automatic surface reconstruction pipeline capable of reconstructing multi-class 3D cardiac anatomy meshes from raw cine MRI acquisitions. Its key component is a multi-class point cloud completion network (PCCN) capable of correcting both the sparsity and misalignment issues of the 3D reconstruction task in a unified model. We first evaluate the PCCN on a large synthetic dataset of biventricular anatomies and observe Chamfer distances between reconstructed and gold standard anatomies below or similar to the underlying image resolution for multiple levels of slice misalignment. Furthermore, we find a reduction in reconstruction error compared to a benchmark 3D U-Net by 32% and 24% in terms of Hausdorff distance and mean surface distance, respectively. We then apply the PCCN as part of our automated reconstruction pipeline to 1000 subjects from the UK Biobank study in a cross-domain transfer setting and demonstrate its ability to reconstruct accurate and topologically plausible biventricular heart meshes with clinical metrics comparable to the previous literature. Finally, we investigate the robustness of our proposed approach and observe its capacity to successfully handle multiple common outlier conditions. ",
    "url": "https://arxiv.org/abs/2307.08535",
    "authors": [
      "Marcel Beetz",
      "Abhirup Banerjee",
      "Julius Ossenberg-Engels",
      "Vicente Grau"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08646",
    "title": "Global path preference and local response: A reward decomposition  approach for network path choice analysis in the presence of locally  perceived attributes",
    "abstract": "This study performs an attribute-level analysis of the global and local path preferences of network travelers. To this end, a reward decomposition approach is proposed and integrated into a link-based recursive (Markovian) path choice model. The approach decomposes the instantaneous reward function associated with each state-action pair into the global utility, a function of attributes globally perceived from anywhere in the network, and the local utility, a function of attributes that are only locally perceived from the current state. Only the global utility then enters the value function of each state, representing the future expected utility toward the destination. This global-local path choice model with decomposed reward functions allows us to analyze to what extent and which attributes affect the global and local path choices of agents. Moreover, unlike most adaptive path choice models, the proposed model can be estimated based on revealed path observations (without the information of plans) and as efficiently as deterministic recursive path choice models. The model was applied to the real pedestrian path choice observations in an urban street network where the green view index was extracted as a visual street quality from Google Street View images. The result revealed that pedestrians locally perceive and react to the visual street quality, rather than they have the pre-trip global perception on it. Furthermore, the simulation results using the estimated models suggested the importance of location selection of interventions when policy-related attributes are only locally perceived by travelers. ",
    "url": "https://arxiv.org/abs/2307.08646",
    "authors": [
      "Yuki Oyama"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2307.08657",
    "title": "Neural Image Compression: Generalization, Robustness, and Spectral  Biases",
    "abstract": "Recent neural image compression (NIC) advances have produced models which are starting to outperform traditional codecs. While this has led to growing excitement about using NIC in real-world applications, the successful adoption of any machine learning system in the wild requires it to generalize (and be robust) to unseen distribution shifts at deployment. Unfortunately, current research lacks comprehensive datasets and informative tools to evaluate and understand NIC performance in real-world settings. To bridge this crucial gap, first, this paper presents a comprehensive benchmark suite to evaluate the out-of-distribution (OOD) performance of image compression methods. Specifically, we provide CLIC-C and Kodak-C by introducing 15 corruptions to popular CLIC and Kodak benchmarks. Next, we propose spectrally inspired inspection tools to gain deeper insight into errors introduced by image compression methods as well as their OOD performance. We then carry out a detailed performance comparison of a classical codec with several NIC variants, revealing intriguing findings that challenge our current understanding of the strengths and limitations of NIC. Finally, we corroborate our empirical findings with theoretical analysis, providing an in-depth view of the OOD performance of NIC and its dependence on the spectral properties of the data. Our benchmarks, spectral inspection tools, and findings provide a crucial bridge to the real-world adoption of NIC. We hope that our work will propel future efforts in designing robust and generalizable NIC methods. Code and data will be made available at https://github.com/klieberman/ood_nic. ",
    "url": "https://arxiv.org/abs/2307.08657",
    "authors": [
      "Kelsey Lieberman",
      "James Diffenderfer",
      "Charles Godfrey",
      "Bhavya Kailkhura"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08686",
    "title": "An R package for parametric estimation of causal effects",
    "abstract": "This article explains the usage of R package CausalModels, which is publicly available on the Comprehensive R Archive Network. While packages are available for sufficiently estimating causal effects, there lacks a package that provides a collection of structural models using the conventional statistical approach developed by Hern\\'an and Robins (2020). CausalModels addresses this deficiency of software in R concerning causal inference by offering tools for methods that account for biases in observational data without requiring extensive statistical knowledge. These methods should not be ignored and may be more appropriate or efficient in solving particular problems. While implementations of these statistical models are distributed among a number of causal packages, CausalModels introduces a simple and accessible framework for a consistent modeling pipeline among a variety of statistical methods for estimating causal effects in a single R package. It consists of common methods including standardization, IP weighting, G-estimation, outcome regression, instrumental variables and propensity matching. ",
    "url": "https://arxiv.org/abs/2307.08686",
    "authors": [
      "Joshua Wolff Anderson",
      "Cyril Rakovsk"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:1812.11479",
    "title": "Abelian varieties with prescribed embedding and full embedding degrees",
    "abstract": " Comments: Typos fixed ",
    "url": "https://arxiv.org/abs/1812.11479",
    "authors": [
      "Steve Thakur"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:1905.06683",
    "title": "Uneven illumination surface defects inspection based on convolutional  neural network",
    "abstract": " Title: Uneven illumination surface defects inspection based on convolutional  neural network ",
    "url": "https://arxiv.org/abs/1905.06683",
    "authors": [
      "Hao Wu",
      "Yulong Liu",
      "Wenbin Gao",
      "Xiangrong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2003.11446",
    "title": "Probabilistic Counters for Privacy Preserving Data Aggregation",
    "abstract": " Title: Probabilistic Counters for Privacy Preserving Data Aggregation ",
    "url": "https://arxiv.org/abs/2003.11446",
    "authors": [
      "Dominik Bojko",
      "Krzysztof Grining",
      "Marek Klonowski"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2103.02774",
    "title": "Non-Asymptotic Guarantees for Reliable Identification of Granger  Causality via the LASSO",
    "abstract": " Title: Non-Asymptotic Guarantees for Reliable Identification of Granger  Causality via the LASSO ",
    "url": "https://arxiv.org/abs/2103.02774",
    "authors": [
      "Proloy Das",
      "Behtash Babadi"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2106.02797",
    "title": "Neural Distributed Source Coding",
    "abstract": " Title: Neural Distributed Source Coding ",
    "url": "https://arxiv.org/abs/2106.02797",
    "authors": [
      "Jay Whang",
      "Alliot Nagle",
      "Anish Acharya",
      "Hyeji Kim",
      "Alexandros G. Dimakis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.04486",
    "title": "Sketch-Based Anomaly Detection in Streaming Graphs",
    "abstract": " Comments: Accepted at SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2023 ",
    "url": "https://arxiv.org/abs/2106.04486",
    "authors": [
      "Siddharth Bhatia",
      "Mohit Wadhwa",
      "Kenji Kawaguchi",
      "Neil Shah",
      "Philip S. Yu",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.12655",
    "title": "MKConv: Multidimensional Feature Representation for Point Cloud Analysis",
    "abstract": " Comments: Accepted by Pattern Recognition 2023 ",
    "url": "https://arxiv.org/abs/2107.12655",
    "authors": [
      "Sungmin Woo",
      "Dogyoon Lee",
      "Sangwon Hwang",
      "Woojin Kim",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.01771",
    "title": "Self-Supervised Beat Tracking in Musical Signals with Polyphonic  Contrastive Learning",
    "abstract": " Comments: 59 pages, 20 figures, masters thesis, degree granted ",
    "url": "https://arxiv.org/abs/2201.01771",
    "authors": [
      "Dorian Desblancs"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2205.11472",
    "title": "Diversity Over Size: On the Effect of Sample and Topic Sizes for  Argument Mining Datasets",
    "abstract": " Title: Diversity Over Size: On the Effect of Sample and Topic Sizes for  Argument Mining Datasets ",
    "url": "https://arxiv.org/abs/2205.11472",
    "authors": [
      "Benjamin Schiller",
      "Johannes Daxenberger",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.14842",
    "title": "Efficient Reward Poisoning Attacks on Online Deep Reinforcement Learning",
    "abstract": " Comments: Accepted by TMLR ",
    "url": "https://arxiv.org/abs/2205.14842",
    "authors": [
      "Yinglun Xu",
      "Qi Zeng",
      "Gagandeep Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.03535",
    "title": "A Multiplex Approach Against Disturbance Propagation in Nonlinear  Networks with Delays",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2202.07638 ",
    "url": "https://arxiv.org/abs/2206.03535",
    "authors": [
      "Shihao Xie",
      "Giovanni Russo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.05794",
    "title": "SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks",
    "abstract": " Title: SGD and Weight Decay Provably Induce a Low-Rank Bias in Neural Networks ",
    "url": "https://arxiv.org/abs/2206.05794",
    "authors": [
      "Tomer Galanti",
      "Zachary S. Siegel",
      "Aparna Gupte",
      "Tomaso Poggio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.08260",
    "title": "From Bi-Level to One-Level: A Framework for Structural Attacks to Graph  Anomaly Detection",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2106.09989 ",
    "url": "https://arxiv.org/abs/2206.08260",
    "authors": [
      "Yulin Zhu",
      "Yuni Lai",
      "Kaifa Zhao",
      "Xiapu Luo",
      "Mingquan Yuan",
      "Jun Wu",
      "Jian Ren",
      "Kai Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.12781",
    "title": "Efficiently Leveraging Multi-level User Intent for Session-based  Recommendation via Atten-Mixer Network",
    "abstract": " Title: Efficiently Leveraging Multi-level User Intent for Session-based  Recommendation via Atten-Mixer Network ",
    "url": "https://arxiv.org/abs/2206.12781",
    "authors": [
      "Peiyan Zhang",
      "Jiayan Guo",
      "Chaozhuo Li",
      "Yueqi Xie",
      "Jaeboum Kim",
      "Yan Zhang",
      "Xing Xie",
      "Haohan Wang",
      "Sunghun Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.13104",
    "title": "Towards Secrecy-Aware Attacks Against Trust Prediction in Signed Social  Networks",
    "abstract": " Title: Towards Secrecy-Aware Attacks Against Trust Prediction in Signed Social  Networks ",
    "url": "https://arxiv.org/abs/2206.13104",
    "authors": [
      "Yulin Zhu",
      "Tomasz Michalak",
      "Xiapu Luo",
      "Xiaoge Zhang",
      "Kai Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.10603",
    "title": "Unsupervised pre-training of graph transformers on patient population  graphs",
    "abstract": " Comments: accepted for publication at the Medical Image Analysis Journal: this https URL 20 pages, 3 figures, 20 tables ",
    "url": "https://arxiv.org/abs/2207.10603",
    "authors": [
      "Chantal Pellegrini",
      "Nassir Navab",
      "Anees Kazi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.09418",
    "title": "SAFARI: Versatile and Efficient Evaluations for Robustness of  Interpretability",
    "abstract": " Comments: Accepted by the IEEE/CVF International Conference on Computer Vision 2023 (ICCV'23) ",
    "url": "https://arxiv.org/abs/2208.09418",
    "authors": [
      "Wei Huang",
      "Xingyu Zhao",
      "Gaojie Jin",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.10818",
    "title": "Memory-Augmented Graph Neural Networks: A Brain-Inspired Review",
    "abstract": " Title: Memory-Augmented Graph Neural Networks: A Brain-Inspired Review ",
    "url": "https://arxiv.org/abs/2209.10818",
    "authors": [
      "Guixiang Ma",
      "Vy A. Vo",
      "Theodore Willke",
      "Nesreen K. Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2209.11134",
    "title": "Neural Networks Based on Power Method and Inverse Power Method for  Solving Linear Eigenvalue Problems",
    "abstract": " Title: Neural Networks Based on Power Method and Inverse Power Method for  Solving Linear Eigenvalue Problems ",
    "url": "https://arxiv.org/abs/2209.11134",
    "authors": [
      "Qihong Yang",
      "Yangtao Deng",
      "Yu Yang",
      "Qiaolin He",
      "Shiquan Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.12068",
    "title": "NeRF-Loc: Transformer-Based Object Localization Within Neural Radiance  Fields",
    "abstract": " Title: NeRF-Loc: Transformer-Based Object Localization Within Neural Radiance  Fields ",
    "url": "https://arxiv.org/abs/2209.12068",
    "authors": [
      "Jiankai Sun",
      "Yan Xu",
      "Mingyu Ding",
      "Hongwei Yi",
      "Chen Wang",
      "Jingdong Wang",
      "Liangjun Zhang",
      "Mac Schwager"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.06282",
    "title": "DialoGen: Generalized Long-Range Context Representation for Dialogue  Systems",
    "abstract": " Title: DialoGen: Generalized Long-Range Context Representation for Dialogue  Systems ",
    "url": "https://arxiv.org/abs/2210.06282",
    "authors": [
      "Suvodip Dey",
      "Maunendra Sankar Desarkar",
      "P. K. Srijith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.10886",
    "title": "Backdoor Attack and Defense in Federated Generative Adversarial  Network-based Medical Image Synthesis",
    "abstract": " Comments: 25 pages, 7 figures. arXiv admin note: text overlap with arXiv:2207.00762 ",
    "url": "https://arxiv.org/abs/2210.10886",
    "authors": [
      "Ruinan Jin",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13815",
    "title": "FocusedCleaner: Sanitizing Poisoned Graphs for Robust GNN-based Node  Classification",
    "abstract": " Title: FocusedCleaner: Sanitizing Poisoned Graphs for Robust GNN-based Node  Classification ",
    "url": "https://arxiv.org/abs/2210.13815",
    "authors": [
      "Yulin Zhu",
      "Liang Tong",
      "Gaolei Li",
      "Xiapu Luo",
      "Kai Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.15539",
    "title": "Multi-Target Tracking with Transferable Convolutional Neural Networks",
    "abstract": " Comments: 5 pages, 3 figures; submitted to Proc. CAMSAP2023, December 10-13, 2023, Los Sue\\~nos, Costa Rica; Associated code is available at this https URL ",
    "url": "https://arxiv.org/abs/2210.15539",
    "authors": [
      "Damian Owerko",
      "Charilaos I. Kanatsoulis",
      "Jennifer Bondarchuk",
      "Donald J. Bucci Jr",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.02641",
    "title": "Graph Neural Networks on SPD Manifolds for Motor Imagery Classification:  A Perspective from the Time-Frequency Analysis",
    "abstract": " Comments: 15 pages, 5 figures, 6 Tables; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2211.02641",
    "authors": [
      "Ce Ju",
      "Cuntai Guan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05867",
    "title": "Robust Data-Driven Predictive Control of Unknown Nonlinear Systems using  Reachability Analysis",
    "abstract": " Comments: 8 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2211.05867",
    "authors": [
      "Mahsa Farjadnia",
      "Amr Alanwar",
      "Muhammad Umar B. Niazi",
      "Marco Molinari",
      "Karl Henrik Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.14400",
    "title": "Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev and  Besov Spaces",
    "abstract": " Title: Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev and  Besov Spaces ",
    "url": "https://arxiv.org/abs/2211.14400",
    "authors": [
      "Jonathan W. Siegel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.14646",
    "title": "Towards Improved Input Masking for Convolutional Neural Networks",
    "abstract": " Comments: 29 pages, 19 figures. Accepted at ICCV 2023 ",
    "url": "https://arxiv.org/abs/2211.14646",
    "authors": [
      "Sriram Balasubramanian",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.12887",
    "title": "Closed-form control with spike coding networks",
    "abstract": " Comments: 2nd stage review in an IEEE journal ",
    "url": "https://arxiv.org/abs/2212.12887",
    "authors": [
      "Filip S. Slijkhuis",
      "Sander W. Keemink",
      "Pablo Lanillos"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2301.01947",
    "title": "StitchNet: Composing Neural Networks from Pre-Trained Fragments",
    "abstract": " Title: StitchNet: Composing Neural Networks from Pre-Trained Fragments ",
    "url": "https://arxiv.org/abs/2301.01947",
    "authors": [
      "Surat Teerapittayanon",
      "Marcus Comiter",
      "Brad McDanel",
      "H.T. Kung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.06719",
    "title": "FemtoDet: An Object Detection Baseline for Energy Versus Performance  Tradeoffs",
    "abstract": " Comments: 15 pages, accepted by ICCV 2023 ",
    "url": "https://arxiv.org/abs/2301.06719",
    "authors": [
      "Peng Tu",
      "Xu Xie",
      "Guo AI",
      "Yuexiang Li",
      "Yawen Huang",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.08913",
    "title": "Unifying Structure Reasoning and Language Model Pre-training for Complex  Reasoning",
    "abstract": " Comments: 10 pages, 4 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2301.08913",
    "authors": [
      "Siyuan Wang",
      "Zhongyu Wei",
      "Jiarong Xu",
      "Taishan Li",
      "Zhihao Fan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.13192",
    "title": "Robust empirical risk minimization via Newton's method",
    "abstract": " Title: Robust empirical risk minimization via Newton's method ",
    "url": "https://arxiv.org/abs/2301.13192",
    "authors": [
      "Eirini Ioannou",
      "Muni Sreenivas Pydi",
      "Po-Ling Loh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02064",
    "title": "Lived Experience Matters: Automatic Detection of Stigma on Social Media  Toward People Who Use Substances",
    "abstract": " Comments: Accepted for publication the 2024 International AAAI Conference on Web and Social Media (ICWSM) ",
    "url": "https://arxiv.org/abs/2302.02064",
    "authors": [
      "Salvatore Giorgi",
      "Douglas Bellew",
      "Daniel Roy Sadek Habib",
      "Garrick Sherman",
      "Joao Sedoc",
      "Chase Smitterberg",
      "Amanda Devoto",
      "McKenzie Himelein-Wachowiak",
      "Brenda Curtis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.03665",
    "title": "HumanMAC: Masked Motion Completion for Human Motion Prediction",
    "abstract": " Title: HumanMAC: Masked Motion Completion for Human Motion Prediction ",
    "url": "https://arxiv.org/abs/2302.03665",
    "authors": [
      "Ling-Hao Chen",
      "Jiawei Zhang",
      "Yewen Li",
      "Yiren Pang",
      "Xiaobo Xia",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.06294",
    "title": "CholecTriplet2022: Show me a tool and tell me the triplet -- an  endoscopic vision challenge for surgical action triplet detection",
    "abstract": " Comments: MICCAI EndoVis CholecTriplet2022 challenge report. Published at Elsevier journal of Medical Image Analysis. 25 pages, 15 figures, 8 tables ",
    "url": "https://arxiv.org/abs/2302.06294",
    "authors": [
      "Chinedu Innocent Nwoye",
      "Tong Yu",
      "Saurav Sharma",
      "Aditya Murali",
      "Deepak Alapatt",
      "Armine Vardazaryan",
      "Kun Yuan",
      "Jonas Hajek",
      "Wolfgang Reiter",
      "Amine Yamlahi",
      "Finn-Henri Smidt",
      "Xiaoyang Zou",
      "Guoyan Zheng",
      "Bruno Oliveira",
      "Helena R. Torres",
      "Satoshi Kondo",
      "Satoshi Kasai",
      "Felix Holm",
      "Ege \u00d6zsoy",
      "Shuangchun Gui",
      "Han Li",
      "Sista Raviteja",
      "Rachana Sathish",
      "Pranav Poudel",
      "Binod Bhattarai",
      "Ziheng Wang",
      "Guo Rui",
      "Melanie Schellenberg",
      "Jo\u00e3o L. Vila\u00e7a",
      "Tobias Czempiel",
      "Zhenkun Wang",
      "Debdoot Sheet",
      "Shrawan Kumar Thapa",
      "Max Berniker",
      "Patrick Godau",
      "Pedro Morais",
      "Sudarshan Regmi",
      "Thuy Nuong Tran",
      "Jaime Fonseca",
      "Jan-Hinrich N\u00f6lke",
      "Estev\u00e3o Lima",
      "Eduard Vazquez",
      "Lena Maier-Hein",
      "Nassir Navab",
      "Pietro Mascagni",
      "Barbara Seeliger",
      "Cristians Gonzalez",
      "Didier Mutter",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.06494",
    "title": "Explicit3D: Graph Network with Spatial Inference for Single Image 3D  Object Detection",
    "abstract": " Title: Explicit3D: Graph Network with Spatial Inference for Single Image 3D  Object Detection ",
    "url": "https://arxiv.org/abs/2302.06494",
    "authors": [
      "Yanjun Liu",
      "Wenming Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.08942",
    "title": "PAC-Bayesian Generalization Bounds for Adversarial Generative Models",
    "abstract": " Title: PAC-Bayesian Generalization Bounds for Adversarial Generative Models ",
    "url": "https://arxiv.org/abs/2302.08942",
    "authors": [
      "Sokhna Diarra Mbacke",
      "Florence Clerc",
      "Pascal Germain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.11351",
    "title": "Regularised neural networks mimic human insight",
    "abstract": " Comments: 17 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2302.11351",
    "authors": [
      "Anika T. L\u00f6we",
      "L\u00e9o Touzo",
      "Paul S. Muhle-Karbe",
      "Andrew M. Saxe",
      "Christopher Summerfield",
      "Nicolas W. Schuck"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2302.12200",
    "title": "A Neural Span-Based Continual Named Entity Recognition Model",
    "abstract": " Comments: Accepted by AAAI'23 (Update to official format) ",
    "url": "https://arxiv.org/abs/2302.12200",
    "authors": [
      "Yunan Zhang",
      "Qingcai Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.13262",
    "title": "Modulated Neural ODEs",
    "abstract": " Title: Modulated Neural ODEs ",
    "url": "https://arxiv.org/abs/2302.13262",
    "authors": [
      "Ilze Amanda Auzina",
      "\u00c7a\u011fatay Y\u0131ld\u0131z",
      "Sara Magliacane",
      "Matthias Bethge",
      "Efstratios Gavves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.14267",
    "title": "Adversarial Attack with Raindrops",
    "abstract": " Comments: 10 pages, 7 figures, This manuscript was submitted to CVPR 2023 ",
    "url": "https://arxiv.org/abs/2302.14267",
    "authors": [
      "Jiyuan Liu",
      "Bingyi Lu",
      "Mingkang Xiong",
      "Tao Zhang",
      "Huilin Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.01002",
    "title": "Nearest-neighbour directed random hyperbolic graphs",
    "abstract": " Comments: 26 papers, 12 figures ",
    "url": "https://arxiv.org/abs/2303.01002",
    "authors": [
      "I.A. Kasyanov",
      "P. van der Hoorn",
      "D. Krioukov",
      "M.V. Tamm"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2303.02867",
    "title": "Dual Feedback Attention Framework via Boundary-Aware Auxiliary and  Progressive Semantic Optimization for Salient Object Detection in Optical  Remote Sensing Imagery",
    "abstract": " Comments: The article got reviewer feedback that we needed to redesign the network and the experiments needed to be rebuilt. Because the changes involved are so substantial, we have decided to retract the manuscript ",
    "url": "https://arxiv.org/abs/2303.02867",
    "authors": [
      "Dejun Feng",
      "Hongyu Chen",
      "Suning Liu",
      "Xingyu Shen",
      "Ziyang Liao",
      "Yakun Xie",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2303.03323",
    "title": "CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive  Learning",
    "abstract": " Comments: 22 pages. Accepted at ICCV 2023 ",
    "url": "https://arxiv.org/abs/2303.03323",
    "authors": [
      "Hritik Bansal",
      "Nishad Singhi",
      "Yu Yang",
      "Fan Yin",
      "Aditya Grover",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.04676",
    "title": "Considerations on the Theory of Training Models with Differential  Privacy",
    "abstract": " Comments: 18 pages, a book chapter. arXiv admin note: text overlap with arXiv:2212.05796 ",
    "url": "https://arxiv.org/abs/2303.04676",
    "authors": [
      "Marten van Dijk",
      "Phuong Ha Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.06662",
    "title": "Fuzzy Alignments in Directed Acyclic Graph for Non-Autoregressive  Machine Translation",
    "abstract": " Comments: ICLR 2023 ",
    "url": "https://arxiv.org/abs/2303.06662",
    "authors": [
      "Zhengrui Ma",
      "Chenze Shao",
      "Shangtong Gui",
      "Min Zhang",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.09706",
    "title": "Unsupervised Self-Driving Attention Prediction via Uncertainty Mining  and Knowledge Embedding",
    "abstract": " Comments: ICCV 2023 ",
    "url": "https://arxiv.org/abs/2303.09706",
    "authors": [
      "Pengfei Zhu",
      "Mengshi Qi",
      "Xia Li",
      "Weijian Li",
      "Huadong Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.10840",
    "title": "Ref-NeuS: Ambiguity-Reduced Neural Implicit Surface Learning for  Multi-View Reconstruction with Reflection",
    "abstract": " Comments: ICCV 2023, Project webpage: this https URL ",
    "url": "https://arxiv.org/abs/2303.10840",
    "authors": [
      "Wenhang Ge",
      "Tao Hu",
      "Haoyu Zhao",
      "Shu Liu",
      "Ying-Cong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.11324",
    "title": "Open-vocabulary Panoptic Segmentation with Embedding Modulation",
    "abstract": " Comments: ICCV2023 ",
    "url": "https://arxiv.org/abs/2303.11324",
    "authors": [
      "Xi Chen",
      "Shuang Li",
      "Ser-Nam Lim",
      "Antonio Torralba",
      "Hengshuang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17765",
    "title": "Learning from Similar Linear Representations: Adaptivity, Minimaxity,  and Robustness",
    "abstract": " Comments: 76 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2303.17765",
    "authors": [
      "Ye Tian",
      "Yuqi Gu",
      "Yang Feng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03935",
    "title": "Last-Layer Fairness Fine-tuning is Simple and Effective for Neural  Networks",
    "abstract": " Comments: Published at the ICML 2023 Workshop on Spurious Correlations, Invariance, and Stability ",
    "url": "https://arxiv.org/abs/2304.03935",
    "authors": [
      "Yuzhen Mao",
      "Zhun Deng",
      "Huaxiu Yao",
      "Ting Ye",
      "Kenji Kawaguchi",
      "James Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04391",
    "title": "CAFIN: Centrality Aware Fairness inducing IN-processing for Unsupervised  Representation Learning on Graphs",
    "abstract": " Title: CAFIN: Centrality Aware Fairness inducing IN-processing for Unsupervised  Representation Learning on Graphs ",
    "url": "https://arxiv.org/abs/2304.04391",
    "authors": [
      "Arvindh Arun",
      "Aakash Aanegola",
      "Amul Agrawal",
      "Ramasuri Narayanam",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2304.08224",
    "title": "Uncharted Territory: Energy Attacks in the Battery-less Internet of  Things",
    "abstract": " Title: Uncharted Territory: Energy Attacks in the Battery-less Internet of  Things ",
    "url": "https://arxiv.org/abs/2304.08224",
    "authors": [
      "Luca Mottola",
      "Arslan Hameed",
      "Thiemo Voigt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.01979",
    "title": "Glitch in the Matrix: A Large Scale Benchmark for Content Driven  Audio-Visual Forgery Detection and Localization",
    "abstract": " Comments: The paper is under consideration/review at Computer Vision and Image Understanding Journal ",
    "url": "https://arxiv.org/abs/2305.01979",
    "authors": [
      "Zhixi Cai",
      "Shreya Ghosh",
      "Abhinav Dhall",
      "Tom Gedeon",
      "Kalin Stefanov",
      "Munawar Hayat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14301",
    "title": "A Laplacian Pyramid Based Generative H&E Stain Augmentation Network",
    "abstract": " Title: A Laplacian Pyramid Based Generative H&E Stain Augmentation Network ",
    "url": "https://arxiv.org/abs/2305.14301",
    "authors": [
      "Fangda Li",
      "Zhiqiang Hu",
      "Wen Chen",
      "Avinash Kak"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14758",
    "title": "MRN: Multiplexed Routing Network for Incremental Multilingual Text  Recognition",
    "abstract": " Comments: Accepted by ICCV 2023 ",
    "url": "https://arxiv.org/abs/2305.14758",
    "authors": [
      "Tianlun Zheng",
      "Zhineng Chen",
      "BingChen Huang",
      "Wei Zhang",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18465",
    "title": "Federated Learning of Gboard Language Models with Differential Privacy",
    "abstract": " Comments: ACL industry track; v2 updating SecAgg details ",
    "url": "https://arxiv.org/abs/2305.18465",
    "authors": [
      "Zheng Xu",
      "Yanxiang Zhang",
      "Galen Andrew",
      "Christopher A. Choquette-Choo",
      "Peter Kairouz",
      "H. Brendan McMahan",
      "Jesse Rosenstock",
      "Yuanbo Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.01359",
    "title": "DWT-CompCNN: Deep Image Classification Network for High Throughput JPEG  2000 Compressed Documents",
    "abstract": " Comments: Accepted in Pattern Analysis and Applications (this https URL) ",
    "url": "https://arxiv.org/abs/2306.01359",
    "authors": [
      "Tejasvee Bisen",
      "Mohammed Javed",
      "Shashank Kirtania",
      "P. Nagabhushan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2306.04904",
    "title": "An adaptive augmented Lagrangian method for training physics and  equality constrained artificial neural networks",
    "abstract": " Title: An adaptive augmented Lagrangian method for training physics and  equality constrained artificial neural networks ",
    "url": "https://arxiv.org/abs/2306.04904",
    "authors": [
      "Shamsulhaq Basir",
      "Inanc Senocak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2306.06206",
    "title": "PotatoPestNet: A CTInceptionV3-RS-Based Neural Network for Accurate  Identification of Potato Pests",
    "abstract": " Title: PotatoPestNet: A CTInceptionV3-RS-Based Neural Network for Accurate  Identification of Potato Pests ",
    "url": "https://arxiv.org/abs/2306.06206",
    "authors": [
      "Md. Simul Hasan Talukder",
      "Rejwan Bin Sulaiman",
      "Mohammad Raziuddin Chowdhury",
      "Musarrat Saberin Nipun",
      "Taminul Islam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07274",
    "title": "CryoChains: Heterogeneous Reconstruction of Molecular Assembly of  Semi-flexible Chains from Cryo-EM Images",
    "abstract": " Title: CryoChains: Heterogeneous Reconstruction of Molecular Assembly of  Semi-flexible Chains from Cryo-EM Images ",
    "url": "https://arxiv.org/abs/2306.07274",
    "authors": [
      "Bongjin Koo",
      "Julien Martel",
      "Ariana Peck",
      "Axel Levy",
      "Fr\u00e9d\u00e9ric Poitevin",
      "Nina Miolane"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2306.10123",
    "title": "Dual Node and Edge Fairness-Aware Graph Partition",
    "abstract": " Comments: Revised Equation 2 and Equation 7, results unchanged ",
    "url": "https://arxiv.org/abs/2306.10123",
    "authors": [
      "Tingwei Liu",
      "Peizhao Li",
      "Hongfu Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13800",
    "title": "A First Order Meta Stackelberg Method for Robust Federated Learning",
    "abstract": " Comments: Accepted to ICML 2023 Workshop on The 2nd New Frontiers In Adversarial Machine Learning. Associated technical report arXiv:2306.13273 ",
    "url": "https://arxiv.org/abs/2306.13800",
    "authors": [
      "Yunian Pan",
      "Tao Li",
      "Henger Li",
      "Tianyi Xu",
      "Zizhan Zheng",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2306.16175",
    "title": "$\\mathbf{C}^2$Former: Calibrated and Complementary Transformer for  RGB-Infrared Object Detection",
    "abstract": " Title: $\\mathbf{C}^2$Former: Calibrated and Complementary Transformer for  RGB-Infrared Object Detection ",
    "url": "https://arxiv.org/abs/2306.16175",
    "authors": [
      "Maoxun Yuan",
      "Xingxing Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2307.01066",
    "title": "PIGNet2: A Versatile Deep Learning-based Protein-Ligand Interaction  Prediction Model for Binding Affinity Scoring and Virtual Screening",
    "abstract": " Comments: 13 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2307.01066",
    "authors": [
      "Seokhyun Moon",
      "Sang-Yeon Hwang",
      "Jaechang Lim",
      "Woo Youn Kim"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.02054",
    "title": "Emoji Prediction using Transformer Models",
    "abstract": " Title: Emoji Prediction using Transformer Models ",
    "url": "https://arxiv.org/abs/2307.02054",
    "authors": [
      "Muhammad Osama Nusrat",
      "Zeeshan Habib",
      "Mehreen Alam",
      "Saad Ahmed Jamal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.03903",
    "title": "Adversarial Self-Attack Defense and Spatial-Temporal Relation Mining for  Visible-Infrared Video Person Re-Identification",
    "abstract": " Comments: 11 pages,8 figures ",
    "url": "https://arxiv.org/abs/2307.03903",
    "authors": [
      "Huafeng Li",
      "Le Xu",
      "Yafei Zhang",
      "Dapeng Tao",
      "Zhengtao Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.04500",
    "title": "Algorithm-Generated Versus Human-Generated Academic Plans: Determining  Optimality from Community College Articulation Agreements",
    "abstract": " Title: Algorithm-Generated Versus Human-Generated Academic Plans: Determining  Optimality from Community College Articulation Agreements ",
    "url": "https://arxiv.org/abs/2307.04500",
    "authors": [
      "David Van Nguyen",
      "Shayan Doroudi",
      "Daniel A. Epstein"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2307.04954",
    "title": "Hybrid hidden Markov LSTM for short-term traffic flow prediction",
    "abstract": " Title: Hybrid hidden Markov LSTM for short-term traffic flow prediction ",
    "url": "https://arxiv.org/abs/2307.04954",
    "authors": [
      "Agnimitra Sengupta",
      "Adway Das",
      "S. Ilgin Guler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.05217",
    "title": "Supervised Attention Using Homophily in Graph Neural Networks",
    "abstract": " Comments: Accepted at ICANN 2023 ",
    "url": "https://arxiv.org/abs/2307.05217",
    "authors": [
      "Michail Chatzianastasis",
      "Giannis Nikolentzos",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2307.05422",
    "title": "Differential Analysis of Triggers and Benign Features for Black-Box DNN  Backdoor Detection",
    "abstract": " Comments: Published in the IEEE Transactions on Information Forensics and Security ",
    "url": "https://arxiv.org/abs/2307.05422",
    "authors": [
      "Hao Fu",
      "Prashanth Krishnamurthy",
      "Siddharth Garg",
      "Farshad Khorrami"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.05949",
    "title": "Newell's theory based feature transformations for spatio-temporal  traffic prediction",
    "abstract": " Title: Newell's theory based feature transformations for spatio-temporal  traffic prediction ",
    "url": "https://arxiv.org/abs/2307.05949",
    "authors": [
      "Agnimitra Sengupta",
      "S. Ilgin Guler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.06548",
    "title": "Multi-objective Evolutionary Search of Variable-length Composite  Semantic Perturbations",
    "abstract": " Title: Multi-objective Evolutionary Search of Variable-length Composite  Semantic Perturbations ",
    "url": "https://arxiv.org/abs/2307.06548",
    "authors": [
      "Jialiang Sun",
      "Wen Yao",
      "Tingsong Jiang",
      "Xiaoqian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.06919",
    "title": "DAXiot: A Decentralized Authentication and Authorization Scheme for  Dynamic IoT Networks",
    "abstract": " Comments: 6 pages, 2 figures, 3 listings, 1 table. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2307.06919",
    "authors": [
      "Artur Philipp",
      "Axel K\u00fcpper"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.07125",
    "title": "CeRF: Convolutional Neural Radiance Fields for New View Synthesis with  Derivatives of Ray Modeling",
    "abstract": " Comments: 16 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2307.07125",
    "authors": [
      "Xiaoyan Yang",
      "Dingbo Lu",
      "Yang Li",
      "Chenhui Li",
      "Changbo Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2307.07417",
    "title": "RoPDA: Robust Prompt-based Data Augmentation for Low-Resource Named  Entity Recognition",
    "abstract": " Title: RoPDA: Robust Prompt-based Data Augmentation for Low-Resource Named  Entity Recognition ",
    "url": "https://arxiv.org/abs/2307.07417",
    "authors": [
      "Sihan Song",
      "Furao Shen",
      "Jian Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]