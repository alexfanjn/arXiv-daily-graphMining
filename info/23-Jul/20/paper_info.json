[
  {
    "id": "arXiv:2307.09518",
    "title": "Efficient Inverse-designed Structural Infill for Complex Engineering  Structures",
    "abstract": "Inverse design of high-resolution and fine-detailed 3D lightweight mechanical structures is notoriously expensive due to the need for vast computational resources and the use of very fine-scaled complex meshes. Furthermore, in designing for additive manufacturing, infill is often neglected as a component of the optimized structure. In this paper, both concerns are addressed using a de-homogenization topology optimization procedure on complex engineering structures discretized by 3D unstructured hexahedrals. Using a rectangular-hole microstructure (reminiscent to the stiffness optimal orthogonal rank-3 multi-scale) as a base material for the multi-scale optimization, a coarse-scale optimized geometry can be obtained using homogenization-based topology optimization. Due to the microstructure periodicity, this coarse-scale geometry can be up-sampled to a fine physical geometry with optimized infill, with minor loss in structural performance and at a fraction of the cost of a fine-scale solution. The upsampling on 3D unstructured grids is achieved through stream surface tracing which aligns with the optimized local orientation. The periodicity of the physical geometry can be tuned, such that the material serves as a structural component and also as an efficient infill for additive manufacturing designs. The method is demonstrated through three examples. It achieves comparable structural performance to state-of-the-art methods but stands out for its significant computational time reduction, much faster than the base-line method. By allowing multiple active layers, the mapped solution becomes more mechanically stable, leading to an increased critical buckling load factor without additional computational expense. The proposed approach achieves promising results, benchmarking against large-scale SIMP models demonstrates computational efficiency improvements of up to 250 times. ",
    "url": "https://arxiv.org/abs/2307.09518",
    "authors": [
      "Peter D\u00f8rffler Ladegaard Jensen",
      "Tim Felle Olsen",
      "J. Andreas B\u00e6rentzen",
      "Niels Aage",
      "Ole Sigmund"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.09520",
    "title": "Adversarial Bayesian Augmentation for Single-Source Domain  Generalization",
    "abstract": "Generalizing to unseen image domains is a challenging problem primarily due to the lack of diverse training data, inaccessible target data, and the large domain shift that may exist in many real-world settings. As such data augmentation is a critical component of domain generalization methods that seek to address this problem. We present Adversarial Bayesian Augmentation (ABA), a novel algorithm that learns to generate image augmentations in the challenging single-source domain generalization setting. ABA draws on the strengths of adversarial learning and Bayesian neural networks to guide the generation of diverse data augmentations -- these synthesized image domains aid the classifier in generalizing to unseen domains. We demonstrate the strength of ABA on several types of domain shift including style shift, subpopulation shift, and shift in the medical imaging setting. ABA outperforms all previous state-of-the-art methods, including pre-specified augmentations, pixel-based and convolutional-based augmentations. ",
    "url": "https://arxiv.org/abs/2307.09520",
    "authors": [
      "Sheng Cheng",
      "Tejas Gokhale",
      "Yezhou Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09533",
    "title": "Approximately counting independent sets in dense bipartite graphs via  subspace enumeration",
    "abstract": "We give a randomized algorithm that approximates the number of independent sets in a dense, regular bipartite graph -- in the language of approximate counting, we give an FPRAS for #BIS on the class of dense, regular bipartite graphs. Efficient counting algorithms typically apply to ``high-temperature'' problems on bounded-degree graphs, and our contribution is a notable exception as it applies to dense graphs in a low-temperature setting. Our methods give a counting-focused complement to the long line of work in combinatorial optimization showing that CSPs such as Max-Cut and Unique Games are easy on dense graphs via spectral arguments. The proof exploits the fact that dense, regular graphs exhibit a kind of small-set expansion (i.e. bounded threshold rank), which via subspace enumeration lets us enumerate small cuts efficiently. ",
    "url": "https://arxiv.org/abs/2307.09533",
    "authors": [
      "Charlie Carlson",
      "Ewan Davies",
      "Alexandra Kolla",
      "Aditya Potukuchi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2307.09542",
    "title": "Can Neural Network Memorization Be Localized?",
    "abstract": "Recent efforts at explaining the interplay of memorization and generalization in deep overparametrized networks have posited that neural networks $\\textit{memorize}$ \"hard\" examples in the final few layers of the model. Memorization refers to the ability to correctly predict on $\\textit{atypical}$ examples of the training set. In this work, we show that rather than being confined to individual layers, memorization is a phenomenon confined to a small set of neurons in various layers of the model. First, via three experimental sources of converging evidence, we find that most layers are redundant for the memorization of examples and the layers that contribute to example memorization are, in general, not the final layers. The three sources are $\\textit{gradient accounting}$ (measuring the contribution to the gradient norms from memorized and clean examples), $\\textit{layer rewinding}$ (replacing specific model weights of a converged model with previous training checkpoints), and $\\textit{retraining}$ (training rewound layers only on clean examples). Second, we ask a more generic question: can memorization be localized $\\textit{anywhere}$ in a model? We discover that memorization is often confined to a small number of neurons or channels (around 5) of the model. Based on these insights we propose a new form of dropout -- $\\textit{example-tied dropout}$ that enables us to direct the memorization of examples to an apriori determined set of neurons. By dropping out these neurons, we are able to reduce the accuracy on memorized examples from $100\\%\\to3\\%$, while also reducing the generalization gap. ",
    "url": "https://arxiv.org/abs/2307.09542",
    "authors": [
      "Pratyush Maini",
      "Michael C. Mozer",
      "Hanie Sedghi",
      "Zachary C. Lipton",
      "J. Zico Kolter",
      "Chiyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09548",
    "title": "Surgical Action Triplet Detection by Mixed Supervised Learning of  Instrument-Tissue Interactions",
    "abstract": "Surgical action triplets describe instrument-tissue interactions as (instrument, verb, target) combinations, thereby supporting a detailed analysis of surgical scene activities and workflow. This work focuses on surgical action triplet detection, which is challenging but more precise than the traditional triplet recognition task as it consists of joint (1) localization of surgical instruments and (2) recognition of the surgical action triplet associated with every localized instrument. Triplet detection is highly complex due to the lack of spatial triplet annotation. We analyze how the amount of instrument spatial annotations affects triplet detection and observe that accurate instrument localization does not guarantee better triplet detection due to the risk of erroneous associations with the verbs and targets. To solve the two tasks, we propose MCIT-IG, a two-stage network, that stands for Multi-Class Instrument-aware Transformer-Interaction Graph. The MCIT stage of our network models per class embedding of the targets as additional features to reduce the risk of misassociating triplets. Furthermore, the IG stage constructs a bipartite dynamic graph to model the interaction between the instruments and targets, cast as the verbs. We utilize a mixed-supervised learning strategy that combines weak target presence labels for MCIT and pseudo triplet labels for IG to train our network. We observed that complementing minimal instrument spatial annotations with target embeddings results in better triplet detection. We evaluate our model on the CholecT50 dataset and show improved performance on both instrument localization and triplet detection, topping the leaderboard of the CholecTriplet challenge in MICCAI 2022. ",
    "url": "https://arxiv.org/abs/2307.09548",
    "authors": [
      "Saurav Sharma",
      "Chinedu Innocent Nwoye",
      "Didier Mutter",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09550",
    "title": "The semantic landscape paradigm for neural networks",
    "abstract": "Deep neural networks exhibit a fascinating spectrum of phenomena ranging from predictable scaling laws to the unpredictable emergence of new capabilities as a function of training time, dataset size and network size. Analysis of these phenomena has revealed the existence of concepts and algorithms encoded within the learned representations of these networks. While significant strides have been made in explaining observed phenomena separately, a unified framework for understanding, dissecting, and predicting the performance of neural networks is lacking. Here, we introduce the semantic landscape paradigm, a conceptual and mathematical framework that describes the training dynamics of neural networks as trajectories on a graph whose nodes correspond to emergent algorithms that are instrinsic to the learned representations of the networks. This abstraction enables us to describe a wide range of neural network phenomena in terms of well studied problems in statistical physics. Specifically, we show that grokking and emergence with scale are associated with percolation phenomena, and neural scaling laws are explainable in terms of the statistics of random walks on graphs. Finally, we discuss how the semantic landscape paradigm complements existing theoretical and practical approaches aimed at understanding and interpreting deep neural networks. ",
    "url": "https://arxiv.org/abs/2307.09550",
    "authors": [
      "Shreyas Gokhale"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ]
  },
  {
    "id": "arXiv:2307.09552",
    "title": "Self-Compatibility: Evaluating Causal Discovery without Ground Truth",
    "abstract": "As causal ground truth is incredibly rare, causal discovery algorithms are commonly only evaluated on simulated data. This is concerning, given that simulations reflect common preconceptions about generating processes regarding noise distributions, model classes, and more. In this work, we propose a novel method for falsifying the output of a causal discovery algorithm in the absence of ground truth. Our key insight is that while statistical learning seeks stability across subsets of data points, causal learning should seek stability across subsets of variables. Motivated by this insight, our method relies on a notion of compatibility between causal graphs learned on different subsets of variables. We prove that detecting incompatibilities can falsify wrongly inferred causal relations due to violation of assumptions or errors from finite sample effects. Although passing such compatibility tests is only a necessary criterion for good performance, we argue that it provides strong evidence for the causal models whenever compatibility entails strong implications for the joint distribution. We also demonstrate experimentally that detection of incompatibilities can aid in causal model selection. ",
    "url": "https://arxiv.org/abs/2307.09552",
    "authors": [
      "Philipp M. Faller",
      "Leena Chennuru Vankadara",
      "Atalanti A. Mastakouri",
      "Francesco Locatello",
      "Dominik Janzing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.09555",
    "title": "Transient Neural Radiance Fields for Lidar View Synthesis and 3D  Reconstruction",
    "abstract": "Neural radiance fields (NeRFs) have become a ubiquitous tool for modeling scene appearance and geometry from multiview imagery. Recent work has also begun to explore how to use additional supervision from lidar or depth sensor measurements in the NeRF framework. However, previous lidar-supervised NeRFs focus on rendering conventional camera imagery and use lidar-derived point cloud data as auxiliary supervision; thus, they fail to incorporate the underlying image formation model of the lidar. Here, we propose a novel method for rendering transient NeRFs that take as input the raw, time-resolved photon count histograms measured by a single-photon lidar system, and we seek to render such histograms from novel views. Different from conventional NeRFs, the approach relies on a time-resolved version of the volume rendering equation to render the lidar measurements and capture transient light transport phenomena at picosecond timescales. We evaluate our method on a first-of-its-kind dataset of simulated and captured transient multiview scans from a prototype single-photon lidar. Overall, our work brings NeRFs to a new dimension of imaging at transient timescales, newly enabling rendering of transient imagery from novel views. Additionally, we show that our approach recovers improved geometry and conventional appearance compared to point cloud-based supervision when training on few input viewpoints. Transient NeRFs may be especially useful for applications which seek to simulate raw lidar measurements for downstream tasks in autonomous driving, robotics, and remote sensing. ",
    "url": "https://arxiv.org/abs/2307.09555",
    "authors": [
      "Anagh Malik",
      "Parsa Mirdehghan",
      "Sotiris Nousias",
      "Kiriakos N. Kutulakos",
      "David B. Lindell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.09562",
    "title": "Rethinking Intersection Over Union for Small Object Detection in  Few-Shot Regime",
    "abstract": "In Few-Shot Object Detection (FSOD), detecting small objects is extremely difficult. The limited supervision cripples the localization capabilities of the models and a few pixels shift can dramatically reduce the Intersection over Union (IoU) between the ground truth and predicted boxes for small objects. To this end, we propose Scale-adaptive Intersection over Union (SIoU), a novel box similarity measure. SIoU changes with the objects' size, it is more lenient with small object shifts. We conducted a user study and SIoU better aligns than IoU with human judgment. Employing SIoU as an evaluation criterion helps to build more user-oriented models. SIoU can also be used as a loss function to prioritize small objects during training, outperforming existing loss functions. SIoU improves small object detection in the non-few-shot regime, but this setting is unrealistic in the industry as annotated detection datasets are often too expensive to acquire. Hence, our experiments mainly focus on the few-shot regime to demonstrate the superiority and versatility of SIoU loss. SIoU improves significantly FSOD performance on small objects in both natural (Pascal VOC and COCO datasets) and aerial images (DOTA and DIOR). In aerial imagery, small objects are critical and SIoU loss achieves new state-of-the-art FSOD on DOTA and DIOR. ",
    "url": "https://arxiv.org/abs/2307.09562",
    "authors": [
      "Pierre Le Jeune",
      "Anissa Mokraoui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09575",
    "title": "Causal Influences over Social Learning Networks",
    "abstract": "This paper investigates causal influences between agents linked by a social graph and interacting over time. In particular, the work examines the dynamics of social learning models and distributed decision-making protocols, and derives expressions that reveal the causal relations between pairs of agents and explain the flow of influence over the network. The results turn out to be dependent on the graph topology and the level of information that each agent has about the inference problem they are trying to solve. Using these conclusions, the paper proposes an algorithm to rank the overall influence between agents to discover highly influential agents. It also provides a method to learn the necessary model parameters from raw observational data. The results and the proposed algorithm are illustrated by considering both synthetic data and real Twitter data. ",
    "url": "https://arxiv.org/abs/2307.09575",
    "authors": [
      "Mert Kayaalp",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.09588",
    "title": "Automating Wood Species Detection and Classification in Microscopic  Images of Fibrous Materials with Deep Learning",
    "abstract": "We have developed a methodology for the systematic generation of a large image dataset of macerated wood references, which we used to generate image data for nine hardwood genera. This is the basis for a substantial approach to automate, for the first time, the identification of hardwood species in microscopic images of fibrous materials by deep learning. Our methodology includes a flexible pipeline for easy annotation of vessel elements. We compare the performance of different neural network architectures and hyperparameters. Our proposed method performs similarly well to human experts. In the future, this will improve controls on global wood fiber product flows to protect forests. ",
    "url": "https://arxiv.org/abs/2307.09588",
    "authors": [
      "Lars Nieradzik",
      "J\u00f6rdis Sieburg-Rockel",
      "Stephanie Helmling",
      "Janis Keuper",
      "Thomas Weibel",
      "Andrea Olbrich",
      "Henrike Stephani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09602",
    "title": "A max-affine spline approximation of neural networks using the Legendre  transform of a convex-concave representation",
    "abstract": "This work presents a novel algorithm for transforming a neural network into a spline representation. Unlike previous work that required convex and piecewise-affine network operators to create a max-affine spline alternate form, this work relaxes this constraint. The only constraint is that the function be bounded and possess a well-define second derivative, although this was shown experimentally to not be strictly necessary. It can also be performed over the whole network rather than on each layer independently. As in previous work, this bridges the gap between neural networks and approximation theory but also enables the visualisation of network feature maps. Mathematical proof and experimental investigation of the technique is performed with approximation error and feature maps being extracted from a range of architectures, including convolutional neural networks. ",
    "url": "https://arxiv.org/abs/2307.09602",
    "authors": [
      "Adam Perrett",
      "Danny Wood",
      "Gavin Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09613",
    "title": "Retrieving Continuous Time Event Sequences using Neural Temporal Point  Processes with Learnable Hashing",
    "abstract": "Temporal sequences have become pervasive in various real-world applications. Consequently, the volume of data generated in the form of continuous time-event sequence(s) or CTES(s) has increased exponentially in the past few years. Thus, a significant fraction of the ongoing research on CTES datasets involves designing models to address downstream tasks such as next-event prediction, long-term forecasting, sequence classification etc. The recent developments in predictive modeling using marked temporal point processes (MTPP) have enabled an accurate characterization of several real-world applications involving the CTESs. However, due to the complex nature of these CTES datasets, the task of large-scale retrieval of temporal sequences has been overlooked by the past literature. In detail, by CTES retrieval we mean that for an input query sequence, a retrieval system must return a ranked list of relevant sequences from a large corpus. To tackle this, we propose NeuroSeqRet, a first-of-its-kind framework designed specifically for end-to-end CTES retrieval. Specifically, NeuroSeqRet introduces multiple enhancements over standard retrieval frameworks and first applies a trainable unwarping function on the query sequence which makes it comparable with corpus sequences, especially when a relevant query-corpus pair has individually different attributes. Next, it feeds the unwarped query sequence and the corpus sequence into MTPP-guided neural relevance models. We develop four variants of the relevance model for different kinds of applications based on the trade-off between accuracy and efficiency. We also propose an optimization framework to learn binary sequence embeddings from the relevance scores, suitable for the locality-sensitive hashing. Our experiments show the significant accuracy boost of NeuroSeqRet as well as the efficacy of our hashing mechanism. ",
    "url": "https://arxiv.org/abs/2307.09613",
    "authors": [
      "Vinayak Gupta",
      "Srikanta Bedathur",
      "Abir De"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2307.09618",
    "title": "Privacy Preserving Billing in Local Energy Markets with Imperfect  Bid-Offer Fulfillment (Long Version)",
    "abstract": "Smart grids are being increasingly deployed worldwide, as they constitute the electricity grid of the future, providing bidirectional communication between households. One of their main potential applications is the peer-to-peer (P2P) energy trading market, which promises users better electricity prices and higher incentives to produce renewable energy. However, most P2P markets require users to submit energy bids/offers in advance, which cannot account for unexpected surpluses of energy consumption/production. Moreover, the fine-grained metering information used in calculating and settling bills/rewards is inherently sensitive and must be protected in conformity with existing privacy regulations. To address these issues, this report proposes a novel privacy-preserving billing and settlements protocol, PPBSP, for use in local energy markets with imperfect bid-offer fulfillment, which only uses homomorphically encrypted versions of the half-hourly user consumption data. PPBSP also supports various cost-sharing mechanisms among market participants, including two new and improved methods of proportionally redistributing the cost of maintaining the balance of the grid in a fair manner. An informal privacy analysis is performed, highlighting the privacy-enhancing characteristics of the protocol, which include metering data and bill confidentiality. PPBSP is also evaluated in terms of computation cost and communication overhead, demonstrating its efficiency and feasibility for markets with varying sizes. ",
    "url": "https://arxiv.org/abs/2307.09618",
    "authors": [
      "Andrei Hutu",
      "Mustafa A. Mustafa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2307.09633",
    "title": "Co-Simulation Framework For Network Attack Generation and Monitoring",
    "abstract": "Resilience assessment is a critical requirement of a power grid to maintain high availability, security, and quality of service. Most grid research work that is currently pursued does not have the capability to have hardware testbeds. Additionally, with the integration of distributed energy resources, the attack surface of the grid is increasing. This increases the need for reliable and realistic modeling techniques that are usable by the wider research community. Therefore, simulation testbeds have been used to model a real-world power grid topology and measure the impact of various perturbations. Existing co-simulation platforms for powergrid focus on a limited components of the overall system, such as focusing only on the dynamics of the physical layer. Additionally a significant number of existing platforms need specialized hardware that may be too expensive for most researchers. Finally, not many platforms support realistic modeling of the communication layer, which requires use of Supervisory Control and Data Acquisition communication protocol such as DNP3 while modeling cybersecurity scenarios. We present Network Attack Testbed in [Power] Grid (NATI[P]G), (pronounced natig), a standalone, containerized, and reusable environment to enable cyber analysts and researchers to run different cybersecurity and performance scenarios on powergrid. Our tool combines GridLAB-D, a grid simulator, HELICS, a co-simulation framework, and NS-3, a network simulator, to create an end-to-end simulation environment for the power grid. We demonstrate use cases by generating a library of datasets for several scenarios. These datasets can be used to detect cyberattacks at the cyber layer, and develop counter measures to these adverse scenarios. ",
    "url": "https://arxiv.org/abs/2307.09633",
    "authors": [
      "Oceane Bel",
      "Joonseok Kim",
      "William J Hofer",
      "Manisha Maharjan",
      "Sumit Purohit",
      "Shwetha Niddodi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.09650",
    "title": "With Flying Colors: Predicting Community Success in Large-scale  Collaborative Campaigns",
    "abstract": "Online communities develop unique characteristics, establish social norms, and exhibit distinct dynamics among their members. Activity in online communities often results in concrete ``off-line'' actions with a broad societal impact (e.g., political street protests and norms related to sexual misconduct). While community dynamics, information diffusion, and online collaborations have been widely studied in the past two decades, quantitative studies that measure the effectiveness of online communities in promoting their agenda are scarce. In this work, we study the correspondence between the effectiveness of a community, measured by its success level in a competitive online campaign, and the underlying dynamics between its members. To this end, we define a novel task: predicting the success level of online communities in Reddit's r/place - a large-scale distributed experiment that required collaboration between community members. We consider an array of definitions for success level; each is geared toward different aspects of collaborative achievement. We experiment with several hybrid models, combining various types of features. Our models significantly outperform all baseline models over all definitions of `success level'. Analysis of the results and the factors that contribute to the success of coordinated campaigns can provide a better understanding of the resilience or the vulnerability of communities to online social threats such as election interference or anti-science trends. We make all data used for this study publicly available for further research. ",
    "url": "https://arxiv.org/abs/2307.09650",
    "authors": [
      "Abraham Israeli",
      "Oren Tsur"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09660",
    "title": "Neural Priority Queues for Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have shown considerable success in neural algorithmic reasoning. Many traditional algorithms make use of an explicit memory in the form of a data structure. However, there has been limited exploration on augmenting GNNs with external memory. In this paper, we present Neural Priority Queues, a differentiable analogue to algorithmic priority queues, for GNNs. We propose and motivate a desiderata for memory modules, and show that Neural PQs exhibit the desiderata, and reason about their use with algorithmic reasoning. This is further demonstrated by empirical results on the CLRS-30 dataset. Furthermore, we find the Neural PQs useful in capturing long-range interactions, as empirically shown on a dataset from the Long-Range Graph Benchmark. ",
    "url": "https://arxiv.org/abs/2307.09660",
    "authors": [
      "Rishabh Jain",
      "Petar Veli\u010dkovi\u0107",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.09662",
    "title": "Object-aware Gaze Target Detection",
    "abstract": "Gaze target detection aims to predict the image location where the person is looking and the probability that a gaze is out of the scene. Several works have tackled this task by regressing a gaze heatmap centered on the gaze location, however, they overlooked decoding the relationship between the people and the gazed objects. This paper proposes a Transformer-based architecture that automatically detects objects (including heads) in the scene to build associations between every head and the gazed-head/object, resulting in a comprehensive, explainable gaze analysis composed of: gaze target area, gaze pixel point, the class and the image location of the gazed-object. Upon evaluation of the in-the-wild benchmarks, our method achieves state-of-the-art results on all metrics (up to 2.91% gain in AUC, 50% reduction in gaze distance, and 9% gain in out-of-frame average precision) for gaze target detection and 11-13% improvement in average precision for the classification and the localization of the gazed-objects. The code of the proposed method is available https://github.com/francescotonini/object-aware-gaze-target-detection ",
    "url": "https://arxiv.org/abs/2307.09662",
    "authors": [
      "Francesco Tonini",
      "Nicola Dall'Asen",
      "Cigdem Beyan",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09665",
    "title": "Anticipating Technical Expertise and Capability Evolution in Research  Communities using Dynamic Graph Transformers",
    "abstract": "The ability to anticipate technical expertise and capability evolution trends globally is essential for national and global security, especially in safety-critical domains like nuclear nonproliferation (NN) and rapidly emerging fields like artificial intelligence (AI). In this work, we extend traditional statistical relational learning approaches (e.g., link prediction in collaboration networks) and formulate a problem of anticipating technical expertise and capability evolution using dynamic heterogeneous graph representations. We develop novel capabilities to forecast collaboration patterns, authorship behavior, and technical capability evolution at different granularities (e.g., scientist and institution levels) in two distinct research fields. We implement a dynamic graph transformer (DGT) neural architecture, which pushes the state-of-the-art graph neural network models by (a) forecasting heterogeneous (rather than homogeneous) nodes and edges, and (b) relying on both discrete -- and continuous -- time inputs. We demonstrate that our DGT models predict collaboration, partnership, and expertise patterns with 0.26, 0.73, and 0.53 mean reciprocal rank values for AI and 0.48, 0.93, and 0.22 for NN domains. DGT model performance exceeds the best-performing static graph baseline models by 30-80% across AI and NN domains. Our findings demonstrate that DGT models boost inductive task performance, when previously unseen nodes appear in the test data, for the domains with emerging collaboration patterns (e.g., AI). Specifically, models accurately predict which established scientists will collaborate with early career scientists and vice-versa in the AI domain. ",
    "url": "https://arxiv.org/abs/2307.09665",
    "authors": [
      "Sameera Horawalavithana",
      "Ellyn Ayton",
      "Anastasiya Usenko",
      "Robin Cosbey",
      "Svitlana Volkova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2307.09676",
    "title": "Domain Adaptation for Enhanced Object Detection in Foggy and Rainy  Weather for Autonomous Driving",
    "abstract": "Most object detection models for autonomous driving may experience a significant drop in performance when deployed in real-world applications, due to the well-known domain shift issue. Supervised object detection methods for autonomous driving usually assume a consistent feature distribution between training and testing data, however, such assumptions may not always be the case when weather conditions differ significantly. For example, an object detection model trained under clear weather may not perform well in foggy or rainy weather, due to the domain gap. Overcoming detection bottlenecks in foggy or rainy weather scenarios is a significant challenge for autonomous vehicles deployed in the wild. To address the domain gap in different weather conditions, This paper proposes a novel domain adaptive object detection framework for autonomous driving in foggy and rainy weather. Our method leverages both image-level and object-level adaptation to reduce the domain discrepancy in image style and object appearance. Additionally, to enhance the model's performance under challenging samples, we introduce a new adversarial gradient reversal layer that performs adversarial mining on hard examples alongside domain adaptation. Moreover, we propose to generate an auxiliary domain by data augmentation to enforce a new domain-level metric regularization. Experimental results on public benchmarks demonstrate that object detection performance is significantly improved when using our proposed method in domain shift scenarios for autonomous driving applications. ",
    "url": "https://arxiv.org/abs/2307.09676",
    "authors": [
      "Jinlong Li",
      "Runsheng Xu",
      "Jin Ma",
      "Qin Zou",
      "Jiaqi Ma",
      "Hongkai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09692",
    "title": "STRAPPER: Preference-based Reinforcement Learning via Self-training  Augmentation and Peer Regularization",
    "abstract": "Preference-based reinforcement learning (PbRL) promises to learn a complex reward function with binary human preference. However, such human-in-the-loop formulation requires considerable human effort to assign preference labels to segment pairs, hindering its large-scale applications. Recent approache has tried to reuse unlabeled segments, which implicitly elucidates the distribution of segments and thereby alleviates the human effort. And consistency regularization is further considered to improve the performance of semi-supervised learning. However, we notice that, unlike general classification tasks, in PbRL there exits a unique phenomenon that we defined as similarity trap in this paper. Intuitively, human can have diametrically opposite preferredness for similar segment pairs, but such similarity may trap consistency regularization fail in PbRL. Due to the existence of similarity trap, such consistency regularization improperly enhances the consistency possiblity of the model's predictions between segment pairs, and thus reduces the confidence in reward learning, since the augmented distribution does not match with the original one in PbRL. To overcome such issue, we present a self-training method along with our proposed peer regularization, which penalizes the reward model memorizing uninformative labels and acquires confident predictions. Empirically, we demonstrate that our approach is capable of learning well a variety of locomotion and robotic manipulation behaviors using different semi-supervised alternatives and peer regularization. ",
    "url": "https://arxiv.org/abs/2307.09692",
    "authors": [
      "Yachen Kang",
      "Li He",
      "Jinxin Liu",
      "Zifeng Zhuang",
      "Donglin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09721",
    "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
    "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous mentions to a multimodal knowledge graph, has attracted wide attention in recent years. Though large efforts have been made to explore the complementary effect among multiple modalities, however, they may fail to fully absorb the comprehensive expression of abbreviated textual context and implicit visual indication. Even worse, the inevitable noisy data may cause inconsistency of different modalities during the learning process, which severely degenerates the performance. To address the above issues, in this paper, we propose a novel Multi-GraIned Multimodal InteraCtion Network $\\textbf{(MIMIC)}$ framework for solving the MEL task. Specifically, the unified inputs of mentions and entities are first encoded by textual/visual encoders separately, to extract global descriptive features and local detailed features. Then, to derive the similarity matching score for each mention-entity pair, we device three interaction units to comprehensively explore the intra-modal interaction and inter-modal fusion among features of entities and mentions. In particular, three modules, namely the Text-based Global-Local interaction Unit (TGLU), Vision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based interaction Unit (CMFU) are designed to capture and integrate the fine-grained representation lying in abbreviated text and implicit visual cues. Afterwards, we introduce a unit-consistency objective function via contrastive learning to avoid inconsistency and model degradation. Experimental results on three public benchmark datasets demonstrate that our solution outperforms various state-of-the-art baselines, and ablation studies verify the effectiveness of designed modules. ",
    "url": "https://arxiv.org/abs/2307.09721",
    "authors": [
      "Pengfei Luo",
      "Tong Xu",
      "Shiwei Wu",
      "Chen Zhu",
      "Linli Xu",
      "Enhong Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09724",
    "title": "AesPA-Net: Aesthetic Pattern-Aware Style Transfer Networks",
    "abstract": "To deliver the artistic expression of the target style, recent studies exploit the attention mechanism owing to its ability to map the local patches of the style image to the corresponding patches of the content image. However, because of the low semantic correspondence between arbitrary content and artworks, the attention module repeatedly abuses specific local patches from the style image, resulting in disharmonious and evident repetitive artifacts. To overcome this limitation and accomplish impeccable artistic style transfer, we focus on enhancing the attention mechanism and capturing the rhythm of patterns that organize the style. In this paper, we introduce a novel metric, namely pattern repeatability, that quantifies the repetition of patterns in the style image. Based on the pattern repeatability, we propose Aesthetic Pattern-Aware style transfer Networks (AesPA-Net) that discover the sweet spot of local and global style expressions. In addition, we propose a novel self-supervisory task to encourage the attention mechanism to learn precise and meaningful semantic correspondence. Lastly, we introduce the patch-wise style loss to transfer the elaborate rhythm of local patterns. Through qualitative and quantitative evaluations, we verify the reliability of the proposed pattern repeatability that aligns with human perception, and demonstrate the superiority of the proposed framework. ",
    "url": "https://arxiv.org/abs/2307.09724",
    "authors": [
      "Kibeom Hong",
      "Seogkyu Jeon",
      "Junsoo Lee",
      "Namhyuk Ahn",
      "Kunhee Kim",
      "Pilhyeon Lee",
      "Daesik Kim",
      "Youngjung Uh",
      "Hyeran Byun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09727",
    "title": "SAMConvex: Fast Discrete Optimization for CT Registration using  Self-supervised Anatomical Embedding and Correlation Pyramid",
    "abstract": "Estimating displacement vector field via a cost volume computed in the feature space has shown great success in image registration, but it suffers excessive computation burdens. Moreover, existing feature descriptors only extract local features incapable of representing the global semantic information, which is especially important for solving large transformations. To address the discussed issues, we propose SAMConvex, a fast coarse-to-fine discrete optimization method for CT registration that includes a decoupled convex optimization procedure to obtain deformation fields based on a self-supervised anatomical embedding (SAM) feature extractor that captures both local and global information. To be specific, SAMConvex extracts per-voxel features and builds 6D correlation volumes based on SAM features, and iteratively updates a flow field by performing lookups on the correlation volumes with a coarse-to-fine scheme. SAMConvex outperforms the state-of-the-art learning-based methods and optimization-based methods over two inter-patient registration datasets (Abdomen CT and HeadNeck CT) and one intra-patient registration dataset (Lung CT). Moreover, as an optimization-based method, SAMConvex only takes $\\sim2$s ($\\sim5s$ with instance optimization) for one paired images. ",
    "url": "https://arxiv.org/abs/2307.09727",
    "authors": [
      "Zi Li",
      "Lin Tian",
      "Tony C. W. Mok",
      "Xiaoyu Bai",
      "Puyang Wang",
      "Jia Ge",
      "Jingren Zhou",
      "Le Lu",
      "Xianghua Ye",
      "Ke Yan",
      "Dakai Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09728",
    "title": "Uncertainty-Driven Multi-Scale Feature Fusion Network for Real-time  Image Deraining",
    "abstract": "Visual-based measurement systems are frequently affected by rainy weather due to the degradation caused by rain streaks in captured images, and existing imaging devices struggle to address this issue in real-time. While most efforts leverage deep networks for image deraining and have made progress, their large parameter sizes hinder deployment on resource-constrained devices. Additionally, these data-driven models often produce deterministic results, without considering their inherent epistemic uncertainty, which can lead to undesired reconstruction errors. Well-calibrated uncertainty can help alleviate prediction errors and assist measurement devices in mitigating risks and improving usability. Therefore, we propose an Uncertainty-Driven Multi-Scale Feature Fusion Network (UMFFNet) that learns the probability mapping distribution between paired images to estimate uncertainty. Specifically, we introduce an uncertainty feature fusion block (UFFB) that utilizes uncertainty information to dynamically enhance acquired features and focus on blurry regions obscured by rain streaks, reducing prediction errors. In addition, to further boost the performance of UMFFNet, we fused feature information from multiple scales to guide the network for efficient collaborative rain removal. Extensive experiments demonstrate that UMFFNet achieves significant performance improvements with few parameters, surpassing state-of-the-art image deraining methods. ",
    "url": "https://arxiv.org/abs/2307.09728",
    "authors": [
      "Ming Tong",
      "Xuefeng Yan",
      "Yongzhen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.09738",
    "title": "A discretization-invariant extension and analysis of some deep operator  networks",
    "abstract": "We present a generalized version of the discretization-invariant neural operator and prove that the network is a universal approximation in the operator sense. Moreover, by incorporating additional terms in the architecture, we establish a connection between this discretization-invariant neural operator network and those discussed before. The discretization-invariance property of the operator network implies that different input functions can be sampled using various sensor locations within the same training and testing phases. Additionally, since the network learns a ``basis'' for the input and output function spaces, our approach enables the evaluation of input functions on different discretizations. To evaluate the performance of the proposed discretization-invariant neural operator, we focus on challenging examples from multiscale partial differential equations. Our experimental results indicate that the method achieves lower prediction errors compared to previous networks and benefits from its discretization-invariant property. ",
    "url": "https://arxiv.org/abs/2307.09738",
    "authors": [
      "Zecheng Zhang",
      "Wing Tat Leung",
      "Hayden Schaeffer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.09749",
    "title": "Towards Robust Scene Text Image Super-resolution via Explicit Location  Enhancement",
    "abstract": "Scene text image super-resolution (STISR), aiming to improve image quality while boosting downstream scene text recognition accuracy, has recently achieved great success. However, most existing methods treat the foreground (character regions) and background (non-character regions) equally in the forward process, and neglect the disturbance from the complex background, thus limiting the performance. To address these issues, in this paper, we propose a novel method LEMMA that explicitly models character regions to produce high-level text-specific guidance for super-resolution. To model the location of characters effectively, we propose the location enhancement module to extract character region features based on the attention map sequence. Besides, we propose the multi-modal alignment module to perform bidirectional visual-semantic alignment to generate high-quality prior guidance, which is then incorporated into the super-resolution branch in an adaptive manner using the proposed adaptive fusion module. Experiments on TextZoom and four scene text recognition benchmarks demonstrate the superiority of our method over other state-of-the-art methods. Code is available at https://github.com/csguoh/LEMMA. ",
    "url": "https://arxiv.org/abs/2307.09749",
    "authors": [
      "Hang Guo",
      "Tao Dai",
      "Guanghao Meng",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09751",
    "title": "Information Retrieval Meets Large Language Models: A Strategic Report  from Chinese IR Community",
    "abstract": "The research field of Information Retrieval (IR) has evolved significantly, expanding beyond traditional search to meet diverse user information needs. Recently, Large Language Models (LLMs) have demonstrated exceptional capabilities in text understanding, generation, and knowledge inference, opening up exciting avenues for IR research. LLMs not only facilitate generative retrieval but also offer improved solutions for user understanding, model evaluation, and user-system interactions. More importantly, the synergistic relationship among IR models, LLMs, and humans forms a new technical paradigm that is more powerful for information seeking. IR models provide real-time and relevant information, LLMs contribute internal knowledge, and humans play a central role of demanders and evaluators to the reliability of information services. Nevertheless, significant challenges exist, including computational costs, credibility concerns, domain-specific limitations, and ethical considerations. To thoroughly discuss the transformative impact of LLMs on IR research, the Chinese IR community conducted a strategic workshop in April 2023, yielding valuable insights. This paper provides a summary of the workshop's outcomes, including the rethinking of IR's core values, the mutual enhancement of LLMs and IR, the proposal of a novel IR technical paradigm, and open challenges. ",
    "url": "https://arxiv.org/abs/2307.09751",
    "authors": [
      "Qingyao Ai",
      "Ting Bai",
      "Zhao Cao",
      "Yi Chang",
      "Jiawei Chen",
      "Zhumin Chen",
      "Zhiyong Cheng",
      "Shoubin Dong",
      "Zhicheng Dou",
      "Fuli Feng",
      "Shen Gao",
      "Jiafeng Guo",
      "Xiangnan He",
      "Yanyan Lan",
      "Chenliang Li",
      "Yiqun Liu",
      "Ziyu Lyu",
      "Weizhi Ma",
      "Jun Ma",
      "Zhaochun Ren",
      "Pengjie Ren",
      "Zhiqiang Wang",
      "Mingwen Wang",
      "Jirong Wen",
      "Le Wu",
      "Xin Xin",
      "Jun Xu",
      "Dawei Yin",
      "Peng Zhang",
      "Fan Zhang",
      "Weinan Zhang",
      "Min Zhang",
      "Xiaofei Zhu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09762",
    "title": "Reinforcing POD based model reduction techniques in reaction-diffusion  complex networks using stochastic filtering and pattern recognition",
    "abstract": "Complex networks are used to model many real-world systems. However, the dimensionality of these systems can make them challenging to analyze. Dimensionality reduction techniques like POD can be used in such cases. However, these models are susceptible to perturbations in the input data. We propose an algorithmic framework that combines techniques from pattern recognition (PR) and stochastic filtering theory to enhance the output of such models. The results of our study show that our method can improve the accuracy of the surrogate model under perturbed inputs. Deep Neural Networks (DNNs) are susceptible to adversarial attacks. However, recent research has revealed that neural Ordinary Differential Equations (ODEs) exhibit robustness in specific applications. We benchmark our algorithmic framework with a Neural ODE-based approach as a reference. ",
    "url": "https://arxiv.org/abs/2307.09762",
    "authors": [
      "Abhishek Ajayakumar",
      "Soumyendu Raha"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.09763",
    "title": "Towards Building More Robust Models with Frequency Bias",
    "abstract": "The vulnerability of deep neural networks to adversarial samples has been a major impediment to their broad applications, despite their success in various fields. Recently, some works suggested that adversarially-trained models emphasize the importance of low-frequency information to achieve higher robustness. While several attempts have been made to leverage this frequency characteristic, they have all faced the issue that applying low-pass filters directly to input images leads to irreversible loss of discriminative information and poor generalizability to datasets with distinct frequency features. This paper presents a plug-and-play module called the Frequency Preference Control Module that adaptively reconfigures the low- and high-frequency components of intermediate feature representations, providing better utilization of frequency in robust learning. Empirical studies show that our proposed module can be easily incorporated into any adversarial training framework, further improving model robustness across different architectures and datasets. Additionally, experiments were conducted to examine how the frequency bias of robust models impacts the adversarial training process and its final robustness, revealing interesting insights. ",
    "url": "https://arxiv.org/abs/2307.09763",
    "authors": [
      "Qingwen Bu",
      "Dong Huang",
      "Heming Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09775",
    "title": "DisCover: Disentangled Music Representation Learning for Cover Song  Identification",
    "abstract": "In the field of music information retrieval (MIR), cover song identification (CSI) is a challenging task that aims to identify cover versions of a query song from a massive collection. Existing works still suffer from high intra-song variances and inter-song correlations, due to the entangled nature of version-specific and version-invariant factors in their modeling. In this work, we set the goal of disentangling version-specific and version-invariant factors, which could make it easier for the model to learn invariant music representations for unseen query songs. We analyze the CSI task in a disentanglement view with the causal graph technique, and identify the intra-version and inter-version effects biasing the invariant learning. To block these effects, we propose the disentangled music representation learning framework (DisCover) for CSI. DisCover consists of two critical components: (1) Knowledge-guided Disentanglement Module (KDM) and (2) Gradient-based Adversarial Disentanglement Module (GADM), which block intra-version and inter-version biased effects, respectively. KDM minimizes the mutual information between the learned representations and version-variant factors that are identified with prior domain knowledge. GADM identifies version-variant factors by simulating the representation transitions between intra-song versions, and exploits adversarial distillation for effect blocking. Extensive comparisons with best-performing methods and in-depth analysis demonstrate the effectiveness of DisCover and the and necessity of disentanglement for CSI. ",
    "url": "https://arxiv.org/abs/2307.09775",
    "authors": [
      "Jiahao Xun",
      "Shengyu Zhang",
      "Yanting Yang",
      "Jieming Zhu",
      "Liqun Deng",
      "Zhou Zhao",
      "Zhenhua Dong",
      "Ruiqi Li",
      "Lichao Zhang",
      "Fei Wu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.09793",
    "title": "On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large  Language Models",
    "abstract": "Since late 2022, Large Language Models (LLMs) have become very prominent with LLMs like ChatGPT and Bard receiving millions of users. Hundreds of new LLMs are announced each week, many of which are deposited to Hugging Face, a repository of machine learning models and datasets. To date, nearly 16,000 Text Generation models have been uploaded to the site. Given the huge influx of LLMs, it is of interest to know which LLM backbones, settings, training methods, and families are popular or trending. However, there is no comprehensive index of LLMs available. We take advantage of the relatively systematic nomenclature of Hugging Face LLMs to perform hierarchical clustering and identify communities amongst LLMs using n-grams and term frequency-inverse document frequency. Our methods successfully identify families of LLMs and accurately cluster LLMs into meaningful subgroups. We present a public web application to navigate and explore Constellation, our atlas of 15,821 LLMs. Constellation rapidly generates a variety of visualizations, namely dendrograms, graphs, word clouds, and scatter plots. Constellation is available at the following link: https://constellation.sites.stanford.edu/. ",
    "url": "https://arxiv.org/abs/2307.09793",
    "authors": [
      "Sarah Gao",
      "Andrew Kean Gao"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.09801",
    "title": "Graph Federated Learning Based on the Decentralized Framework",
    "abstract": "Graph learning has a wide range of applications in many scenarios, which require more need for data privacy. Federated learning is an emerging distributed machine learning approach that leverages data from individual devices or data centers to improve the accuracy and generalization of the model, while also protecting the privacy of user data. Graph-federated learning is mainly based on the classical federated learning framework i.e., the Client-Server framework. However, the Client-Server framework faces problems such as a single point of failure of the central server and poor scalability of network topology. First, we introduce the decentralized framework to graph-federated learning. Second, determine the confidence among nodes based on the similarity of data among nodes, subsequently, the gradient information is then aggregated by linear weighting based on confidence. Finally, the proposed method is compared with FedAvg, Fedprox, GCFL, and GCFL+ to verify the effectiveness of the proposed method. Experiments demonstrate that the proposed method outperforms other methods. ",
    "url": "https://arxiv.org/abs/2307.09801",
    "authors": [
      "Peilin Liu",
      "Yanni Tang",
      "Mingyue Zhang",
      "Wu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2307.09804",
    "title": "Fix your downsampling ASAP! Be natively more robust via Aliasing and  Spectral Artifact free Pooling",
    "abstract": "Convolutional neural networks encode images through a sequence of convolutions, normalizations and non-linearities as well as downsampling operations into potentially strong semantic embeddings. Yet, previous work showed that even slight mistakes during sampling, leading to aliasing, can be directly attributed to the networks' lack in robustness. To address such issues and facilitate simpler and faster adversarial training, [12] recently proposed FLC pooling, a method for provably alias-free downsampling - in theory. In this work, we conduct a further analysis through the lens of signal processing and find that such current pooling methods, which address aliasing in the frequency domain, are still prone to spectral leakage artifacts. Hence, we propose aliasing and spectral artifact-free pooling, short ASAP. While only introducing a few modifications to FLC pooling, networks using ASAP as downsampling method exhibit higher native robustness against common corruptions, a property that FLC pooling was missing. ASAP also increases native robustness against adversarial attacks on high and low resolution data while maintaining similar clean accuracy or even outperforming the baseline. ",
    "url": "https://arxiv.org/abs/2307.09804",
    "authors": [
      "Julia Grabinski",
      "Janis Keuper",
      "Margret Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.09807",
    "title": "A Low-Complexity Beamforming Design for Beyond-Diagonal RIS aided  Multi-User Networks",
    "abstract": "Beyond-diagonal reconfigurable intelligent surface (BD-RIS) has been proposed recently as a novel and generalized RIS architecture that offers enhanced wave manipulation flexibility and large coverage expansion. However, the beyond-diagonal mathematical model in BD-RIS inevitably introduces additional optimization challenges in beamforming design. In this letter, we derive a closed-form solution for the BD-RIS passive beamforming matrix that maximizes the sum of the effective channel gains among users. We further propose a computationally efficient two-stage beamforming framework to jointly design the active beamforming at the base station and passive beamforming at the BD-RIS to enhance the sum-rate for a BD-RIS aided multi-user multi-antenna network.Numerical results show that our proposed algorithm achieves a higher sum-rate while requiring less computation time compared to state-of-the-art algorithms. The proposed algorithm paves the way for practical beamforming design in BD-RIS aided wireless networks. ",
    "url": "https://arxiv.org/abs/2307.09807",
    "authors": [
      "Tianyu Fang",
      "Yijie Mao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.09813",
    "title": "DAPrompt: Deterministic Assumption Prompt Learning for Event Causality  Identification",
    "abstract": "Event Causality Identification (ECI) aims at determining whether there is a causal relation between two event mentions. Conventional prompt learning designs a prompt template to first predict an answer word and then maps it to the final decision. Unlike conventional prompts, we argue that predicting an answer word may not be a necessary prerequisite for the ECI task. Instead, we can first make a deterministic assumption on the existence of causal relation between two events and then evaluate its rationality to either accept or reject the assumption. The design motivation is to try the most utilization of the encyclopedia-like knowledge embedded in a pre-trained language model. In light of such considerations, we propose a deterministic assumption prompt learning model, called DAPrompt, for the ECI task. In particular, we design a simple deterministic assumption template concatenating with the input event pair, which includes two masks as predicted events' tokens. We use the probabilities of predicted events to evaluate the assumption rationality for the final event causality decision. Experiments on the EventStoryLine corpus and Causal-TimeBank corpus validate our design objective in terms of significant performance improvements over the state-of-the-art algorithms. ",
    "url": "https://arxiv.org/abs/2307.09813",
    "authors": [
      "Wei Xiang",
      "Chuanhong Zhan",
      "Bang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.09815",
    "title": "LDP: Language-driven Dual-Pixel Image Defocus Deblurring Network",
    "abstract": "Recovering sharp images from dual-pixel (DP) pairs with disparity-dependent blur is a challenging task.~Existing blur map-based deblurring methods have demonstrated promising results. In this paper, we propose, to the best of our knowledge, the first framework to introduce the contrastive language-image pre-training framework (CLIP) to achieve accurate blur map estimation from DP pairs unsupervisedly. To this end, we first carefully design text prompts to enable CLIP to understand blur-related geometric prior knowledge from the DP pair. Then, we propose a format to input stereo DP pair to the CLIP without any fine-tuning, where the CLIP is pre-trained on monocular images. Given the estimated blur map, we introduce a blur-prior attention block, a blur-weighting loss and a blur-aware loss to recover the all-in-focus image. Our method achieves state-of-the-art performance in extensive experiments. ",
    "url": "https://arxiv.org/abs/2307.09815",
    "authors": [
      "Hao Yang",
      "Liyuan Pan",
      "Yan Yang",
      "Miaomiao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09827",
    "title": "Online Continual Learning for Robust Indoor Object Recognition",
    "abstract": "Vision systems mounted on home robots need to interact with unseen classes in changing environments. Robots have limited computational resources, labelled data and storage capability. These requirements pose some unique challenges: models should adapt without forgetting past knowledge in a data- and parameter-efficient way. We characterize the problem as few-shot (FS) online continual learning (OCL), where robotic agents learn from a non-repeated stream of few-shot data updating only a few model parameters. Additionally, such models experience variable conditions at test time, where objects may appear in different poses (e.g., horizontal or vertical) and environments (e.g., day or night). To improve robustness of CL agents, we propose RobOCLe, which; 1) constructs an enriched feature space computing high order statistical moments from the embedded features of samples; and 2) computes similarity between high order statistics of the samples on the enriched feature space, and predicts their class labels. We evaluate robustness of CL models to train/test augmentations in various cases. We show that different moments allow RobOCLe to capture different properties of deformations, providing higher robustness with no decrease of inference speed. ",
    "url": "https://arxiv.org/abs/2307.09827",
    "authors": [
      "Umberto Michieli",
      "Mete Ozay"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09829",
    "title": "What do neural networks learn in image classification? A frequency  shortcut perspective",
    "abstract": "Frequency analysis is useful for understanding the mechanisms of representation learning in neural networks (NNs). Most research in this area focuses on the learning dynamics of NNs for regression tasks, while little for classification. This study empirically investigates the latter and expands the understanding of frequency shortcuts. First, we perform experiments on synthetic datasets, designed to have a bias in different frequency bands. Our results demonstrate that NNs tend to find simple solutions for classification, and what they learn first during training depends on the most distinctive frequency characteristics, which can be either low- or high-frequencies. Second, we confirm this phenomenon on natural images. We propose a metric to measure class-wise frequency characteristics and a method to identify frequency shortcuts. The results show that frequency shortcuts can be texture-based or shape-based, depending on what best simplifies the objective. Third, we validate the transferability of frequency shortcuts on out-of-distribution (OOD) test sets. Our results suggest that frequency shortcuts can be transferred across datasets and cannot be fully avoided by larger model capacity and data augmentation. We recommend that future research should focus on effective training schemes mitigating frequency shortcut learning. ",
    "url": "https://arxiv.org/abs/2307.09829",
    "authors": [
      "Shunxin Wang",
      "Raymond Veldhuis",
      "Christoph Brune",
      "Nicola Strisciuglio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09831",
    "title": "A Fast and Map-Free Model for Trajectory Prediction in Traffics",
    "abstract": "To handle the two shortcomings of existing methods, (i)nearly all models rely on high-definition (HD) maps, yet the map information is not always available in real traffic scenes and HD map-building is expensive and time-consuming and (ii) existing models usually focus on improving prediction accuracy at the expense of reducing computing efficiency, yet the efficiency is crucial for various real applications, this paper proposes an efficient trajectory prediction model that is not dependent on traffic maps. The core idea of our model is encoding single-agent's spatial-temporal information in the first stage and exploring multi-agents' spatial-temporal interactions in the second stage. By comprehensively utilizing attention mechanism, LSTM, graph convolution network and temporal transformer in the two stages, our model is able to learn rich dynamic and interaction information of all agents. Our model achieves the highest performance when comparing with existing map-free methods and also exceeds most map-based state-of-the-art methods on the Argoverse dataset. In addition, our model also exhibits a faster inference speed than the baseline methods. ",
    "url": "https://arxiv.org/abs/2307.09831",
    "authors": [
      "Junhong Xiang",
      "Jingmin Zhang",
      "Zhixiong Nan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09835",
    "title": "Deep Operator Network Approximation Rates for Lipschitz Operators",
    "abstract": "We establish universality and expression rate bounds for a class of neural Deep Operator Networks (DON) emulating Lipschitz (or H\\\"older) continuous maps $\\mathcal G:\\mathcal X\\to\\mathcal Y$ between (subsets of) separable Hilbert spaces $\\mathcal X$, $\\mathcal Y$. The DON architecture considered uses linear encoders $\\mathcal E$ and decoders $\\mathcal D$ via (biorthogonal) Riesz bases of $\\mathcal X$, $\\mathcal Y$, and an approximator network of an infinite-dimensional, parametric coordinate map that is Lipschitz continuous on the sequence space $\\ell^2(\\mathbb N)$. Unlike previous works ([Herrmann, Schwab and Zech: Neural and Spectral operator surrogates: construction and expression rate bounds, SAM Report, 2022], [Marcati and Schwab: Exponential Convergence of Deep Operator Networks for Elliptic Partial Differential Equations, SAM Report, 2022]), which required for example $\\mathcal G$ to be holomorphic, the present expression rate results require mere Lipschitz (or H\\\"older) continuity of $\\mathcal G$. Key in the proof of the present expression rate bounds is the use of either super-expressive activations (e.g. [Yarotski: Elementary superexpressive activations, Int. Conf. on ML, 2021], [Shen, Yang and Zhang: Neural network approximation: Three hidden layers are enough, Neural Networks, 2021], and the references there) which are inspired by the Kolmogorov superposition theorem, or of nonstandard NN architectures with standard (ReLU) activations as recently proposed in [Zhang, Shen and Yang: Neural Network Architecture Beyond Width and Depth, Adv. in Neural Inf. Proc. Sys., 2022]. We illustrate the abstract results by approximation rate bounds for emulation of a) solution operators for parametric elliptic variational inequalities, and b) Lipschitz maps of Hilbert-Schmidt operators. ",
    "url": "https://arxiv.org/abs/2307.09835",
    "authors": [
      "Christoph Schwab",
      "Andreas Stein",
      "Jakob Zech"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.09848",
    "title": "Transmitter Side Beyond-Diagonal Reconfigurable Intelligent Surface for  Massive MIMO Networks",
    "abstract": "This letter focuses on a transmitter or base station (BS) side beyond-diagonal reflecting intelligent surface (BD-RIS) deployment strategy to enhance the spectral efficiency (SE) of a time-division-duplex massive multiple-input multiple-output (MaMIMO) network. In this strategy, the active antenna array utilizes a BD-RIS at the BS to serve multiple users in the downlink. Based on the knowledge of statistical channel state information (CSI), the BD-RIS coefficients matrix is optimized by employing a novel manifold algorithm, and the power control coefficients are then optimized with the objective of maximizing the minimum SE. Through numerical results we illustrate the SE performance of the proposed transmission framework and compare it with that of a conventional MaMIMO transmission for different network settings. ",
    "url": "https://arxiv.org/abs/2307.09848",
    "authors": [
      "Anup Mishra",
      "Yijie Mao",
      "Carmen D'Andrea",
      "Stefano Buzzi",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.09855",
    "title": "Cross-thread critical sections and efficient dynamic race prediction  methods",
    "abstract": "The lock set method and the partial order method are two main approaches to guarantee that dynamic data race prediction remains efficient. There are many variations of these ideas. Common to all of them is the assumption that the events in a critical section belong to the same thread. We have evidence that critical sections in the wild do extend across thread boundaries even if the surrounding acquire and release events occur in the same thread. We introduce the novel concept of a cross-thread critical section to capture such situations, offer a theoretical comprehensive framework, and study their impact on state-of-the-art data race analyses. For sound partial order relations such as WCP, SDP, and DCtp, the occurrence of cross-thread critical sections negatively impacts their precision. For complete partial order relations such as WDP and PWR, cross-thread critical sections help to eliminate more false positives. The same (positive) impact applies to the lock set construction. Our experimental evaluation confirms that cross-thread critical sections arise in practice. For the complete relation PWR, we are able to reduce the number of false positives. The performance overhead incurred by tracking cross-thread critical sections slows down the analysis by 10\\%-20\\%, on average. ",
    "url": "https://arxiv.org/abs/2307.09855",
    "authors": [
      "Martin Sulzmann",
      "Peter Thiemann"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2307.09856",
    "title": "Hierarchical Spatio-Temporal Representation Learning for Gait  Recognition",
    "abstract": "Gait recognition is a biometric technique that identifies individuals by their unique walking styles, which is suitable for unconstrained environments and has a wide range of applications. While current methods focus on exploiting body part-based representations, they often neglect the hierarchical dependencies between local motion patterns. In this paper, we propose a hierarchical spatio-temporal representation learning (HSTL) framework for extracting gait features from coarse to fine. Our framework starts with a hierarchical clustering analysis to recover multi-level body structures from the whole body to local details. Next, an adaptive region-based motion extractor (ARME) is designed to learn region-independent motion features. The proposed HSTL then stacks multiple ARMEs in a top-down manner, with each ARME corresponding to a specific partition level of the hierarchy. An adaptive spatio-temporal pooling (ASTP) module is used to capture gait features at different levels of detail to perform hierarchical feature mapping. Finally, a frame-level temporal aggregation (FTA) module is employed to reduce redundant information in gait sequences through multi-scale temporal downsampling. Extensive experiments on CASIA-B, OUMVLP, GREW, and Gait3D datasets demonstrate that our method outperforms the state-of-the-art while maintaining a reasonable balance between model accuracy and complexity. ",
    "url": "https://arxiv.org/abs/2307.09856",
    "authors": [
      "Lei Wang",
      "Bo Liu",
      "Fangfang Liang",
      "Bincheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09858",
    "title": "Towards Reliable Rare Category Analysis on Graphs via Individual  Calibration",
    "abstract": "Rare categories abound in a number of real-world networks and play a pivotal role in a variety of high-stakes applications, including financial fraud detection, network intrusion detection, and rare disease diagnosis. Rare category analysis (RCA) refers to the task of detecting, characterizing, and comprehending the behaviors of minority classes in a highly-imbalanced data distribution. While the vast majority of existing work on RCA has focused on improving the prediction performance, a few fundamental research questions heretofore have received little attention and are less explored: How confident or uncertain is a prediction model in rare category analysis? How can we quantify the uncertainty in the learning process and enable reliable rare category analysis? To answer these questions, we start by investigating miscalibration in existing RCA methods. Empirical results reveal that state-of-the-art RCA methods are mainly over-confident in predicting minority classes and under-confident in predicting majority classes. Motivated by the observation, we propose a novel individual calibration framework, named CALIRARE, for alleviating the unique challenges of RCA, thus enabling reliable rare category analysis. In particular, to quantify the uncertainties in RCA, we develop a node-level uncertainty quantification algorithm to model the overlapping support regions with high uncertainty; to handle the rarity of minority classes in miscalibration calculation, we generalize the distribution-based calibration metric to the instance level and propose the first individual calibration measurement on graphs named Expected Individual Calibration Error (EICE). We perform extensive experimental evaluations on real-world datasets, including rare category characterization and model calibration tasks, which demonstrate the significance of our proposed framework. ",
    "url": "https://arxiv.org/abs/2307.09858",
    "authors": [
      "Longfeng Wu",
      "Bowen Lei",
      "Dongkuan Xu",
      "Dawei Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09860",
    "title": "Magic NeRF Lens: Interactive Fusion of Neural Radiance Fields for  Virtual Facility Inspection",
    "abstract": "Large industrial facilities such as particle accelerators and nuclear power plants are critical infrastructures for scientific research and industrial processes. These facilities are complex systems that not only require regular maintenance and upgrades but are often inaccessible to humans due to various safety hazards. Therefore, a virtual reality (VR) system that can quickly replicate real-world remote environments to provide users with a high level of spatial and situational awareness is crucial for facility maintenance planning. However, the exact 3D shapes of these facilities are often too complex to be accurately modeled with geometric primitives through the traditional rasterization pipeline. In this work, we develop Magic NeRF Lens, an interactive framework to support facility inspection in immersive VR using neural radiance fields (NeRF) and volumetric rendering. We introduce a novel data fusion approach that combines the complementary strengths of volumetric rendering and geometric rasterization, allowing a NeRF model to be merged with other conventional 3D data, such as a computer-aided design model. We develop two novel 3D magic lens effects to optimize NeRF rendering by exploiting the properties of human vision and context-aware visualization. We demonstrate the high usability of our framework and methods through a technical benchmark, a visual search user study, and expert reviews. In addition, the source code of our VR NeRF framework is made publicly available for future research and development. ",
    "url": "https://arxiv.org/abs/2307.09860",
    "authors": [
      "Ke Li",
      "Susanne Schmidt",
      "Tim Rolff",
      "Reinhard Bacher",
      "Wim Leemans",
      "Frank Steinicke"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2307.09861",
    "title": "BSDM: Background Suppression Diffusion Model for Hyperspectral Anomaly  Detection",
    "abstract": "Hyperspectral anomaly detection (HAD) is widely used in Earth observation and deep space exploration. A major challenge for HAD is the complex background of the input hyperspectral images (HSIs), resulting in anomalies confused in the background. On the other hand, the lack of labeled samples for HSIs leads to poor generalization of existing HAD methods. This paper starts the first attempt to study a new and generalizable background learning problem without labeled samples. We present a novel solution BSDM (background suppression diffusion model) for HAD, which can simultaneously learn latent background distributions and generalize to different datasets for suppressing complex background. It is featured in three aspects: (1) For the complex background of HSIs, we design pseudo background noise and learn the potential background distribution in it with a diffusion model (DM). (2) For the generalizability problem, we apply a statistical offset module so that the BSDM adapts to datasets of different domains without labeling samples. (3) For achieving background suppression, we innovatively improve the inference process of DM by feeding the original HSIs into the denoising network, which removes the background as noise. Our work paves a new background suppression way for HAD that can improve HAD performance without the prerequisite of manually labeled data. Assessments and generalization experiments of four HAD methods on several real HSI datasets demonstrate the above three unique properties of the proposed method. The code is available at https://github.com/majitao-xd/BSDM-HAD. ",
    "url": "https://arxiv.org/abs/2307.09861",
    "authors": [
      "Jitao Ma",
      "Weiying Xie",
      "Yunsong Li",
      "Leyuan Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09866",
    "title": "Detecting Vulnerable Nodes in Urban Infrastructure Interdependent  Network",
    "abstract": "Understanding and characterizing the vulnerability of urban infrastructures, which refers to the engineering facilities essential for the regular running of cities and that exist naturally in the form of networks, is of great value to us. Potential applications include protecting fragile facilities and designing robust topologies, etc. Due to the strong correlation between different topological characteristics and infrastructure vulnerability and their complicated evolution mechanisms, some heuristic and machine-assisted analysis fall short in addressing such a scenario. In this paper, we model the interdependent network as a heterogeneous graph and propose a system based on graph neural network with reinforcement learning, which can be trained on real-world data, to characterize the vulnerability of the city system accurately. The presented system leverages deep learning techniques to understand and analyze the heterogeneous graph, which enables us to capture the risk of cascade failure and discover vulnerable infrastructures of cities. Extensive experiments with various requests demonstrate not only the expressive power of our system but also transferring ability and necessity of the specific components. ",
    "url": "https://arxiv.org/abs/2307.09866",
    "authors": [
      "Jinzhu Mao",
      "Liu Cao",
      "Chen Gao",
      "Huandong Wang",
      "Hangyu Fan",
      "Depeng Jin",
      "Yong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2307.09874",
    "title": "Agricultural Robotic System: The Automation of Detection and Speech  Control",
    "abstract": "Agriculture industries often face challenges in manual tasks such as planting, harvesting, fertilizing, and detection, which can be time consuming and prone to errors. The \"Agricultural Robotic System\" project addresses these issues through a modular design that integrates advanced visual, speech recognition, and robotic technologies. This system is comprised of separate but interconnected modules for vision detection and speech recognition, creating a flexible and adaptable solution. The vision detection module uses computer vision techniques, trained on YOLOv5 and deployed on the Jetson Nano in TensorRT format, to accurately detect and identify different items. A robotic arm module then precisely controls the picking up of seedlings or seeds, and arranges them in specific locations. The speech recognition module enhances intelligent human robot interaction, allowing for efficient and intuitive control of the system. This modular approach improves the efficiency and accuracy of agricultural tasks, demonstrating the potential of robotics in the agricultural industry. ",
    "url": "https://arxiv.org/abs/2307.09874",
    "authors": [
      "Yang Wenkai",
      "Ji Ruihang",
      "Yue Yiran",
      "Gu Zhonghan",
      "Shu Wanyang",
      "Sam Ge Shuzhi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.09882",
    "title": "Adversarial Likelihood Estimation with One-way Flows",
    "abstract": "Generative Adversarial Networks (GANs) can produce high-quality samples, but do not provide an estimate of the probability density around the samples. However, it has been noted that maximizing the log-likelihood within an energy-based setting can lead to an adversarial framework where the discriminator provides unnormalized density (often called energy). We further develop this perspective, incorporate importance sampling, and show that 1) Wasserstein GAN performs a biased estimate of the partition function, and we propose instead to use an unbiased estimator; 2) when optimizing for likelihood, one must maximize generator entropy. This is hypothesized to provide a better mode coverage. Different from previous works, we explicitly compute the density of the generated samples. This is the key enabler to designing an unbiased estimator of the partition function and computation of the generator entropy term. The generator density is obtained via a new type of flow network, called one-way flow network, that is less constrained in terms of architecture, as it does not require to have a tractable inverse function. Our experimental results show that we converge faster, produce comparable sample quality to GANs with similar architecture, successfully avoid over-fitting to commonly used datasets and produce smooth low-dimensional latent representations of the training data. ",
    "url": "https://arxiv.org/abs/2307.09882",
    "authors": [
      "Omri Ben-Dov",
      "Pravir Singh Gupta",
      "Victoria Abrevaya",
      "Michael J. Black",
      "Partha Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09906",
    "title": "Implicit Identity Representation Conditioned Memory Compensation Network  for Talking Head video Generation",
    "abstract": "Talking head video generation aims to animate a human face in a still image with dynamic poses and expressions using motion information derived from a target-driving video, while maintaining the person's identity in the source image. However, dramatic and complex motions in the driving video cause ambiguous generation, because the still source image cannot provide sufficient appearance information for occluded regions or delicate expression variations, which produces severe artifacts and significantly degrades the generation quality. To tackle this problem, we propose to learn a global facial representation space, and design a novel implicit identity representation conditioned memory compensation network, coined as MCNet, for high-fidelity talking head generation.~Specifically, we devise a network module to learn a unified spatial facial meta-memory bank from all training samples, which can provide rich facial structure and appearance priors to compensate warped source facial features for the generation. Furthermore, we propose an effective query mechanism based on implicit identity representations learned from the discrete keypoints of the source image. It can greatly facilitate the retrieval of more correlated information from the memory bank for the compensation. Extensive experiments demonstrate that MCNet can learn representative and complementary facial memory, and can clearly outperform previous state-of-the-art talking head generation methods on VoxCeleb1 and CelebV datasets. Please check our \\href{https://github.com/harlanhong/ICCV2023-MCNET}{Project}. ",
    "url": "https://arxiv.org/abs/2307.09906",
    "authors": [
      "Fa-Ting Hong",
      "Dan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09909",
    "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
    "abstract": "This research investigates the application of Large Language Models (LLMs) to augment conversational agents in process mining, aiming to tackle its inherent complexity and diverse skill requirements. While LLM advancements present novel opportunities for conversational process mining, generating efficient outputs is still a hurdle. We propose an innovative approach that amend many issues in existing solutions, informed by prior research on Natural Language Processing (NLP) for conversational agents. Leveraging LLMs, our framework improves both accessibility and agent performance, as demonstrated by experiments on public question and data sets. Our research sets the stage for future explorations into LLMs' role in process mining and concludes with propositions for enhancing LLM memory, implementing real-time user testing, and examining diverse data sets. ",
    "url": "https://arxiv.org/abs/2307.09909",
    "authors": [
      "Urszula Jessen",
      "Michal Sroka",
      "Dirk Fahland"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09912",
    "title": "Deep projection networks for learning time-homogeneous dynamical systems",
    "abstract": "We consider the general class of time-homogeneous dynamical systems, both discrete and continuous, and study the problem of learning a meaningful representation of the state from observed data. This is instrumental for the task of learning a forward transfer operator of the system, that in turn can be used for forecasting future states or observables. The representation, typically parametrized via a neural network, is associated with a projection operator and is learned by optimizing an objective function akin to that of canonical correlation analysis (CCA). However, unlike CCA, our objective avoids matrix inversions and therefore is generally more stable and applicable to challenging scenarios. Our objective is a tight relaxation of CCA and we further enhance it by proposing two regularization schemes, one encouraging the orthogonality of the components of the representation while the other exploiting Chapman-Kolmogorov's equation. We apply our method to challenging discrete dynamical systems, discussing improvements over previous methods, as well as to continuous dynamical systems. ",
    "url": "https://arxiv.org/abs/2307.09912",
    "authors": [
      "Vladimir R. Kostic",
      "Pietro Novelli",
      "Riccardo Grazzi",
      "Karim Lounici",
      "Massimiliano Pontil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.09915",
    "title": "Embedded Heterogeneous Attention Transformer for Cross-lingual Image  Captioning",
    "abstract": "Cross-lingual image captioning is confronted with both cross-lingual and cross-modal challenges for multimedia analysis. The crucial issue in this task is to model the global and local matching between the image and different languages. Existing cross-modal embedding methods based on Transformer architecture oversight the local matching between the image region and monolingual words, not to mention in the face of a variety of differentiated languages. Due to the heterogeneous property of the cross-modal and cross-lingual task, we utilize the heterogeneous network to establish cross-domain relationships and the local correspondences between the image and different languages. In this paper, we propose an Embedded Heterogeneous Attention Transformer (EHAT) to build reasoning paths bridging cross-domain for cross-lingual image captioning and integrate into transformer. The proposed EHAT consists of a Masked Heterogeneous Cross-attention (MHCA), Heterogeneous Attention Reasoning Network (HARN) and Heterogeneous Co-attention (HCA). HARN as the core network, models and infers cross-domain relationship anchored by vision bounding box representation features to connect two languages word features and learn the heterogeneous maps. MHCA and HCA implement cross-domain integration in the encoder through the special heterogeneous attention and enable single model to generate two language captioning. We test on MSCOCO dataset to generate English and Chinese, which are most widely used and have obvious difference between their language families. Our experiments show that our method even achieve better than advanced monolingual methods. ",
    "url": "https://arxiv.org/abs/2307.09915",
    "authors": [
      "Zijie Song",
      "Zhenzhen Hu",
      "Richang Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2307.09936",
    "title": "AGAR: Attention Graph-RNN for Adaptative Motion Prediction of Point  Clouds of Deformable Objects",
    "abstract": "This paper focuses on motion prediction for point cloud sequences in the challenging case of deformable 3D objects, such as human body motion. First, we investigate the challenges caused by deformable shapes and complex motions present in this type of representation, with the ultimate goal of understanding the technical limitations of state-of-the-art models. From this understanding, we propose an improved architecture for point cloud prediction of deformable 3D objects. Specifically, to handle deformable shapes, we propose a graph-based approach that learns and exploits the spatial structure of point clouds to extract more representative features. Then we propose a module able to combine the learned features in an adaptative manner according to the point cloud movements. The proposed adaptative module controls the composition of local and global motions for each point, enabling the network to model complex motions in deformable 3D objects more effectively. We tested the proposed method on the following datasets: MNIST moving digits, the Mixamo human bodies motions, JPEG and CWIPC-SXR real-world dynamic bodies. Simulation results demonstrate that our method outperforms the current baseline methods given its improved ability to model complex movements as well as preserve point cloud shape. Furthermore, we demonstrate the generalizability of the proposed framework for dynamic feature learning, by testing the framework for action recognition on the MSRAction3D dataset and achieving results on-par with state-of-the-art methods ",
    "url": "https://arxiv.org/abs/2307.09936",
    "authors": [
      "Pedro Gomes",
      "Silvia Rossi",
      "Laura Toni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2307.09942",
    "title": "TREEMENT: Interpretable Patient-Trial Matching via Personalized Dynamic  Tree-Based Memory Network",
    "abstract": "Clinical trials are critical for drug development but often suffer from expensive and inefficient patient recruitment. In recent years, machine learning models have been proposed for speeding up patient recruitment via automatically matching patients with clinical trials based on longitudinal patient electronic health records (EHR) data and eligibility criteria of clinical trials. However, they either depend on trial-specific expert rules that cannot expand to other trials or perform matching at a very general level with a black-box model where the lack of interpretability makes the model results difficult to be adopted. To provide accurate and interpretable patient trial matching, we introduce a personalized dynamic tree-based memory network model named TREEMENT. It utilizes hierarchical clinical ontologies to expand the personalized patient representation learned from sequential EHR data, and then uses an attentional beam-search query learned from eligibility criteria embedding to offer a granular level of alignment for improved performance and interpretability. We evaluated TREEMENT against existing models on real-world datasets and demonstrated that TREEMENT outperforms the best baseline by 7% in terms of error reduction in criteria-level matching and achieves state-of-the-art results in its trial-level matching ability. Furthermore, we also show TREEMENT can offer good interpretability to make the model results easier for adoption. ",
    "url": "https://arxiv.org/abs/2307.09942",
    "authors": [
      "Brandon Theodorou",
      "Cao Xiao",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09944",
    "title": "ProtoCaps: A Fast and Non-Iterative Capsule Network Routing Method",
    "abstract": "Capsule Networks have emerged as a powerful class of deep learning architectures, known for robust performance with relatively few parameters compared to Convolutional Neural Networks (CNNs). However, their inherent efficiency is often overshadowed by their slow, iterative routing mechanisms which establish connections between Capsule layers, posing computational challenges resulting in an inability to scale. In this paper, we introduce a novel, non-iterative routing mechanism, inspired by trainable prototype clustering. This innovative approach aims to mitigate computational complexity, while retaining, if not enhancing, performance efficacy. Furthermore, we harness a shared Capsule subspace, negating the need to project each lower-level Capsule to each higher-level Capsule, thereby significantly reducing memory requisites during training. Our approach demonstrates superior results compared to the current best non-iterative Capsule Network and tests on the Imagewoof dataset, which is too computationally demanding to handle efficiently by iterative approaches. Our findings underscore the potential of our proposed methodology in enhancing the operational efficiency and performance of Capsule Networks, paving the way for their application in increasingly complex computational scenarios. ",
    "url": "https://arxiv.org/abs/2307.09944",
    "authors": [
      "Miles Everett",
      "Mingjun Zhong",
      "Georgios Leontidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09954",
    "title": "Priority-based DREAM Approach for Highly Manoeuvring Intruders in A  Perimeter Defense Problem",
    "abstract": "In this paper, a Priority-based Dynamic REsource Allocation with decentralized Multi-task assignment (P-DREAM) approach is presented to protect a territory from highly manoeuvring intruders. In the first part, static optimization problems are formulated to compute the following parameters of the perimeter defense problem; the number of reserve stations, their locations, the priority region, the monitoring region, and the minimum number of defenders required for the monitoring purpose. The concept of a prioritized intruder is proposed here to identify and handle those critical intruders (computed based on the velocity ratio and location) to be tackled on a priority basis. The computed priority region helps to assign reserve defenders sufficiently earlier such that they can neutralize the prioritized intruders. The monitoring region defines the minimum region to be monitored and is sufficient enough to handle the intruders. In the second part, the earlier developed DREAM approach is modified to incorporate the priority of an intruder. The proposed P-DREAM approach assigns the defenders to the prioritized intruders as the first task. A convex territory protection problem is simulated to illustrate the P-DREAM approach. It involves the computation of static parameters and solving the prioritized task assignments with dynamic resource allocation. Monte-Carlo results were conducted to verify the performance of P-DREAM, and the results clearly show that the P-DREAM approach can protect the territory with consistent performance against highly manoeuvring intruders. ",
    "url": "https://arxiv.org/abs/2307.09954",
    "authors": [
      "Shridhar Velhal",
      "Suresh Sundaram",
      "Narasimhan Sundararajan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.09961",
    "title": "On Dynamic Graph Algorithms with Predictions",
    "abstract": "We study dynamic algorithms in the model of algorithms with predictions. We assume the algorithm is given imperfect predictions regarding future updates, and we ask how such predictions can be used to improve the running time. This can be seen as a model interpolating between classic online and offline dynamic algorithms. Our results give smooth tradeoffs between these two extreme settings. First, we give algorithms for incremental and decremental transitive closure and approximate APSP that take as an additional input a predicted sequence of updates (edge insertions, or edge deletions, respectively). They preprocess it in $\\tilde{O}(n^{(3+\\omega)/2})$ time, and then handle updates in $\\tilde{O}(1)$ worst-case time and queries in $\\tilde{O}(\\eta^2)$ worst-case time. Here $\\eta$ is an error measure that can be bounded by the maximum difference between the predicted and actual insertion (deletion) time of an edge, i.e., by the $\\ell_\\infty$-error of the predictions. The second group of results concerns fully dynamic problems with vertex updates, where the algorithm has access to a predicted sequence of the next $n$ updates. We show how to solve fully dynamic triangle detection, maximum matching, single-source reachability, and more, in $O(n^{\\omega-1}+n\\eta_i)$ worst-case update time. Here $\\eta_i$ denotes how much earlier the $i$-th update occurs than predicted. Our last result is a reduction that transforms a worst-case incremental algorithm without predictions into a fully dynamic algorithm which is given a predicted deletion time for each element at the time of its insertion. As a consequence we can, e.g., maintain fully dynamic exact APSP with such predictions in $\\tilde{O}(n^2)$ worst-case vertex insertion time and $\\tilde{O}(n^2 (1+\\eta_i))$ worst-case vertex deletion time (for the prediction error $\\eta_i$ defined as above). ",
    "url": "https://arxiv.org/abs/2307.09961",
    "authors": [
      "Jan van den Brand",
      "Sebastian Forster",
      "Yasamin Nazari",
      "Adam Polak"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2307.09968",
    "title": "EPUF: A Novel Scheme Based on Entropy Features of Latency-based DRAM  PUFs Providing Lightweight Authentication in IoT Networks",
    "abstract": "Physical unclonable functions (PUFs) are hardware-oriented primitives that exploit manufacturing variations to generate a unique identity for a physical system. Recent advancements showed how DRAM can be exploited to implement PUFs. DRAM PUFs require no additional circuits for PUF operations and can be used in most of the applications with resource-constrained nodes such as Internet of Things (IoT) networks. However, the existing DRAM PUF solutions either require to interrupt other functions in the host system, or provide unreliable responses due to their sensitiveness to the environmental conditions. In this paper, we propose EPUF, a novel strategy to extract random and unique features from DRAM cells to generate reliable PUF responses. In particular, we use the bitmap images of the binary DRAM values and their entropy features. We show via real device experiments that EPUF is approximately $1.7$ times faster than other state of the art solutions, achieves $100\\%$ reliability, generates features with $47.79\\%$ uniqueness, and supports a large set of CRP that leads to new potentials for DRAM PUF-based authentication. We also propose a lightweight authentication protocol based on EPUF, which not only provides far better security guarantees but also outperforms the state-of-the-art in terms of communication overhead and computational cost. ",
    "url": "https://arxiv.org/abs/2307.09968",
    "authors": [
      "Fatemeh Najafi",
      "Masoud Kaveh",
      "Mohammad Reza Mosavi",
      "Alessandro Brighente",
      "Mauro Conti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.09971",
    "title": "Solving scalability issues in calculating PV hosting capacity in low  voltage distribution networks",
    "abstract": "The share of end-users with installed rooftop photovoltaic (PV) systems is continuously growing. Since most end-users are located at the low voltage (LV) level and due to technical limitations of LV networks, it is necessary to calculate PV hosting capacity. Most approaches in calculating a network's hosting capacity are based on three-phase optimal power flow (OPF) formulations. Linearized and relaxed three-phase OPF formulations respectively lose their accuracy and exactness when applied to solve the hosting capacity problem, and only non-linear programming (NLP) models guarantee the exact solution. Compared to linearized or relaxed models, NLP models require a higher computational time for finding an optimal solution. The binary variables uplift the problem to mixed-integer (MI)NLP and increase the computational burden. To resolve the scalability issues in calculating the hosting capacity of single-phase connected PVs, we propose a method that does not entail binary variables but still ensures that PVs are not connected to more than one phase at a time. Due to a risk of a sub-optimal solution, the proposed approach is compared to the results obtained by the MINLP formulation. The comparison includes values of the solution time and technical quantities such as network losses, voltage deviations, and voltage unbalance factor. ",
    "url": "https://arxiv.org/abs/2307.09971",
    "authors": [
      "Tomislav Antic",
      "Andrew Keane",
      "Tomislav Capuder"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.09977",
    "title": "Learner Referral for Cost-Effective Federated Learning Over Hierarchical  IoT Networks",
    "abstract": "The paradigm of federated learning (FL) to address data privacy concerns by locally training parameters on resource-constrained clients in a distributed manner has garnered significant attention. Nonetheless, FL is not applicable when not all clients within the coverage of the FL server are registered with the FL network. To bridge this gap, this paper proposes joint learner referral aided federated client selection (LRef-FedCS), along with communications and computing resource scheduling, and local model accuracy optimization (LMAO) methods. These methods are designed to minimize the cost incurred by the worst-case participant and ensure the long-term fairness of FL in hierarchical Internet of Things (HieIoT) networks. Utilizing the Lyapunov optimization technique, we reformulate the original problem into a stepwise joint optimization problem (JOP). Subsequently, to tackle the mixed-integer non-convex JOP, we separatively and iteratively address LRef-FedCS and LMAO through the centralized method and self-adaptive global best harmony search (SGHS) algorithm, respectively. To enhance scalability, we further propose a distributed LRef-FedCS approach based on a matching game to replace the centralized method described above. Numerical simulations and experimental results on the MNIST/CIFAR-10 datasets demonstrate that our proposed LRef-FedCS approach could achieve a good balance between pursuing high global accuracy and reducing cost. ",
    "url": "https://arxiv.org/abs/2307.09977",
    "authors": [
      "Yulan Gao",
      "Ziqiang Ye",
      "Yue Xiao",
      "Wei Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.09988",
    "title": "TinyTrain: Deep Neural Network Training at the Extreme Edge",
    "abstract": "On-device training is essential for user personalisation and privacy. With the pervasiveness of IoT devices and microcontroller units (MCU), this task becomes more challenging due to the constrained memory and compute resources, and the limited availability of labelled user data. Nonetheless, prior works neglect the data scarcity issue, require excessively long training time (e.g. a few hours), or induce substantial accuracy loss ($\\geq$10\\%). We propose TinyTrain, an on-device training approach that drastically reduces training time by selectively updating parts of the model and explicitly coping with data scarcity. TinyTrain introduces a task-adaptive sparse-update method that dynamically selects the layer/channel based on a multi-objective criterion that jointly captures user data, the memory, and the compute capabilities of the target device, leading to high accuracy on unseen tasks with reduced computation and memory footprint. TinyTrain outperforms vanilla fine-tuning of the entire network by 3.6-5.0\\% in accuracy, while reducing the backward-pass memory and computation cost by up to 2,286$\\times$ and 7.68$\\times$, respectively. Targeting broadly used real-world edge devices, TinyTrain achieves 9.5$\\times$ faster and 3.5$\\times$ more energy-efficient training over status-quo approaches, and 2.8$\\times$ smaller memory footprint than SOTA approaches, while remaining within the 1 MB memory envelope of MCU-grade platforms. ",
    "url": "https://arxiv.org/abs/2307.09988",
    "authors": [
      "Young D. Kwon",
      "Rui Li",
      "Stylianos I. Venieris",
      "Jagmohan Chauhan",
      "Nicholas D. Lane",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09994",
    "title": "Impact of Disentanglement on Pruning Neural Networks",
    "abstract": "Deploying deep learning neural networks on edge devices, to accomplish task specific objectives in the real-world, requires a reduction in their memory footprint, power consumption, and latency. This can be realized via efficient model compression. Disentangled latent representations produced by variational autoencoder (VAE) networks are a promising approach for achieving model compression because they mainly retain task-specific information, discarding useless information for the task at hand. We make use of the Beta-VAE framework combined with a standard criterion for pruning to investigate the impact of forcing the network to learn disentangled representations on the pruning process for the task of classification. In particular, we perform experiments on MNIST and CIFAR10 datasets, examine disentanglement challenges, and propose a path forward for future works. ",
    "url": "https://arxiv.org/abs/2307.09994",
    "authors": [
      "Carl Shneider",
      "Peyman Rostami",
      "Anis Kacem",
      "Nilotpal Sinha",
      "Abd El Rahman Shabayek",
      "Djamila Aouada"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.10001",
    "title": "As large as it gets: Learning infinitely large Filters via Neural  Implicit Functions in the Fourier Domain",
    "abstract": "Motivated by the recent trend towards the usage of larger receptive fields for more context-aware neural networks in vision applications, we aim to investigate how large these receptive fields really need to be. To facilitate such study, several challenges need to be addressed, most importantly: (i) We need to provide an effective way for models to learn large filters (potentially as large as the input data) without increasing their memory consumption during training or inference, (ii) the study of filter sizes has to be decoupled from other effects such as the network width or number of learnable parameters, and (iii) the employed convolution operation should be a plug-and-play module that can replace any conventional convolution in a Convolutional Neural Network (CNN) and allow for an efficient implementation in current frameworks. To facilitate such models, we propose to learn not spatial but frequency representations of filter weights as neural implicit functions, such that even infinitely large filters can be parameterized by only a few learnable weights. The resulting neural implicit frequency CNNs are the first models to achieve results on par with the state-of-the-art on large image classification benchmarks while executing convolutions solely in the frequency domain and can be employed within any CNN architecture. They allow us to provide an extensive analysis of the learned receptive fields. Interestingly, our analysis shows that, although the proposed networks could learn very large convolution kernels, the learned filters practically translate into well-localized and relatively small convolution kernels in the spatial domain. ",
    "url": "https://arxiv.org/abs/2307.10001",
    "authors": [
      "Julia Grabinski",
      "Janis Keuper",
      "Margret Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.10003",
    "title": "TbExplain: A Text-based Explanation Method for Scene Classification  Models with the Statistical Prediction Correction",
    "abstract": "The field of Explainable Artificial Intelligence (XAI) aims to improve the interpretability of black-box machine learning models. Building a heatmap based on the importance value of input features is a popular method for explaining the underlying functions of such models in producing their predictions. Heatmaps are almost understandable to humans, yet they are not without flaws. Non-expert users, for example, may not fully understand the logic of heatmaps (the logic in which relevant pixels to the model's prediction are highlighted with different intensities or colors). Additionally, objects and regions of the input image that are relevant to the model prediction are frequently not entirely differentiated by heatmaps. In this paper, we propose a framework called TbExplain that employs XAI techniques and a pre-trained object detector to present text-based explanations of scene classification models. Moreover, TbExplain incorporates a novel method to correct predictions and textually explain them based on the statistics of objects in the input image when the initial prediction is unreliable. To assess the trustworthiness and validity of the text-based explanations, we conducted a qualitative experiment, and the findings indicated that these explanations are sufficiently reliable. Furthermore, our quantitative and qualitative experiments on TbExplain with scene classification datasets reveal an improvement in classification accuracy over ResNet variants. ",
    "url": "https://arxiv.org/abs/2307.10003",
    "authors": [
      "Amirhossein Aminimehr",
      "Pouya Khani",
      "Amirali Molaei",
      "Amirmohammad Kazemeini",
      "Erik Cambria"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2307.10004",
    "title": "6G Network Business Support System",
    "abstract": "6G is the next-generation intelligent and integrated digital information infrastructure, characterized by ubiquitous interconnection, native intelligence, multi-dimensional perception, global coverage, green and low-carbon, native network security, etc. 6G will realize the transition from serving people and people-things communication to supporting the efficient connection of intelligent agents, and comprehensively leading the digital, intelligent and green transformation of the economy and the society. As the core support system for mobile communication network, 6 6G BSS need to integrate with new business models brought about by the development of the next-generation Internet and IT, upgrade from \"network-centric\" to \"business and service centric\" and \"customer-centric\". 6G OSS and BSS systems need to strengthen their integration to improve the operational efficiency and benefits of customers by connecting the digital intelligence support capabilities on both sides of supply and demand. This paper provides a detailed introduction to the overall vision, potential key technologies, and functional architecture of 6G BSS systems. It also presents an evolutionary roadmap and technological prospects for the BSS systems from 5G to 6G. ",
    "url": "https://arxiv.org/abs/2307.10004",
    "authors": [
      "Ye Ouyang",
      "Yaqin Zhang",
      "Peng Wang",
      "Yunxin Liu",
      "Wen Qiao",
      "Jun Zhu",
      "Yang Liu",
      "Feng Zhang",
      "Shuling Wang",
      "Xidong Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.10039",
    "title": "Deteksi Sampah di Permukaan dan Dalam Perairan pada Objek Video dengan  Metode Robust and Efficient Post-Processing dan Tubelet-Level Bounding Box  Linking",
    "abstract": "Indonesia, as a maritime country, has a significant portion of its territory covered by water. Ineffective waste management has resulted in a considerable amount of trash in Indonesian waters, leading to various issues. The development of an automated trash-collecting robot can be a solution to address this problem. The robot requires a system capable of detecting objects in motion, such as in videos. However, using naive object detection methods in videos has limitations, particularly when image focus is reduced and the target object is obstructed by other objects. This paper's contribution provides an explanation of the methods that can be applied to perform video object detection in an automated trash-collecting robot. The study utilizes the YOLOv5 model and the Robust & Efficient Post Processing (REPP) method, along with tubelet-level bounding box linking on the FloW and Roboflow datasets. The combination of these methods enhances the performance of naive object detection from YOLOv5 by considering the detection results in adjacent frames. The results show that the post-processing stage and tubelet-level bounding box linking can improve the quality of detection, achieving approximately 3% better performance compared to YOLOv5 alone. The use of these methods has the potential to detect surface and underwater trash and can be applied to a real-time image-based trash-collecting robot. Implementing this system is expected to mitigate the damage caused by trash in the past and improve Indonesia's waste management system in the future. ",
    "url": "https://arxiv.org/abs/2307.10039",
    "authors": [
      "Bryan Tjandra",
      "Made S. N. Negara",
      "Nyoo S. C. Handoko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.10041",
    "title": "BERRY: Bit Error Robustness for Energy-Efficient Reinforcement  Learning-Based Autonomous Systems",
    "abstract": "Autonomous systems, such as Unmanned Aerial Vehicles (UAVs), are expected to run complex reinforcement learning (RL) models to execute fully autonomous position-navigation-time tasks within stringent onboard weight and power constraints. We observe that reducing onboard operating voltage can benefit the energy efficiency of both the computation and flight mission, however, it can also result in on-chip bit failures that are detrimental to mission safety and performance. To this end, we propose BERRY, a robust learning framework to improve bit error robustness and energy efficiency for RL-enabled autonomous systems. BERRY supports robust learning, both offline and on-board the UAV, and for the first time, demonstrates the practicality of robust low-voltage operation on UAVs that leads to high energy savings in both compute-level operation and system-level quality-of-flight. We perform extensive experiments on 72 autonomous navigation scenarios and demonstrate that BERRY generalizes well across environments, UAVs, autonomy policies, operating voltages and fault patterns, and consistently improves robustness, efficiency and mission performance, achieving up to 15.62% reduction in flight energy, 18.51% increase in the number of successful missions, and 3.43x processing energy reduction. ",
    "url": "https://arxiv.org/abs/2307.10041",
    "authors": [
      "Zishen Wan",
      "Nandhini Chandramoorthy",
      "Karthik Swaminathan",
      "Pin-Yu Chen",
      "Vijay Janapa Reddi",
      "Arijit Raychowdhury"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2307.10062",
    "title": "Unsupervised Accuracy Estimation of Deep Visual Models using  Domain-Adaptive Adversarial Perturbation without Source Samples",
    "abstract": "Deploying deep visual models can lead to performance drops due to the discrepancies between source and target distributions. Several approaches leverage labeled source data to estimate target domain accuracy, but accessing labeled source data is often prohibitively difficult due to data confidentiality or resource limitations on serving devices. Our work proposes a new framework to estimate model accuracy on unlabeled target data without access to source data. We investigate the feasibility of using pseudo-labels for accuracy estimation and evolve this idea into adopting recent advances in source-free domain adaptation algorithms. Our approach measures the disagreement rate between the source hypothesis and the target pseudo-labeling function, adapted from the source hypothesis. We mitigate the impact of erroneous pseudo-labels that may arise due to a high ideal joint hypothesis risk by employing adaptive adversarial perturbation on the input of the target model. Our proposed source-free framework effectively addresses the challenging distribution shift scenarios and outperforms existing methods requiring source data and labels for training. ",
    "url": "https://arxiv.org/abs/2307.10062",
    "authors": [
      "JoonHo Lee",
      "Jae Oh Woo",
      "Hankyu Moon",
      "Kwonho Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.10069",
    "title": "Robust constrained nonlinear Model Predictive Control with Gated  Recurrent Unit model -- Extended version",
    "abstract": "In this paper we propose a robust Model Predictive Control where a Gated Recurrent Unit network model is used to learn the input-output dynamic of the system under control. Robust satisfaction of input and output constraints and recursive feasibility in presence of model uncertainties are achieved using a constraint tightening approach. Moreover, new terminal cost and terminal set are introduced in the Model Predictive Control formulation to guarantee Input-to-State Stability of the closed loop system with respect to the uncertainty term. ",
    "url": "https://arxiv.org/abs/2307.10069",
    "authors": [
      "Irene Schimperna",
      "Lalo Magni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.10073",
    "title": "Scalable Deep Learning for RNA Secondary Structure Prediction",
    "abstract": "The field of RNA secondary structure prediction has made significant progress with the adoption of deep learning techniques. In this work, we present the RNAformer, a lean deep learning model using axial attention and recycling in the latent space. We gain performance improvements by designing the architecture for modeling the adjacency matrix directly in the latent space and by scaling the size of the model. Our approach achieves state-of-the-art performance on the popular TS0 benchmark dataset and even outperforms methods that use external information. Further, we show experimentally that the RNAformer can learn a biophysical model of the RNA folding process. ",
    "url": "https://arxiv.org/abs/2307.10073",
    "authors": [
      "J\u00f6rg K.H. Franke",
      "Frederic Runge",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2307.10107",
    "title": "Dynamic constant time parallel graph algorithms with sub-linear work",
    "abstract": "The paper proposes dynamic parallel algorithms for connectivity and bipartiteness of undirected graphs that require constant time and $O(n^{1/2+\\epsilon})$ work on the CRCW PRAM model. The work of these algorithms almost matches the work of the $O(\\log n)$ time algorithm for connectivity by Kopelowitz et al. (2018) on the EREW PRAM model and the time of the sequential algorithm for bipartiteness by Eppstein et al. (1997). In particular, we show that the sparsification technique, which has been used in both mentioned papers, can in principle also be used for constant time algorithms in the CRCW PRAM model, despite the logarithmic depth of sparsification trees. ",
    "url": "https://arxiv.org/abs/2307.10107",
    "authors": [
      "Jonas Schmidt",
      "Thomas Schwentick"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2307.10112",
    "title": "Extended Graph Assessment Metrics for Graph Neural Networks",
    "abstract": "When re-structuring patient cohorts into so-called population graphs, initially independent data points can be incorporated into one interconnected graph structure. This population graph can then be used for medical downstream tasks using graph neural networks (GNNs). The construction of a suitable graph structure is a challenging step in the learning pipeline that can have severe impact on model performance. To this end, different graph assessment metrics have been introduced to evaluate graph structures. However, these metrics are limited to classification tasks and discrete adjacency matrices, only covering a small subset of real-world applications. In this work, we introduce extended graph assessment metrics (GAMs) for regression tasks and continuous adjacency matrices. We focus on two GAMs in specific: \\textit{homophily} and \\textit{cross-class neighbourhood similarity} (CCNS). We extend the notion of GAMs to more than one hop, define homophily for regression tasks, as well as continuous adjacency matrices, and propose a light-weight CCNS distance for discrete and continuous adjacency matrices. We show the correlation of these metrics with model performance on different medical population graphs and under different learning settings. ",
    "url": "https://arxiv.org/abs/2307.10112",
    "authors": [
      "Tamara T. Mueller",
      "Sophie Starck",
      "Leonhard F. Feiner",
      "Kyriaki-Margarita Bintsi",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.10155",
    "title": "Curvature-based Clustering on Graphs",
    "abstract": "Unsupervised node clustering (or community detection) is a classical graph learning task. In this paper, we study algorithms, which exploit the geometry of the graph to identify densely connected substructures, which form clusters or communities. Our method implements discrete Ricci curvatures and their associated geometric flows, under which the edge weights of the graph evolve to reveal its community structure. We consider several discrete curvature notions and analyze the utility of the resulting algorithms. In contrast to prior literature, we study not only single-membership community detection, where each node belongs to exactly one community, but also mixed-membership community detection, where communities may overlap. For the latter, we argue that it is beneficial to perform community detection on the line graph, i.e., the graph's dual. We provide both theoretical and empirical evidence for the utility of our curvature-based clustering algorithms. In addition, we give several results on the relationship between the curvature of a graph and that of its dual, which enable the efficient implementation of our proposed mixed-membership community detection approach and which may be of independent interest for curvature-based network analysis. ",
    "url": "https://arxiv.org/abs/2307.10155",
    "authors": [
      "Yu Tian",
      "Zachary Lubberts",
      "Melanie Weber"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.10157",
    "title": "Leveraging Visemes for Better Visual Speech Representation and Lip  Reading",
    "abstract": "Lip reading is a challenging task that has many potential applications in speech recognition, human-computer interaction, and security systems. However, existing lip reading systems often suffer from low accuracy due to the limitations of video features. In this paper, we propose a novel approach that leverages visemes, which are groups of phonetically similar lip shapes, to extract more discriminative and robust video features for lip reading. We evaluate our approach on various tasks, including word-level and sentence-level lip reading, and audiovisual speech recognition using the Arman-AV dataset, a largescale Persian corpus. Our experimental results show that our viseme based approach consistently outperforms the state-of-theart methods in all these tasks. The proposed method reduces the lip-reading word error rate (WER) by 9.1% relative to the best previous method. ",
    "url": "https://arxiv.org/abs/2307.10157",
    "authors": [
      "Javad Peymanfard",
      "Vahid Saeedi",
      "Mohammad Reza Mohammadi",
      "Hossein Zeinali",
      "Nasser Mozayani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.10160",
    "title": "Robust Driving Policy Learning with Guided Meta Reinforcement Learning",
    "abstract": "Although deep reinforcement learning (DRL) has shown promising results for autonomous navigation in interactive traffic scenarios, existing work typically adopts a fixed behavior policy to control social vehicles in the training environment. This may cause the learned driving policy to overfit the environment, making it difficult to interact well with vehicles with different, unseen behaviors. In this work, we introduce an efficient method to train diverse driving policies for social vehicles as a single meta-policy. By randomizing the interaction-based reward functions of social vehicles, we can generate diverse objectives and efficiently train the meta-policy through guiding policies that achieve specific objectives. We further propose a training strategy to enhance the robustness of the ego vehicle's driving policy using the environment where social vehicles are controlled by the learned meta-policy. Our method successfully learns an ego driving policy that generalizes well to unseen situations with out-of-distribution (OOD) social agents' behaviors in a challenging uncontrolled T-intersection scenario. ",
    "url": "https://arxiv.org/abs/2307.10160",
    "authors": [
      "Kanghoon Lee",
      "Jiachen Li",
      "David Isele",
      "Jinkyoo Park",
      "Kikuo Fujimura",
      "Mykel J. Kochenderfer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2307.10163",
    "title": "Rethinking Backdoor Attacks",
    "abstract": "In a backdoor attack, an adversary inserts maliciously constructed backdoor examples into a training set to make the resulting model vulnerable to manipulation. Defending against such attacks typically involves viewing these inserted examples as outliers in the training set and using techniques from robust statistics to detect and remove them. In this work, we present a different approach to the backdoor attack problem. Specifically, we show that without structural information about the training data distribution, backdoor attacks are indistinguishable from naturally-occurring features in the data--and thus impossible to \"detect\" in a general sense. Then, guided by this observation, we revisit existing defenses against backdoor attacks and characterize the (often latent) assumptions they make and on which they depend. Finally, we explore an alternative perspective on backdoor attacks: one that assumes these attacks correspond to the strongest feature in the training data. Under this assumption (which we make formal) we develop a new primitive for detecting backdoor attacks. Our primitive naturally gives rise to a detection algorithm that comes with theoretical guarantees and is effective in practice. ",
    "url": "https://arxiv.org/abs/2307.10163",
    "authors": [
      "Alaa Khaddaj",
      "Guillaume Leclerc",
      "Aleksandar Makelov",
      "Kristian Georgiev",
      "Hadi Salman",
      "Andrew Ilyas",
      "Aleksander Madry"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.10165",
    "title": "Drone navigation and license place detection for vehicle location in  indoor spaces",
    "abstract": "Millions of vehicles are transported every year, tightly parked in vessels or boats. To reduce the risks of associated safety issues like fires, knowing the location of vehicles is essential, since different vehicles may need different mitigation measures, e.g. electric cars. This work is aimed at creating a solution based on a nano-drone that navigates across rows of parked vehicles and detects their license plates. We do so via a wall-following algorithm, and a CNN trained to detect license plates. All computations are done in real-time on the drone, which just sends position and detected images that allow the creation of a 2D map with the position of the plates. Our solution is capable of reading all plates across eight test cases (with several rows of plates, different drone speeds, or low light) by aggregation of measurements across several drone journeys. ",
    "url": "https://arxiv.org/abs/2307.10165",
    "authors": [
      "Moa Arvidsson",
      "Sithichot Sawirot",
      "Cristofer Englund",
      "Fernando Alonso-Fernandez",
      "Martin Torstensson",
      "Boris Duran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.10166",
    "title": "Adversarial Latent Autoencoder with Self-Attention for Structural Image  Synthesis",
    "abstract": "Generative Engineering Design approaches driven by Deep Generative Models (DGM) have been proposed to facilitate industrial engineering processes. In such processes, designs often come in the form of images, such as blueprints, engineering drawings, and CAD models depending on the level of detail. DGMs have been successfully employed for synthesis of natural images, e.g., displaying animals, human faces and landscapes. However, industrial design images are fundamentally different from natural scenes in that they contain rich structural patterns and long-range dependencies, which are challenging for convolution-based DGMs to generate. Moreover, DGM-driven generation process is typically triggered based on random noisy inputs, which outputs unpredictable samples and thus cannot perform an efficient industrial design exploration. We tackle these challenges by proposing a novel model Self-Attention Adversarial Latent Autoencoder (SA-ALAE), which allows generating feasible design images of complex engineering parts. With SA-ALAE, users can not only explore novel variants of an existing design, but also control the generation process by operating in latent space. The potential of SA-ALAE is shown by generating engineering blueprints in a real automotive design task. ",
    "url": "https://arxiv.org/abs/2307.10166",
    "authors": [
      "Jiajie Fan",
      "Laure Vuaille",
      "Hao Wang",
      "Thomas B\u00e4ck"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.10171",
    "title": "LightPath: Lightweight and Scalable Path Representation Learning",
    "abstract": "Movement paths are used widely in intelligent transportation and smart city applications. To serve such applications, path representation learning aims to provide compact representations of paths that enable efficient and accurate operations when used for different downstream tasks such as path ranking and travel cost estimation. In many cases, it is attractive that the path representation learning is lightweight and scalable; in resource-limited environments and under green computing limitations, it is essential. Yet, existing path representation learning studies focus on accuracy and pay at most secondary attention to resource consumption and scalability. We propose a lightweight and scalable path representation learning framework, termed LightPath, that aims to reduce resource consumption and achieve scalability without affecting accuracy, thus enabling broader applicability. More specifically, we first propose a sparse auto-encoder that ensures that the framework achieves good scalability with respect to path length. Next, we propose a relational reasoning framework to enable faster training of more robust sparse path encoders. We also propose global-local knowledge distillation to further reduce the size and improve the performance of sparse path encoders. Finally, we report extensive experiments on two real-world datasets to offer insight into the efficiency, scalability, and effectiveness of the proposed framework. ",
    "url": "https://arxiv.org/abs/2307.10171",
    "authors": [
      "Sean Bin Yang",
      "Jilin Hu",
      "Chenjuan Guo",
      "Bin Yang",
      "Christian S. Jensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2307.10173",
    "title": "DNA-Rendering: A Diverse Neural Actor Repository for High-Fidelity  Human-centric Rendering",
    "abstract": "Realistic human-centric rendering plays a key role in both computer vision and computer graphics. Rapid progress has been made in the algorithm aspect over the years, yet existing human-centric rendering datasets and benchmarks are rather impoverished in terms of diversity, which are crucial for rendering effect. Researchers are usually constrained to explore and evaluate a small set of rendering problems on current datasets, while real-world applications require methods to be robust across different scenarios. In this work, we present DNA-Rendering, a large-scale, high-fidelity repository of human performance data for neural actor rendering. DNA-Rendering presents several alluring attributes. First, our dataset contains over 1500 human subjects, 5000 motion sequences, and 67.5M frames' data volume. Second, we provide rich assets for each subject -- 2D/3D human body keypoints, foreground masks, SMPLX models, cloth/accessory materials, multi-view images, and videos. These assets boost the current method's accuracy on downstream rendering tasks. Third, we construct a professional multi-view system to capture data, which contains 60 synchronous cameras with max 4096 x 3000 resolution, 15 fps speed, and stern camera calibration steps, ensuring high-quality resources for task training and evaluation. Along with the dataset, we provide a large-scale and quantitative benchmark in full-scale, with multiple tasks to evaluate the existing progress of novel view synthesis, novel pose animation synthesis, and novel identity rendering methods. In this manuscript, we describe our DNA-Rendering effort as a revealing of new observations, challenges, and future directions to human-centric rendering. The dataset, code, and benchmarks will be publicly available at https://dna-rendering.github.io/ ",
    "url": "https://arxiv.org/abs/2307.10173",
    "authors": [
      "Wei Cheng",
      "Ruixiang Chen",
      "Wanqi Yin",
      "Siming Fan",
      "Keyu Chen",
      "Honglin He",
      "Huiwen Luo",
      "Zhongang Cai",
      "Jingbo Wang",
      "Yang Gao",
      "Zhengming Yu",
      "Zhengyu Lin",
      "Daxuan Ren",
      "Lei Yang",
      "Ziwei Liu",
      "Chen Change Loy",
      "Chen Qian",
      "Wayne Wu",
      "Dahua Lin",
      "Bo Dai",
      "Kwan-Yee Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09529",
    "title": "QDoor: Exploiting Approximate Synthesis for Backdoor Attacks in Quantum  Neural Networks",
    "abstract": "Quantum neural networks (QNNs) succeed in object recognition, natural language processing, and financial analysis. To maximize the accuracy of a QNN on a Noisy Intermediate Scale Quantum (NISQ) computer, approximate synthesis modifies the QNN circuit by reducing error-prone 2-qubit quantum gates. The success of QNNs motivates adversaries to attack QNNs via backdoors. However, na\\\"ively transplanting backdoors designed for classical neural networks to QNNs yields only low attack success rate, due to the noises and approximate synthesis on NISQ computers. Prior quantum circuit-based backdoors cannot selectively attack some inputs or work with all types of encoding layers of a QNN circuit. Moreover, it is easy to detect both transplanted and circuit-based backdoors in a QNN. In this paper, we propose a novel and stealthy backdoor attack, QDoor, to achieve high attack success rate in approximately-synthesized QNN circuits by weaponizing unitary differences between uncompiled QNNs and their synthesized counterparts. QDoor trains a QNN behaving normally for all inputs with and without a trigger. However, after approximate synthesis, the QNN circuit always predicts any inputs with a trigger to a predefined class while still acts normally for benign inputs. Compared to prior backdoor attacks, QDoor improves the attack success rate by $13\\times$ and the clean data accuracy by $65\\%$ on average. Furthermore, prior backdoor detection techniques cannot find QDoor attacks in uncompiled QNN circuits. ",
    "url": "https://arxiv.org/abs/2307.09529",
    "authors": [
      "Cheng Chu",
      "Fan Chen",
      "Philip Richerme",
      "Lei Jiang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2307.09614",
    "title": "Multi-view self-supervised learning for multivariate variable-channel  time series",
    "abstract": "Labeling of multivariate biomedical time series data is a laborious and expensive process. Self-supervised contrastive learning alleviates the need for large, labeled datasets through pretraining on unlabeled data. However, for multivariate time series data the set of input channels often varies between applications, and most existing work does not allow for transfer between datasets with different sets of input channels. We propose learning one encoder to operate on all input channels individually. We then use a message passing neural network to extract a single representation across channels. We demonstrate the potential of this method by pretraining our network on a dataset with six EEG channels and finetuning on a dataset with two different EEG channels. We compare networks with and without the message passing neural network across different contrastive loss functions. We show that our method combined with the TS2Vec loss outperforms all other methods in most settings. ",
    "url": "https://arxiv.org/abs/2307.09614",
    "authors": [
      "Thea Br\u00fcsch",
      "Mikkel N. Schmidt",
      "Tommy S. Alstr\u00f8m"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.09620",
    "title": "Complete representation by partial functions for signatures containing  antidomain restriction",
    "abstract": "We investigate notions of complete representation by partial functions, where the operations in the signature include antidomain restriction and may include composition, intersection, update, preferential union, domain, antidomain, and set difference. When the signature includes both antidomain restriction and intersection, the join-complete and the meet-complete representations coincide. Otherwise, for the signatures we consider, meet-complete is strictly stronger than join-complete. A necessary condition to be meet-completely representable is that the atoms are separating. For the signatures we consider, this condition is sufficient if and only if composition is not in the signature. For each of the signatures we consider, the class of (meet-)completely representable algebras is not axiomatisable by any existential-universal-existential first-order theory. For 14 expressively distinct signatures, we show, by giving an explicit representation, that the (meet-)completely representable algebras form a basic elementary class, axiomatisable by a universal-existential-universal first-order sentence. The signatures we axiomatise are those containing antidomain restriction and any of intersection, update, and preferential union and also those containing antidomain restriction, composition, and intersection and any of update, preferential union, domain, and antidomain. ",
    "url": "https://arxiv.org/abs/2307.09620",
    "authors": [
      "Brett McLean"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2307.09624",
    "title": "Transformer-based Dual-domain Network for Few-view Dedicated Cardiac  SPECT Image Reconstructions",
    "abstract": "Cardiovascular disease (CVD) is the leading cause of death worldwide, and myocardial perfusion imaging using SPECT has been widely used in the diagnosis of CVDs. The GE 530/570c dedicated cardiac SPECT scanners adopt a stationary geometry to simultaneously acquire 19 projections to increase sensitivity and achieve dynamic imaging. However, the limited amount of angular sampling negatively affects image quality. Deep learning methods can be implemented to produce higher-quality images from stationary data. This is essentially a few-view imaging problem. In this work, we propose a novel 3D transformer-based dual-domain network, called TIP-Net, for high-quality 3D cardiac SPECT image reconstructions. Our method aims to first reconstruct 3D cardiac SPECT images directly from projection data without the iterative reconstruction process by proposing a customized projection-to-image domain transformer. Then, given its reconstruction output and the original few-view reconstruction, we further refine the reconstruction using an image-domain reconstruction network. Validated by cardiac catheterization images, diagnostic interpretations from nuclear cardiologists, and defect size quantified by an FDA 510(k)-cleared clinical software, our method produced images with higher cardiac defect contrast on human studies compared with previous baseline methods, potentially enabling high-quality defect visualization using stationary few-view dedicated cardiac SPECT scanners. ",
    "url": "https://arxiv.org/abs/2307.09624",
    "authors": [
      "Huidong Xie",
      "Bo Zhou",
      "Xiongchao Chen",
      "Xueqi Guo",
      "Stephanie Thorn",
      "Yi-Hwa Liu",
      "Ge Wang",
      "Albert Sinusas",
      "Chi Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09770",
    "title": "Perturbing a Neural Network to Infer Effective Connectivity: Evidence  from Synthetic EEG Data",
    "abstract": "Identifying causal relationships among distinct brain areas, known as effective connectivity, holds key insights into the brain's information processing and cognitive functions. Electroencephalogram (EEG) signals exhibit intricate dynamics and inter-areal interactions within the brain. However, methods for characterizing nonlinear causal interactions among multiple brain regions remain relatively underdeveloped. In this study, we proposed a data-driven framework to infer effective connectivity by perturbing the trained neural networks. Specifically, we trained neural networks (i.e., CNN, vanilla RNN, GRU, LSTM, and Transformer) to predict future EEG signals according to historical data and perturbed the networks' input to obtain effective connectivity (EC) between the perturbed EEG channel and the rest of the channels. The EC reflects the causal impact of perturbing one node on others. The performance was tested on the synthetic EEG generated by a biological-plausible Jansen-Rit model. CNN and Transformer obtained the best performance on both 3-channel and 90-channel synthetic EEG data, outperforming the classical Granger causality method. Our work demonstrated the potential of perturbing an artificial neural network, learned to predict future system dynamics, to uncover the underlying causal structure. ",
    "url": "https://arxiv.org/abs/2307.09770",
    "authors": [
      "Peizhen Yang",
      "Xinke Shen",
      "Zongsheng Li",
      "Zixiang Luo",
      "Kexin Lou",
      "Quanying Liu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2307.09794",
    "title": "DiffDP: Radiotherapy Dose Prediction via a Diffusion Model",
    "abstract": "Currently, deep learning (DL) has achieved the automatic prediction of dose distribution in radiotherapy planning, enhancing its efficiency and quality. However, existing methods suffer from the over-smoothing problem for their commonly used L_1 or L_2 loss with posterior average calculations. To alleviate this limitation, we innovatively introduce a diffusion-based dose prediction (DiffDP) model for predicting the radiotherapy dose distribution of cancer patients. Specifically, the DiffDP model contains a forward process and a reverse process. In the forward process, DiffDP gradually transforms dose distribution maps into Gaussian noise by adding small noise and trains a noise predictor to predict the noise added in each timestep. In the reverse process, it removes the noise from the original Gaussian noise in multiple steps with the well-trained noise predictor and finally outputs the predicted dose distribution map. To ensure the accuracy of the prediction, we further design a structure encoder to extract anatomical information from patient anatomy images and enable the noise predictor to be aware of the dose constraints within several essential organs, i.e., the planning target volume and organs at risk. Extensive experiments on an in-house dataset with 130 rectum cancer patients demonstrate the s ",
    "url": "https://arxiv.org/abs/2307.09794",
    "authors": [
      "Zhenghao Feng",
      "Lu Wen",
      "Peng Wang",
      "Binyu Yan",
      "Xi Wu",
      "Jiliu Zhou",
      "Yan Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2307.09818",
    "title": "Deep unrolling Shrinkage Network for Dynamic MR imaging",
    "abstract": "Deep unrolling networks that utilize sparsity priors have achieved great success in dynamic magnetic resonance (MR) imaging. The convolutional neural network (CNN) is usually utilized to extract the transformed domain, and then the soft thresholding (ST) operator is applied to the CNN-transformed data to enforce the sparsity priors. However, the ST operator is usually constrained to be the same across all channels of the CNN-transformed data. In this paper, we propose a novel operator, called soft thresholding with channel attention (AST), that learns the threshold for each channel. In particular, we put forward a novel deep unrolling shrinkage network (DUS-Net) by unrolling the alternating direction method of multipliers (ADMM) for optimizing the transformed $l_1$ norm dynamic MR reconstruction model. Experimental results on an open-access dynamic cine MR dataset demonstrate that the proposed DUS-Net outperforms the state-of-the-art methods. The source code is available at \\url{https://github.com/yhao-z/DUS-Net}. ",
    "url": "https://arxiv.org/abs/2307.09818",
    "authors": [
      "Yinghao Zhang",
      "Xiaodi Li",
      "Weihang Li",
      "Yue Hu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.09823",
    "title": "Multi-modal Learning based Prediction for Disease",
    "abstract": "Non alcoholic fatty liver disease (NAFLD) is the most common cause of chronic liver disease, which can be predicted accurately to prevent advanced fibrosis and cirrhosis. While, a liver biopsy, the gold standard for NAFLD diagnosis, is invasive, expensive, and prone to sampling errors. Therefore, non-invasive studies are extremely promising, yet they are still in their infancy due to the lack of comprehensive research data and intelligent methods for multi-modal data. This paper proposes a NAFLD diagnosis system (DeepFLDDiag) combining a comprehensive clinical dataset (FLDData) and a multi-modal learning based NAFLD prediction method (DeepFLD). The dataset includes over 6000 participants physical examinations, laboratory and imaging studies, extensive questionnaires, and facial images of partial participants, which is comprehensive and valuable for clinical studies. From the dataset, we quantitatively analyze and select clinical metadata that most contribute to NAFLD prediction. Furthermore, the proposed DeepFLD, a deep neural network model designed to predict NAFLD using multi-modal input, including metadata and facial images, outperforms the approach that only uses metadata. Satisfactory performance is also verified on other unseen datasets. Inspiringly, DeepFLD can achieve competitive results using only facial images as input rather than metadata, paving the way for a more robust and simpler non-invasive NAFLD diagnosis. ",
    "url": "https://arxiv.org/abs/2307.09823",
    "authors": [
      "Yaran Chen",
      "Xueyu Chen",
      "Yu Han",
      "Haoran Li",
      "Dongbin Zhao",
      "Jingzhong Li",
      "Xu Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.09850",
    "title": "Communication-Efficient Distribution-Free Inference Over Networks",
    "abstract": "Consider a star network where each local node possesses a set of distribution-free test statistics that exhibit a symmetric distribution around zero when their corresponding null hypothesis is true. This paper investigates statistical inference problems in networks concerning the aggregation of this general type of statistics and global error rate control under communication constraints in various scenarios. The study proposes communication-efficient algorithms that are built on established non-parametric methods, such as the Wilcoxon and sign tests, as well as modern inference methods such as the Benjamini-Hochberg (BH) and Barber-Candes (BC) procedures, coupled with sampling and quantization operations. The proposed methods are evaluated through extensive simulation studies. ",
    "url": "https://arxiv.org/abs/2307.09850",
    "authors": [
      "Mehrdad Pournaderi",
      "Yu Xiang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.09898",
    "title": "An analysis on the effects of speaker embedding choice in non  auto-regressive TTS",
    "abstract": "In this paper we introduce a first attempt on understanding how a non-autoregressive factorised multi-speaker speech synthesis architecture exploits the information present in different speaker embedding sets. We analyse if jointly learning the representations, and initialising them from pretrained models determine any quality improvements for target speaker identities. In a separate analysis, we investigate how the different sets of embeddings impact the network's core speech abstraction (i.e. zero conditioned) in terms of speaker identity and representation learning. We show that, regardless of the used set of embeddings and learning strategy, the network can handle various speaker identities equally well, with barely noticeable variations in speech output quality, and that speaker leakage within the core structure of the synthesis system is inevitable in the standard training procedures adopted thus far. ",
    "url": "https://arxiv.org/abs/2307.09898",
    "authors": [
      "Adriana Stan",
      "Johannah O'Mahony"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.10005",
    "title": "Alzheimer's Disease Detection from Spontaneous Speech and Text: A review",
    "abstract": "In the past decade, there has been a surge in research examining the use of voice and speech analysis as a means of detecting neurodegenerative diseases such as Alzheimer's. Many studies have shown that certain acoustic features can be used to differentiate between normal aging and Alzheimer's disease, and speech analysis has been found to be a cost-effective method of detecting Alzheimer's dementia. The aim of this review is to analyze the various algorithms used in speech-based detection and classification of Alzheimer's disease. A literature survey was conducted using databases such as Web of Science, Google Scholar, and Science Direct, and articles published from January 2020 to the present were included based on keywords such as ``Alzheimer's detection'', \"speech,\" and \"natural language processing.\" The ADReSS, Pitt corpus, and CCC datasets are commonly used for the analysis of dementia from speech, and this review focuses on the various acoustic and linguistic feature engineering-based classification models drawn from 15 studies. Based on the findings of this study, it appears that a more accurate model for classifying Alzheimer's disease can be developed by considering both linguistic and acoustic data. The review suggests that speech signals can be a useful tool for detecting dementia and may serve as a reliable biomarker for efficiently identifying Alzheimer's disease. ",
    "url": "https://arxiv.org/abs/2307.10005",
    "authors": [
      "Vrindha M. K.",
      "Geethu V.",
      "Anurenjan P. R.",
      "Deepak S.",
      "Sreeni K. G."
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2001.05887",
    "title": "MixPath: A Unified Approach for One-shot Neural Architecture Search",
    "abstract": " Comments: ICCV2023 ",
    "url": "https://arxiv.org/abs/2001.05887",
    "authors": [
      "Xiangxiang Chu",
      "Shun Lu",
      "Xudong Li",
      "Bo Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2103.02404",
    "title": "Quantum Network Discrimination",
    "abstract": " Comments: 39 pages, 1 Table, 9 Figures incl. 1 Animation. v2: Several improvements and clarifications. Version accepted for publication ",
    "url": "https://arxiv.org/abs/2103.02404",
    "authors": [
      "Christoph Hirche"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ]
  },
  {
    "id": "arXiv:2107.06960",
    "title": "MAFAT: Memory-Aware Fusing and Tiling of Neural Networks for Accelerated  Edge Inference",
    "abstract": " Title: MAFAT: Memory-Aware Fusing and Tiling of Neural Networks for Accelerated  Edge Inference ",
    "url": "https://arxiv.org/abs/2107.06960",
    "authors": [
      "Jackson Farley",
      "Andreas Gerstlauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2107.11403",
    "title": "Quantifying Network Similarity using Graph Cumulants",
    "abstract": " Comments: Shared first authorship. Title changed from \"A principled (and practical) test for network comparison\" to \"Quantifying Network Similarity using Graph Cumulants\". Updated version accepted for publication in Journal of Machine Learning Research (JMLR), 2023 ",
    "url": "https://arxiv.org/abs/2107.11403",
    "authors": [
      "Gecia Bravo-Hermsdorff",
      "Lee M. Gunderson",
      "Pierre-Andr\u00e9 Maugis",
      "Carey E. Priebe"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Discrete Mathematics (cs.DM)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2111.01396",
    "title": "Boundary Distribution Estimation for Precise Object Detection",
    "abstract": " Title: Boundary Distribution Estimation for Precise Object Detection ",
    "url": "https://arxiv.org/abs/2111.01396",
    "authors": [
      "Peng Zhi",
      "Haoran Zhou",
      "Hang Huang",
      "Rui Zhao",
      "Rui Zhou",
      "Qingguo Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10403",
    "title": "Tackling Provably Hard Representative Selection via Graph Neural  Networks",
    "abstract": " Comments: Accepted at the Transactions of Machine Learning Research (TMLR) Journal ",
    "url": "https://arxiv.org/abs/2205.10403",
    "authors": [
      "Mehran Kazemi",
      "Anton Tsitsulin",
      "Hossein Esfandiari",
      "MohammadHossein Bateni",
      "Deepak Ramachandran",
      "Bryan Perozzi",
      "Vahab Mirrokni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2206.03638",
    "title": "Alternately Optimized Graph Neural Networks",
    "abstract": " Title: Alternately Optimized Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2206.03638",
    "authors": [
      "Haoyu Han",
      "Xiaorui Liu",
      "Haitao Mao",
      "MohamadAli Torkamani",
      "Feng Shi",
      "Victor Lee",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00419",
    "title": "Self-Supervised Learning for Videos: A Survey",
    "abstract": " Comments: ACM CSUR (December 2022). Project Link: this https URL ",
    "url": "https://arxiv.org/abs/2207.00419",
    "authors": [
      "Madeline C. Schiappa",
      "Yogesh S. Rawat",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2207.07683",
    "title": "First Order Logic and Twin-Width in Tournaments and Dense Oriented  Graphs",
    "abstract": " Comments: 28 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2207.07683",
    "authors": [
      "Colin Geniet",
      "St\u00e9phan Thomass\u00e9"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2208.10741",
    "title": "Hierarchically Decomposed Graph Convolutional Networks for  Skeleton-Based Action Recognition",
    "abstract": " Comments: Accepted by ICCV 2023 ",
    "url": "https://arxiv.org/abs/2208.10741",
    "authors": [
      "Jungho Lee",
      "Minhyeok Lee",
      "Dogyoon Lee",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.10901",
    "title": "Pretraining the Vision Transformer using self-supervised methods for  vision based Deep Reinforcement Learning",
    "abstract": " Title: Pretraining the Vision Transformer using self-supervised methods for  vision based Deep Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2209.10901",
    "authors": [
      "Manuel Goul\u00e3o",
      "Arlindo L. Oliveira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04318",
    "title": "Prediction intervals for neural network models using weighted asymmetric  loss functions",
    "abstract": " Comments: 14 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2210.04318",
    "authors": [
      "Milo Grillo",
      "Yunpeng Han",
      "Agnieszka Werpachowska"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08955",
    "title": "Monitoring edge-geodetic sets: hardness and graph products",
    "abstract": " Comments: 9 pages, 2 figures. Final version to appear in Discrete Applied MMathematics ",
    "url": "https://arxiv.org/abs/2210.08955",
    "authors": [
      "John Haslegrave"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.16117",
    "title": "Improving the Transferability of Adversarial Attacks on Face Recognition  with Beneficial Perturbation Feature Augmentation",
    "abstract": " Comments: \\c{opyright} 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works ",
    "url": "https://arxiv.org/abs/2210.16117",
    "authors": [
      "Fengfan Zhou",
      "Hefei Ling",
      "Yuxuan Shi",
      "Jiazhong Chen",
      "Zongyi Li",
      "Ping Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.07766",
    "title": "On Tuza's conjecture in co-chain graphs",
    "abstract": " Title: On Tuza's conjecture in co-chain graphs ",
    "url": "https://arxiv.org/abs/2211.07766",
    "authors": [
      "Luis Chahua",
      "Juan Guti\u00e9rrez"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2301.02307",
    "title": "What You Say Is What You Show: Visual Narration Detection in  Instructional Videos",
    "abstract": " Comments: Technical Report ",
    "url": "https://arxiv.org/abs/2301.02307",
    "authors": [
      "Kumar Ashutosh",
      "Rohit Girdhar",
      "Lorenzo Torresani",
      "Kristen Grauman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.01561",
    "title": "Hierarchically Composing Level Generators for the Creation of Complex  Structures",
    "abstract": " Comments: Code is available at this https URL This work has been accepted to IEEE Transactions on Games, with copyright transferred to the IEEE ",
    "url": "https://arxiv.org/abs/2302.01561",
    "authors": [
      "Michael Beukman",
      "Manuel Fokam",
      "Marcel Kruger",
      "Guy Axelrod",
      "Muhammad Nasir",
      "Branden Ingram",
      "Benjamin Rosman",
      "Steven James"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.05086",
    "title": "Making Substitute Models More Bayesian Can Enhance Transferability of  Adversarial Examples",
    "abstract": " Comments: Accepted by ICLR 2023, fix typos ",
    "url": "https://arxiv.org/abs/2302.05086",
    "authors": [
      "Qizhang Li",
      "Yiwen Guo",
      "Wangmeng Zuo",
      "Hao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.05783",
    "title": "ConCerNet: A Contrastive Learning Based Framework for Automated  Conservation Law Discovery and Trustworthy Dynamical System Prediction",
    "abstract": " Comments: Accepted by ICML 2023 ",
    "url": "https://arxiv.org/abs/2302.05783",
    "authors": [
      "Wang Zhang",
      "Tsui-Wei Weng",
      "Subhro Das",
      "Alexandre Megretski",
      "Luca Daniel",
      "Lam M. Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.14101",
    "title": "Robust Field-level Likelihood-free Inference with Galaxies",
    "abstract": " Comments: 34 pages, 12 figures. For a video summarizing the results, see this https URL ",
    "url": "https://arxiv.org/abs/2302.14101",
    "authors": [
      "Natal\u00ed S. M. de Santi",
      "Helen Shao",
      "Francisco Villaescusa-Navarro",
      "L. Raul Abramo",
      "Romain Teyssier",
      "Pablo Villanueva-Domingo",
      "Yueying Ni",
      "Daniel Angl\u00e9s-Alc\u00e1zar",
      "Shy Genel",
      "Elena Hernandez-Martinez",
      "Ulrich P. Steinwandel",
      "Christopher C. Lovell",
      "Klaus Dolag",
      "Tiago Castro",
      "Mark Vogelsberger"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.02918",
    "title": "Graph Positional Encoding via Random Feature Propagation",
    "abstract": " Comments: ICML 2023 ",
    "url": "https://arxiv.org/abs/2303.02918",
    "authors": [
      "Moshe Eliasof",
      "Fabrizio Frasca",
      "Beatrice Bevilacqua",
      "Eran Treister",
      "Gal Chechik",
      "Haggai Maron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03027",
    "title": "Critical Points and Convergence Analysis of Generative Deep Linear  Networks Trained with Bures-Wasserstein Loss",
    "abstract": " Comments: 42 pages, 3 figures, accepted at ICML 2023 ",
    "url": "https://arxiv.org/abs/2303.03027",
    "authors": [
      "Pierre Br\u00e9chet",
      "Katerina Papagiannouli",
      "Jing An",
      "Guido Mont\u00fafar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03786",
    "title": "Stability of the personal relationship networks in a longitudinal study  of middle school students",
    "abstract": " Comments: 10 pages, 7 figures, requires wlscirep.cls, jabbrv.sty, jabbrv-ltwa-all.ldf, and jabbrv-ltwa-en.ldf (included) ",
    "url": "https://arxiv.org/abs/2303.03786",
    "authors": [
      "Diego Escribano",
      "Francisco J. Lapuente",
      "Jos\u00e9 A. Cuesta",
      "Robin I. M. Dunbar",
      "Angel S\u00e1nchez"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.09340",
    "title": "Improving Automated Hemorrhage Detection in Sparse-view Computed  Tomography via Deep Convolutional Neural Network based Artifact Reduction",
    "abstract": " Comments: 11 pages, 6 figures, 1 table ",
    "url": "https://arxiv.org/abs/2303.09340",
    "authors": [
      "Johannes Thalhammer",
      "Manuel Schultheiss",
      "Tina Dorosti",
      "Tobias Lasser",
      "Franz Pfeiffer",
      "Daniela Pfeiffer",
      "Florian Schaff"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2304.04578",
    "title": "Bitcoin's Carbon Footprint Revisited: Proof of Work Mining for Renewable  Energy Expansion",
    "abstract": " Comments: A previous version of this paper was titled \"Can Bitcoin Stop Climate Change? Proof of Work, Energy Consumption and Carbon Footprint (SoK)\" ",
    "url": "https://arxiv.org/abs/2304.04578",
    "authors": [
      "Juan Ignacio Iba\u00f1ez",
      "Alexander Freier"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.10727",
    "title": "RoCOCO: Robustness Benchmark of MS-COCO to Stress-test Image-Text  Matching Models",
    "abstract": " Title: RoCOCO: Robustness Benchmark of MS-COCO to Stress-test Image-Text  Matching Models ",
    "url": "https://arxiv.org/abs/2304.10727",
    "authors": [
      "Seulki Park",
      "Daeho Um",
      "Hajung Yoon",
      "Sanghyuk Chun",
      "Sangdoo Yun",
      "Jin Young Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.00909",
    "title": "Outline, Then Details: Syntactically Guided Coarse-To-Fine Code  Generation",
    "abstract": " Comments: Accepted in ICML 2023 ",
    "url": "https://arxiv.org/abs/2305.00909",
    "authors": [
      "Wenqing Zheng",
      "S P Sharan",
      "Ajay Kumar Jaiswal",
      "Kevin Wang",
      "Yihan Xi",
      "Dejia Xu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.09211",
    "title": "CB-HVTNet: A channel-boosted hybrid vision transformer network for  lymphocyte assessment in histopathological images",
    "abstract": " Title: CB-HVTNet: A channel-boosted hybrid vision transformer network for  lymphocyte assessment in histopathological images ",
    "url": "https://arxiv.org/abs/2305.09211",
    "authors": [
      "Momina Liaqat Ali",
      "Zunaira Rauf",
      "Asifullah Khan",
      "Anabia Sohail",
      "Rafi Ullah",
      "Jeonghwan Gwak"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.09946",
    "title": "AdaMSS: Adaptive Multi-Modality Segmentation-to-Survival Learning for  Survival Outcome Prediction from PET/CT Images",
    "abstract": " Comments: Under Review ",
    "url": "https://arxiv.org/abs/2305.09946",
    "authors": [
      "Mingyuan Meng",
      "Bingxin Gu",
      "Michael Fulham",
      "Shaoli Song",
      "Dagan Feng",
      "Lei Bi",
      "Jinman Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13659",
    "title": "Flare-Aware Cross-modal Enhancement Network for Multi-spectral Vehicle  Re-identification",
    "abstract": " Title: Flare-Aware Cross-modal Enhancement Network for Multi-spectral Vehicle  Re-identification ",
    "url": "https://arxiv.org/abs/2305.13659",
    "authors": [
      "Aihua Zheng",
      "Zhiqi Ma",
      "Zi Wang",
      "Chenglong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16165",
    "title": "A Conceptual Model for End-to-End Causal Discovery in Knowledge Tracing",
    "abstract": " Comments: 16th International Conference on Educational Data Mining (EDM 2023) ",
    "url": "https://arxiv.org/abs/2305.16165",
    "authors": [
      "Nischal Ashok Kumar",
      "Wanyong Feng",
      "Jaewook Lee",
      "Hunter McNichols",
      "Aritra Ghosh",
      "Andrew Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.18060",
    "title": "Mining Negative Temporal Contexts For False Positive Suppression In  Real-Time Ultrasound Lesion Detection",
    "abstract": " Comments: 10 pages, 4 figures, MICCAI 2023 Early Accept ",
    "url": "https://arxiv.org/abs/2305.18060",
    "authors": [
      "Haojun Yu",
      "Youcheng Li",
      "QuanLin Wu",
      "Ziwei Zhao",
      "Dengbo Chen",
      "Dong Wang",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.07591",
    "title": "I See Dead People: Gray-Box Adversarial Attack on Image-To-Text Models",
    "abstract": " Title: I See Dead People: Gray-Box Adversarial Attack on Image-To-Text Models ",
    "url": "https://arxiv.org/abs/2306.07591",
    "authors": [
      "Raz Lapid",
      "Moshe Sipper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2306.08617",
    "title": "Multi-class Graph Clustering via Approximated Effective $p$-Resistance",
    "abstract": " Comments: Accepted to ICML2023 ",
    "url": "https://arxiv.org/abs/2306.08617",
    "authors": [
      "Shota Saito",
      "Mark Herbster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.01533",
    "title": "Unsupervised Video Anomaly Detection with Diffusion Models Conditioned  on Compact Motion Representations",
    "abstract": " Comments: Accepted to ICIAP 2023 ",
    "url": "https://arxiv.org/abs/2307.01533",
    "authors": [
      "Anil Osman Tur",
      "Nicola Dall'Asen",
      "Cigdem Beyan",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.01646",
    "title": "SwinGNN: Rethinking Permutation Invariance in Diffusion Models for Graph  Generation",
    "abstract": " Title: SwinGNN: Rethinking Permutation Invariance in Diffusion Models for Graph  Generation ",
    "url": "https://arxiv.org/abs/2307.01646",
    "authors": [
      "Qi Yan",
      "Zhengyang Liang",
      "Yang Song",
      "Renjie Liao",
      "Lele Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.02203",
    "title": "Neural Fields for Interactive Visualization of Statistical Dependencies  in 3D Simulation Ensembles",
    "abstract": " Title: Neural Fields for Interactive Visualization of Statistical Dependencies  in 3D Simulation Ensembles ",
    "url": "https://arxiv.org/abs/2307.02203",
    "authors": [
      "Fatemeh Farokhmanesh",
      "Kevin H\u00f6hlein",
      "Christoph Neuhauser",
      "R\u00fcdiger Westermann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.04228",
    "title": "Efficient Bayesian travel-time tomography with geologically-complex  priors using sensitivity-informed polynomial chaos expansion and deep  generative networks",
    "abstract": " Comments: 25 pages, 15 figures ",
    "url": "https://arxiv.org/abs/2307.04228",
    "authors": [
      "Giovanni Angelo Meles",
      "Macarena Amaya",
      "Shiran Levy",
      "Stefano Marelli",
      "Niklas Linde"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.04838",
    "title": "CREPE: Learnable Prompting With CLIP Improves Visual Relationship  Prediction",
    "abstract": " Title: CREPE: Learnable Prompting With CLIP Improves Visual Relationship  Prediction ",
    "url": "https://arxiv.org/abs/2307.04838",
    "authors": [
      "Rakshith Subramanyam",
      "T. S. Jayram",
      "Rushil Anirudh",
      "Jayaraman J. Thiagarajan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.04988",
    "title": "Benchmarking Bayesian Causal Discovery Methods for Downstream Treatment  Effect Estimation",
    "abstract": " Comments: Peer-Reviewed and Accepted to ICML 2023 Workshop on Structured Probabilistic Inference & Generative Modeling ",
    "url": "https://arxiv.org/abs/2307.04988",
    "authors": [
      "Chris Chinenye Emezue",
      "Alexandre Drouin",
      "Tristan Deleu",
      "Stefan Bauer",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2307.06608",
    "title": "Introducing Foundation Models as Surrogate Models: Advancing Towards  More Practical Adversarial Attacks",
    "abstract": " Title: Introducing Foundation Models as Surrogate Models: Advancing Towards  More Practical Adversarial Attacks ",
    "url": "https://arxiv.org/abs/2307.06608",
    "authors": [
      "Jiaming Zhang",
      "Jitao Sang",
      "Qi Yi",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.06698",
    "title": "IntelliGraphs: Datasets for Benchmarking Knowledge Graph Generation",
    "abstract": " Title: IntelliGraphs: Datasets for Benchmarking Knowledge Graph Generation ",
    "url": "https://arxiv.org/abs/2307.06698",
    "authors": [
      "Thiviyan Thanapalasingam",
      "Emile van Krieken",
      "Peter Bloem",
      "Paul Groth"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.06975",
    "title": "Neuro-symbolic Empowered Denoising Diffusion Probabilistic Models for  Real-time Anomaly Detection in Industry 4.0",
    "abstract": " Comments: Accepted at the 26th Forum on specification and Design Languages (FDL 2023) ",
    "url": "https://arxiv.org/abs/2307.06975",
    "authors": [
      "Luigi Capogrosso",
      "Alessio Mascolini",
      "Federico Girella",
      "Geri Skenderi",
      "Sebastiano Gaiardelli",
      "Nicola Dall'Ora",
      "Francesco Ponzio",
      "Enrico Fraccaroli",
      "Santa Di Cataldo",
      "Sara Vinco",
      "Enrico Macii",
      "Franco Fummi",
      "Marco Cristani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.07859",
    "title": "Unified Adversarial Patch for Cross-modal Attacks in the Physical World",
    "abstract": " Comments: 10 pages, 8 figures, accepted by ICCV2023 ",
    "url": "https://arxiv.org/abs/2307.07859",
    "authors": [
      "Xingxing Wei",
      "Yao Huang",
      "Yitong Sun",
      "Jie Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07873",
    "title": "Why Does Little Robustness Help? Understanding Adversarial  Transferability From Surrogate Training",
    "abstract": " Comments: Accepted by IEEE Symposium on Security and Privacy (Oakland) 2024; 21 pages, 12 figures, 13 tables ",
    "url": "https://arxiv.org/abs/2307.07873",
    "authors": [
      "Yechao Zhang",
      "Shengshan Hu",
      "Leo Yu Zhang",
      "Junyu Shi",
      "Minghui Li",
      "Xiaogeng Liu",
      "Wei Wan",
      "Hai Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08913",
    "title": "Towards the Sparseness of Projection Head in Self-Supervised Learning",
    "abstract": " Comments: 9 pages,3 figures ",
    "url": "https://arxiv.org/abs/2307.08913",
    "authors": [
      "Zeen Song",
      "Xingzhe Su",
      "Jingyao Wang",
      "Wenwen Qiang",
      "Changwen Zheng",
      "Fuchun Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09045",
    "title": "6G Network Operation Support System",
    "abstract": " Comments: 103 pages, 20 figures, 52 references ",
    "url": "https://arxiv.org/abs/2307.09045",
    "authors": [
      "Ye Ouyang",
      "Yaqin Zhang",
      "Xiaozhou Ye",
      "Yunxin Liu",
      "Xidong Wang",
      "Jie Sun",
      "Yang Liu",
      "Shoufeng Wang",
      "Sen Bian",
      "Yun Li"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.09455",
    "title": "Pseudo Outlier Exposure for Out-of-Distribution Detection using  Pretrained Transformers",
    "abstract": " Comments: 12 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2307.09455",
    "authors": [
      "Jaeyoung Kim",
      "Kyuheon Jung",
      "Dongbin Na",
      "Sion Jang",
      "Eunbin Park",
      "Sungchul Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  }
]