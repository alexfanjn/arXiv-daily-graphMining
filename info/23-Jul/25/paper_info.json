[
  {
    "id": "arXiv:2307.11752",
    "title": "OpenLB User Guide: Associated with Release 1.6 of the Code",
    "abstract": "OpenLB is an object-oriented implementation of LBM. It is the first implementation of a generic platform for LBM programming, which is shared with the open source community (GPLv2). Since the first release in 2007, the code has been continuously improved and extended which is documented by thirteen releases as well as the corresponding release notes which are available on the OpenLB website (https://www.openlb.net). The OpenLB code is written in C++ and is used by application programmers as well as developers, with the ability to implement custom models OpenLB supports complex data structures that allow simulations in complex geometries and parallel execution using MPI, OpenMP and CUDA on high-performance computers. The source code uses the concepts of interfaces and templates, so that efficient, direct and intuitive implementations of the LBM become possible. The efficiency and scalability has been checked and proved by code reviews. This user manual and a source code documentation by DoxyGen are available on the OpenLB project website. ",
    "url": "https://arxiv.org/abs/2307.11752",
    "authors": [
      "Adrian Kummerl\u00e4nder",
      "Samuel J. Avis",
      "Halim Kusumaatmaja",
      "Fedor Bukreev",
      "Michael Crocoll",
      "Davide Dapelo",
      "Simon Gro\u00dfmann",
      "Nicolas Hafen",
      "Shota Ito",
      "Julius Je\u00dfberger",
      "Eliane Kummer",
      "Jan E. Marquardt",
      "Johanna M\u00f6dl",
      "Tim Pertzel",
      "Franti\u0161ek Prinz",
      "Florian Raichle",
      "Martin Sadric",
      "Maximilian Schecher",
      "Dennis Teutscher",
      "Stephan Simonis",
      "Mathias J. Krause"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.11772",
    "title": "AutoAlign: Fully Automatic and Effective Knowledge Graph Alignment  enabled by Large Language Models",
    "abstract": "The task of entity alignment between knowledge graphs (KGs) aims to identify every pair of entities from two different KGs that represent the same entity. Many machine learning-based methods have been proposed for this task. However, to our best knowledge, existing methods all require manually crafted seed alignments, which are expensive to obtain. In this paper, we propose the first fully automatic alignment method named AutoAlign, which does not require any manually crafted seed alignments. Specifically, for predicate embeddings, AutoAlign constructs a predicate-proximity-graph with the help of large language models to automatically capture the similarity between predicates across two KGs. For entity embeddings, AutoAlign first computes the entity embeddings of each KG independently using TransE, and then shifts the two KGs' entity embeddings into the same vector space by computing the similarity between entities based on their attributes. Thus, both predicate alignment and entity alignment can be done without manually crafted seed alignments. AutoAlign is not only fully automatic, but also highly effective. Experiments using real-world KGs show that AutoAlign improves the performance of entity alignment significantly compared to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2307.11772",
    "authors": [
      "Rui Zhang",
      "Yixin Su",
      "Bayu Distiawan Trisedya",
      "Xiaoyan Zhao",
      "Min Yang",
      "Hong Cheng",
      "Jianzhong Qi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.11775",
    "title": "A Topical Approach to Capturing Customer Insight In Social Media",
    "abstract": "The age of social media has opened new opportunities for businesses. This flourishing wealth of information is outside traditional channels and frameworks of classical marketing research, including that of Marketing Mix Modeling (MMM). Textual data, in particular, poses many challenges that data analysis practitioners must tackle. Social media constitute massive, heterogeneous, and noisy document sources. Industrial data acquisition processes include some amount of ETL. However, the variability of noise in the data and the heterogeneity induced by different sources create the need for ad-hoc tools. Put otherwise, customer insight extraction in fully unsupervised, noisy contexts is an arduous task. This research addresses the challenge of fully unsupervised topic extraction in noisy, Big Data contexts. We present three approaches we built on the Variational Autoencoder framework: the Embedded Dirichlet Process, the Embedded Hierarchical Dirichlet Process, and the time-aware Dynamic Embedded Dirichlet Process. These nonparametric approaches concerning topics present the particularity of determining word embeddings and topic embeddings. These embeddings do not require transfer learning, but knowledge transfer remains possible. We test these approaches on benchmark and automotive industry-related datasets from a real-world use case. We show that our models achieve equal to better performance than state-of-the-art methods and that the field of topic modeling would benefit from improved evaluation metrics. ",
    "url": "https://arxiv.org/abs/2307.11775",
    "authors": [
      "Miguel Palencia-Olivar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.11777",
    "title": "Prediction of Handball Matches with Statistically Enhanced Learning via  Estimated Team Strengths",
    "abstract": "We propose a Statistically Enhanced Learning (aka. SEL) model to predict handball games. Our Machine Learning model augmented with SEL features outperforms state-of-the-art models with an accuracy beyond 80%. In this work, we show how we construct the data set to train Machine Learning models on past female club matches. We then compare different models and evaluate them to assess their performance capabilities. Finally, explainability methods allow us to change the scope of our tool from a purely predictive solution to a highly insightful analytical tool. This can become a valuable asset for handball teams' coaches providing valuable statistical and predictive insights to prepare future competitions. ",
    "url": "https://arxiv.org/abs/2307.11777",
    "authors": [
      "Florian Felice",
      "Christophe Ley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2307.11781",
    "title": "Development of an Autonomous Reverse Engineering Capability for  Controller Area Network Messages to Support Autonomous Control Retrofits",
    "abstract": "As the autonomous vehicle industry continues to grow, various companies are exploring the use of aftermarket kits to retrofit existing vehicles with semi-autonomous capabilities. However, differences in implementation of the controller area network (CAN) used by each vehicle manufacturer poses a significant challenge to achieving large-scale implementation of retrofits. To address this challenge, this research proposes a method for reverse engineering the CAN channels associated with a vehicle's accelerator and brake pedals, without any prior knowledge of the vehicle. By simultaneously recording inertial measurement unit (IMU) and CAN data during vehicle operation, the proposed algorithms can identify the CAN channels that correspond to each control. During testing of six vehicles from three manufacturers, the proposed method was shown to successfully identify the CAN channels for the accelerator pedal and brake pedal for each vehicle tested. These promising results demonstrate the potential for using this approach for developing aftermarket autonomous vehicle kits - potentially with additional research to facilitate real-time use. Notably, the proposed system has the potential to maintain its effectiveness despite changes in vehicle CAN standards, and it could potentially be adapted to function with any vehicle communications medium. ",
    "url": "https://arxiv.org/abs/2307.11781",
    "authors": [
      "Kevin Setterstrom",
      "Jeremy Straub"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.11785",
    "title": "Adversarial Conversational Shaping for Intelligent Agents",
    "abstract": "The recent emergence of deep learning methods has enabled the research community to achieve state-of-the art results in several domains including natural language processing. However, the current robocall system remains unstable and inaccurate: text generator and chat-bots can be tedious and misunderstand human-like dialogue. In this work, we study the performance of two models able to enhance an intelligent conversational agent through adversarial conversational shaping: a generative adversarial network with policy gradient (GANPG) and a generative adversarial network with reward for every generation step (REGS) based on the REGS model presented in Li et al. [18] . This model is able to assign rewards to both partially and fully generated text sequences. We discuss performance with different training details : seq2seq [ 36] and transformers [37 ] in a reinforcement learning framework. ",
    "url": "https://arxiv.org/abs/2307.11785",
    "authors": [
      "Piotr Tarasiewicz",
      "Sultan Kenjeyev",
      "Ilana Sebag",
      "Shehab Alshehabi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.11793",
    "title": "Leveraging arbitrary mobile sensor trajectories with shallow recurrent  decoder networks for full-state reconstruction",
    "abstract": "Sensing is one of the most fundamental tasks for the monitoring, forecasting and control of complex, spatio-temporal systems. In many applications, a limited number of sensors are mobile and move with the dynamics, with examples including wearable technology, ocean monitoring buoys, and weather balloons. In these dynamic systems (without regions of statistical-independence), the measurement time history encodes a significant amount of information that can be extracted for critical tasks. Most model-free sensing paradigms aim to map current sparse sensor measurements to the high-dimensional state space, ignoring the time-history all together. Using modern deep learning architectures, we show that a sequence-to-vector model, such as an LSTM (long, short-term memory) network, with a decoder network, dynamic trajectory information can be mapped to full state-space estimates. Indeed, we demonstrate that by leveraging mobile sensor trajectories with shallow recurrent decoder networks, we can train the network (i) to accurately reconstruct the full state space using arbitrary dynamical trajectories of the sensors, (ii) the architecture reduces the variance of the mean-square error of the reconstruction error in comparison with immobile sensors, and (iii) the architecture also allows for rapid generalization (parameterization of dynamics) for data outside the training set. Moreover, the path of the sensor can be chosen arbitrarily, provided training data for the spatial trajectory of the sensor is available. The exceptional performance of the network architecture is demonstrated on three applications: turbulent flows, global sea-surface temperature data, and human movement biomechanics. ",
    "url": "https://arxiv.org/abs/2307.11793",
    "authors": [
      "Megan R. Ebers",
      "Jan P. Williams",
      "Katherine M. Steele",
      "J. Nathan Kutz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2307.11796",
    "title": "Unsupervised Embedding Learning for Human Activity Recognition Using  Wearable Sensor Data",
    "abstract": "The embedded sensors in widely used smartphones and other wearable devices make the data of human activities more accessible. However, recognizing different human activities from the wearable sensor data remains a challenging research problem in ubiquitous computing. One of the reasons is that the majority of the acquired data has no labels. In this paper, we present an unsupervised approach, which is based on the nature of human activity, to project the human activities into an embedding space in which similar activities will be located closely together. Using this, subsequent clustering algorithms can benefit from the embeddings, forming behavior clusters that represent the distinct activities performed by a person. Results of experiments on three labeled benchmark datasets demonstrate the effectiveness of the framework and show that our approach can help the clustering algorithm achieve improved performance in identifying and categorizing the underlying human activities compared to unsupervised techniques applied directly to the original data set. ",
    "url": "https://arxiv.org/abs/2307.11796",
    "authors": [
      "Taoran Sheng",
      "Manfred Huber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.11806",
    "title": "How do you feel? Measuring User-Perceived Value for Rejecting Machine  Decisions in Hate Speech Detection",
    "abstract": "Hate speech moderation remains a challenging task for social media platforms. Human-AI collaborative systems offer the potential to combine the strengths of humans' reliability and the scalability of machine learning to tackle this issue effectively. While methods for task handover in human-AI collaboration exist that consider the costs of incorrect predictions, insufficient attention has been paid to accurately estimating these costs. In this work, we propose a value-sensitive rejection mechanism that automatically rejects machine decisions for human moderation based on users' value perceptions regarding machine decisions. We conduct a crowdsourced survey study with 160 participants to evaluate their perception of correct and incorrect machine decisions in the domain of hate speech detection, as well as occurrences where the system rejects making a prediction. Here, we introduce Magnitude Estimation, an unbounded scale, as the preferred method for measuring user (dis)agreement with machine decisions. Our results show that Magnitude Estimation can provide a reliable measurement of participants' perception of machine decisions. By integrating user-perceived value into human-AI collaboration, we further show that it can guide us in 1) determining when to accept or reject machine decisions to obtain the optimal total value a model can deliver and 2) selecting better classification models as compared to the more widely used target of model accuracy. ",
    "url": "https://arxiv.org/abs/2307.11806",
    "authors": [
      "Philippe Lammerts",
      "Philip Lippmann",
      "Yen-Chia Hsu",
      "Fabio Casati",
      "Jie Yang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2307.11807",
    "title": "Local Kernel Renormalization as a mechanism for feature learning in  overparametrized Convolutional Neural Networks",
    "abstract": "Feature learning, or the ability of deep neural networks to automatically learn relevant features from raw data, underlies their exceptional capability to solve complex tasks. However, feature learning seems to be realized in different ways in fully-connected (FC) or convolutional architectures (CNNs). Empirical evidence shows that FC neural networks in the infinite-width limit eventually outperform their finite-width counterparts. Since the kernel that describes infinite-width networks does not evolve during training, whatever form of feature learning occurs in deep FC architectures is not very helpful in improving generalization. On the other hand, state-of-the-art architectures with convolutional layers achieve optimal performances in the finite-width regime, suggesting that an effective form of feature learning emerges in this case. In this work, we present a simple theoretical framework that provides a rationale for these differences, in one hidden layer networks. First, we show that the generalization performance of a finite-width FC network can be obtained by an infinite-width network, with a suitable choice of the Gaussian priors. Second, we derive a finite-width effective action for an architecture with one convolutional hidden layer and compare it with the result available for FC networks. Remarkably, we identify a completely different form of kernel renormalization: whereas the kernel of the FC architecture is just globally renormalized by a single scalar parameter, the CNN kernel undergoes a local renormalization, meaning that the network can select the local components that will contribute to the final prediction in a data-dependent way. This finding highlights a simple mechanism for feature learning that can take place in overparametrized shallow CNNs, but not in shallow FC architectures or in locally connected neural networks without weight sharing. ",
    "url": "https://arxiv.org/abs/2307.11807",
    "authors": [
      "R. Aiudi",
      "R. Pacelli",
      "A. Vezzani",
      "R. Burioni",
      "P. Rotondo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ]
  },
  {
    "id": "arXiv:2307.11808",
    "title": "Automatic Data Augmentation Learning using Bilevel Optimization for  Histopathological Images",
    "abstract": "Training a deep learning model to classify histopathological images is challenging, because of the color and shape variability of the cells and tissues, and the reduced amount of available data, which does not allow proper learning of those variations. Variations can come from the image acquisition process, for example, due to different cell staining protocols or tissue deformation. To tackle this challenge, Data Augmentation (DA) can be used during training to generate additional samples by applying transformations to existing ones, to help the model become invariant to those color and shape transformations. The problem with DA is that it is not only dataset-specific but it also requires domain knowledge, which is not always available. Without this knowledge, selecting the right transformations can only be done using heuristics or through a computationally demanding search. To address this, we propose an automatic DA learning method. In this method, the DA parameters, i.e. the transformation parameters needed to improve the model training, are considered learnable and are learned automatically using a bilevel optimization approach in a quick and efficient way using truncated backpropagation. We validated the method on six different datasets. Experimental results show that our model can learn color and affine transformations that are more helpful to train an image classifier than predefined DA transformations, which are also more expensive as they need to be selected before the training by grid search on a validation set. We also show that similarly to a model trained with RandAugment, our model has also only a few method-specific hyperparameters to tune but is performing better. This makes our model a good solution for learning the best DA parameters, especially in the context of histopathological images, where defining potentially useful transformation heuristically is not trivial. ",
    "url": "https://arxiv.org/abs/2307.11808",
    "authors": [
      "Saypraseuth Mounsaveng",
      "Issam Laradji",
      "David V\u00e1zquez",
      "Marco Perdersoli",
      "Ismail Ben Ayed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.11823",
    "title": "HybridAugment++: Unified Frequency Spectra Perturbations for Model  Robustness",
    "abstract": "Convolutional Neural Networks (CNN) are known to exhibit poor generalization performance under distribution shifts. Their generalization have been studied extensively, and one line of work approaches the problem from a frequency-centric perspective. These studies highlight the fact that humans and CNNs might focus on different frequency components of an image. First, inspired by these observations, we propose a simple yet effective data augmentation method HybridAugment that reduces the reliance of CNNs on high-frequency components, and thus improves their robustness while keeping their clean accuracy high. Second, we propose HybridAugment++, which is a hierarchical augmentation method that attempts to unify various frequency-spectrum augmentations. HybridAugment++ builds on HybridAugment, and also reduces the reliance of CNNs on the amplitude component of images, and promotes phase information instead. This unification results in competitive to or better than state-of-the-art results on clean accuracy (CIFAR-10/100 and ImageNet), corruption benchmarks (ImageNet-C, CIFAR-10-C and CIFAR-100-C), adversarial robustness on CIFAR-10 and out-of-distribution detection on various datasets. HybridAugment and HybridAugment++ are implemented in a few lines of code, does not require extra data, ensemble models or additional networks. ",
    "url": "https://arxiv.org/abs/2307.11823",
    "authors": [
      "Mehmet Kerim Yucel",
      "Ramazan Gokberk Cinbis",
      "Pinar Duygulu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.11833",
    "title": "PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural  Networks",
    "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as a promising deep learning framework for approximating numerical solutions for partial differential equations (PDEs). While conventional PINNs and most related studies adopt fully-connected multilayer perceptrons (MLP) as the backbone structure, they have neglected the temporal relations in PDEs and failed to approximate the true solution. In this paper, we propose a novel Transformer-based framework, namely PINNsFormer, that accurately approximates PDEs' solutions by capturing the temporal dependencies with multi-head attention mechanisms in Transformer-based models. Instead of approximating point predictions, PINNsFormer adapts input vectors to pseudo sequences and point-wise PINNs loss to a sequential PINNs loss. In addition, PINNsFormer is equipped with a novel activation function, namely Wavelet, which anticipates the Fourier decomposition through deep neural networks. We empirically demonstrate PINNsFormer's ability to capture the PDE solutions for various scenarios, in which conventional PINNs have failed to learn. We also show that PINNsFormer achieves superior approximation accuracy on such problems than conventional PINNs with non-sensitive hyperparameters, in trade of marginal computational and memory costs, with extensive experiments. ",
    "url": "https://arxiv.org/abs/2307.11833",
    "authors": [
      "Leo Zhiyuan Zhao",
      "Xueying Ding",
      "B. Aditya Prakash"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.11844",
    "title": "Bio-realistic Neural Network Implementation on Loihi 2 with Izhikevich  Neurons",
    "abstract": "In this paper, we presented a bio-realistic basal ganglia neural network and its integration into Intel's Loihi neuromorphic processor to perform simple Go/No-Go task. To incorporate more bio-realistic and diverse set of neuron dynamics, we used Izhikevich neuron model, implemented as microcode, instead of Leaky-Integrate and Fire (LIF) neuron model that has built-in support on Loihi. This work aims to demonstrate the feasibility of implementing computationally efficient custom neuron models on Loihi for building spiking neural networks (SNNs) that features these custom neurons to realize bio-realistic neural networks. ",
    "url": "https://arxiv.org/abs/2307.11844",
    "authors": [
      "Recep Bu\u011fra Uluda\u011f",
      "Serhat \u00c7a\u011fda\u015f",
      "Yavuz Selim \u0130\u015fler",
      "Neslihan Serap \u015eeng\u00f6r",
      "Ismail Akturk"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2307.11848",
    "title": "MythQA: Query-Based Large-Scale Check-Worthy Claim Detection through  Multi-Answer Open-Domain Question Answering",
    "abstract": "Check-worthy claim detection aims at providing plausible misinformation to downstream fact-checking systems or human experts to check. This is a crucial step toward accelerating the fact-checking process. Many efforts have been put into how to identify check-worthy claims from a small scale of pre-collected claims, but how to efficiently detect check-worthy claims directly from a large-scale information source, such as Twitter, remains underexplored. To fill this gap, we introduce MythQA, a new multi-answer open-domain question answering(QA) task that involves contradictory stance mining for query-based large-scale check-worthy claim detection. The idea behind this is that contradictory claims are a strong indicator of misinformation that merits scrutiny by the appropriate authorities. To study this task, we construct TweetMythQA, an evaluation dataset containing 522 factoid multi-answer questions based on controversial topics. Each question is annotated with multiple answers. Moreover, we collect relevant tweets for each distinct answer, then classify them into three categories: \"Supporting\", \"Refuting\", and \"Neutral\". In total, we annotated 5.3K tweets. Contradictory evidence is collected for all answers in the dataset. Finally, we present a baseline system for MythQA and evaluate existing NLP models for each system component using the TweetMythQA dataset. We provide initial benchmarks and identify key challenges for future models to improve upon. Code and data are available at: https://github.com/TonyBY/Myth-QA ",
    "url": "https://arxiv.org/abs/2307.11848",
    "authors": [
      "Yang Bai",
      "Anthony Colas",
      "Daisy Zhe Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2307.11862",
    "title": "Digital Modeling on Large Kernel Metamaterial Neural Network",
    "abstract": "Deep neural networks (DNNs) utilized recently are physically deployed with computational units (e.g., CPUs and GPUs). Such a design might lead to a heavy computational burden, significant latency, and intensive power consumption, which are critical limitations in applications such as the Internet of Things (IoT), edge computing, and the usage of drones. Recent advances in optical computational units (e.g., metamaterial) have shed light on energy-free and light-speed neural networks. However, the digital design of the metamaterial neural network (MNN) is fundamentally limited by its physical limitations, such as precision, noise, and bandwidth during fabrication. Moreover, the unique advantages of MNN's (e.g., light-speed computation) are not fully explored via standard 3x3 convolution kernels. In this paper, we propose a novel large kernel metamaterial neural network (LMNN) that maximizes the digital capacity of the state-of-the-art (SOTA) MNN with model re-parametrization and network compression, while also considering the optical limitation explicitly. The new digital learning scheme can maximize the learning capacity of MNN while modeling the physical restrictions of meta-optic. With the proposed LMNN, the computation cost of the convolutional front-end can be offloaded into fabricated optical hardware. The experimental results on two publicly available datasets demonstrate that the optimized hybrid design improved classification accuracy while reducing computational latency. The development of the proposed LMNN is a promising step towards the ultimate goal of energy-free and light-speed AI. ",
    "url": "https://arxiv.org/abs/2307.11862",
    "authors": [
      "Quan Liu",
      "Hanyu Zheng",
      "Brandon T. Swartz",
      "Ho hin Lee",
      "Zuhayr Asad",
      "Ivan Kravchenko",
      "Jason G. Valentine",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.11864",
    "title": "The Looming Threat of Fake and LLM-generated LinkedIn Profiles:  Challenges and Opportunities for Detection and Prevention",
    "abstract": "In this paper, we present a novel method for detecting fake and Large Language Model (LLM)-generated profiles in the LinkedIn Online Social Network immediately upon registration and before establishing connections. Early fake profile identification is crucial to maintaining the platform's integrity since it prevents imposters from acquiring the private and sensitive information of legitimate users and from gaining an opportunity to increase their credibility for future phishing and scamming activities. This work uses textual information provided in LinkedIn profiles and introduces the Section and Subsection Tag Embedding (SSTE) method to enhance the discriminative characteristics of these data for distinguishing between legitimate profiles and those created by imposters manually or by using an LLM. Additionally, the dearth of a large publicly available LinkedIn dataset motivated us to collect 3600 LinkedIn profiles for our research. We will release our dataset publicly for research purposes. This is, to the best of our knowledge, the first large publicly available LinkedIn dataset for fake LinkedIn account detection. Within our paradigm, we assess static and contextualized word embeddings, including GloVe, Flair, BERT, and RoBERTa. We show that the suggested method can distinguish between legitimate and fake profiles with an accuracy of about 95% across all word embeddings. In addition, we show that SSTE has a promising accuracy for identifying LLM-generated profiles, despite the fact that no LLM-generated profiles were employed during the training phase, and can achieve an accuracy of approximately 90% when only 20 LLM-generated profiles are added to the training set. It is a significant finding since the proliferation of several LLMs in the near future makes it extremely challenging to design a single system that can identify profiles created with various LLMs. ",
    "url": "https://arxiv.org/abs/2307.11864",
    "authors": [
      "Navid Ayoobi",
      "Sadat Shahriar",
      "Arjun Mukherjee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.11876",
    "title": "Safety-Assured Speculative Planning with Adaptive Prediction",
    "abstract": "Recently significant progress has been made in vehicle prediction and planning algorithms for autonomous driving. However, it remains quite challenging for an autonomous vehicle to plan its trajectory in complex scenarios when it is difficult to accurately predict its surrounding vehicles' behaviors and trajectories. In this work, to maximize performance while ensuring safety, we propose a novel speculative planning framework based on a prediction-planning interface that quantifies both the behavior-level and trajectory-level uncertainties of surrounding vehicles. Our framework leverages recent prediction algorithms that can provide one or more possible behaviors and trajectories of the surrounding vehicles with probability estimation. It adapts those predictions based on the latest system states and traffic environment, and conducts planning to maximize the expected reward of the ego vehicle by considering the probabilistic predictions of all scenarios and ensure system safety by ruling out actions that may be unsafe in worst case. We demonstrate the effectiveness of our approach in improving system performance and ensuring system safety over other baseline methods, via extensive simulations in SUMO on a challenging multi-lane highway lane-changing case study. ",
    "url": "https://arxiv.org/abs/2307.11876",
    "authors": [
      "Xiangguo Liu",
      "Ruochen Jiao",
      "Yixuan Wang",
      "Yimin Han",
      "Bowen Zheng",
      "Qi Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.11892",
    "title": "On the Vulnerability of Fairness Constrained Learning to Malicious Noise",
    "abstract": "We consider the vulnerability of fairness-constrained learning to small amounts of malicious noise in the training data. Konstantinov and Lampert (2021) initiated the study of this question and presented negative results showing there exist data distributions where for several fairness constraints, any proper learner will exhibit high vulnerability when group sizes are imbalanced. Here, we present a more optimistic view, showing that if we allow randomized classifiers, then the landscape is much more nuanced. For example, for Demographic Parity we show we can incur only a $\\Theta(\\alpha)$ loss in accuracy, where $\\alpha$ is the malicious noise rate, matching the best possible even without fairness constraints. For Equal Opportunity, we show we can incur an $O(\\sqrt{\\alpha})$ loss, and give a matching $\\Omega(\\sqrt{\\alpha})$lower bound. In contrast, Konstantinov and Lampert (2021) showed for proper learners the loss in accuracy for both notions is $\\Omega(1)$. The key technical novelty of our work is how randomization can bypass simple \"tricks\" an adversary can use to amplify his power. We also consider additional fairness notions including Equalized Odds and Calibration. For these fairness notions, the excess accuracy clusters into three natural regimes $O(\\alpha)$,$O(\\sqrt{\\alpha})$ and $O(1)$. These results provide a more fine-grained view of the sensitivity of fairness-constrained learning to adversarial noise in training data. ",
    "url": "https://arxiv.org/abs/2307.11892",
    "authors": [
      "Avrim Blum",
      "Princewill Okoroafor",
      "Aadirupa Saha",
      "Kevin Stangl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2307.11906",
    "title": "Unveiling Vulnerabilities in Interpretable Deep Learning Systems with  Query-Efficient Black-box Attacks",
    "abstract": "Deep learning has been rapidly employed in many applications revolutionizing many industries, but it is known to be vulnerable to adversarial attacks. Such attacks pose a serious threat to deep learning-based systems compromising their integrity, reliability, and trust. Interpretable Deep Learning Systems (IDLSes) are designed to make the system more transparent and explainable, but they are also shown to be susceptible to attacks. In this work, we propose a novel microbial genetic algorithm-based black-box attack against IDLSes that requires no prior knowledge of the target model and its interpretation model. The proposed attack is a query-efficient approach that combines transfer-based and score-based methods, making it a powerful tool to unveil IDLS vulnerabilities. Our experiments of the attack show high attack success rates using adversarial examples with attribution maps that are highly similar to those of benign samples which makes it difficult to detect even by human analysts. Our results highlight the need for improved IDLS security to ensure their practical reliability. ",
    "url": "https://arxiv.org/abs/2307.11906",
    "authors": [
      "Eldor Abdukhamidov",
      "Mohammed Abuhamad",
      "Simon S. Woo",
      "Eric Chan-Tin",
      "Tamer Abuhmed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.11917",
    "title": "Vulnerability Detection Through an Adversarial Fuzzing Algorithm",
    "abstract": "Fuzzing is a popular vulnerability automated testing method utilized by professionals and broader community alike. However, despite its abilities, fuzzing is a time-consuming, computationally expensive process. This is problematic for the open source community and smaller developers, as most people will not have dedicated security professionals and/or knowledge to perform extensive testing on their own. The goal of this project is to increase the efficiency of existing fuzzers by allowing fuzzers to explore more paths and find more bugs in shorter amounts of time, while still remaining operable on a personal device. To accomplish this, adversarial methods are built on top of current evolutionary algorithms to generate test cases for further and more efficient fuzzing. The results of this show that adversarial attacks do in fact increase outpaces existing fuzzers significantly and, consequently, crashes found. ",
    "url": "https://arxiv.org/abs/2307.11917",
    "authors": [
      "Michael Wang",
      "Michael Robinson"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2307.11921",
    "title": "Poverty rate prediction using multi-modal survey and earth observation  data",
    "abstract": "This work presents an approach for combining household demographic and living standards survey questions with features derived from satellite imagery to predict the poverty rate of a region. Our approach utilizes visual features obtained from a single-step featurization method applied to freely available 10m/px Sentinel-2 surface reflectance satellite imagery. These visual features are combined with ten survey questions in a proxy means test (PMT) to estimate whether a household is below the poverty line. We show that the inclusion of visual features reduces the mean error in poverty rate estimates from 4.09% to 3.88% over a nationally representative out-of-sample test set. In addition to including satellite imagery features in proxy means tests, we propose an approach for selecting a subset of survey questions that are complementary to the visual features extracted from satellite imagery. Specifically, we design a survey variable selection approach guided by the full survey and image features and use the approach to determine the most relevant set of small survey questions to include in a PMT. We validate the choice of small survey questions in a downstream task of predicting the poverty rate using the small set of questions. This approach results in the best performance -- errors in poverty rate decrease from 4.09% to 3.71%. We show that extracted visual features encode geographic and urbanization differences between regions. ",
    "url": "https://arxiv.org/abs/2307.11921",
    "authors": [
      "Simone Fobi",
      "Manuel Cardona",
      "Elliott Collins",
      "Caleb Robinson",
      "Anthony Ortiz",
      "Tina Sederholm",
      "Rahul Dodhia",
      "Juan Lavista Ferres"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.11942",
    "title": "DeepMartNet -- A Martingale based Deep Neural Network learning algorithm  for Eigenvalue Problems in High Dimensions",
    "abstract": "In this paper, we propose a neural network learning algorithm for finding eigenvalue and eigenfunction for elliptic operators in high dimensions using the Martingale property in the stochastic representation for the eigenvalue problem. A loss function based on the Martingale property can be used for efficient optimization by sampling the stochastic processes associated with the elliptic operators. The proposed algorithm can be used for Dirichlet, Neumann, and Robin eigenvalue problems in bounded or unbounded domains. ",
    "url": "https://arxiv.org/abs/2307.11942",
    "authors": [
      "Wei Cai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.11952",
    "title": "Pathology-and-genomics Multimodal Transformer for Survival Outcome  Prediction",
    "abstract": "Survival outcome assessment is challenging and inherently associated with multiple clinical factors (e.g., imaging and genomics biomarkers) in cancer. Enabling multimodal analytics promises to reveal novel predictive patterns of patient outcomes. In this study, we propose a multimodal transformer (PathOmics) integrating pathology and genomics insights into colon-related cancer survival prediction. We emphasize the unsupervised pretraining to capture the intrinsic interaction between tissue microenvironments in gigapixel whole slide images (WSIs) and a wide range of genomics data (e.g., mRNA-sequence, copy number variant, and methylation). After the multimodal knowledge aggregation in pretraining, our task-specific model finetuning could expand the scope of data utility applicable to both multi- and single-modal data (e.g., image- or genomics-only). We evaluate our approach on both TCGA colon and rectum cancer cohorts, showing that the proposed approach is competitive and outperforms state-of-the-art studies. Finally, our approach is desirable to utilize the limited number of finetuned samples towards data-efficient analytics for survival outcome prediction. The code is available at https://github.com/Cassie07/PathOmics. ",
    "url": "https://arxiv.org/abs/2307.11952",
    "authors": [
      "Kexin Ding",
      "Mu Zhou",
      "Dimitris N. Metaxas",
      "Shaoting Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.11967",
    "title": "Nonbossy Mechanisms: Mechanism Design Robust to Secondary Goals",
    "abstract": "We study mechanism design when agents may have hidden secondary goals which will manifest as non-trivial preferences among outcomes for which their primary utility is the same. We show that in such cases, a mechanism is robust against strategic manipulation if and only if it is not only incentive-compatible, but also nonbossy -- a well-studied property in the context of matching and allocation mechanisms. We give complete characterizations of incentive-compatible and nonbossy mechanisms in various settings, including auctions with single-parameter agents and public decision settings where all agents share a common outcome. In particular, we show that in the single-item setting, a mechanism is incentive-compatible, individually rational, and nonbossy if and only if it is a sequential posted-price mechanism. In contrast, we show that in more general single-parameter environments, there exist mechanisms satisfying our characterization that significantly outperform sequential posted-price mechanisms in terms of revenue or efficiency (sometimes by an exponential factor). ",
    "url": "https://arxiv.org/abs/2307.11967",
    "authors": [
      "Renato Paes Leme",
      "Jon Schneider",
      "Hanrui Zhang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2307.11978",
    "title": "Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels?",
    "abstract": "Vision-language models such as CLIP learn a generic text-image embedding from large-scale training data. A vision-language model can be adapted to a new classification task through few-shot prompt tuning. We find that such a prompt tuning process is highly robust to label noises. This intrigues us to study the key reasons contributing to the robustness of the prompt tuning paradigm. We conducted extensive experiments to explore this property and find the key factors are: 1) the fixed classname tokens provide a strong regularization to the optimization of the model, reducing gradients induced by the noisy samples; 2) the powerful pre-trained image-text embedding that is learned from diverse and generic web data provides strong prior knowledge for image classification. Further, we demonstrate that noisy zero-shot predictions from CLIP can be used to tune its own prompt, significantly enhancing prediction accuracy in the unsupervised setting. The code is available at https://github.com/CEWu/PTNL. ",
    "url": "https://arxiv.org/abs/2307.11978",
    "authors": [
      "Cheng-En Wu",
      "Yu Tian",
      "Haichao Yu",
      "Heng Wang",
      "Pedro Morgado",
      "Yu Hen Hu",
      "Linjie Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.11981",
    "title": "Collaborative Graph Neural Networks for Attributed Network Embedding",
    "abstract": "Graph neural networks (GNNs) have shown prominent performance on attributed network embedding. However, existing efforts mainly focus on exploiting network structures, while the exploitation of node attributes is rather limited as they only serve as node features at the initial layer. This simple strategy impedes the potential of node attributes in augmenting node connections, leading to limited receptive field for inactive nodes with few or even no neighbors. Furthermore, the training objectives (i.e., reconstructing network structures) of most GNNs also do not include node attributes, although studies have shown that reconstructing node attributes is beneficial. Thus, it is encouraging to deeply involve node attributes in the key components of GNNs, including graph convolution operations and training objectives. However, this is a nontrivial task since an appropriate way of integration is required to maintain the merits of GNNs. To bridge the gap, in this paper, we propose COllaborative graph Neural Networks--CONN, a tailored GNN architecture for attribute network embedding. It improves model capacity by 1) selectively diffusing messages from neighboring nodes and involved attribute categories, and 2) jointly reconstructing node-to-node and node-to-attribute-category interactions via cross-correlation. Experiments on real-world networks demonstrate that CONN excels state-of-the-art embedding algorithms with a great margin. ",
    "url": "https://arxiv.org/abs/2307.11981",
    "authors": [
      "Qiaoyu Tan",
      "Xin Zhang",
      "Xiao Huang",
      "Hao Chen",
      "Jundong Li",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2307.11986",
    "title": "Expert Knowledge-Aware Image Difference Graph Representation Learning  for Difference-Aware Medical Visual Question Answering",
    "abstract": "To contribute to automating the medical vision-language model, we propose a novel Chest-Xray Difference Visual Question Answering (VQA) task. Given a pair of main and reference images, this task attempts to answer several questions on both diseases and, more importantly, the differences between them. This is consistent with the radiologist's diagnosis practice that compares the current image with the reference before concluding the report. We collect a new dataset, namely MIMIC-Diff-VQA, including 700,703 QA pairs from 164,324 pairs of main and reference images. Compared to existing medical VQA datasets, our questions are tailored to the Assessment-Diagnosis-Intervention-Evaluation treatment procedure used by clinical professionals. Meanwhile, we also propose a novel expert knowledge-aware graph representation learning model to address this task. The proposed baseline model leverages expert knowledge such as anatomical structure prior, semantic, and spatial knowledge to construct a multi-relationship graph, representing the image differences between two images for the image difference VQA task. The dataset and code can be found at https://github.com/Holipori/MIMIC-Diff-VQA. We believe this work would further push forward the medical vision language model. ",
    "url": "https://arxiv.org/abs/2307.11986",
    "authors": [
      "Xinyue Hu",
      "Lin Gu",
      "Qiyuan An",
      "Mengliang Zhang",
      "Liangchen Liu",
      "Kazuma Kobayashi",
      "Tatsuya Harada",
      "Ronald M. Summers",
      "Yingying Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12033",
    "title": "Self-Supervised and Semi-Supervised Polyp Segmentation using Synthetic  Data",
    "abstract": "Early detection of colorectal polyps is of utmost importance for their treatment and for colorectal cancer prevention. Computer vision techniques have the potential to aid professionals in the diagnosis stage, where colonoscopies are manually carried out to examine the entirety of the patient's colon. The main challenge in medical imaging is the lack of data, and a further challenge specific to polyp segmentation approaches is the difficulty of manually labeling the available data: the annotation process for segmentation tasks is very time-consuming. While most recent approaches address the data availability challenge with sophisticated techniques to better exploit the available labeled data, few of them explore the self-supervised or semi-supervised paradigm, where the amount of labeling required is greatly reduced. To address both challenges, we leverage synthetic data and propose an end-to-end model for polyp segmentation that integrates real and synthetic data to artificially increase the size of the datasets and aid the training when unlabeled samples are available. Concretely, our model, Pl-CUT-Seg, transforms synthetic images with an image-to-image translation module and combines the resulting images with real images to train a segmentation model, where we use model predictions as pseudo-labels to better leverage unlabeled samples. Additionally, we propose PL-CUT-Seg+, an improved version of the model that incorporates targeted regularization to address the domain gap between real and synthetic images. The models are evaluated on standard benchmarks for polyp segmentation and reach state-of-the-art results in the self- and semi-supervised setups. ",
    "url": "https://arxiv.org/abs/2307.12033",
    "authors": [
      "Enric Moreu",
      "Eric Arazo",
      "Kevin McGuinness",
      "Noel E. O'Connor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12059",
    "title": "Fast Knowledge Graph Completion using Graphics Processing Units",
    "abstract": "Knowledge graphs can be used in many areas related to data semantics such as question-answering systems, knowledge based systems. However, the currently constructed knowledge graphs need to be complemented for better knowledge in terms of relations. It is called knowledge graph completion. To add new relations to the existing knowledge graph by using knowledge graph embedding models, we have to evaluate $N\\times N \\times R$ vector operations, where $N$ is the number of entities and $R$ is the number of relation types. It is very costly. In this paper, we provide an efficient knowledge graph completion framework on GPUs to get new relations using knowledge graph embedding vectors. In the proposed framework, we first define \"transformable to a metric space\" and then provide a method to transform the knowledge graph completion problem into the similarity join problem for a model which is \"transformable to a metric space\". After that, to efficiently process the similarity join problem, we derive formulas using the properties of a metric space. Based on the formulas, we develop a fast knowledge graph completion algorithm. Finally, we experimentally show that our framework can efficiently process the knowledge graph completion problem. ",
    "url": "https://arxiv.org/abs/2307.12059",
    "authors": [
      "Chun-Hee Lee",
      "Dong-oh Kang",
      "Hwa Jeon Song"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12062",
    "title": "Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled  Perturbations",
    "abstract": "Robust reinforcement learning (RL) seeks to train policies that can perform well under environment perturbations or adversarial attacks. Existing approaches typically assume that the space of possible perturbations remains the same across timesteps. However, in many settings, the space of possible perturbations at a given timestep depends on past perturbations. We formally introduce temporally-coupled perturbations, presenting a novel challenge for existing robust RL methods. To tackle this challenge, we propose GRAD, a novel game-theoretic approach that treats the temporally-coupled robust RL problem as a partially-observable two-player zero-sum game. By finding an approximate equilibrium in this game, GRAD ensures the agent's robustness against temporally-coupled perturbations. Empirical experiments on a variety of continuous control tasks demonstrate that our proposed approach exhibits significant robustness advantages compared to baselines against both standard and temporally-coupled attacks, in both state and action spaces. ",
    "url": "https://arxiv.org/abs/2307.12062",
    "authors": [
      "Yongyuan Liang",
      "Yanchao Sun",
      "Ruijie Zheng",
      "Xiangyu Liu",
      "Tuomas Sandholm",
      "Furong Huang",
      "Stephen McAleer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.12063",
    "title": "Balancing Exploration and Exploitation in Hierarchical Reinforcement  Learning via Latent Landmark Graphs",
    "abstract": "Goal-Conditioned Hierarchical Reinforcement Learning (GCHRL) is a promising paradigm to address the exploration-exploitation dilemma in reinforcement learning. It decomposes the source task into subgoal conditional subtasks and conducts exploration and exploitation in the subgoal space. The effectiveness of GCHRL heavily relies on subgoal representation functions and subgoal selection strategy. However, existing works often overlook the temporal coherence in GCHRL when learning latent subgoal representations and lack an efficient subgoal selection strategy that balances exploration and exploitation. This paper proposes HIerarchical reinforcement learning via dynamically building Latent Landmark graphs (HILL) to overcome these limitations. HILL learns latent subgoal representations that satisfy temporal coherence using a contrastive representation learning objective. Based on these representations, HILL dynamically builds latent landmark graphs and employs a novelty measure on nodes and a utility measure on edges. Finally, HILL develops a subgoal selection strategy that balances exploration and exploitation by jointly considering both measures. Experimental results demonstrate that HILL outperforms state-of-the-art baselines on continuous control tasks with sparse rewards in sample efficiency and asymptotic performance. Our code is available at https://github.com/papercode2022/HILL. ",
    "url": "https://arxiv.org/abs/2307.12063",
    "authors": [
      "Qingyang Zhang",
      "Yiming Yang",
      "Jingqing Ruan",
      "Xuantang Xiong",
      "Dengpeng Xing",
      "Bo Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12065",
    "title": "Spectral Normalized-Cut Graph Partitioning with Fairness Constraints",
    "abstract": "Normalized-cut graph partitioning aims to divide the set of nodes in a graph into $k$ disjoint clusters to minimize the fraction of the total edges between any cluster and all other clusters. In this paper, we consider a fair variant of the partitioning problem wherein nodes are characterized by a categorical sensitive attribute (e.g., gender or race) indicating membership to different demographic groups. Our goal is to ensure that each group is approximately proportionally represented in each cluster while minimizing the normalized cut value. To resolve this problem, we propose a two-phase spectral algorithm called FNM. In the first phase, we add an augmented Lagrangian term based on our fairness criteria to the objective function for obtaining a fairer spectral node embedding. Then, in the second phase, we design a rounding scheme to produce $k$ clusters from the fair embedding that effectively trades off fairness and partition quality. Through comprehensive experiments on nine benchmark datasets, we demonstrate the superior performance of FNM compared with three baseline methods. ",
    "url": "https://arxiv.org/abs/2307.12065",
    "authors": [
      "Jia Li",
      "Yanhao Wang",
      "Arpit Merchant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2307.12078",
    "title": "Recovery of Localization Errors in Sensor Networks using Inter-Agent  Measurements",
    "abstract": "A practical challenge which arises in the operation of sensor networks is the presence of sensor faults, biases, or adversarial attacks, which can lead to significant errors incurring in the localization of the agents, thereby undermining the security and performance of the network. We consider the problem of identifying and correcting the localization errors using inter-agent measurements, such as the distances or bearings from one agent to another, which can serve as a redundant source of information about the sensor network's configuration. The problem is solved by searching for a block sparse solution to an underdetermined system of equations, where the sparsity is introduced via the fact that the number of localization errors is typically much lesser than the total number of agents. Unlike the existing works, our proposed method does not require the knowledge of the identities of the anchors, i.e., the agents that do not have localization errors. We characterize the necessary and sufficient conditions on the sensor network configuration under which a given number of localization errors can be uniquely identified and corrected using the proposed method. The applicability of our results is demonstrated numerically by processing inter-agent distance measurements using a sequential convex programming (SCP) algorithm to identify the localization errors in a sensor network. ",
    "url": "https://arxiv.org/abs/2307.12078",
    "authors": [
      "Shiraz Khan",
      "Inseok Hwang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.12082",
    "title": "A Quantitative Analysis of Open Source Software Code Quality: Insights  from Metric Distributions",
    "abstract": "Code quality is a crucial construct in open-source software (OSS) with three dimensions: maintainability, reliability, and functionality. To accurately measure them, we divide 20 distinct metrics into two types: 1) threshold-type metrics that influence code quality in a monotonic manner; 2) non-threshold-type metrics that lack a monotonic relationship to evaluate. We propose a distribution-based method to provide scores for metrics, which demonstrates great explainability on OSS adoption. Our empirical analysis includes more than 36,460 OSS projects and their raw metrics from SonarQube and CK. Our work contributes to the understanding of the multi-dimensional construct of code quality and its metric measurements. ",
    "url": "https://arxiv.org/abs/2307.12082",
    "authors": [
      "Siyuan Jin",
      "Mianmian Zhang",
      "Yekai Guo",
      "Yuejiang He",
      "Ziyuan Li",
      "Bichao Chen",
      "Bing Zhu",
      "Yong Xia"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2307.12101",
    "title": "Spatial Self-Distillation for Object Detection with Inaccurate Bounding  Boxes",
    "abstract": "Object detection via inaccurate bounding boxes supervision has boosted a broad interest due to the expensive high-quality annotation data or the occasional inevitability of low annotation quality (\\eg tiny objects). The previous works usually utilize multiple instance learning (MIL), which highly depends on category information, to select and refine a low-quality box. Those methods suffer from object drift, group prediction and part domination problems without exploring spatial information. In this paper, we heuristically propose a \\textbf{Spatial Self-Distillation based Object Detector (SSD-Det)} to mine spatial information to refine the inaccurate box in a self-distillation fashion. SSD-Det utilizes a Spatial Position Self-Distillation \\textbf{(SPSD)} module to exploit spatial information and an interactive structure to combine spatial information and category information, thus constructing a high-quality proposal bag. To further improve the selection procedure, a Spatial Identity Self-Distillation \\textbf{(SISD)} module is introduced in SSD-Det to obtain spatial confidence to help select the best proposals. Experiments on MS-COCO and VOC datasets with noisy box annotation verify our method's effectiveness and achieve state-of-the-art performance. The code is available at https://github.com/ucas-vg/PointTinyBenchmark/tree/SSD-Det. ",
    "url": "https://arxiv.org/abs/2307.12101",
    "authors": [
      "Di Wu",
      "Pengfei Chen",
      "Xuehui Yu",
      "Guorong Li",
      "Zhenjun Han",
      "Jianbin Jiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12122",
    "title": "Synthesis of Batik Motifs using a Diffusion -- Generative Adversarial  Network",
    "abstract": "Batik, a unique blend of art and craftsmanship, is a distinct artistic and technological creation for Indonesian society. Research on batik motifs is primarily focused on classification. However, further studies may extend to the synthesis of batik patterns. Generative Adversarial Networks (GANs) have been an important deep learning model for generating synthetic data, but often face challenges in the stability and consistency of results. This research focuses on the use of StyleGAN2-Ada and Diffusion techniques to produce realistic and high-quality synthetic batik patterns. StyleGAN2-Ada is a variation of the GAN model that separates the style and content aspects in an image, whereas diffusion techniques introduce random noise into the data. In the context of batik, StyleGAN2-Ada and Diffusion are used to produce realistic synthetic batik patterns. This study also made adjustments to the model architecture and used a well-curated batik dataset. The main goal is to assist batik designers or craftsmen in producing unique and quality batik motifs with efficient production time and costs. Based on qualitative and quantitative evaluations, the results show that the model tested is capable of producing authentic and quality batik patterns, with finer details and rich artistic variations. The dataset and code can be accessed here:https://github.com/octadion/diffusion-stylegan2-ada-pytorch ",
    "url": "https://arxiv.org/abs/2307.12122",
    "authors": [
      "One Octadion",
      "Novanto Yudistira",
      "Diva Kurnianingtyas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.12128",
    "title": "AI on the Road: A Comprehensive Analysis of Traffic Accidents and  Accident Detection System in Smart Cities",
    "abstract": "Accident detection and traffic analysis is a critical component of smart city and autonomous transportation systems that can reduce accident frequency, severity and improve overall traffic management. This paper presents a comprehensive analysis of traffic accidents in different regions across the United States using data from the National Highway Traffic Safety Administration (NHTSA) Crash Report Sampling System (CRSS). To address the challenges of accident detection and traffic analysis, this paper proposes a framework that uses traffic surveillance cameras and action recognition systems to detect and respond to traffic accidents spontaneously. Integrating the proposed framework with emergency services will harness the power of traffic cameras and machine learning algorithms to create an efficient solution for responding to traffic accidents and reducing human errors. Advanced intelligence technologies, such as the proposed accident detection systems in smart cities, will improve traffic management and traffic accident severity. Overall, this study provides valuable insights into traffic accidents in the US and presents a practical solution to enhance the safety and efficiency of transportation systems. ",
    "url": "https://arxiv.org/abs/2307.12128",
    "authors": [
      "Victor Adewopo",
      "Nelly Elsayed",
      "Zag Elsayed",
      "Murat Ozer",
      "Victoria Wangia-Anderson",
      "Ahmed Abdelgawad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12130",
    "title": "Improving temperature estimation in low-cost infrared cameras using deep  neural networks",
    "abstract": "Low-cost thermal cameras are inaccurate (usually $\\pm 3^\\circ C$) and have space-variant nonuniformity across their detector. Both inaccuracy and nonuniformity are dependent on the ambient temperature of the camera. The main goal of this work was to improve the temperature accuracy of low-cost cameras and rectify the nonuniformity. A nonuniformity simulator that accounts for the ambient temperature was developed. An end-to-end neural network that incorporates the ambient temperature at image acquisition was introduced. The neural network was trained with the simulated nonuniformity data to estimate the object's temperature and correct the nonuniformity, using only a single image and the ambient temperature measured by the camera itself. Results show that the proposed method lowered the mean temperature error by approximately $1^\\circ C$ compared to previous works. In addition, applying a physical constraint on the network lowered the error by an additional $4\\%$. The mean temperature error over an extensive validation dataset was $0.37^\\circ C$. The method was verified on real data in the field and produced equivalent results. ",
    "url": "https://arxiv.org/abs/2307.12130",
    "authors": [
      "Navot Oz",
      "Nir Sochen",
      "David Mendelovich",
      "Iftach Klapp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.12131",
    "title": "Explainable Topic-Enhanced Argument Mining from Heterogeneous Sources",
    "abstract": "Given a controversial target such as ``nuclear energy'', argument mining aims to identify the argumentative text from heterogeneous sources. Current approaches focus on exploring better ways of integrating the target-associated semantic information with the argumentative text. Despite their empirical successes, two issues remain unsolved: (i) a target is represented by a word or a phrase, which is insufficient to cover a diverse set of target-related subtopics; (ii) the sentence-level topic information within an argument, which we believe is crucial for argument mining, is ignored. To tackle the above issues, we propose a novel explainable topic-enhanced argument mining approach. Specifically, with the use of the neural topic model and the language model, the target information is augmented by explainable topic representations. Moreover, the sentence-level topic information within the argument is captured by minimizing the distance between its latent topic distribution and its semantic representation through mutual learning. Experiments have been conducted on the benchmark dataset in both the in-target setting and the cross-target setting. Results demonstrate the superiority of the proposed model against the state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2307.12131",
    "authors": [
      "Jiasheng Si",
      "Yingjie Zhu",
      "Xingyu Shi",
      "Deyu Zhou",
      "Yulan He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.12134",
    "title": "Modality Confidence Aware Training for Robust End-to-End Spoken Language  Understanding",
    "abstract": "End-to-end (E2E) spoken language understanding (SLU) systems that generate a semantic parse from speech have become more promising recently. This approach uses a single model that utilizes audio and text representations from pre-trained speech recognition models (ASR), and outperforms traditional pipeline SLU systems in on-device streaming scenarios. However, E2E SLU systems still show weakness when text representation quality is low due to ASR transcription errors. To overcome this issue, we propose a novel E2E SLU system that enhances robustness to ASR errors by fusing audio and text representations based on the estimated modality confidence of ASR hypotheses. We introduce two novel techniques: 1) an effective method to encode the quality of ASR hypotheses and 2) an effective approach to integrate them into E2E SLU models. We show accuracy improvements on STOP dataset and share the analysis to demonstrate the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2307.12134",
    "authors": [
      "Suyoun Kim",
      "Akshat Shrivastava",
      "Duc Le",
      "Ju Lin",
      "Ozlem Kalinli",
      "Michael L. Seltzer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.12146",
    "title": "CloudScent: a model for code smell analysis in open-source cloud",
    "abstract": "The low cost and rapid provisioning capabilities have made open-source cloud a desirable platform to launch industrial applications. However, as open-source cloud moves towards maturity, it still suffers from quality issues like code smells. Although, a great emphasis has been provided on the economic benefits of deploying open-source cloud, low importance has been provided to improve the quality of the source code of the cloud itself to ensure its maintainability in the industrial scenario. Code refactoring has been associated with improving the maintenance and understanding of software code by removing code smells. However, analyzing what smells are more prevalent in cloud environment and designing a tool to define and detect those smells require further attention. In this paper, we propose a model called CloudScent which is an open source mechanism to detect smells in open-source cloud. We test our experiments in a real-life cloud environment using OpenStack. Results show that CloudScent is capable of accurately detecting 8 code smells in cloud. This will permit cloud service providers with advanced knowledge about the smells prevalent in open-source cloud platform, thus allowing for timely code refactoring and improving code quality of the cloud platforms. ",
    "url": "https://arxiv.org/abs/2307.12146",
    "authors": [
      "Raj Narendra Shah",
      "Sameer Ahmed Mohamed",
      "Asif Imran",
      "Tevfik Kosar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2307.12149",
    "title": "CorrFL: Correlation-Based Neural Network Architecture for Unavailability  Concerns in a Heterogeneous IoT Environment",
    "abstract": "The Federated Learning (FL) paradigm faces several challenges that limit its application in real-world environments. These challenges include the local models' architecture heterogeneity and the unavailability of distributed Internet of Things (IoT) nodes due to connectivity problems. These factors posit the question of \"how can the available models fill the training gap of the unavailable models?\". This question is referred to as the \"Oblique Federated Learning\" problem. This problem is encountered in the studied environment that includes distributed IoT nodes responsible for predicting CO2 concentrations. This paper proposes the Correlation-based FL (CorrFL) approach influenced by the representational learning field to address this problem. CorrFL projects the various model weights to a common latent space to address the model heterogeneity. Its loss function minimizes the reconstruction loss when models are absent and maximizes the correlation between the generated models. The latter factor is critical because of the intersection of the feature spaces of the IoT devices. CorrFL is evaluated on a realistic use case, involving the unavailability of one IoT device and heightened activity levels that reflect occupancy. The generated CorrFL models for the unavailable IoT device from the available ones trained on the new environment are compared against models trained on different use cases, referred to as the benchmark model. The evaluation criteria combine the mean absolute error (MAE) of predictions and the impact of the amount of exchanged data on the prediction performance improvement. Through a comprehensive experimental procedure, the CorrFL model outperformed the benchmark model in every criterion. ",
    "url": "https://arxiv.org/abs/2307.12149",
    "authors": [
      "Ibrahim Shaer",
      "Abdallah Shami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.12150",
    "title": "Does color modalities affect handwriting recognition? An empirical study  on Persian handwritings using convolutional neural networks",
    "abstract": "Most of the methods on handwritten recognition in the literature are focused and evaluated on Black and White (BW) image databases. In this paper we try to answer a fundamental question in document recognition. Using Convolutional Neural Networks (CNNs), as eye simulator, we investigate to see whether color modalities of handwritten digits and words affect their recognition accuracy or speed? To the best of our knowledge, so far this question has not been answered due to the lack of handwritten databases that have all three color modalities of handwritings. To answer this question, we selected 13,330 isolated digits and 62,500 words from a novel Persian handwritten database, which have three different color modalities and are unique in term of size and variety. Our selected datasets are divided into training, validation, and testing sets. Afterwards, similar conventional CNN models are trained with the training samples. While the experimental results on the testing set show that CNN on the BW digit and word images has a higher performance compared to the other two color modalities, in general there are no significant differences for network accuracy in different color modalities. Also, comparisons of training times in three color modalities show that recognition of handwritten digits and words in BW images using CNN is much more efficient. ",
    "url": "https://arxiv.org/abs/2307.12150",
    "authors": [
      "Abbas Zohrevand",
      "Zahra Imani",
      "Javad Sadri",
      "Ching Y.Suen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12152",
    "title": "Real-Time Neural Video Recovery and Enhancement on Mobile Devices",
    "abstract": "As mobile devices become increasingly popular for video streaming, it's crucial to optimize the streaming experience for these devices. Although deep learning-based video enhancement techniques are gaining attention, most of them cannot support real-time enhancement on mobile devices. Additionally, many of these techniques are focused solely on super-resolution and cannot handle partial or complete loss or corruption of video frames, which is common on the Internet and wireless networks. To overcome these challenges, we present a novel approach in this paper. Our approach consists of (i) a novel video frame recovery scheme, (ii) a new super-resolution algorithm, and (iii) a receiver enhancement-aware video bit rate adaptation algorithm. We have implemented our approach on an iPhone 12, and it can support 30 frames per second (FPS). We have evaluated our approach in various networks such as WiFi, 3G, 4G, and 5G networks. Our evaluation shows that our approach enables real-time enhancement and results in a significant increase in video QoE (Quality of Experience) of 24\\% - 82\\% in our video streaming system. ",
    "url": "https://arxiv.org/abs/2307.12152",
    "authors": [
      "Zhaoyuan He",
      "Yifan Yang",
      "Lili Qiu",
      "Kyoungjun Park"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2307.12159",
    "title": "Facial Point Graphs for Amyotrophic Lateral Sclerosis Identification",
    "abstract": "Identifying Amyotrophic Lateral Sclerosis (ALS) in its early stages is essential for establishing the beginning of treatment, enriching the outlook, and enhancing the overall well-being of those affected individuals. However, early diagnosis and detecting the disease's signs is not straightforward. A simpler and cheaper way arises by analyzing the patient's facial expressions through computational methods. When a patient with ALS engages in specific actions, e.g., opening their mouth, the movement of specific facial muscles differs from that observed in a healthy individual. This paper proposes Facial Point Graphs to learn information from the geometry of facial images to identify ALS automatically. The experimental outcomes in the Toronto Neuroface dataset show the proposed approach outperformed state-of-the-art results, fostering promising developments in the area. ",
    "url": "https://arxiv.org/abs/2307.12159",
    "authors": [
      "N\u00edcolas Barbosa Gomes",
      "Arissa Yoshida",
      "Mateus Roder",
      "Guilherme Camargo de Oliveira",
      "Jo\u00e3o Paulo Papa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12168",
    "title": "Hallucination Improves the Performance of Unsupervised Visual  Representation Learning",
    "abstract": "Contrastive learning models based on Siamese structure have demonstrated remarkable performance in self-supervised learning. Such a success of contrastive learning relies on two conditions, a sufficient number of positive pairs and adequate variations between them. If the conditions are not met, these frameworks will lack semantic contrast and be fragile on overfitting. To address these two issues, we propose Hallucinator that could efficiently generate additional positive samples for further contrast. The Hallucinator is differentiable and creates new data in the feature space. Thus, it is optimized directly with the pre-training task and introduces nearly negligible computation. Moreover, we reduce the mutual information of hallucinated pairs and smooth them through non-linear operations. This process helps avoid over-confident contrastive learning models during the training and achieves more transformation-invariant feature embeddings. Remarkably, we empirically prove that the proposed Hallucinator generalizes well to various contrastive learning models, including MoCoV1&V2, SimCLR and SimSiam. Under the linear classification protocol, a stable accuracy gain is achieved, ranging from 0.3% to 3.0% on CIFAR10&100, Tiny ImageNet, STL-10 and ImageNet. The improvement is also observed in transferring pre-train encoders to the downstream tasks, including object detection and segmentation. ",
    "url": "https://arxiv.org/abs/2307.12168",
    "authors": [
      "Jing Wu",
      "Jennifer Hobbs",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.12169",
    "title": "Optimized Network Architectures for Large Language Model Training with  Billions of Parameters",
    "abstract": "This paper challenges the well-established paradigm for building any-to-any networks for training Large Language Models (LLMs). We show that LLMs exhibit a unique communication pattern where only small groups of GPUs require high-bandwidth any-to-any communication within them, to achieve near-optimal training performance. Across these groups of GPUs, the communication is insignificant, sparse, and homogeneous. We propose a new network architecture that closely resembles the communication requirement of LLMs. Our architecture partitions the cluster into sets of GPUs interconnected with non-blocking any-to-any high-bandwidth interconnects that we call HB domains. Across the HB domains, the network only connects GPUs with communication demands. We call this network a \"rail-only\" connection, and show that our proposed architecture reduces the network cost by up to 75% compared to the state-of-the-art any-to-any Clos networks without compromising the performance of LLM training. ",
    "url": "https://arxiv.org/abs/2307.12169",
    "authors": [
      "Weiyang Wang",
      "Manya Ghobadi",
      "Kayvon Shakeri",
      "Ying Zhang",
      "Naader Hasani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12173",
    "title": "Named Entity Resolution in Personal Knowledge Graphs",
    "abstract": "Entity Resolution (ER) is the problem of determining when two entities refer to the same underlying entity. The problem has been studied for over 50 years, and most recently, has taken on new importance in an era of large, heterogeneous 'knowledge graphs' published on the Web and used widely in domains as wide ranging as social media, e-commerce and search. This chapter will discuss the specific problem of named ER in the context of personal knowledge graphs (PKGs). We begin with a formal definition of the problem, and the components necessary for doing high-quality and efficient ER. We also discuss some challenges that are expected to arise for Web-scale data. Next, we provide a brief literature review, with a special focus on how existing techniques can potentially apply to PKGs. We conclude the chapter by covering some applications, as well as promising directions for future research. ",
    "url": "https://arxiv.org/abs/2307.12173",
    "authors": [
      "Mayank Kejriwal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2307.12179",
    "title": "Leveraging Knowledge Graphs for Zero-Shot Object-agnostic State  Classification",
    "abstract": "We investigate the problem of Object State Classification (OSC) as a zero-shot learning problem. Specifically, we propose the first Object-agnostic State Classification (OaSC) method that infers the state of a certain object without relying on the knowledge or the estimation of the object class. In that direction, we capitalize on Knowledge Graphs (KGs) for structuring and organizing knowledge, which, in combination with visual information, enable the inference of the states of objects in object/state pairs that have not been encountered in the method's training set. A series of experiments investigate the performance of the proposed method in various settings, against several hypotheses and in comparison with state of the art approaches for object attribute classification. The experimental results demonstrate that the knowledge of an object class is not decisive for the prediction of its state. Moreover, the proposed OaSC method outperforms existing methods in all datasets and benchmarks by a great margin. ",
    "url": "https://arxiv.org/abs/2307.12179",
    "authors": [
      "Filipos Gouidis",
      "Theodore Patkos",
      "Antonis Argyros",
      "Dimitris Plexousakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12181",
    "title": "Security and Privacy Issues of Federated Learning",
    "abstract": "Federated Learning (FL) has emerged as a promising approach to address data privacy and confidentiality concerns by allowing multiple participants to construct a shared model without centralizing sensitive data. However, this decentralized paradigm introduces new security challenges, necessitating a comprehensive identification and classification of potential risks to ensure FL's security guarantees. This paper presents a comprehensive taxonomy of security and privacy challenges in Federated Learning (FL) across various machine learning models, including large language models. We specifically categorize attacks performed by the aggregator and participants, focusing on poisoning attacks, backdoor attacks, membership inference attacks, generative adversarial network (GAN) based attacks, and differential privacy attacks. Additionally, we propose new directions for future research, seeking innovative solutions to fortify FL systems against emerging security risks and uphold sensitive data confidentiality in distributed learning environments. ",
    "url": "https://arxiv.org/abs/2307.12181",
    "authors": [
      "Jahid Hasan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.12183",
    "title": "An X3D Neural Network Analysis for Runner's Performance Assessment in a  Wild Sporting Environment",
    "abstract": "We present a transfer learning analysis on a sporting environment of the expanded 3D (X3D) neural networks. Inspired by action quality assessment methods in the literature, our method uses an action recognition network to estimate athletes' cumulative race time (CRT) during an ultra-distance competition. We evaluate the performance considering the X3D, a family of action recognition networks that expand a small 2D image classification architecture along multiple network axes, including space, time, width, and depth. We demonstrate that the resulting neural network can provide remarkable performance for short input footage, with a mean absolute error of 12 minutes and a half when estimating the CRT for runners who have been active from 8 to 20 hours. Our most significant discovery is that X3D achieves state-of-the-art performance while requiring almost seven times less memory to achieve better precision than previous work. ",
    "url": "https://arxiv.org/abs/2307.12183",
    "authors": [
      "David Freire-Obreg\u00f3n",
      "Javier Lorenzo-Navarro",
      "Oliverio J. Santana",
      "Daniel Hern\u00e1ndez-Sosa",
      "Modesto Castrill\u00f3n-Santana"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12198",
    "title": "NCART: Neural Classification and Regression Tree for Tabular Data",
    "abstract": "Deep learning models have become popular in the analysis of tabular data, as they address the limitations of decision trees and enable valuable applications like semi-supervised learning, online learning, and transfer learning. However, these deep-learning approaches often encounter a trade-off. On one hand, they can be computationally expensive when dealing with large-scale or high-dimensional datasets. On the other hand, they may lack interpretability and may not be suitable for small-scale datasets. In this study, we propose a novel interpretable neural network called Neural Classification and Regression Tree (NCART) to overcome these challenges. NCART is a modified version of Residual Networks that replaces fully-connected layers with multiple differentiable oblivious decision trees. By integrating decision trees into the architecture, NCART maintains its interpretability while benefiting from the end-to-end capabilities of neural networks. The simplicity of the NCART architecture makes it well-suited for datasets of varying sizes and reduces computational costs compared to state-of-the-art deep learning models. Extensive numerical experiments demonstrate the superior performance of NCART compared to existing deep learning models, establishing it as a strong competitor to tree-based models. ",
    "url": "https://arxiv.org/abs/2307.12198",
    "authors": [
      "Jiaqi Luo",
      "Shixin Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12204",
    "title": "Adversarial Agents For Attacking Inaudible Voice Activated Devices",
    "abstract": "Our analysis of inaudible attacks on voice-activated devices confirms the alarming risk factor of 7.6 out of 10, underlining significant security vulnerabilities scored independently by NIST National Vulnerability Database (NVD). Our baseline network model showcases a scenario in which an attacker uses inaudible voice commands to gain unauthorized access to confidential information on a secured laptop. We simulated many attack scenarios on this baseline network model, revealing the potential for mass exploitation of interconnected devices to discover and own privileged information through physical access without adding new hardware or amplifying device skills. Using Microsoft's CyberBattleSim framework, we evaluated six reinforcement learning algorithms and found that Deep-Q learning with exploitation proved optimal, leading to rapid ownership of all nodes in fewer steps. Our findings underscore the critical need for understanding non-conventional networks and new cybersecurity measures in an ever-expanding digital landscape, particularly those characterized by mobile devices, voice activation, and non-linear microphones susceptible to malicious actors operating stealth attacks in the near-ultrasound or inaudible ranges. By 2024, this new attack surface might encompass more digital voice assistants than people on the planet yet offer fewer remedies than conventional patching or firmware fixes since the inaudible attacks arise inherently from the microphone design and digital signal processing. ",
    "url": "https://arxiv.org/abs/2307.12204",
    "authors": [
      "Forrest McKee",
      "David Noever"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.12219",
    "title": "Improving Out-of-Distribution Robustness of Classifiers via Generative  Interpolation",
    "abstract": "Deep neural networks achieve superior performance for learning from independent and identically distributed (i.i.d.) data. However, their performance deteriorates significantly when handling out-of-distribution (OoD) data, where the training and test are drawn from different distributions. In this paper, we explore utilizing the generative models as a data augmentation source for improving out-of-distribution robustness of neural classifiers. Specifically, we develop a simple yet effective method called Generative Interpolation to fuse generative models trained from multiple domains for synthesizing diverse OoD samples. Training a generative model directly on the source domains tends to suffer from mode collapse and sometimes amplifies the data bias. Instead, we first train a StyleGAN model on one source domain and then fine-tune it on the other domains, resulting in many correlated generators where their model parameters have the same initialization thus are aligned. We then linearly interpolate the model parameters of the generators to spawn new sets of generators. Such interpolated generators are used as an extra data augmentation source to train the classifiers. The interpolation coefficients can flexibly control the augmentation direction and strength. In addition, a style-mixing mechanism is applied to further improve the diversity of the generated OoD samples. Our experiments show that the proposed method explicitly increases the diversity of training domains and achieves consistent improvements over baselines across datasets and multiple different distribution shifts. ",
    "url": "https://arxiv.org/abs/2307.12219",
    "authors": [
      "Haoyue Bai",
      "Ceyuan Yang",
      "Yinghao Xu",
      "S.-H. Gary Chan",
      "Bolei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12221",
    "title": "FATRER: Full-Attention Topic Regularizer for Accurate and Robust  Conversational Emotion Recognition",
    "abstract": "This paper concentrates on the understanding of interlocutors' emotions evoked in conversational utterances. Previous studies in this literature mainly focus on more accurate emotional predictions, while ignoring model robustness when the local context is corrupted by adversarial attacks. To maintain robustness while ensuring accuracy, we propose an emotion recognizer augmented by a full-attention topic regularizer, which enables an emotion-related global view when modeling the local context in a conversation. A joint topic modeling strategy is introduced to implement regularization from both representation and loss perspectives. To avoid over-regularization, we drop the constraints on prior distributions that exist in traditional topic modeling and perform probabilistic approximations based entirely on attention alignment. Experiments show that our models obtain more favorable results than state-of-the-art models, and gain convincing robustness under three types of adversarial attacks. ",
    "url": "https://arxiv.org/abs/2307.12221",
    "authors": [
      "Yuzhao Mao",
      "Di Lu",
      "Xiaojie Wang",
      "Yang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.12229",
    "title": "EchoGLAD: Hierarchical Graph Neural Networks for Left Ventricle Landmark  Detection on Echocardiograms",
    "abstract": "The functional assessment of the left ventricle chamber of the heart requires detecting four landmark locations and measuring the internal dimension of the left ventricle and the approximate mass of the surrounding muscle. The key challenge of automating this task with machine learning is the sparsity of clinical labels, i.e., only a few landmark pixels in a high-dimensional image are annotated, leading many prior works to heavily rely on isotropic label smoothing. However, such a label smoothing strategy ignores the anatomical information of the image and induces some bias. To address this challenge, we introduce an echocardiogram-based, hierarchical graph neural network (GNN) for left ventricle landmark detection (EchoGLAD). Our main contributions are: 1) a hierarchical graph representation learning framework for multi-resolution landmark detection via GNNs; 2) induced hierarchical supervision at different levels of granularity using a multi-level loss. We evaluate our model on a public and a private dataset under the in-distribution (ID) and out-of-distribution (OOD) settings. For the ID setting, we achieve the state-of-the-art mean absolute errors (MAEs) of 1.46 mm and 1.86 mm on the two datasets. Our model also shows better OOD generalization than prior works with a testing MAE of 4.3 mm. ",
    "url": "https://arxiv.org/abs/2307.12229",
    "authors": [
      "Masoud Mokhtari",
      "Mobina Mahdavi",
      "Hooman Vaseli",
      "Christina Luong",
      "Purang Abolmaesumi",
      "Teresa S. M. Tsang",
      "Renjie Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12231",
    "title": "Exploring the Integration of Speech Separation and Recognition with  Self-Supervised Learning Representation",
    "abstract": "Neural speech separation has made remarkable progress and its integration with automatic speech recognition (ASR) is an important direction towards realizing multi-speaker ASR. This work provides an insightful investigation of speech separation in reverberant and noisy-reverberant scenarios as an ASR front-end. In detail, we explore multi-channel separation methods, mask-based beamforming and complex spectral mapping, as well as the best features to use in the ASR back-end model. We employ the recent self-supervised learning representation (SSLR) as a feature and improve the recognition performance from the case with filterbank features. To further improve multi-speaker recognition performance, we present a carefully designed training strategy for integrating speech separation and recognition with SSLR. The proposed integration using TF-GridNet-based complex spectral mapping and WavLM-based SSLR achieves a 2.5% word error rate in reverberant WHAMR! test set, significantly outperforming an existing mask-based MVDR beamforming and filterbank integration (28.9%). ",
    "url": "https://arxiv.org/abs/2307.12231",
    "authors": [
      "Yoshiki Masuyama",
      "Xuankai Chang",
      "Wangyou Zhang",
      "Samuele Cornell",
      "Zhong-Qiu Wang",
      "Nobutaka Ono",
      "Yanmin Qian",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.12233",
    "title": "Adaptive Consensus-based Regulation of Open-Channel Networks",
    "abstract": "This paper deals with water management over open-channel networks subject to water height imbalance. Specifically, it is devised a fully distributed adaptive consensus-based algorithm within the discrete-time domain capable of (i) providing a suitable tracking reference that stabilizes the water increments over the underlying network at a common level; (ii) coping with general flow constraints related to each channel of the considered system. This iterative procedure is derived by solving a guidance problem that guarantees to steer the regulated network - represented as a closed-loop system - while satisfying requirements (i) and (ii), provided that a suitable design for the local feedback law controlling each channel flow is already available. The proposed solution converges exponentially fast towards the average consensus without violating the imposed constraints over time. In addition, numerical results are reported to support the theoretical findings, and the performance of the developed algorithm is discussed in the context of a realistic scenario. ",
    "url": "https://arxiv.org/abs/2307.12233",
    "authors": [
      "Marco Fabris",
      "Marco D. Bellinazzi",
      "Andrea Furlanetto",
      "Angelo Cenedese"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.12237",
    "title": "Demonstration of a Response Time Based Remaining Useful Life (RUL)  Prediction for Software Systems",
    "abstract": "Prognostic and Health Management (PHM) has been widely applied to hardware systems in the electronics and non-electronics domains but has not been explored for software. While software does not decay over time, it can degrade over release cycles. Software health management is confined to diagnostic assessments that identify problems, whereas prognostic assessment potentially indicates when in the future a problem will become detrimental. Relevant research areas such as software defect prediction, software reliability prediction, predictive maintenance of software, software degradation, and software performance prediction, exist, but all of these represent diagnostic models built upon historical data, none of which can predict an RUL for software. This paper addresses the application of PHM concepts to software systems for fault predictions and RUL estimation. Specifically, this paper addresses how PHM can be used to make decisions for software systems such as version update and upgrade, module changes, system reengineering, rejuvenation, maintenance scheduling, budgeting, and total abandonment. This paper presents a method to prognostically and continuously predict the RUL of a software system based on usage parameters (e.g., the numbers and categories of releases) and performance parameters (e.g., response time). The model developed has been validated by comparing actual data, with the results that were generated by predictive models. Statistical validation (regression validation, and k-fold cross validation) has also been carried out. A case study, based on publicly available data for the Bugzilla application is presented. This case study demonstrates that PHM concepts can be applied to software systems and RUL can be calculated to make system management decisions. ",
    "url": "https://arxiv.org/abs/2307.12237",
    "authors": [
      "Ray Islam",
      "Peter Sandborn"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2307.12239",
    "title": "DQ-Det: Learning Dynamic Query Combinations for Transformer-based Object  Detection and Segmentation",
    "abstract": "Transformer-based detection and segmentation methods use a list of learned detection queries to retrieve information from the transformer network and learn to predict the location and category of one specific object from each query. We empirically find that random convex combinations of the learned queries are still good for the corresponding models. We then propose to learn a convex combination with dynamic coefficients based on the high-level semantics of the image. The generated dynamic queries, named modulated queries, better capture the prior of object locations and categories in the different images. Equipped with our modulated queries, a wide range of DETR-based models achieve consistent and superior performance across multiple tasks including object detection, instance segmentation, panoptic segmentation, and video instance segmentation. ",
    "url": "https://arxiv.org/abs/2307.12239",
    "authors": [
      "Yiming Cui",
      "Linjie Yang",
      "Haichao Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12241",
    "title": "Explainable Depression Detection via Head Motion Patterns",
    "abstract": "While depression has been studied via multimodal non-verbal behavioural cues, head motion behaviour has not received much attention as a biomarker. This study demonstrates the utility of fundamental head-motion units, termed \\emph{kinemes}, for depression detection by adopting two distinct approaches, and employing distinctive features: (a) discovering kinemes from head motion data corresponding to both depressed patients and healthy controls, and (b) learning kineme patterns only from healthy controls, and computing statistics derived from reconstruction errors for both the patient and control classes. Employing machine learning methods, we evaluate depression classification performance on the \\emph{BlackDog} and \\emph{AVEC2013} datasets. Our findings indicate that: (1) head motion patterns are effective biomarkers for detecting depressive symptoms, and (2) explanatory kineme patterns consistent with prior findings can be observed for the two classes. Overall, we achieve peak F1 scores of 0.79 and 0.82, respectively, over BlackDog and AVEC2013 for binary classification over episodic \\emph{thin-slices}, and a peak F1 of 0.72 over videos for AVEC2013. ",
    "url": "https://arxiv.org/abs/2307.12241",
    "authors": [
      "Monika Gahalawat",
      "Raul Fernandez Rojas",
      "Tanaya Guha",
      "Ramanathan Subramanian",
      "Roland Goecke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12254",
    "title": "Semantic Communication-Empowered Traffic Management using Vehicle Count  Prediction",
    "abstract": "Vehicle count prediction is an important aspect of smart city traffic management. Most major roads are monitored by cameras with computing and transmitting capabilities. These cameras provide data to the central traffic controller (CTC), which is in charge of traffic control management. In this paper, we propose a joint CNN-LSTM-based semantic communication (SemCom) model in which the semantic encoder of a camera extracts the relevant semantics from raw images. The encoded semantics are then sent to the CTC by the transmitter in the form of symbols. The semantic decoder of the CTC predicts the vehicle count on each road based on the sequence of received symbols and develops a traffic management strategy accordingly. An optimization problem to improve the quality of experience (QoE) is introduced and numerically solved, taking into account constraints such as vehicle user safety, transmit power of camera devices, vehicle count prediction accuracy, and semantic entropy. Using numerical results, we show that the proposed SemCom model reduces overhead by $54.42\\%$ when compared to source encoder/decoder methods. Also, we demonstrate through simulations that the proposed model outperforms state-of-the-art models in terms of mean absolute error (MAE) and QoE. ",
    "url": "https://arxiv.org/abs/2307.12254",
    "authors": [
      "Sachin Kadam",
      "Dong In Kim"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.12264",
    "title": "QoE-Driven Video Transmission: Energy-Efficient Multi-UAV Network  Optimization",
    "abstract": "This paper is concerned with the issue of improving video subscribers' quality of experience (QoE) by deploying a multi-unmanned aerial vehicle (UAV) network. Different from existing works, we characterize subscribers' QoE by video bitrates, latency, and frame freezing and propose to improve their QoE by energy-efficiently and dynamically optimizing the multi-UAV network in terms of serving UAV selection, UAV trajectory, and UAV transmit power. The dynamic multi-UAV network optimization problem is formulated as a challenging sequential-decision problem with the goal of maximizing subscribers' QoE while minimizing the total network power consumption, subject to some physical resource constraints. We propose a novel network optimization algorithm to solve this challenging problem, in which a Lyapunov technique is first explored to decompose the sequential-decision problem into several repeatedly optimized sub-problems to avoid the curse of dimensionality. To solve the sub-problems, iterative and approximate optimization mechanisms with provable performance guarantees are then developed. Finally, we design extensive simulations to verify the effectiveness of the proposed algorithm. Simulation results show that the proposed algorithm can effectively improve the QoE of subscribers and is 66.75\\% more energy-efficient than benchmarks. ",
    "url": "https://arxiv.org/abs/2307.12264",
    "authors": [
      "Kesong Wu",
      "Xianbin Cao",
      "Peng Yang",
      "Zongyang Yu",
      "Dapeng Oliver Wu",
      "Tony Q. S. Quek"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.12267",
    "title": "Towards Automatic Boundary Detection for Human-AI Hybrid Essay in  Education",
    "abstract": "Human-AI collaborative writing has been greatly facilitated with the help of modern large language models (LLM), e.g., ChatGPT. While admitting the convenience brought by technology advancement, educators also have concerns that students might leverage LLM to partially complete their writing assignment and pass off the human-AI hybrid text as their original work. Driven by such concerns, in this study, we investigated the automatic detection of Human-AI hybrid text in education, where we formalized the hybrid text detection as a boundary detection problem, i.e., identifying the transition points between human-written content and AI-generated content. We constructed a hybrid essay dataset by partially removing sentences from the original student-written essays and then instructing ChatGPT to fill in for the incomplete essays. Then we proposed a two-step detection approach where we (1) Separated AI-generated content from human-written content during the embedding learning process; and (2) Calculated the distances between every two adjacent prototypes (a prototype is the mean of a set of consecutive sentences from the hybrid text in the embedding space) and assumed that the boundaries exist between the two prototypes that have the furthest distance from each other. Through extensive experiments, we summarized the following main findings: (1) The proposed approach consistently outperformed the baseline methods across different experiment settings; (2) The embedding learning process (i.e., step 1) can significantly boost the performance of the proposed approach; (3) When detecting boundaries for single-boundary hybrid essays, the performance of the proposed approach could be enhanced by adopting a relatively large prototype size, leading to a $22$\\% improvement (against the second-best baseline method) in the in-domain setting and an $18$\\% improvement in the out-of-domain setting. ",
    "url": "https://arxiv.org/abs/2307.12267",
    "authors": [
      "Zijie Zeng",
      "Lele Sha",
      "Yuheng Li",
      "Kaixun Yang",
      "Dragan Ga\u0161evi\u0107",
      "Guanliang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.12280",
    "title": "Downstream-agnostic Adversarial Examples",
    "abstract": "Self-supervised learning usually uses a large amount of unlabeled data to pre-train an encoder which can be used as a general-purpose feature extractor, such that downstream users only need to perform fine-tuning operations to enjoy the benefit of \"large model\". Despite this promising prospect, the security of pre-trained encoder has not been thoroughly investigated yet, especially when the pre-trained encoder is publicly available for commercial use. In this paper, we propose AdvEncoder, the first framework for generating downstream-agnostic universal adversarial examples based on the pre-trained encoder. AdvEncoder aims to construct a universal adversarial perturbation or patch for a set of natural images that can fool all the downstream tasks inheriting the victim pre-trained encoder. Unlike traditional adversarial example works, the pre-trained encoder only outputs feature vectors rather than classification labels. Therefore, we first exploit the high frequency component information of the image to guide the generation of adversarial examples. Then we design a generative attack framework to construct adversarial perturbations/patches by learning the distribution of the attack surrogate dataset to improve their attack success rates and transferability. Our results show that an attacker can successfully attack downstream tasks without knowing either the pre-training dataset or the downstream dataset. We also tailor four defenses for pre-trained encoders, the results of which further prove the attack ability of AdvEncoder. ",
    "url": "https://arxiv.org/abs/2307.12280",
    "authors": [
      "Ziqi Zhou",
      "Shengshan Hu",
      "Ruizhi Zhao",
      "Qian Wang",
      "Leo Yu Zhang",
      "Junhui Hou",
      "Hai Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12291",
    "title": "TransHuman: A Transformer-based Human Representation for Generalizable  Neural Human Rendering",
    "abstract": "In this paper, we focus on the task of generalizable neural human rendering which trains conditional Neural Radiance Fields (NeRF) from multi-view videos of different characters. To handle the dynamic human motion, previous methods have primarily used a SparseConvNet (SPC)-based human representation to process the painted SMPL. However, such SPC-based representation i) optimizes under the volatile observation space which leads to the pose-misalignment between training and inference stages, and ii) lacks the global relationships among human parts that is critical for handling the incomplete painted SMPL. Tackling these issues, we present a brand-new framework named TransHuman, which learns the painted SMPL under the canonical space and captures the global relationships between human parts with transformers. Specifically, TransHuman is mainly composed of Transformer-based Human Encoding (TransHE), Deformable Partial Radiance Fields (DPaRF), and Fine-grained Detail Integration (FDI). TransHE first processes the painted SMPL under the canonical space via transformers for capturing the global relationships between human parts. Then, DPaRF binds each output token with a deformable radiance field for encoding the query point under the observation space. Finally, the FDI is employed to further integrate fine-grained information from reference images. Extensive experiments on ZJU-MoCap and H36M show that our TransHuman achieves a significantly new state-of-the-art performance with high efficiency. Project page: https://pansanity666.github.io/TransHuman/ ",
    "url": "https://arxiv.org/abs/2307.12291",
    "authors": [
      "Xiao Pan",
      "Zongxin Yang",
      "Jianxin Ma",
      "Chang Zhou",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12299",
    "title": "Hybrid-CSR: Coupling Explicit and Implicit Shape Representation for  Cortical Surface Reconstruction",
    "abstract": "We present Hybrid-CSR, a geometric deep-learning model that combines explicit and implicit shape representations for cortical surface reconstruction. Specifically, Hybrid-CSR begins with explicit deformations of template meshes to obtain coarsely reconstructed cortical surfaces, based on which the oriented point clouds are estimated for the subsequent differentiable poisson surface reconstruction. By doing so, our method unifies explicit (oriented point clouds) and implicit (indicator function) cortical surface reconstruction. Compared to explicit representation-based methods, our hybrid approach is more friendly to capture detailed structures, and when compared with implicit representation-based methods, our method can be topology aware because of end-to-end training with a mesh-based deformation module. In order to address topology defects, we propose a new topology correction pipeline that relies on optimization-based diffeomorphic surface registration. Experimental results on three brain datasets show that our approach surpasses existing implicit and explicit cortical surface reconstruction methods in numeric metrics in terms of accuracy, regularity, and consistency. ",
    "url": "https://arxiv.org/abs/2307.12299",
    "authors": [
      "Shanlin Sun",
      "Thanh-Tung Le",
      "Chenyu You",
      "Hao Tang",
      "Kun Han",
      "Haoyu Ma",
      "Deying Kong",
      "Xiangyi Yan",
      "Xiaohui Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12301",
    "title": "RANSAC-NN: Unsupervised Image Outlier Detection using RANSAC",
    "abstract": "Image outlier detection (OD) is crucial for ensuring the quality and accuracy of image datasets used in computer vision tasks. The majority of OD algorithms, however, have not been targeted toward image data. Consequently, the results of applying such algorithms to images are often suboptimal. In this work, we propose RANSAC-NN, a novel unsupervised OD algorithm specifically designed for images. By comparing images in a RANSAC-based approach, our algorithm automatically predicts the outlier score of each image without additional training or label information. We evaluate RANSAC-NN against state-of-the-art OD algorithms on 15 diverse datasets. Without any hyperparameter tuning, RANSAC-NN consistently performs favorably in contrast to other algorithms in almost every dataset category. Furthermore, we provide a detailed analysis to understand each RANSAC-NN component, and we demonstrate its potential applications in image mislabeled detection. Code for RANSAC-NN is provided at https://github.com/mxtsai/ransac-nn ",
    "url": "https://arxiv.org/abs/2307.12301",
    "authors": [
      "Chen-Han Tsai",
      "Yu-Shao Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12306",
    "title": "Tackling the Curse of Dimensionality with Physics-Informed Neural  Networks",
    "abstract": "The curse-of-dimensionality (CoD) taxes computational resources heavily with exponentially increasing computational cost as the dimension increases. This poses great challenges in solving high-dimensional PDEs as Richard Bellman first pointed out over 60 years ago. While there has been some recent success in solving numerically partial differential equations (PDEs) in high dimensions, such computations are prohibitively expensive, and true scaling of general nonlinear PDEs to high dimensions has never been achieved. In this paper, we develop a new method of scaling up physics-informed neural networks (PINNs) to solve arbitrary high-dimensional PDEs. The new method, called Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs into pieces corresponding to different dimensions and samples randomly a subset of these dimensional pieces in each iteration of training PINNs. We theoretically prove the convergence guarantee and other desired properties of the proposed method. We experimentally demonstrate that the proposed method allows us to solve many notoriously hard high-dimensional PDEs, including the Hamilton-Jacobi-Bellman and the Schr\\\"{o}dinger equations in thousands of dimensions very fast on a single GPU using the PINNs mesh-free approach. For example, we solve nontrivial nonlinear PDEs (the HJB-Lin equation and the BSB equation) in 100,000 dimensions in 6 hours on a single GPU using SDGD with PINNs. Since SDGD is a general training methodology of PINNs, SDGD can be applied to any current and future variants of PINNs to scale them up for arbitrary high-dimensional PDEs. ",
    "url": "https://arxiv.org/abs/2307.12306",
    "authors": [
      "Zheyuan Hu",
      "Khemraj Shukla",
      "George Em Karniadakis",
      "Kenji Kawaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.12307",
    "title": "Robust Weighted Sum-Rate Maximization for Transmissive RIS Transmitter  Enabled RSMA Networks",
    "abstract": "Due to the low power consumption and low cost nature of transmissive reconfigurable intelligent surface (RIS),in this paper, we propose a downlink multi-user rate-splitting multiple access (RSMA) architecture based on the transmissive RIS transmitter, where the channel state information (CSI) is only accquired partially. We investigate the weighted sum-rate maximization problem by jointly optimizing the power, RIS transmissive coefficients and common rate allocated to each user. Due to the coupling of optimization variables, the problem is nonconvex, and it is difficult to directly obtain the optimal solution. Hence, a block coordinate descent (BCD) algorithm based on sample average approximation (SAA) and weighted minimum mean square error (WMMSE) is proposed to tackle it. Numerical results illustrate that the transmissive RIS transmitter with ratesplitting architecture has advantages over conventional space division multiple access (SDMA) and non-orthgonal multiple access (NOMA). ",
    "url": "https://arxiv.org/abs/2307.12307",
    "authors": [
      "Bojiang Li",
      "Wen Chen",
      "Zhendong Li",
      "Qingqing Wu",
      "Nan Cheng",
      "Changle Li",
      "Linglong Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.12309",
    "title": "Building Extraction from Remote Sensing Images via an Uncertainty-Aware  Network",
    "abstract": "Building extraction aims to segment building pixels from remote sensing images and plays an essential role in many applications, such as city planning and urban dynamic monitoring. Over the past few years, deep learning methods with encoder-decoder architectures have achieved remarkable performance due to their powerful feature representation capability. Nevertheless, due to the varying scales and styles of buildings, conventional deep learning models always suffer from uncertain predictions and cannot accurately distinguish the complete footprints of the building from the complex distribution of ground objects, leading to a large degree of omission and commission. In this paper, we realize the importance of uncertain prediction and propose a novel and straightforward Uncertainty-Aware Network (UANet) to alleviate this problem. To verify the performance of our proposed UANet, we conduct extensive experiments on three public building datasets, including the WHU building dataset, the Massachusetts building dataset, and the Inria aerial image dataset. Results demonstrate that the proposed UANet outperforms other state-of-the-art algorithms by a large margin. ",
    "url": "https://arxiv.org/abs/2307.12309",
    "authors": [
      "Wei He",
      "Jiepan Li",
      "Weinan Cao",
      "Liangpei Zhang",
      "Hongyan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12326",
    "title": "Scale jump-aware pose graph relaxation for monocular SLAM with  re-initializations",
    "abstract": "Pose graph relaxation has become an indispensable addition to SLAM enabling efficient global registration of sensor reference frames under the objective of satisfying pair-wise relative transformation constraints. The latter may be given by incremental motion estimation or global place recognition. While the latter case enables loop closures and drift compensation, care has to be taken in the monocular case in which local estimates of structure and displacements can differ from reality not just in terms of noise, but also in terms of a scale factor. Owing to the accumulation of scale propagation errors, this scale factor is drifting over time, hence scale-drift aware pose graph relaxation has been introduced. We extend this idea to cases in which the relative scale between subsequent sensor frames is unknown, a situation that can easily occur if monocular SLAM enters re-initialization and no reliable overlap between successive local maps can be identified. The approach is realized by a hybrid pose graph formulation that combines the regular similarity consistency terms with novel, scale-blind constraints. We apply the technique to the practically relevant case of small indoor service robots capable of effectuating purely rotational displacements, a condition that can easily cause tracking failures. We demonstrate that globally consistent trajectories can be recovered even if multiple re-initializations occur along the loop, and present an in-depth study of success and failure cases. ",
    "url": "https://arxiv.org/abs/2307.12326",
    "authors": [
      "Runze Yuan",
      "Ran Cheng",
      "Lige Liu",
      "Tao Sun",
      "Laurent Kneip"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.12332",
    "title": "X-CapsNet For Fake News Detection",
    "abstract": "News consumption has significantly increased with the growing popularity and use of web-based forums and social media. This sets the stage for misinforming and confusing people. To help reduce the impact of misinformation on users' potential health-related decisions and other intents, it is desired to have machine learning models to detect and combat fake news automatically. This paper proposes a novel transformer-based model using Capsule neural Networks(CapsNet) called X-CapsNet. This model includes a CapsNet with dynamic routing algorithm paralyzed with a size-based classifier for detecting short and long fake news statements. We use two size-based classifiers, a Deep Convolutional Neural Network (DCNN) for detecting long fake news statements and a Multi-Layer Perceptron (MLP) for detecting short news statements. To resolve the problem of representing short news statements, we use indirect features of news created by concatenating the vector of news speaker profiles and a vector of polarity, sentiment, and counting words of news statements. For evaluating the proposed architecture, we use the Covid-19 and the Liar datasets. The results in terms of the F1-score for the Covid-19 dataset and accuracy for the Liar dataset show that models perform better than the state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2307.12332",
    "authors": [
      "Mohammad Hadi Goldani",
      "Reza Safabakhsh",
      "Saeedeh Momtazi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2307.12333",
    "title": "An axiomatized PDE model of deep neural networks",
    "abstract": "Inspired by the relation between deep neural network (DNN) and partial differential equations (PDEs), we study the general form of the PDE models of deep neural networks. To achieve this goal, we formulate DNN as an evolution operator from a simple base model. Based on several reasonable assumptions, we prove that the evolution operator is actually determined by convection-diffusion equation. This convection-diffusion equation model gives mathematical explanation for several effective networks. Moreover, we show that the convection-diffusion model improves the robustness and reduces the Rademacher complexity. Based on the convection-diffusion equation, we design a new training method for ResNets. Experiments validate the performance of the proposed method. ",
    "url": "https://arxiv.org/abs/2307.12333",
    "authors": [
      "Tangjun Wang",
      "Wenqi Tao",
      "Chenglong Bao",
      "Zuoqiang Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12336",
    "title": "TabADM: Unsupervised Tabular Anomaly Detection with Diffusion Models",
    "abstract": "Tables are an abundant form of data with use cases across all scientific fields. Real-world datasets often contain anomalous samples that can negatively affect downstream analysis. In this work, we only assume access to contaminated data and present a diffusion-based probabilistic model effective for unsupervised anomaly detection. Our model is trained to learn the density of normal samples by utilizing a unique rejection scheme to attenuate the influence of anomalies on the density estimation. At inference, we identify anomalies as samples in low-density regions. We use real data to demonstrate that our method improves detection capabilities over baselines. Furthermore, our method is relatively stable to the dimension of the data and does not require extensive hyperparameter tuning. ",
    "url": "https://arxiv.org/abs/2307.12336",
    "authors": [
      "Guy Zamberg",
      "Moshe Salhov",
      "Ofir Lindenbaum",
      "Amir Averbuch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12339",
    "title": "Temporal network analysis: Introduction, methods and detailed tutorial  with R",
    "abstract": "Learning involves relations, interactions and connections between learners, teachers and the world at large. Such interactions are essentially temporal and unfold in time. Yet, researchers have rarely combined the two aspects (the temporal and relational aspects) in an analytics framework. Temporal networks allow modeling of the temporal learning processes i.e., the emergence and flow of activities, communities, and social processes through fine-grained dynamic analysis. This can provide insights into phenomena like knowledge co-construction, information flow, and relationship building. This chapter introduces the basic concepts of temporal networks, their types and techniques. A detailed guide of temporal network analysis is introduced in this chapter, that starts with building the network, visualization, mathematical analysis on the node and graph level. The analysis is performed with a real-world dataset. The discussion chapter offers some extra resources for interested users who want to expand their knowledge of the technique. ",
    "url": "https://arxiv.org/abs/2307.12339",
    "authors": [
      "Mohammed Saqr"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2307.12341",
    "title": "Rapid detection of soil carbonates by means of NIR spectroscopy, deep  learning methods and phase quantification by powder Xray diffraction",
    "abstract": "Soil NIR spectral absorbance/reflectance libraries are utilized towards improving agricultural production and analysis of soil properties which are key prerequisite for agroecological balance and environmental sustainability. Carbonates in particular, represent a soil property which is mostly affected even by mild, let alone extreme, changes of environmental conditions during climate change. In this study we propose a rapid and efficient way to predict carbonates content in soil by means of FT NIR reflectance spectroscopy and by use of deep learning methods. We exploited multiple machine learning methods, such as: 1) a MLP Regressor and 2) a CNN and compare their performance with other traditional ML algorithms such as PLSR, Cubist and SVM on the combined dataset of two NIR spectral libraries: KSSL (USDA), a dataset of soil samples reflectance spectra collected nationwide, and LUCAS TopSoil (European Soil Library) which contains soil sample absorbance spectra from all over the European Union, and use them to predict carbonate content on never before seen soil samples. Soil samples in KSSL and in TopSoil spectral libraries were acquired in the spectral region of visNIR, however in this study, only the NIR spectral region was utilized. Quantification of carbonates by means of Xray Diffraction is in good agreement with the volumetric method and the MLP prediction. Our work contributes to rapid carbonates content prediction in soil samples in cases where: 1) no volumetric method is available and 2) only NIR spectra absorbance data are available. Up till now and to the best of our knowledge, there exists no other study, that presents a prediction model trained on such an extensive dataset with such promising results on unseen data, undoubtedly supporting the notion that deep learning models present excellent prediction tools for soil carbonates content. ",
    "url": "https://arxiv.org/abs/2307.12341",
    "authors": [
      "Lykourgos Chiniadis",
      "Petros Tamvakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.12342",
    "title": "Towards Generic and Controllable Attacks Against Object Detection",
    "abstract": "Existing adversarial attacks against Object Detectors (ODs) suffer from two inherent limitations. Firstly, ODs have complicated meta-structure designs, hence most advanced attacks for ODs concentrate on attacking specific detector-intrinsic structures, which makes it hard for them to work on other detectors and motivates us to design a generic attack against ODs. Secondly, most works against ODs make Adversarial Examples (AEs) by generalizing image-level attacks from classification to detection, which brings redundant computations and perturbations in semantically meaningless areas (e.g., backgrounds) and leads to an emergency for seeking controllable attacks for ODs. To this end, we propose a generic white-box attack, LGP (local perturbations with adaptively global attacks), to blind mainstream object detectors with controllable perturbations. For a detector-agnostic attack, LGP tracks high-quality proposals and optimizes three heterogeneous losses simultaneously. In this way, we can fool the crucial components of ODs with a part of their outputs without the limitations of specific structures. Regarding controllability, we establish an object-wise constraint that exploits foreground-background separation adaptively to induce the attachment of perturbations to foregrounds. Experimentally, the proposed LGP successfully attacked sixteen state-of-the-art object detectors on MS-COCO and DOTA datasets, with promising imperceptibility and transferability obtained. Codes are publicly released in https://github.com/liguopeng0923/LGP.git ",
    "url": "https://arxiv.org/abs/2307.12342",
    "authors": [
      "Guopeng Li",
      "Yue Xu",
      "Jian Ding",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.12343",
    "title": "Self-Supervised Learning for Audio-Based Emotion Recognition",
    "abstract": "Emotion recognition models using audio input data can enable the development of interactive systems with applications in mental healthcare, marketing, gaming, and social media analysis. While the field of affective computing using audio data is rich, a major barrier to achieve consistently high-performance models is the paucity of available training labels. Self-supervised learning (SSL) is a family of methods which can learn despite a scarcity of supervised labels by predicting properties of the data itself. To understand the utility of self-supervised learning for audio-based emotion recognition, we have applied self-supervised learning pre-training to the classification of emotions from the CMU- MOSEI's acoustic modality. Unlike prior papers that have experimented with raw acoustic data, our technique has been applied to encoded acoustic data. Our model is first pretrained to uncover the randomly-masked timestamps of the acoustic data. The pre-trained model is then fine-tuned using a small sample of annotated data. The performance of the final model is then evaluated via several evaluation metrics against a baseline deep learning model with an identical backbone architecture. We find that self-supervised learning consistently improves the performance of the model across all metrics. This work shows the utility of self-supervised learning for affective computing, demonstrating that self-supervised learning is most useful when the number of training examples is small, and that the effect is most pronounced for emotions which are easier to classify such as happy, sad and anger. This work further demonstrates that self-supervised learning works when applied to embedded feature representations rather than the traditional approach of pre-training on the raw input space. ",
    "url": "https://arxiv.org/abs/2307.12343",
    "authors": [
      "Peranut Nimitsurachat",
      "Peter Washington"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.12345",
    "title": "Tell me, what are you most afraid of? Exploring the Effects of Agent  Representation on Information Disclosure in Human-Chatbot Interaction",
    "abstract": "Self-disclosure counts as a key factor influencing successful health treatment, particularly when it comes to building a functioning patient-therapist-connection. To this end, the use of chatbots may be considered a promising puzzle piece that helps foster respective information provision. Several studies have shown that people disclose more information when they are interacting with a chatbot than when they are interacting with another human being. If and how the chatbot is embodied, however, seems to play an important role influencing the extent to which information is disclosed. Here, research shows that people disclose less if the chatbot is embodied with a human avatar in comparison to a chatbot without embodiment. Still, there is only little information available as to whether it is the embodiment with a human face that inhibits disclosure, or whether any type of face will reduce the amount of shared information. The study presented in this paper thus aims to investigate how the type of chatbot embodiment influences self-disclosure in human-chatbot-interaction. We conducted a quasi-experimental study in which $n=178$ participants were asked to interact with one of three settings of a chatbot app. In each setting, the humanness of the chatbot embodiment was different (i.e., human vs. robot vs. disembodied). A subsequent discourse analysis explored difference in the breadth and depth of self-disclosure. Results show that non-human embodiment seems to have little effect on self-disclosure. Yet, our data also shows, that, contradicting to previous work, human embodiment may have a positive effect on the breadth and depth of self-disclosure. ",
    "url": "https://arxiv.org/abs/2307.12345",
    "authors": [
      "Anna Stock",
      "Stephan Schl\u00f6gl",
      "Aleksander Groth"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2307.12349",
    "title": "ComPtr: Towards Diverse Bi-source Dense Prediction Tasks via A Simple  yet General Complementary Transformer",
    "abstract": "Deep learning (DL) has advanced the field of dense prediction, while gradually dissolving the inherent barriers between different tasks. However, most existing works focus on designing architectures and constructing visual cues only for the specific task, which ignores the potential uniformity introduced by the DL paradigm. In this paper, we attempt to construct a novel \\underline{ComP}lementary \\underline{tr}ansformer, \\textbf{ComPtr}, for diverse bi-source dense prediction tasks. Specifically, unlike existing methods that over-specialize in a single task or a subset of tasks, ComPtr starts from the more general concept of bi-source dense prediction. Based on the basic dependence on information complementarity, we propose consistency enhancement and difference awareness components with which ComPtr can evacuate and collect important visual semantic cues from different image sources for diverse tasks, respectively. ComPtr treats different inputs equally and builds an efficient dense interaction model in the form of sequence-to-sequence on top of the transformer. This task-generic design provides a smooth foundation for constructing the unified model that can simultaneously deal with various bi-source information. In extensive experiments across several representative vision tasks, i.e. remote sensing change detection, RGB-T crowd counting, RGB-D/T salient object detection, and RGB-D semantic segmentation, the proposed method consistently obtains favorable performance. The code will be available at \\url{https://github.com/lartpang/ComPtr}. ",
    "url": "https://arxiv.org/abs/2307.12349",
    "authors": [
      "Youwei Pang",
      "Xiaoqi Zhao",
      "Lihe Zhang",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12369",
    "title": "Early Prediction of Alzheimers Disease Leveraging Symptom Occurrences  from Longitudinal Electronic Health Records of US Military Veterans",
    "abstract": "Early prediction of Alzheimer's disease (AD) is crucial for timely intervention and treatment. This study aims to use machine learning approaches to analyze longitudinal electronic health records (EHRs) of patients with AD and identify signs and symptoms that can predict AD onset earlier. We used a case-control design with longitudinal EHRs from the U.S. Department of Veterans Affairs Veterans Health Administration (VHA) from 2004 to 2021. Cases were VHA patients with AD diagnosed after 1/1/2016 based on ICD-10-CM codes, matched 1:9 with controls by age, sex and clinical utilization with replacement. We used a panel of AD-related keywords and their occurrences over time in a patient's longitudinal EHRs as predictors for AD prediction with four machine learning models. We performed subgroup analyses by age, sex, and race/ethnicity, and validated the model in a hold-out and \"unseen\" VHA stations group. Model discrimination, calibration, and other relevant metrics were reported for predictions up to ten years before ICD-based diagnosis. The study population included 16,701 cases and 39,097 matched controls. The average number of AD-related keywords (e.g., \"concentration\", \"speaking\") per year increased rapidly for cases as diagnosis approached, from around 10 to over 40, while remaining flat at 10 for controls. The best model achieved high discriminative accuracy (ROCAUC 0.997) for predictions using data from at least ten years before ICD-based diagnoses. The model was well-calibrated (Hosmer-Lemeshow goodness-of-fit p-value = 0.99) and consistent across subgroups of age, sex and race/ethnicity, except for patients younger than 65 (ROCAUC 0.746). Machine learning models using AD-related keywords identified from EHR notes can predict future AD diagnoses, suggesting its potential use for identifying AD risk using EHR notes, offering an affordable way for early screening on large population. ",
    "url": "https://arxiv.org/abs/2307.12369",
    "authors": [
      "Rumeng Li",
      "Xun Wang",
      "Dan Berlowitz",
      "Brian Silver",
      "Wen Hu",
      "Heather Keating",
      "Raelene Goodwin",
      "Weisong Liu",
      "Honghuang Lin",
      "Hong Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.12392",
    "title": "Iterative Robust Visual Grounding with Masked Reference based  Centerpoint Supervision",
    "abstract": "Visual Grounding (VG) aims at localizing target objects from an image based on given expressions and has made significant progress with the development of detection and vision transformer. However, existing VG methods tend to generate false-alarm objects when presented with inaccurate or irrelevant descriptions, which commonly occur in practical applications. Moreover, existing methods fail to capture fine-grained features, accurate localization, and sufficient context comprehension from the whole image and textual descriptions. To address both issues, we propose an Iterative Robust Visual Grounding (IR-VG) framework with Masked Reference based Centerpoint Supervision (MRCS). The framework introduces iterative multi-level vision-language fusion (IMVF) for better alignment. We use MRCS to ahieve more accurate localization with point-wised feature supervision. Then, to improve the robustness of VG, we also present a multi-stage false-alarm sensitive decoder (MFSD) to prevent the generation of false-alarm objects when presented with inaccurate expressions. The proposed framework is evaluated on five regular VG datasets and two newly constructed robust VG datasets. Extensive experiments demonstrate that IR-VG achieves new state-of-the-art (SOTA) results, with improvements of 25\\% and 10\\% compared to existing SOTA approaches on the two newly proposed robust VG datasets. Moreover, the proposed framework is also verified effective on five regular VG datasets. Codes and models will be publicly at https://github.com/cv516Buaa/IR-VG. ",
    "url": "https://arxiv.org/abs/2307.12392",
    "authors": [
      "Menghao Li",
      "Chunlei Wang",
      "Wenquan Feng",
      "Shuchang Lyu",
      "Guangliang Cheng",
      "Xiangtai Li",
      "Binghao Liu",
      "Qi Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12393",
    "title": "Treebar Maps: Schematic Representation of Networks at Scale",
    "abstract": "Many data sets, crucial for today's applications, consist essentially of enormous networks, containing millions or even billions of elements. Having the possibility of visualizing such networks is of paramount importance. We propose an algorithmic framework and a visual metaphor, dubbed treebar map, to provide schematic representations of huge networks. Our goal is to convey the main features of the network's inner structure in a straightforward, two-dimensional, one-page drawing. This drawing effectively captures the essential quantitative information about the network's main components. Our experiments show that we are able to create such representations in a few hundreds of seconds. We demonstrate the metaphor's efficacy through visual examination of extensive graphs, highlighting how their diverse structures are instantly comprehensible via their representations. ",
    "url": "https://arxiv.org/abs/2307.12393",
    "authors": [
      "Giuseppe Di Battista",
      "Fabrizio Grosso",
      "Silvia Montorselli",
      "Maurizio Patrignani"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2307.12399",
    "title": "Generation of Time-Varying Impedance Attacks Against Haptic Shared  Control Steering Systems",
    "abstract": "The safety-critical nature of vehicle steering is one of the main motivations for exploring the space of possible cyber-physical attacks against the steering systems of modern vehicles. This paper investigates the adversarial capabilities for destabilizing the interaction dynamics between human drivers and vehicle haptic shared control (HSC) steering systems. In contrast to the conventional robotics literature, where the main objective is to render the human-automation interaction dynamics stable by ensuring passivity, this paper takes the exact opposite route. In particular, to investigate the damaging capabilities of a successful cyber-physical attack, this paper demonstrates that an attacker who targets the HSC steering system can destabilize the interaction dynamics between the human driver and the vehicle HSC steering system through synthesis of time-varying impedance profiles. Specifically, it is shown that the adversary can utilize a properly designed non-passive and time-varying adversarial impedance target dynamics, which are fed with a linear combination of the human driver and the steering column torques. Using these target dynamics, it is possible for the adversary to generate in real-time a reference angular command for the driver input device and the directional control steering assembly of the vehicle. Furthermore, it is shown that the adversary can make the steering wheel and the vehicle steering column angular positions to follow the reference command generated by the time-varying impedance target dynamics using proper adaptive control strategies. Numerical simulations demonstrate the effectiveness of such time-varying impedance attacks, which result in a non-passive and inherently unstable interaction between the driver and the HSC steering system. ",
    "url": "https://arxiv.org/abs/2307.12399",
    "authors": [
      "Alireza Mohammadi",
      "Hafiz Malik"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.12409",
    "title": "A Machine Learning Approach to Two-Stage Adaptive Robust Optimization",
    "abstract": "We propose an approach based on machine learning to solve two-stage linear adaptive robust optimization (ARO) problems with binary here-and-now variables and polyhedral uncertainty sets. We encode the optimal here-and-now decisions, the worst-case scenarios associated with the optimal here-and-now decisions, and the optimal wait-and-see decisions into what we denote as the strategy. We solve multiple similar ARO instances in advance using the column and constraint generation algorithm and extract the optimal strategies to generate a training set. We train a machine learning model that predicts high-quality strategies for the here-and-now decisions, the worst-case scenarios associated with the optimal here-and-now decisions, and the wait-and-see decisions. We also introduce an algorithm to reduce the number of different target classes the machine learning algorithm needs to be trained on. We apply the proposed approach to the facility location, the multi-item inventory control and the unit commitment problems. Our approach solves ARO problems drastically faster than the state-of-the-art algorithms with high accuracy. ",
    "url": "https://arxiv.org/abs/2307.12409",
    "authors": [
      "Dimitris Bertsimas",
      "Cheol Woo Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.12417",
    "title": "Practical Commercial 5G Standalone (SA) Uplink Throughput Prediction",
    "abstract": "While the 5G New Radio (NR) network promises a huge uplift of the uplink throughput, the improvement can only be seen when the User Equipment (UE) is connected to the high-frequency millimeter wave (mmWave) band. With the rise of uplink-intensive smartphone applications such as the real-time transmission of UHD 4K/8K videos, and Virtual Reality (VR)/Augmented Reality (AR) contents, uplink throughput prediction plays a huge role in maximizing the users' quality of experience (QoE). In this paper, we propose using a ConvLSTM-based neural network to predict the future uplink throughput based on past uplink throughput and RF parameters. The network is trained using the data from real-world drive tests on commercial 5G SA networks while riding commuter trains, which accounted for various frequency bands, handover, and blind spots. To make sure our model can be practically implemented, we then limited our model to only use the information available via Android API, then evaluate our model using the data from both commuter trains and other methods of transportation. The results show that our model reaches an average prediction accuracy of 98.9\\% with an average RMSE of 1.80 Mbps across all unseen evaluation scenarios. ",
    "url": "https://arxiv.org/abs/2307.12417",
    "authors": [
      "Kasidis Arunruangsirilert",
      "Jiro Katto"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2307.12427",
    "title": "Augmented Box Replay: Overcoming Foreground Shift for Incremental Object  Detection",
    "abstract": "In incremental learning, replaying stored samples from previous tasks together with current task samples is one of the most efficient approaches to address catastrophic forgetting. However, unlike incremental classification, image replay has not been successfully applied to incremental object detection (IOD). In this paper, we identify the overlooked problem of foreground shift as the main reason for this. Foreground shift only occurs when replaying images of previous tasks and refers to the fact that their background might contain foreground objects of the current task. To overcome this problem, a novel and efficient Augmented Box Replay (ABR) method is developed that only stores and replays foreground objects and thereby circumvents the foreground shift problem. In addition, we propose an innovative Attentive RoI Distillation loss that uses spatial attention from region-of-interest (RoI) features to constrain current model to focus on the most important information from old model. ABR significantly reduces forgetting of previous classes while maintaining high plasticity in current classes. Moreover, it considerably reduces the storage requirements when compared to standard image replay. Comprehensive experiments on Pascal-VOC and COCO datasets support the state-of-the-art performance of our model. ",
    "url": "https://arxiv.org/abs/2307.12427",
    "authors": [
      "Liu Yuyang",
      "Cong Yang",
      "Goswami Dipam",
      "Liu Xialei",
      "Joost van de Weijer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12429",
    "title": "SwIPE: Efficient and Robust Medical Image Segmentation with Implicit  Patch Embeddings",
    "abstract": "Modern medical image segmentation methods primarily use discrete representations in the form of rasterized masks to learn features and generate predictions. Although effective, this paradigm is spatially inflexible, scales poorly to higher-resolution images, and lacks direct understanding of object shapes. To address these limitations, some recent works utilized implicit neural representations (INRs) to learn continuous representations for segmentation. However, these methods often directly adopted components designed for 3D shape reconstruction. More importantly, these formulations were also constrained to either point-based or global contexts, lacking contextual understanding or local fine-grained details, respectively--both critical for accurate segmentation. To remedy this, we propose a novel approach, SwIPE (Segmentation with Implicit Patch Embeddings), that leverages the advantages of INRs and predicts shapes at the patch level--rather than at the point level or image level--to enable both accurate local boundary delineation and global shape coherence. Extensive evaluations on two tasks (2D polyp segmentation and 3D abdominal organ segmentation) show that SwIPE significantly improves over recent implicit approaches and outperforms state-of-the-art discrete methods with over 10x fewer parameters. Our method also demonstrates superior data efficiency and improved robustness to data shifts across image resolutions and datasets. Code is available on Github. ",
    "url": "https://arxiv.org/abs/2307.12429",
    "authors": [
      "Yejia Zhang",
      "Pengfei Gu",
      "Nishchal Sapkota",
      "Danny Z. Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12435",
    "title": "A Generalized Schwarz-type Non-overlapping Domain Decomposition Method  using Physics-constrained Neural Networks",
    "abstract": "We present a meshless Schwarz-type non-overlapping domain decomposition method based on artificial neural networks for solving forward and inverse problems involving partial differential equations (PDEs). To ensure the consistency of solutions across neighboring subdomains, we adopt a generalized Robin-type interface condition, assigning unique Robin parameters to each subdomain. These subdomain-specific Robin parameters are learned to minimize the mismatch on the Robin interface condition, facilitating efficient information exchange during training. Our method is applicable to both the Laplace's and Helmholtz equations. It represents local solutions by an independent neural network model which is trained to minimize the loss on the governing PDE while strictly enforcing boundary and interface conditions through an augmented Lagrangian formalism. A key strength of our method lies in its ability to learn a Robin parameter for each subdomain, thereby enhancing information exchange with its neighboring subdomains. We observe that the learned Robin parameters adapt to the local behavior of the solution, domain partitioning and subdomain location relative to the overall domain. Extensive experiments on forward and inverse problems, including one-way and two-way decompositions with crosspoints, demonstrate the versatility and performance of our proposed approach. ",
    "url": "https://arxiv.org/abs/2307.12435",
    "authors": [
      "Shamsulhaq Basir",
      "Inanc Senocak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2307.12437",
    "title": "Robust explicit model predictive control for hybrid linear systems with  parameter uncertainties",
    "abstract": "Explicit model-predictive control (MPC) is a widely used control design method that employs optimization tools to find control policies offline; commonly it is posed as a semi-definite program (SDP) or as a mixed-integer SDP in the case of hybrid systems. However, mixed-integer SDPs are computationally expensive, motivating alternative formulations, such as zonotope-based MPC (zonotopes are a special type of symmetric polytopes). In this paper, we propose a robust explicit MPC method applicable to hybrid systems. More precisely, we extend existing zonotope-based MPC methods to account for multiplicative parametric uncertainty. Additionally, we propose a convex zonotope order reduction method that takes advantage of the iterative structure of the zonotope propagation problem to promote diagonal blocks in the zonotope generators and lower the number of decision variables. Finally, we developed a quasi-time-free policy choice algorithm, allowing the system to start from any point on the trajectory and avoid chattering associated with discrete switching of linear control policies based on the current state's membership in state-space regions. Last but not least, we verify the validity of the proposed methods on two experimental setups, varying physical parameters between experiments. ",
    "url": "https://arxiv.org/abs/2307.12437",
    "authors": [
      "Oleg Balakhnov",
      "Sergei Savin",
      "Alexandr Klimchik"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.12459",
    "title": "Robust face anti-spoofing framework with Convolutional Vision  Transformer",
    "abstract": "Owing to the advances in image processing technology and large-scale datasets, companies have implemented facial authentication processes, thereby stimulating increased focus on face anti-spoofing (FAS) against realistic presentation attacks. Recently, various attempts have been made to improve face recognition performance using both global and local learning on face images; however, to the best of our knowledge, this is the first study to investigate whether the robustness of FAS against domain shifts is improved by considering global information and local cues in face images captured using self-attention and convolutional layers. This study proposes a convolutional vision transformer-based framework that achieves robust performance for various unseen domain data. Our model resulted in 7.3%$p$ and 12.9%$p$ increases in FAS performance compared to models using only a convolutional neural network or vision transformer, respectively. It also shows the highest average rank in sub-protocols of cross-dataset setting over the other nine benchmark models for domain generalization. ",
    "url": "https://arxiv.org/abs/2307.12459",
    "authors": [
      "Yunseung Lee",
      "Youngjun Kwak",
      "Jinho Shin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12461",
    "title": "Rates of Approximation by ReLU Shallow Neural Networks",
    "abstract": "Neural networks activated by the rectified linear unit (ReLU) play a central role in the recent development of deep learning. The topic of approximating functions from H\\\"older spaces by these networks is crucial for understanding the efficiency of the induced learning algorithms. Although the topic has been well investigated in the setting of deep neural networks with many layers of hidden neurons, it is still open for shallow networks having only one hidden layer. In this paper, we provide rates of uniform approximation by these networks. We show that ReLU shallow neural networks with $m$ hidden neurons can uniformly approximate functions from the H\\\"older space $W_\\infty^r([-1, 1]^d)$ with rates $O((\\log m)^{\\frac{1}{2} +d}m^{-\\frac{r}{d}\\frac{d+2}{d+4}})$ when $r<d/2 +2$. Such rates are very close to the optimal one $O(m^{-\\frac{r}{d}})$ in the sense that $\\frac{d+2}{d+4}$ is close to $1$, when the dimension $d$ is large. ",
    "url": "https://arxiv.org/abs/2307.12461",
    "authors": [
      "Tong Mao",
      "Ding-Xuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.12485",
    "title": "Web3.0 Security: Privacy Enhancing and Anonym Auditing in  Blockchain-based Structures",
    "abstract": "The advent of Web 3.0, underpinned by blockchain technologies, promises to transform the internet's landscape by empowering individuals with decentralized control over their data. However, this evolution brings unique security challenges that need to be addressed. This paper explores these complexities, focusing on enhancing privacy and anonymous auditing within blockchain structures. We present the architecture of Web 3.0 based on the blockchain, providing a clear perspective on its workflow and security mechanisms. A security protocol for Web 3.0 systems, employing privacy-preserving techniques and anonymous auditing during runtime, is proposed. Key components of our solution include the integration of privacy-enhancing techniques and the utilization of Tor for anonymous auditing. We discuss related work and propose a framework that meets these new security requirements. Lastly, we offer an evaluation and comparison of our model to existing methods. This research contributes towards the foundational understanding of Web 3.0's secure structure and offers a pathway towards secure and privacy-preserving digital interactions in this novel internet landscape. ",
    "url": "https://arxiv.org/abs/2307.12485",
    "authors": [
      "Danyal Namakshenas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2307.12491",
    "title": "Learning Universal and Robust 3D Molecular Representations with Graph  Convolutional Networks",
    "abstract": "To learn accurate representations of molecules, it is essential to consider both chemical and geometric features. To encode geometric information, many descriptors have been proposed in constrained circumstances for specific types of molecules and do not have the properties to be ``robust\": 1. Invariant to rotations and translations; 2. Injective when embedding molecular structures. In this work, we propose a universal and robust Directional Node Pair (DNP) descriptor based on the graph representations of 3D molecules. Our DNP descriptor is robust compared to previous ones and can be applied to multiple molecular types. To combine the DNP descriptor and chemical features in molecules, we construct the Robust Molecular Graph Convolutional Network (RoM-GCN) which is capable to take both node and edge features into consideration when generating molecule representations. We evaluate our model on protein and small molecule datasets. Our results validate the superiority of the DNP descriptor in incorporating 3D geometric information of molecules. RoM-GCN outperforms all compared baselines. ",
    "url": "https://arxiv.org/abs/2307.12491",
    "authors": [
      "Shuo Zhang",
      "Yang Liu",
      "Li Xie",
      "Lei Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2307.12496",
    "title": "A faster and simpler algorithm for learning shallow networks",
    "abstract": "We revisit the well-studied problem of learning a linear combination of $k$ ReLU activations given labeled examples drawn from the standard $d$-dimensional Gaussian measure. Chen et al. [CDG+23] recently gave the first algorithm for this problem to run in $\\text{poly}(d,1/\\varepsilon)$ time when $k = O(1)$, where $\\varepsilon$ is the target error. More precisely, their algorithm runs in time $(d/\\varepsilon)^{\\mathrm{quasipoly}(k)}$ and learns over multiple stages. Here we show that a much simpler one-stage version of their algorithm suffices, and moreover its runtime is only $(d/\\varepsilon)^{O(k^2)}$. ",
    "url": "https://arxiv.org/abs/2307.12496",
    "authors": [
      "Sitan Chen",
      "Shyam Narayanan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.12498",
    "title": "Robust Automatic Speech Recognition via WavAugment Guided Phoneme  Adversarial Training",
    "abstract": "Developing a practically-robust automatic speech recognition (ASR) is challenging since the model should not only maintain the original performance on clean samples, but also achieve consistent efficacy under small volume perturbations and large domain shifts. To address this problem, we propose a novel WavAugment Guided Phoneme Adversarial Training (wapat). wapat use adversarial examples in phoneme space as augmentation to make the model invariant to minor fluctuations in phoneme representation and preserve the performance on clean samples. In addition, wapat utilizes the phoneme representation of augmented samples to guide the generation of adversaries, which helps to find more stable and diverse gradient-directions, resulting in improved generalization. Extensive experiments demonstrate the effectiveness of wapat on End-to-end Speech Challenge Benchmark (ESB). Notably, SpeechLM-wapat outperforms the original model by 6.28% WER reduction on ESB, achieving the new state-of-the-art. ",
    "url": "https://arxiv.org/abs/2307.12498",
    "authors": [
      "Gege Qi",
      "Yuefeng Chen",
      "Xiaofeng Mao",
      "Xiaojun Jia",
      "Ranjie Duan",
      "Rong Zhang",
      "Hui Xue"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.12499",
    "title": "AdvDiff: Generating Unrestricted Adversarial Examples using Diffusion  Models",
    "abstract": "Unrestricted adversarial attacks present a serious threat to deep learning models and adversarial defense techniques. They pose severe security problems for deep learning applications because they can effectively bypass defense mechanisms. However, previous attack methods often utilize Generative Adversarial Networks (GANs), which are not theoretically provable and thus generate unrealistic examples by incorporating adversarial objectives, especially for large-scale datasets like ImageNet. In this paper, we propose a new method, called AdvDiff, to generate unrestricted adversarial examples with diffusion models. We design two novel adversarial guidance techniques to conduct adversarial sampling in the reverse generation process of diffusion models. These two techniques are effective and stable to generate high-quality, realistic adversarial examples by integrating gradients of the target classifier interpretably. Experimental results on MNIST and ImageNet datasets demonstrate that AdvDiff is effective to generate unrestricted adversarial examples, which outperforms GAN-based methods in terms of attack performance and generation quality. ",
    "url": "https://arxiv.org/abs/2307.12499",
    "authors": [
      "Xuelong Dai",
      "Kaisheng Liang",
      "Bin Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12510",
    "title": "An Empirical Evaluation of Temporal Graph Benchmark",
    "abstract": "In this paper, we conduct an empirical evaluation of Temporal Graph Benchmark (TGB) by extending our Dynamic Graph Library (DyGLib) to TGB. Compared with TGB, we include eleven popular dynamic graph learning methods for more exhaustive comparisons. Through the experiments, we find that (1) some issues need to be addressed in the current version of TGB, including mismatched data statistics, inaccurate evaluation metric computation, and so on; (2) different models depict varying performance across various datasets, which is in line with previous observations; (3) the performance of some baselines can be significantly improved over the reported results in TGB when using DyGLib. This work aims to ease the researchers' efforts in evaluating various dynamic graph learning methods on TGB and attempts to offer results that can be directly referenced in the follow-up research. All the used resources in this project are publicly available at https://github.com/yule-BUAA/DyGLib_TGB. This work is in progress, and feedback from the community is welcomed for improvements. ",
    "url": "https://arxiv.org/abs/2307.12510",
    "authors": [
      "Le Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12518",
    "title": "FaFCNN: A General Disease Classification Framework Based on Feature  Fusion Neural Networks",
    "abstract": "There are two fundamental problems in applying deep learning/machine learning methods to disease classification tasks, one is the insufficient number and poor quality of training samples; another one is how to effectively fuse multiple source features and thus train robust classification models. To address these problems, inspired by the process of human learning knowledge, we propose the Feature-aware Fusion Correlation Neural Network (FaFCNN), which introduces a feature-aware interaction module and a feature alignment module based on domain adversarial learning. This is a general framework for disease classification, and FaFCNN improves the way existing methods obtain sample correlation features. The experimental results show that training using augmented features obtained by pre-training gradient boosting decision tree yields more performance gains than random-forest based methods. On the low-quality dataset with a large amount of missing data in our setup, FaFCNN obtains a consistently optimal performance compared to competitive baselines. In addition, extensive experiments demonstrate the robustness of the proposed method and the effectiveness of each component of the model\\footnote{Accepted in IEEE SMC2023}. ",
    "url": "https://arxiv.org/abs/2307.12518",
    "authors": [
      "Menglin Kong",
      "Shaojie Zhao",
      "Juan Cheng",
      "Xingquan Li",
      "Ri Su",
      "Muzhou Hou",
      "Cong Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2307.12519",
    "title": "DEPHN: Different Expression Parallel Heterogeneous Network using virtual  gradient optimization for Multi-task Learning",
    "abstract": "Recommendation system algorithm based on multi-task learning (MTL) is the major method for Internet operators to understand users and predict their behaviors in the multi-behavior scenario of platform. Task correlation is an important consideration of MTL goals, traditional models use shared-bottom models and gating experts to realize shared representation learning and information differentiation. However, The relationship between real-world tasks is often more complex than existing methods do not handle properly sharing information. In this paper, we propose an Different Expression Parallel Heterogeneous Network (DEPHN) to model multiple tasks simultaneously. DEPHN constructs the experts at the bottom of the model by using different feature interaction methods to improve the generalization ability of the shared information flow. In view of the model's differentiating ability for different task information flows, DEPHN uses feature explicit mapping and virtual gradient coefficient for expert gating during the training process, and adaptively adjusts the learning intensity of the gated unit by considering the difference of gating values and task correlation. Extensive experiments on artificial and real-world datasets demonstrate that our proposed method can capture task correlation in complex situations and achieve better performance than baseline models\\footnote{Accepted in IJCNN2023}. ",
    "url": "https://arxiv.org/abs/2307.12519",
    "authors": [
      "Menglin Kong",
      "Ri Su",
      "Shaojie Zhao",
      "Muzhou Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12520",
    "title": "Lost In Translation: Generating Adversarial Examples Robust to  Round-Trip Translation",
    "abstract": "Language Models today provide a high accuracy across a large number of downstream tasks. However, they remain susceptible to adversarial attacks, particularly against those where the adversarial examples maintain considerable similarity to the original text. Given the multilingual nature of text, the effectiveness of adversarial examples across translations and how machine translations can improve the robustness of adversarial examples remain largely unexplored. In this paper, we present a comprehensive study on the robustness of current text adversarial attacks to round-trip translation. We demonstrate that 6 state-of-the-art text-based adversarial attacks do not maintain their efficacy after round-trip translation. Furthermore, we introduce an intervention-based solution to this problem, by integrating Machine Translation into the process of adversarial example generation and demonstrating increased robustness to round-trip translation. Our results indicate that finding adversarial examples robust to translation can help identify the insufficiency of language models that is common across languages, and motivate further research into multilingual adversarial attacks. ",
    "url": "https://arxiv.org/abs/2307.12520",
    "authors": [
      "Neel Bhandari",
      "Pin-Yu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12524",
    "title": "Landslide Surface Displacement Prediction Based on VSXC-LSTM Algorithm",
    "abstract": "Landslide is a natural disaster that can easily threaten local ecology, people's lives and property. In this paper, we conduct modelling research on real unidirectional surface displacement data of recent landslides in the research area and propose a time series prediction framework named VMD-SegSigmoid-XGBoost-ClusterLSTM (VSXC-LSTM) based on variational mode decomposition, which can predict the landslide surface displacement more accurately. The model performs well on the test set. Except for the random item subsequence that is hard to fit, the root mean square error (RMSE) and the mean absolute percentage error (MAPE) of the trend item subsequence and the periodic item subsequence are both less than 0.1, and the RMSE is as low as 0.006 for the periodic item prediction module based on XGBoost\\footnote{Accepted in ICANN2023}. ",
    "url": "https://arxiv.org/abs/2307.12524",
    "authors": [
      "Menglin Kong",
      "Ruichen Li",
      "Fan Liu",
      "Xingquan Li",
      "Juan Cheng",
      "Muzhou Hou",
      "Cong Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2307.12526",
    "title": "Rethinking Medical Report Generation: Disease Revealing Enhancement with  Knowledge Graph",
    "abstract": "Knowledge Graph (KG) plays a crucial role in Medical Report Generation (MRG) because it reveals the relations among diseases and thus can be utilized to guide the generation process. However, constructing a comprehensive KG is labor-intensive and its applications on the MRG process are under-explored. In this study, we establish a complete KG on chest X-ray imaging that includes 137 types of diseases and abnormalities. Based on this KG, we find that the current MRG data sets exhibit a long-tailed problem in disease distribution. To mitigate this problem, we introduce a novel augmentation strategy that enhances the representation of disease types in the tail-end of the distribution. We further design a two-stage MRG approach, where a classifier is first trained to detect whether the input images exhibit any abnormalities. The classified images are then independently fed into two transformer-based generators, namely, ``disease-specific generator\" and ``disease-free generator\" to generate the corresponding reports. To enhance the clinical evaluation of whether the generated reports correctly describe the diseases appearing in the input image, we propose diverse sensitivity (DS), a new metric that checks whether generated diseases match ground truth and measures the diversity of all generated diseases. Results show that the proposed two-stage generation framework and augmentation strategies improve DS by a considerable margin, indicating a notable reduction in the long-tailed problem associated with under-represented diseases. ",
    "url": "https://arxiv.org/abs/2307.12526",
    "authors": [
      "Yixin Wang",
      "Zihao Lin",
      "Haoyu Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12532",
    "title": "On the Connection between Pre-training Data Diversity and Fine-tuning  Robustness",
    "abstract": "Pre-training has been widely adopted in deep learning to improve model performance, especially when the training data for a target task is limited. In our work, we seek to understand the implications of this training strategy on the generalization properties of downstream models. More specifically, we ask the following question: how do properties of the pre-training distribution affect the robustness of a fine-tuned model? The properties we explore include the label space, label semantics, image diversity, data domains, and data quantity of the pre-training distribution. We find that the primary factor influencing downstream effective robustness (Taori et al., 2020) is data quantity, while other factors have limited significance. For example, reducing the number of ImageNet pre-training classes by 4x while increasing the number of images per class by 4x (that is, keeping total data quantity fixed) does not impact the robustness of fine-tuned models. We demonstrate our findings on pre-training distributions drawn from various natural and synthetic data sources, primarily using the iWildCam-WILDS distribution shift as a test for downstream robustness. ",
    "url": "https://arxiv.org/abs/2307.12532",
    "authors": [
      "Vivek Ramanujan",
      "Thao Nguyen",
      "Sewoong Oh",
      "Ludwig Schmidt",
      "Ali Farhadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12534",
    "title": "Towards Generalizable Deepfake Detection by Primary Region  Regularization",
    "abstract": "The existing deepfake detection methods have reached a bottleneck in generalizing to unseen forgeries and manipulation approaches. Based on the observation that the deepfake detectors exhibit a preference for overfitting the specific primary regions in input, this paper enhances the generalization capability from a novel regularization perspective. This can be simply achieved by augmenting the images through primary region removal, thereby preventing the detector from over-relying on data bias. Our method consists of two stages, namely the static localization for primary region maps, as well as the dynamic exploitation of primary region masks. The proposed method can be seamlessly integrated into different backbones without affecting their inference efficiency. We conduct extensive experiments over three widely used deepfake datasets - DFDC, DF-1.0, and Celeb-DF with five backbones. Our method demonstrates an average performance improvement of 6% across different backbones and performs competitively with several state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2307.12534",
    "authors": [
      "Harry Cheng",
      "Yangyang Guo",
      "Tianyi Wang",
      "Liqiang Nie",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12540",
    "title": "SelFormaly: Towards Task-Agnostic Unified Anomaly Detection",
    "abstract": "The core idea of visual anomaly detection is to learn the normality from normal images, but previous works have been developed specifically for certain tasks, leading to fragmentation among various tasks: defect detection, semantic anomaly detection, multi-class anomaly detection, and anomaly clustering. This one-task-one-model approach is resource-intensive and incurs high maintenance costs as the number of tasks increases. This paper presents SelFormaly, a universal and powerful anomaly detection framework. We emphasize the necessity of our off-the-shelf approach by pointing out a suboptimal issue with fluctuating performance in previous online encoder-based methods. In addition, we question the effectiveness of using ConvNets as previously employed in the literature and confirm that self-supervised ViTs are suitable for unified anomaly detection. We introduce back-patch masking and discover the new role of top k-ratio feature matching to achieve unified and powerful anomaly detection. Back-patch masking eliminates irrelevant regions that possibly hinder target-centric detection with representations of the scene layout. The top k-ratio feature matching unifies various anomaly levels and tasks. Finally, SelFormaly achieves state-of-the-art results across various datasets for all the aforementioned tasks. ",
    "url": "https://arxiv.org/abs/2307.12540",
    "authors": [
      "Yujin Lee",
      "Harin Lim",
      "Hyunsoo Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.12542",
    "title": "Client-Level Differential Privacy via Adaptive Intermediary in Federated  Medical Imaging",
    "abstract": "Despite recent progress in enhancing the privacy of federated learning (FL) via differential privacy (DP), the trade-off of DP between privacy protection and performance is still underexplored for real-world medical scenario. In this paper, we propose to optimize the trade-off under the context of client-level DP, which focuses on privacy during communications. However, FL for medical imaging involves typically much fewer participants (hospitals) than other domains (e.g., mobile devices), thus ensuring clients be differentially private is much more challenging. To tackle this problem, we propose an adaptive intermediary strategy to improve performance without harming privacy. Specifically, we theoretically find splitting clients into sub-clients, which serve as intermediaries between hospitals and the server, can mitigate the noises introduced by DP without harming privacy. Our proposed approach is empirically evaluated on both classification and segmentation tasks using two public datasets, and its effectiveness is demonstrated with significant performance improvements and comprehensive analytical studies. Code is available at: https://github.com/med-air/Client-DP-FL. ",
    "url": "https://arxiv.org/abs/2307.12542",
    "authors": [
      "Meirui Jiang",
      "Yuan Zhong",
      "Anjie Le",
      "Xiaoxiao Li",
      "Qi Dou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.12548",
    "title": "MFMAN-YOLO: A Method for Detecting Pole-like Obstacles in Complex  Environment",
    "abstract": "In real-world traffic, there are various uncertainties and complexities in road and weather conditions. To solve the problem that the feature information of pole-like obstacles in complex environments is easily lost, resulting in low detection accuracy and low real-time performance, a multi-scale hybrid attention mechanism detection algorithm is proposed in this paper. First, the optimal transport function Monge-Kantorovich (MK) is incorporated not only to solve the problem of overlapping multiple prediction frames with optimal matching but also the MK function can be regularized to prevent model over-fitting; then, the features at different scales are up-sampled separately according to the optimized efficient multi-scale feature pyramid. Finally, the extraction of multi-scale feature space channel information is enhanced in complex environments based on the hybrid attention mechanism, which suppresses the irrelevant complex environment background information and focuses the feature information of pole-like obstacles. Meanwhile, this paper conducts real road test experiments in a variety of complex environments. The experimental results show that the detection precision, recall, and average precision of the method are 94.7%, 93.1%, and 97.4%, respectively, and the detection frame rate is 400 f/s. This research method can detect pole-like obstacles in a complex road environment in real time and accurately, which further promotes innovation and progress in the field of automatic driving. ",
    "url": "https://arxiv.org/abs/2307.12548",
    "authors": [
      "Lei Cai",
      "Hao Wang",
      "Congling Zhou",
      "Yongqiang Wang",
      "Boyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12555",
    "title": "Homophily-Driven Sanitation View for Robust Graph Contrastive Learning",
    "abstract": "We investigate adversarial robustness of unsupervised Graph Contrastive Learning (GCL) against structural attacks. First, we provide a comprehensive empirical and theoretical analysis of existing attacks, revealing how and why they downgrade the performance of GCL. Inspired by our analytic results, we present a robust GCL framework that integrates a homophily-driven sanitation view, which can be learned jointly with contrastive learning. A key challenge this poses, however, is the non-differentiable nature of the sanitation objective. To address this challenge, we propose a series of techniques to enable gradient-based end-to-end robust GCL. Moreover, we develop a fully unsupervised hyperparameter tuning method which, unlike prior approaches, does not require knowledge of node labels. We conduct extensive experiments to evaluate the performance of our proposed model, GCHS (Graph Contrastive Learning with Homophily-driven Sanitation View), against two state of the art structural attacks on GCL. Our results demonstrate that GCHS consistently outperforms all state of the art baselines in terms of the quality of generated node embeddings as well as performance on two important downstream tasks. ",
    "url": "https://arxiv.org/abs/2307.12555",
    "authors": [
      "Yulin Zhu",
      "Xing Ai",
      "Yevgeniy Vorobeychik",
      "Kai Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2307.12564",
    "title": "Towards Generalising Neural Topical Representations",
    "abstract": "Topic models have evolved from conventional Bayesian probabilistic models to Neural Topic Models (NTMs) over the last two decays. Although NTMs have achieved promising performance when trained and tested on a specific corpus, their generalisation ability across corpora is rarely studied. In practice, we often expect that an NTM trained on a source corpus can still produce quality topical representation for documents in a different target corpus without retraining. In this work, we aim to improve NTMs further so that their benefits generalise reliably across corpora and tasks. To do so, we propose to model similar documents by minimising their semantical distance when training NTMs. Specifically, similar documents are created by data augmentation during training; The semantical distance between documents is measured by the Hierarchical Topic Transport Distance (HOTT), which computes the Optimal Transport (OT) distance between the topical representations. Our framework can be readily applied to most NTMs as a plug-and-play module. Extensive experiments show that our framework significantly improves the generalisation ability regarding neural topical representation across corpora. ",
    "url": "https://arxiv.org/abs/2307.12564",
    "authors": [
      "Xiaohao Yang",
      "He Zhao",
      "Dinh Phung",
      "Lan Du"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12573",
    "title": "Tachikuma: Understading Complex Interactions with Multi-Character and  Novel Objects by Large Language Models",
    "abstract": "Recent advancements in natural language and Large Language Models (LLMs) have enabled AI agents to simulate human-like interactions within virtual worlds. However, these interactions still face limitations in complexity and flexibility, particularly in scenarios involving multiple characters and novel objects. Pre-defining all interactable objects in the agent's world model presents challenges, and conveying implicit intentions to multiple characters through complex interactions remains difficult. To address these issues, we propose integrating virtual Game Masters (GMs) into the agent's world model, drawing inspiration from Tabletop Role-Playing Games (TRPGs). GMs play a crucial role in overseeing information, estimating players' intentions, providing environment descriptions, and offering feedback, compensating for current world model deficiencies. To facilitate future explorations for complex interactions, we introduce a benchmark named Tachikuma, comprising a Multiple character and novel Object based interaction Estimation (MOE) task and a supporting dataset. MOE challenges models to understand characters' intentions and accurately determine their actions within intricate contexts involving multi-character and novel object interactions. Besides, the dataset captures log data from real-time communications during gameplay, providing diverse, grounded, and complex interactions for further explorations. Finally, we present a simple prompting baseline and evaluate its performance, demonstrating its effectiveness in enhancing interaction understanding. We hope that our dataset and task will inspire further research in complex interactions with natural language, fostering the development of more advanced AI agents. ",
    "url": "https://arxiv.org/abs/2307.12573",
    "authors": [
      "Yuanzhi Liang",
      "Linchao Zhu",
      "Yi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.12577",
    "title": "PRIOR: Prototype Representation Joint Learning from Medical Images and  Reports",
    "abstract": "Contrastive learning based vision-language joint pre-training has emerged as a successful representation learning strategy. In this paper, we present a prototype representation learning framework incorporating both global and local alignment between medical images and reports. In contrast to standard global multi-modality alignment methods, we employ a local alignment module for fine-grained representation. Furthermore, a cross-modality conditional reconstruction module is designed to interchange information across modalities in the training phase by reconstructing masked images and reports. For reconstructing long reports, a sentence-wise prototype memory bank is constructed, enabling the network to focus on low-level localized visual and high-level clinical linguistic features. Additionally, a non-auto-regressive generation paradigm is proposed for reconstructing non-sequential reports. Experimental results on five downstream tasks, including supervised classification, zero-shot classification, image-to-text retrieval, semantic segmentation, and object detection, show the proposed method outperforms other state-of-the-art methods across multiple datasets and under different dataset size settings. The code is available at https://github.com/QtacierP/PRIOR. ",
    "url": "https://arxiv.org/abs/2307.12577",
    "authors": [
      "Pujin Cheng",
      "Li Lin",
      "Junyan Lyu",
      "Yijin Huang",
      "Wenhan Luo",
      "Xiaoying Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12596",
    "title": "Refining ChatGPT-Generated Code: Characterizing and Mitigating Code  Quality Issues",
    "abstract": "In this paper, we systematically study the quality of 4,066 ChatGPT-generated code implemented in two popular programming languages, i.e., Java and Python, for 2,033 programming tasks. The goal of this work is three folds. First, we analyze the correctness of ChatGPT on code generation tasks and uncover the factors that influence its effectiveness, including task difficulty, programming language, time that tasks are introduced, and program size. Second, we identify and characterize potential issues with the quality of ChatGPT-generated code. Last, we provide insights into how these issues can be mitigated. Experiments highlight that out of 4,066 programs generated by ChatGPT, 2,757 programs are deemed correct, 1,081 programs provide wrong outputs, and 177 programs contain compilation or runtime errors. Additionally, we further analyze other characteristics of the generated code through static analysis tools, such as code style and maintainability, and find that 1,933 ChatGPT-generated code snippets suffer from maintainability issues. Subsequently, we investigate ChatGPT's self-debugging ability and its interaction with static analysis tools to fix the errors uncovered in the previous step. Experiments suggest that ChatGPT can partially address these challenges, improving code quality by more than 20%, but there are still limitations and opportunities for improvement. Overall, our study provides valuable insights into the current limitations of ChatGPT and offers a roadmap for future research and development efforts to enhance the code generation capabilities of AI models like ChatGPT. ",
    "url": "https://arxiv.org/abs/2307.12596",
    "authors": [
      "Yue Liu",
      "Thanh Le-Cong",
      "Ratnadira Widyasari",
      "Chakkrit Tantithamthavorn",
      "Li Li",
      "Xuan-Bach D. Le",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2307.12601",
    "title": "Concept backpropagation: An Explainable AI approach for visualising  learned concepts in neural network models",
    "abstract": "Neural network models are widely used in a variety of domains, often as black-box solutions, since they are not directly interpretable for humans. The field of explainable artificial intelligence aims at developing explanation methods to address this challenge, and several approaches have been developed over the recent years, including methods for investigating what type of knowledge these models internalise during the training process. Among these, the method of concept detection, investigates which \\emph{concepts} neural network models learn to represent in order to complete their tasks. In this work, we present an extension to the method of concept detection, named \\emph{concept backpropagation}, which provides a way of analysing how the information representing a given concept is internalised in a given neural network model. In this approach, the model input is perturbed in a manner guided by a trained concept probe for the described model, such that the concept of interest is maximised. This allows for the visualisation of the detected concept directly in the input space of the model, which in turn makes it possible to see what information the model depends on for representing the described concept. We present results for this method applied to a various set of input modalities, and discuss how our proposed method can be used to visualise what information trained concept probes use, and the degree as to which the representation of the probed concept is entangled within the neural network model itself. ",
    "url": "https://arxiv.org/abs/2307.12601",
    "authors": [
      "Patrik Hammersborg",
      "Inga Str\u00fcmke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12602",
    "title": "Shortest two disjoint paths in conservative graphs",
    "abstract": "We consider the following problem that we call the Shortest Two Disjoint Paths problem: given an undirected graph $G=(V,E)$ with edge weights $w:E\\rightarrow \\mathbb{R}$, two terminals $s$ and $t$ in $G$, find two internally vertex-disjoint paths between $s$ and $t$ with minimum total weight. As shown recently by Schlotter and Seb\\H{o} (2023), this problem becomes NP-hard if edges can have negative weights, even if the weight function is conservative, i.e., there are are no cycles in $G$ with negative weight. We propose a polynomial-time algorithm that solves the Shortest Two Disjoint Paths problem for conservative weights in the case when the negative-weight edges form a single tree in $G$. ",
    "url": "https://arxiv.org/abs/2307.12602",
    "authors": [
      "Ildik\u00f3 Schlotter"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2307.12625",
    "title": "De-confounding Representation Learning for Counterfactual Inference on  Continuous Treatment via Generative Adversarial Network",
    "abstract": "Counterfactual inference for continuous rather than binary treatment variables is more common in real-world causal inference tasks. While there are already some sample reweighting methods based on Marginal Structural Model for eliminating the confounding bias, they generally focus on removing the treatment's linear dependence on confounders and rely on the accuracy of the assumed parametric models, which are usually unverifiable. In this paper, we propose a de-confounding representation learning (DRL) framework for counterfactual outcome estimation of continuous treatment by generating the representations of covariates disentangled with the treatment variables. The DRL is a non-parametric model that eliminates both linear and nonlinear dependence between treatment and covariates. Specifically, we train the correlations between the de-confounded representations and the treatment variables against the correlations between the covariate representations and the treatment variables to eliminate confounding bias. Further, a counterfactual inference network is embedded into the framework to make the learned representations serve both de-confounding and trusted inference. Extensive experiments on synthetic datasets show that the DRL model performs superiorly in learning de-confounding representations and outperforms state-of-the-art counterfactual inference models for continuous treatment variables. In addition, we apply the DRL model to a real-world medical dataset MIMIC and demonstrate a detailed causal relationship between red cell width distribution and mortality. ",
    "url": "https://arxiv.org/abs/2307.12625",
    "authors": [
      "Yonghe Zhao",
      "Qiang Huang",
      "Haolong Zeng",
      "Yun Pen",
      "Huiyan Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2307.12637",
    "title": "PG-RCNN: Semantic Surface Point Generation for 3D Object Detection",
    "abstract": "One of the main challenges in LiDAR-based 3D object detection is that the sensors often fail to capture the complete spatial information about the objects due to long distance and occlusion. Two-stage detectors with point cloud completion approaches tackle this problem by adding more points to the regions of interest (RoIs) with a pre-trained network. However, these methods generate dense point clouds of objects for all region proposals, assuming that objects always exist in the RoIs. This leads to the indiscriminate point generation for incorrect proposals as well. Motivated by this, we propose Point Generation R-CNN (PG-RCNN), a novel end-to-end detector that generates semantic surface points of foreground objects for accurate detection. Our method uses a jointly trained RoI point generation module to process the contextual information of RoIs and estimate the complete shape and displacement of foreground objects. For every generated point, PG-RCNN assigns a semantic feature that indicates the estimated foreground probability. Extensive experiments show that the point clouds generated by our method provide geometrically and semantically rich information for refining false positive and misaligned proposals. PG-RCNN achieves competitive performance on the KITTI benchmark, with significantly fewer parameters than state-of-the-art models. The code is available at https://github.com/quotation2520/PG-RCNN. ",
    "url": "https://arxiv.org/abs/2307.12637",
    "authors": [
      "Inyong Koo",
      "Inyoung Lee",
      "Se-Ho Kim",
      "Hee-Seon Kim",
      "Woo-jin Jeon",
      "Changick Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12639",
    "title": "Fake News Detection Through Graph-based Neural Networks: A Survey",
    "abstract": "The popularity of online social networks has enabled rapid dissemination of information. People now can share and consume information much more rapidly than ever before. However, low-quality and/or accidentally/deliberately fake information can also spread rapidly. This can lead to considerable and negative impacts on society. Identifying, labelling and debunking online misinformation as early as possible has become an increasingly urgent problem. Many methods have been proposed to detect fake news including many deep learning and graph-based approaches. In recent years, graph-based methods have yielded strong results, as they can closely model the social context and propagation process of online news. In this paper, we present a systematic review of fake news detection studies based on graph-based and deep learning-based techniques. We classify existing graph-based methods into knowledge-driven methods, propagation-based methods, and heterogeneous social context-based methods, depending on how a graph structure is constructed to model news related information flows. We further discuss the challenges and open problems in graph-based fake news detection and identify future research directions. ",
    "url": "https://arxiv.org/abs/2307.12639",
    "authors": [
      "Shuzhi Gong",
      "Richard O. Sinnott",
      "Jianzhong Qi",
      "Cecile Paris"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12648",
    "title": "Execution at RISC: Stealth JOP Attacks on RISC-V Applications",
    "abstract": "RISC-V is a recently developed open instruction set architecture gaining a lot of attention. To achieve a lasting security on these systems and design efficient countermeasures, a better understanding of vulnerabilities to novel and potential future attacks is mandatory. This paper demonstrates that RISC-V is sensible to Jump-Oriented Programming, a class of complex code-reuse attacks. We provide an analysis of new dispatcher gadgets we discovered, and show how they can be used together in order to build a stealth attack, bypassing existing protections. A proof-of-concept attack is implemented on an embedded web server compiled for RISC-V, in which we introduced a vulnerability, allowing an attacker to remotely read an arbitrary file from the host machine. ",
    "url": "https://arxiv.org/abs/2307.12648",
    "authors": [
      "Lo\u00efc Buckwell",
      "Olivier Gilles",
      "Daniel Gracia P\u00e9rez",
      "Nikolai Kosmatov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2307.12676",
    "title": "Damage Vision Mining Opportunity for Imbalanced Anomaly Detection",
    "abstract": "In past decade, previous balanced datasets have been used to advance algorithms for classification, object detection, semantic segmentation, and anomaly detection in industrial applications. Specifically, for condition-based maintenance, automating visual inspection is crucial to ensure high quality. Deterioration prognostic attempts to optimize the fine decision process for predictive maintenance and proactive repair. In civil infrastructure and living environment, damage data mining cannot avoid the imbalanced data issue because of rare unseen events and high quality status by improved operations. For visual inspection, deteriorated class acquired from the surface of concrete and steel components are occasionally imbalanced. From numerous related surveys, we summarize that imbalanced data problems can be categorized into four types; 1) missing range of target and label valuables, 2) majority-minority class imbalance, 3) foreground-background of spatial imbalance, 4) long-tailed class of pixel-wise imbalance. Since 2015, there has been many imbalanced studies using deep learning approaches that includes regression, image classification, object detection, semantic segmentation. However, anomaly detection for imbalanced data is not yet well known. In the study, we highlight one-class anomaly detection application whether anomalous class or not, and demonstrate clear examples on imbalanced vision datasets: wooden, concrete deterioration, and disaster damage. We provide key results on damage vision mining advantage, hypothesizing that the more effective range of positive ratio, the higher accuracy gain of anomaly detection application. Finally, the applicability of the damage learning methods, limitations, and future works are mentioned. ",
    "url": "https://arxiv.org/abs/2307.12676",
    "authors": [
      "Takato Yasuno"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12679",
    "title": "An Estimator for the Sensitivity to Perturbations of Deep Neural  Networks",
    "abstract": "For Deep Neural Networks (DNNs) to become useful in safety-critical applications, such as self-driving cars and disease diagnosis, they must be stable to perturbations in input and model parameters. Characterizing the sensitivity of a DNN to perturbations is necessary to determine minimal bit-width precision that may be used to safely represent the network. However, no general result exists that is capable of predicting the sensitivity of a given DNN to round-off error, noise, or other perturbations in input. This paper derives an estimator that can predict such quantities. The estimator is derived via inequalities and matrix norms, and the resulting quantity is roughly analogous to a condition number for the entire neural network. An approximation of the estimator is tested on two Convolutional Neural Networks, AlexNet and VGG-19, using the ImageNet dataset. For each of these networks, the tightness of the estimator is explored via random perturbations and adversarial attacks. ",
    "url": "https://arxiv.org/abs/2307.12679",
    "authors": [
      "Naman Maheshwari",
      "Nicholas Malaya",
      "Scott Moe",
      "Jaydeep P. Kulkarni",
      "Sudhanva Gurumurthi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.12689",
    "title": "Addressing the Impact of Localized Training Data in Graph Neural  Networks",
    "abstract": "Graph Neural Networks (GNNs) have achieved notable success in learning from graph-structured data, owing to their ability to capture intricate dependencies and relationships between nodes. They excel in various applications, including semi-supervised node classification, link prediction, and graph generation. However, it is important to acknowledge that the majority of state-of-the-art GNN models are built upon the assumption of an in-distribution setting, which hinders their performance on real-world graphs with dynamic structures. In this article, we aim to assess the impact of training GNNs on localized subsets of the graph. Such restricted training data may lead to a model that performs well in the specific region it was trained on but fails to generalize and make accurate predictions for the entire graph. In the context of graph-based semi-supervised learning (SSL), resource constraints often lead to scenarios where the dataset is large, but only a portion of it can be labeled, affecting the model's performance. This limitation affects tasks like anomaly detection or spam detection when labeling processes are biased or influenced by human subjectivity. To tackle the challenges posed by localized training data, we approach the problem as an out-of-distribution (OOD) data issue by by aligning the distributions between the training data, which represents a small portion of labeled data, and the graph inference process that involves making predictions for the entire graph. We propose a regularization method to minimize distributional discrepancies between localized training data and graph inference, improving model performance on OOD data. Extensive tests on popular GNN models show significant performance improvement on three citation GNN benchmark datasets. The regularization approach effectively enhances model adaptation and generalization, overcoming challenges posed by OOD data. ",
    "url": "https://arxiv.org/abs/2307.12689",
    "authors": [
      "Singh Akansha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.12698",
    "title": "MC-JEPA: A Joint-Embedding Predictive Architecture for Self-Supervised  Learning of Motion and Content Features",
    "abstract": "Self-supervised learning of visual representations has been focusing on learning content features, which do not capture object motion or location, and focus on identifying and differentiating objects in images and videos. On the other hand, optical flow estimation is a task that does not involve understanding the content of the images on which it is estimated. We unify the two approaches and introduce MC-JEPA, a joint-embedding predictive architecture and self-supervised learning approach to jointly learn optical flow and content features within a shared encoder, demonstrating that the two associated objectives; the optical flow estimation objective and the self-supervised learning objective; benefit from each other and thus learn content features that incorporate motion information. The proposed approach achieves performance on-par with existing unsupervised optical flow benchmarks, as well as with common self-supervised learning approaches on downstream tasks such as semantic segmentation of images and videos. ",
    "url": "https://arxiv.org/abs/2307.12698",
    "authors": [
      "Adrien Bardes",
      "Jean Ponce",
      "Yann LeCun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12701",
    "title": "Leveraging Large Language Models (LLMs) for Process Mining (Technical  Report)",
    "abstract": "This technical report describes the intersection of process mining and large language models (LLMs), specifically focusing on the abstraction of traditional and object-centric process mining artifacts into textual format. We introduce and explore various prompting strategies: direct answering, where the large language model directly addresses user queries; multi-prompt answering, which allows the model to incrementally build on the knowledge obtained through a series of prompts; and the generation of database queries, facilitating the validation of hypotheses against the original event log. Our assessment considers two large language models, GPT-4 and Google's Bard, under various contextual scenarios across all prompting strategies. Results indicate that these models exhibit a robust understanding of key process mining abstractions, with notable proficiency in interpreting both declarative and procedural process models. In addition, we find that both models demonstrate strong performance in the object-centric setting, which could significantly propel the advancement of the object-centric process mining discipline. Additionally, these models display a noteworthy capacity to evaluate various concepts of fairness in process mining. This opens the door to more rapid and efficient assessments of the fairness of process mining event logs, which has significant implications for the field. The integration of these large language models into process mining applications may open new avenues for exploration, innovation, and insight generation in the field. ",
    "url": "https://arxiv.org/abs/2307.12701",
    "authors": [
      "Alessandro Berti",
      "Mahnaz Sadat Qafari"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2307.12709",
    "title": "A Dynamic Equivalent Energy Storage Model of Natural Gas Networks for  Joint Optimal Dispatch of Electricity-Gas Systems",
    "abstract": "The development of energy conversion techniques enhances the coupling between the gas network and power system. However, challenges remain in the joint optimal dispatch of electricity-gas systems. The dynamic model of the gas network, described by partial differential equations, is complex and computationally demanding for power system operators. Furthermore, information privacy concerns and limited accessibility to detailed gas network models by power system operators necessitate quantifying the equivalent energy storage capacity of gas networks. This paper proposes a multi-port energy storage model with time-varying capacity to represent the dynamic gas state transformation and operational constraints in a compact and intuitive form. The model can be easily integrated into the optimal dispatch problem of the power system. Test cases demonstrate that the proposed model ensures feasible control strategies and significantly reduces the computational burden while maintaining high accuracy in the joint optimal dispatch of electricity-gas systems. In contrast, the existing static equivalent model fails to capture the full flexibility of the gas network and may yield infeasible results. ",
    "url": "https://arxiv.org/abs/2307.12709",
    "authors": [
      "Siyuan Wang",
      "Wenchuan Wu",
      "Chenhui Lin",
      "Binbin Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.12715",
    "title": "Safety monitoring under stealthy sensor injection attacks using  reachable sets",
    "abstract": "Stealthy sensor injection attacks are serious threats for industrial plants as they can compromise the plant's integrity without being detected by traditional fault detectors. In this manuscript, we study the possibility of revealing the presence of such attacks by monitoring only the control input. This approach consists in computing an ellipsoidal bound of the input reachable set. When the control input does not belong to this set, this means that a stealthy sensor injection attack is driving the plant to critical states. The problem of finding this ellipsoidal bound is posed as a convex optimization problem (convex cost with Linear Matrix Inequalities constraints). Our monitoring approach is tested in simulation. ",
    "url": "https://arxiv.org/abs/2307.12715",
    "authors": [
      "C\u00e9dric Escudero",
      "Michelle S. Chong",
      "Paolo Massioni",
      "Eric Zama\u00ef"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.12716",
    "title": "Safety Performance of Neural Networks in the Presence of Covariate Shift",
    "abstract": "Covariate shift may impact the operational safety performance of neural networks. A re-evaluation of the safety performance, however, requires collecting new operational data and creating corresponding ground truth labels, which often is not possible during operation. We are therefore proposing to reshape the initial test set, as used for the safety performance evaluation prior to deployment, based on an approximation of the operational data. This approximation is obtained by observing and learning the distribution of activation patterns of neurons in the network during operation. The reshaped test set reflects the distribution of neuron activation values as observed during operation, and may therefore be used for re-evaluating safety performance in the presence of covariate shift. First, we derive conservative bounds on the values of neurons by applying finite binning and static dataflow analysis. Second, we formulate a mixed integer linear programming (MILP) constraint for constructing the minimum set of data points to be removed in the test set, such that the difference between the discretized test and operational distributions is bounded. We discuss potential benefits and limitations of this constraint-based approach based on our initial experience with an implemented research prototype. ",
    "url": "https://arxiv.org/abs/2307.12716",
    "authors": [
      "Chih-Hong Cheng",
      "Harald Ruess",
      "Konstantinos Theodorou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2307.12717",
    "title": "Dense Transformer based Enhanced Coding Network for Unsupervised Metal  Artifact Reduction",
    "abstract": "CT images corrupted by metal artifacts have serious negative effects on clinical diagnosis. Considering the difficulty of collecting paired data with ground truth in clinical settings, unsupervised methods for metal artifact reduction are of high interest. However, it is difficult for previous unsupervised methods to retain structural information from CT images while handling the non-local characteristics of metal artifacts. To address these challenges, we proposed a novel Dense Transformer based Enhanced Coding Network (DTEC-Net) for unsupervised metal artifact reduction. Specifically, we introduce a Hierarchical Disentangling Encoder, supported by the high-order dense process, and transformer to obtain densely encoded sequences with long-range correspondence. Then, we present a second-order disentanglement method to improve the dense sequence's decoding process. Extensive experiments and model discussions illustrate DTEC-Net's effectiveness, which outperforms the previous state-of-the-art methods on a benchmark dataset, and greatly reduces metal artifacts while restoring richer texture details. ",
    "url": "https://arxiv.org/abs/2307.12717",
    "authors": [
      "Wangduo Xie",
      "Matthew B.Blaschko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.12721",
    "title": "AMAE: Adaptation of Pre-Trained Masked Autoencoder for Dual-Distribution  Anomaly Detection in Chest X-Rays",
    "abstract": "Unsupervised anomaly detection in medical images such as chest radiographs is stepping into the spotlight as it mitigates the scarcity of the labor-intensive and costly expert annotation of anomaly data. However, nearly all existing methods are formulated as a one-class classification trained only on representations from the normal class and discard a potentially significant portion of the unlabeled data. This paper focuses on a more practical setting, dual distribution anomaly detection for chest X-rays, using the entire training data, including both normal and unlabeled images. Inspired by a modern self-supervised vision transformer model trained using partial image inputs to reconstruct missing image regions -- we propose AMAE, a two-stage algorithm for adaptation of the pre-trained masked autoencoder (MAE). Starting from MAE initialization, AMAE first creates synthetic anomalies from only normal training images and trains a lightweight classifier on frozen transformer features. Subsequently, we propose an adaptation strategy to leverage unlabeled images containing anomalies. The adaptation scheme is accomplished by assigning pseudo-labels to unlabeled images and using two separate MAE based modules to model the normative and anomalous distributions of pseudo-labeled images. The effectiveness of the proposed adaptation strategy is evaluated with different anomaly ratios in an unlabeled training set. AMAE leads to consistent performance gains over competing self-supervised and dual distribution anomaly detection methods, setting the new state-of-the-art on three public chest X-ray benchmarks: RSNA, NIH-CXR, and VinDr-CXR. ",
    "url": "https://arxiv.org/abs/2307.12721",
    "authors": [
      "Behzad Bozorgtabar",
      "Dwarikanath Mahapatra",
      "Jean-Philippe Thiran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12750",
    "title": "DawnIK: Decentralized Collision-Aware Inverse Kinematics Solver for  Heterogeneous Multi-Arm Systems",
    "abstract": "Although inverse kinematics of serial manipulators is a well studied problem, challenges still exist in finding smooth feasible solutions that are also collision aware. Furthermore, with collaborative and service robots gaining traction, different robotic systems have to work in close proximity. This means that the current inverse kinematics approaches have to not only avoid collisions with themselves but also collisions with other robot arms. Therefore, we present a novel approach to compute inverse kinematics for serial manipulators that take into account different constraints while trying to reach a desired end-effector position and/or orientation that avoids collisions with themselves and other arms. Unlike other constraint based approaches, we neither perform expensive inverse Jacobian computations nor do we require arms with redundant degrees of freedom. Instead, we formulate different constraints as weighted cost functions to be optimized by a non-linear optimization solver. Our approach is superior to the state-of-the-art CollisionIK in terms of collision avoidance in the presence of multiple arms in confined spaces with no detected collisions at all in all the experimental scenarios. When the probability of collision is low, our approach shows better performance at trajectory tracking as well. Additionally, our approach is capable of simultaneous yet decentralized control of multiple arms for trajectory tracking in intersecting workspace without any collisions. ",
    "url": "https://arxiv.org/abs/2307.12750",
    "authors": [
      "Salih Marangoz",
      "Rohit Menon",
      "Nils Dengler",
      "Maren Bennewitz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.12756",
    "title": "Unbiased Delayed Feedback Label Correction for Conversion Rate  Prediction",
    "abstract": "Conversion rate prediction is critical to many online applications such as digital display advertising. To capture dynamic data distribution, industrial systems often require retraining models on recent data daily or weekly. However, the delay of conversion behavior usually leads to incorrect labeling, which is called delayed feedback problem. Existing work may fail to introduce the correct information about false negative samples due to data sparsity and dynamic data distribution. To directly introduce the correct feedback label information, we propose an Unbiased delayed feedback Label Correction framework (ULC), which uses an auxiliary model to correct labels for observed negative feedback samples. Firstly, we theoretically prove that the label-corrected loss is an unbiased estimate of the oracle loss using true labels. Then, as there are no ready training data for label correction, counterfactual labeling is used to construct artificial training data. Furthermore, since counterfactual labeling utilizes only partial training data, we design an embedding-based alternative training method to enhance performance. Comparative experiments on both public and private datasets and detailed analyses show that our proposed approach effectively alleviates the delayed feedback problem and consistently outperforms the previous state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2307.12756",
    "authors": [
      "Yifan Wang",
      "Peijie Sun",
      "Min Zhang",
      "Qinglin Jia",
      "Jingjie Li",
      "Shaoping Ma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2307.12777",
    "title": "Proceeding of the 1st Workshop on Social Robots Personalisation At the  crossroads between engineering and humanities (CONCATENATE)",
    "abstract": "Nowadays, robots are expected to interact more physically, cognitively, and socially with people. They should adapt to unpredictable contexts alongside individuals with various behaviours. For this reason, personalisation is a valuable attribute for social robots as it allows them to act according to a specific user's needs and preferences and achieve natural and transparent robot behaviours for humans. If correctly implemented, personalisation could also be the key to the large-scale adoption of social robotics. However, achieving personalisation is arduous as it requires us to expand the boundaries of robotics by taking advantage of the expertise of various domains. Indeed, personalised robots need to analyse and model user interactions while considering their involvement in the adaptative process. It also requires us to address ethical and socio-cultural aspects of personalised HRI to achieve inclusive and diverse interaction and avoid deception and misplaced trust when interacting with the users. At the same time, policymakers need to ensure regulations in view of possible short-term and long-term adaptive HRI. This workshop aims to raise an interdisciplinary discussion on personalisation in robotics. It aims at bringing researchers from different fields together to propose guidelines for personalisation while addressing the following questions: how to define it - how to achieve it - and how it should be guided to fit legal and ethical requirements. ",
    "url": "https://arxiv.org/abs/2307.12777",
    "authors": [
      "Imene Tarakli",
      "Georgios Angelopoulos",
      "Mehdi Hellou",
      "Camille Vindolet",
      "Boris Abramovic",
      "Rocco Limongelli",
      "Dimitri Lacroix",
      "Andrea Bertolini",
      "Silvia Rossi",
      "Alessandro Di Nuovo",
      "Angelo Cangelosi",
      "Gordon Cheng"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2307.12797",
    "title": "Causal Fair Machine Learning via Rank-Preserving Interventional  Distributions",
    "abstract": "A decision can be defined as fair if equal individuals are treated equally and unequals unequally. Adopting this definition, the task of designing machine learning models that mitigate unfairness in automated decision-making systems must include causal thinking when introducing protected attributes. Following a recent proposal, we define individuals as being normatively equal if they are equal in a fictitious, normatively desired (FiND) world, where the protected attribute has no (direct or indirect) causal effect on the target. We propose rank-preserving interventional distributions to define an estimand of this FiND world and a warping method for estimation. Evaluation criteria for both the method and resulting model are presented and validated through simulations and empirical data. With this, we show that our warping approach effectively identifies the most discriminated individuals and mitigates unfairness. ",
    "url": "https://arxiv.org/abs/2307.12797",
    "authors": [
      "Ludwig Bothmann",
      "Susanne Dandl",
      "Michael Schomaker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.12807",
    "title": "Comprehending Semantic Types in JSON Data with Graph Neural Networks",
    "abstract": "Semantic types are a more powerful and detailed way of describing data than atomic types such as strings or integers. They establish connections between columns and concepts from the real world, providing more nuanced and fine-grained information that can be useful for tasks such as automated data cleaning, schema matching, and data discovery. Existing deep learning models trained on large text corpora have been successful at performing single-column semantic type prediction for relational data. However, in this work, we propose an extension of the semantic type prediction problem to JSON data, labeling the types based on JSON Paths. Similar to columns in relational data, JSON Path is a query language that enables the navigation of complex JSON data structures by specifying the location and content of the elements. We use a graph neural network to comprehend the structural information within collections of JSON documents. Our model outperforms a state-of-the-art existing model in several cases. These results demonstrate the ability of our model to understand complex JSON data and its potential usage for JSON-related data processing tasks. ",
    "url": "https://arxiv.org/abs/2307.12807",
    "authors": [
      "Shuang Wei",
      "Michael J. Mior"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2307.12813",
    "title": "Exposing the Troublemakers in Described Object Detection",
    "abstract": "Detecting objects based on language descriptions is a popular task that includes Open-Vocabulary object Detection (OVD) and Referring Expression Comprehension (REC). In this paper, we advance them to a more practical setting called Described Object Detection (DOD) by expanding category names to flexible language expressions for OVD and overcoming the limitation of REC to only grounding the pre-existing object. We establish the research foundation for DOD tasks by constructing a Description Detection Dataset ($D^3$), featuring flexible language expressions and annotating all described objects without omission. By evaluating previous SOTA methods on $D^3$, we find some troublemakers that fail current REC, OVD, and bi-functional methods. REC methods struggle with confidence scores, rejecting negative instances, and multi-target scenarios, while OVD methods face constraints with long and complex descriptions. Recent bi-functional methods also do not work well on DOD due to their separated training procedures and inference strategies for REC and OVD tasks. Building upon the aforementioned findings, we propose a baseline that largely improves REC methods by reconstructing the training data and introducing a binary classification sub-task, outperforming existing methods. Data and code is available at https://github.com/shikras/d-cube. ",
    "url": "https://arxiv.org/abs/2307.12813",
    "authors": [
      "Chi Xie",
      "Zhao Zhang",
      "Yixuan Wu",
      "Feng Zhu",
      "Rui Zhao",
      "Shuang Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12822",
    "title": "Learning Provably Robust Estimators for Inverse Problems via Jittering",
    "abstract": "Deep neural networks provide excellent performance for inverse problems such as denoising. However, neural networks can be sensitive to adversarial or worst-case perturbations. This raises the question of whether such networks can be trained efficiently to be worst-case robust. In this paper, we investigate whether jittering, a simple regularization technique that adds isotropic Gaussian noise during training, is effective for learning worst-case robust estimators for inverse problems. While well studied for prediction in classification tasks, the effectiveness of jittering for inverse problems has not been systematically investigated. In this paper, we present a novel analytical characterization of the optimal $\\ell_2$-worst-case robust estimator for linear denoising and show that jittering yields optimal robust denoisers. Furthermore, we examine jittering empirically via training deep neural networks (U-nets) for natural image denoising, deconvolution, and accelerated magnetic resonance imaging (MRI). The results show that jittering significantly enhances the worst-case robustness, but can be suboptimal for inverse problems beyond denoising. Moreover, our results imply that training on real data which often contains slight noise is somewhat robustness enhancing. ",
    "url": "https://arxiv.org/abs/2307.12822",
    "authors": [
      "Anselm Krainovic",
      "Mahdi Soltanolkotabi",
      "Reinhard Heckel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.12833",
    "title": "Inferring social networks from observed groups",
    "abstract": "Collecting social network data directly from network members can be challenging. One alternative involves inferring a social network from individuals' memberships in observed groups, such as teams or clubs. Through a series of simulations, I explore when we can expect such inferences to be accurate. I find that an unobserved network can be inferred with high accuracy under a range of circumstances. In particular, I find that social networks inferred from observed groups are more accurate when (1) the unobserved network has a small world structure, (2) the groups are generated by a shuffling or agglomerative process, (3) a large number of groups are observed, and (4) the observed groups' compositions are tightly coupled to the unobserved network's structure. These findings offer guidance for researchers seeking to indirectly measure a social network of interest through observations of groups. ",
    "url": "https://arxiv.org/abs/2307.12833",
    "authors": [
      "Zachary P. Neal"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2307.12835",
    "title": "Joint Dropout: Improving Generalizability in Low-Resource Neural Machine  Translation through Phrase Pair Variables",
    "abstract": "Despite the tremendous success of Neural Machine Translation (NMT), its performance on low-resource language pairs still remains subpar, partly due to the limited ability to handle previously unseen inputs, i.e., generalization. In this paper, we propose a method called Joint Dropout, that addresses the challenge of low-resource neural machine translation by substituting phrases with variables, resulting in significant enhancement of compositionality, which is a key aspect of generalization. We observe a substantial improvement in translation quality for language pairs with minimal resources, as seen in BLEU and Direct Assessment scores. Furthermore, we conduct an error analysis, and find Joint Dropout to also enhance generalizability of low-resource NMT in terms of robustness and adaptability across different domains ",
    "url": "https://arxiv.org/abs/2307.12835",
    "authors": [
      "Ali Araabi",
      "Vlad Niculae",
      "Christof Monz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.12837",
    "title": "EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge: Mixed  Sequences Prediction",
    "abstract": "This report presents the technical details of our approach for the EPIC-Kitchens-100 Unsupervised Domain Adaptation (UDA) Challenge in Action Recognition. Our approach is based on the idea that the order in which actions are performed is similar between the source and target domains. Based on this, we generate a modified sequence by randomly combining actions from the source and target domains. As only unlabelled target data are available under the UDA setting, we use a standard pseudo-labeling strategy for extracting action labels for the target. We then ask the network to predict the resulting action sequence. This allows to integrate information from both domains during training and to achieve better transfer results on target. Additionally, to better incorporate sequence information, we use a language model to filter unlikely sequences. Lastly, we employed a co-occurrence matrix to eliminate unseen combinations of verbs and nouns. Our submission, labeled as 'sshayan', can be found on the leaderboard, where it currently holds the 2nd position for 'verb' and the 4th position for both 'noun' and 'action'. ",
    "url": "https://arxiv.org/abs/2307.12837",
    "authors": [
      "Amirshayan Nasirimajd",
      "Simone Alberto Peirone",
      "Chiara Plizzari",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.12840",
    "title": "Efficiently Learning One-Hidden-Layer ReLU Networks via Schur  Polynomials",
    "abstract": "We study the problem of PAC learning a linear combination of $k$ ReLU activations under the standard Gaussian distribution on $\\mathbb{R}^d$ with respect to the square loss. Our main result is an efficient algorithm for this learning task with sample and computational complexity $(dk/\\epsilon)^{O(k)}$, where $\\epsilon>0$ is the target accuracy. Prior work had given an algorithm for this problem with complexity $(dk/\\epsilon)^{h(k)}$, where the function $h(k)$ scales super-polynomially in $k$. Interestingly, the complexity of our algorithm is near-optimal within the class of Correlational Statistical Query algorithms. At a high-level, our algorithm uses tensor decomposition to identify a subspace such that all the $O(k)$-order moments are small in the orthogonal directions. Its analysis makes essential use of the theory of Schur polynomials to show that the higher-moment error tensors are small given that the lower-order ones are. ",
    "url": "https://arxiv.org/abs/2307.12840",
    "authors": [
      "Ilias Diakonikolas",
      "Daniel M. Kane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.12847",
    "title": "Securing Bystander Privacy in Mixed Reality While Protecting the User  Experience",
    "abstract": "The modern Mixed Reality devices that make the Metaverse viable can also require vast information about the physical world. These devices can also violate the privacy of unsuspecting or unwilling bystanders in their vicinity. In this article, we explore the problem, existing solutions, and avenues for future research. ",
    "url": "https://arxiv.org/abs/2307.12847",
    "authors": [
      "Matthew Corbett",
      "Brendan David-John",
      "Jiacheng Shang",
      "Y. Charlie Hu",
      "Bo Ji"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.12851",
    "title": "Early Neuron Alignment in Two-layer ReLU Networks with Small  Initialization",
    "abstract": "This paper studies the problem of training a two-layer ReLU network for binary classification using gradient flow with small initialization. We consider a training dataset with well-separated input vectors: Any pair of input data with the same label are positively correlated, and any pair with different labels are negatively correlated. Our analysis shows that, during the early phase of training, neurons in the first layer try to align with either the positive data or the negative data, depending on its corresponding weight on the second layer. A careful analysis of the neurons' directional dynamics allows us to provide an $\\mathcal{O}(\\frac{\\log n}{\\sqrt{\\mu}})$ upper bound on the time it takes for all neurons to achieve good alignment with the input data, where $n$ is the number of data points and $\\mu$ measures how well the data are separated. After the early alignment phase, the loss converges to zero at a $\\mathcal{O}(\\frac{1}{t})$ rate, and the weight matrix on the first layer is approximately low-rank. Numerical experiments on the MNIST dataset illustrate our theoretical findings. ",
    "url": "https://arxiv.org/abs/2307.12851",
    "authors": [
      "Hancheng Min",
      "Ren\u00e9 Vidal",
      "Enrique Mallada"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12855",
    "title": "Efficient STL Control Synthesis under Asynchronous Temporal Robustness  Constraints",
    "abstract": "In time-critical systems, such as air traffic control systems, it is crucial to design control policies that are robust to timing uncertainty. Recently, the notion of Asynchronous Temporal Robustness (ATR) was proposed to capture the robustness of a system trajectory against individual time shifts in its sub-trajectories. In a multi-robot system, this may correspond to individual robots being delayed or early. Control synthesis under ATR constraints is challenging and has not yet been addressed. In this paper, we propose an efficient control synthesis method under ATR constraints which are defined with respect to simple safety or complex signal temporal logic specifications. Given an ATR bound, we compute a sequence of control inputs so that the specification is satisfied by the system as long as each sub-trajectory is shifted not more than the ATR bound. We avoid combinatorially exploring all shifted sub-trajectories by first identifying redundancy between them. We capture this insight by the notion of instant-shift pair sets, and then propose an optimization program that enforces the specification only over the instant-shift pair sets. We show soundness and completeness of our method and analyze its computational complexity. Finally, we present various illustrative case studies. ",
    "url": "https://arxiv.org/abs/2307.12855",
    "authors": [
      "Xinyi Yu",
      "Xiang Yin",
      "Lars Lindemann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.12858",
    "title": "Treatment Outcome Prediction for Intracerebral Hemorrhage via Generative  Prognostic Model with Imaging and Tabular Data",
    "abstract": "Intracerebral hemorrhage (ICH) is the second most common and deadliest form of stroke. Despite medical advances, predicting treat ment outcomes for ICH remains a challenge. This paper proposes a novel prognostic model that utilizes both imaging and tabular data to predict treatment outcome for ICH. Our model is trained on observational data collected from non-randomized controlled trials, providing reliable predictions of treatment success. Specifically, we propose to employ a variational autoencoder model to generate a low-dimensional prognostic score, which can effectively address the selection bias resulting from the non-randomized controlled trials. Importantly, we develop a variational distributions combination module that combines the information from imaging data, non-imaging clinical data, and treatment assignment to accurately generate the prognostic score. We conducted extensive experiments on a real-world clinical dataset of intracerebral hemorrhage. Our proposed method demonstrates a substantial improvement in treatment outcome prediction compared to existing state-of-the-art approaches. Code is available at https://github.com/med-air/TOP-GPM ",
    "url": "https://arxiv.org/abs/2307.12858",
    "authors": [
      "Wenao Ma",
      "Cheng Chen",
      "Jill Abrigo",
      "Calvin Hoi-Kwan Mak",
      "Yuqi Gong",
      "Nga Yan Chan",
      "Chu Han",
      "Zaiyi Liu",
      "Qi Dou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12862",
    "title": "Stochastic Step-wise Feature Selection for Exponential Random Graph  Models (ERGMs)",
    "abstract": "Statistical analysis of social networks provides valuable insights into complex network interactions across various scientific disciplines. However, accurate modeling of networks remains challenging due to the heavy computational burden and the need to account for observed network dependencies. Exponential Random Graph Models (ERGMs) have emerged as a promising technique used in social network modeling to capture network dependencies by incorporating endogenous variables. Nevertheless, using ERGMs poses multiple challenges, including the occurrence of ERGM degeneracy, which generates unrealistic and meaningless network structures. To address these challenges and enhance the modeling of collaboration networks, we propose and test a novel approach that focuses on endogenous variable selection within ERGMs. Our method aims to overcome the computational burden and improve the accommodation of observed network dependencies, thereby facilitating more accurate and meaningful interpretations of network phenomena in various scientific fields. We conduct empirical testing and rigorous analysis to contribute to the advancement of statistical techniques and offer practical insights for network analysis. ",
    "url": "https://arxiv.org/abs/2307.12862",
    "authors": [
      "Helal El-Zaatari",
      "Fei Yu",
      "Michael R Kosorok"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.12872",
    "title": "Data-free Black-box Attack based on Diffusion Model",
    "abstract": "Since the training data for the target model in a data-free black-box attack is not available, most recent schemes utilize GANs to generate data for training substitute model. However, these GANs-based schemes suffer from low training efficiency as the generator needs to be retrained for each target model during the substitute training process, as well as low generation quality. To overcome these limitations, we consider utilizing the diffusion model to generate data, and propose a data-free black-box attack scheme based on diffusion model to improve the efficiency and accuracy of substitute training. Despite the data generated by the diffusion model exhibits high quality, it presents diverse domain distributions and contains many samples that do not meet the discriminative criteria of the target model. To further facilitate the diffusion model to generate data suitable for the target model, we propose a Latent Code Augmentation (LCA) method to guide the diffusion model in generating data. With the guidance of LCA, the data generated by the diffusion model not only meets the discriminative criteria of the target model but also exhibits high diversity. By utilizing this data, it is possible to train substitute model that closely resemble the target model more efficiently. Extensive experiments demonstrate that our LCA achieves higher attack success rates and requires fewer query budgets compared to GANs-based schemes for different target models. ",
    "url": "https://arxiv.org/abs/2307.12872",
    "authors": [
      "Mingwen Shao",
      "Lingzhuang Meng",
      "Yuanjian Qiao",
      "Lixu Zhang",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12874",
    "title": "SoK: Design, Vulnerabilities and Defense of Cryptocurrency Wallets",
    "abstract": "The rapid growth of decentralized digital currencies, enabled by blockchain technology, has ushered in a new era of peer-to-peer transactions, revolutionizing the global economy. Cryptocurrency wallets, serving as crucial endpoints for these transactions, have become increasingly prevalent. However, the escalating value and usage of these wallets also expose them to significant security risks and challenges. This research aims to comprehensively explore the security aspects of cryptocurrency wallets. It provides a taxonomy of wallet types, analyzes their design and implementation, identifies common vulnerabilities and attacks, and discusses defense mechanisms and mitigation strategies. The taxonomy covers custodial, non-custodial, hot, and cold wallets, highlighting their unique characteristics and associated security considerations. The security analysis scrutinizes the theoretical and practical aspects of wallet design, while assessing the efficacy of existing security measures and protocols. Notable wallet attacks, such as Binance, Mt. Gox are examined to understand their causes and consequences. Furthermore, the paper surveys defense mechanisms, transaction monitoring, evaluating their effectiveness in mitigating threats. ",
    "url": "https://arxiv.org/abs/2307.12874",
    "authors": [
      "Yimika Erinle",
      "Yathin Kethepalli",
      "Yebo Feng",
      "Jiahua Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2307.12888",
    "title": "An objective evaluation of Hearing Aids and DNN-based speech enhancement  in complex acoustic scenes",
    "abstract": "We investigate the objective performance of five high-end commercially available Hearing Aid (HA) devices compared to DNN-based speech enhancement algorithms in complex acoustic environments. To this end, we measure the HRTFs of a single HA device to synthesize a binaural dataset for training two state-of-the-art causal and non-causal DNN enhancement models. We then generate an evaluation set of realistic speech-in-noise situations using an Ambisonics loudspeaker setup and record with a KU100 dummy head wearing each of the HA devices, both with and without the conventional HA algorithms, applying the DNN enhancers to the latter. We find that the DNN-based enhancement outperforms the HA algorithms in terms of noise suppression and objective intelligibility metrics. ",
    "url": "https://arxiv.org/abs/2307.12888",
    "authors": [
      "Enric Gus\u00f3",
      "Joanna Luberadzka",
      "Mart\u00ed Baig",
      "Umut Sayin Sara\u00e7",
      "Xavier Serra"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2307.12900",
    "title": "Automotive Object Detection via Learning Sparse Events by Temporal  Dynamics of Spiking Neurons",
    "abstract": "Event-based sensors, with their high temporal resolution (1us) and dynamical range (120dB), have the potential to be deployed in high-speed platforms such as vehicles and drones. However, the highly sparse and fluctuating nature of events poses challenges for conventional object detection techniques based on Artificial Neural Networks (ANNs). In contrast, Spiking Neural Networks (SNNs) are well-suited for representing event-based data due to their inherent temporal dynamics. In particular, we demonstrate that the membrane potential dynamics can modulate network activity upon fluctuating events and strengthen features of sparse input. In addition, the spike-triggered adaptive threshold can stabilize training which further improves network performance. Based on this, we develop an efficient spiking feature pyramid network for event-based object detection. Our proposed SNN outperforms previous SNNs and sophisticated ANNs with attention mechanisms, achieving a mean average precision (map50) of 47.7% on the Gen1 benchmark dataset. This result significantly surpasses the previous best SNN by 9.7% and demonstrates the potential of SNNs for event-based vision. Our model has a concise architecture while maintaining high accuracy and much lower computation cost as a result of sparse computation. Our code will be publicly available. ",
    "url": "https://arxiv.org/abs/2307.12900",
    "authors": [
      "Hu Zhang",
      "Luziwei Leng",
      "Kaiwei Che",
      "Qian Liu",
      "Jie Cheng",
      "Qinghai Guo",
      "Jiangxing Liao",
      "Ran Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12906",
    "title": "QAmplifyNet: Pushing the Boundaries of Supply Chain Backorder Prediction  Using Interpretable Hybrid Quantum - Classical Neural Network",
    "abstract": "Supply chain management relies on accurate backorder prediction for optimizing inventory control, reducing costs, and enhancing customer satisfaction. However, traditional machine-learning models struggle with large-scale datasets and complex relationships, hindering real-world data collection. This research introduces a novel methodological framework for supply chain backorder prediction, addressing the challenge of handling large datasets. Our proposed model, QAmplifyNet, employs quantum-inspired techniques within a quantum-classical neural network to predict backorders effectively on short and imbalanced datasets. Experimental evaluations on a benchmark dataset demonstrate QAmplifyNet's superiority over classical models, quantum ensembles, quantum neural networks, and deep reinforcement learning. Its proficiency in handling short, imbalanced datasets makes it an ideal solution for supply chain management. To enhance model interpretability, we use Explainable Artificial Intelligence techniques. Practical implications include improved inventory control, reduced backorders, and enhanced operational efficiency. QAmplifyNet seamlessly integrates into real-world supply chain management systems, enabling proactive decision-making and efficient resource allocation. Future work involves exploring additional quantum-inspired techniques, expanding the dataset, and investigating other supply chain applications. This research unlocks the potential of quantum computing in supply chain optimization and paves the way for further exploration of quantum-inspired machine learning models in supply chain management. Our framework and QAmplifyNet model offer a breakthrough approach to supply chain backorder prediction, providing superior performance and opening new avenues for leveraging quantum-inspired techniques in supply chain management. ",
    "url": "https://arxiv.org/abs/2307.12906",
    "authors": [
      "Md Abrar Jahin",
      "Md Sakib Hossain Shovon",
      "Md. Saiful Islam",
      "Jungpil Shin",
      "M. F. Mridha",
      "Yuichi Okuyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2307.12909",
    "title": "Dyn-E: Local Appearance Editing of Dynamic Neural Radiance Fields",
    "abstract": "Recently, the editing of neural radiance fields (NeRFs) has gained considerable attention, but most prior works focus on static scenes while research on the appearance editing of dynamic scenes is relatively lacking. In this paper, we propose a novel framework to edit the local appearance of dynamic NeRFs by manipulating pixels in a single frame of training video. Specifically, to locally edit the appearance of dynamic NeRFs while preserving unedited regions, we introduce a local surface representation of the edited region, which can be inserted into and rendered along with the original NeRF and warped to arbitrary other frames through a learned invertible motion representation network. By employing our method, users without professional expertise can easily add desired content to the appearance of a dynamic scene. We extensively evaluate our approach on various scenes and show that our approach achieves spatially and temporally consistent editing results. Notably, our approach is versatile and applicable to different variants of dynamic NeRF representations. ",
    "url": "https://arxiv.org/abs/2307.12909",
    "authors": [
      "Shangzhan Zhang",
      "Sida Peng",
      "Yinji ShenTu",
      "Qing Shuai",
      "Tianrun Chen",
      "Kaicheng Yu",
      "Hujun Bao",
      "Xiaowei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12917",
    "title": "Hierarchical Skeleton Meta-Prototype Contrastive Learning with Hard  Skeleton Mining for Unsupervised Person Re-Identification",
    "abstract": "With rapid advancements in depth sensors and deep learning, skeleton-based person re-identification (re-ID) models have recently achieved remarkable progress with many advantages. Most existing solutions learn single-level skeleton features from body joints with the assumption of equal skeleton importance, while they typically lack the ability to exploit more informative skeleton features from various levels such as limb level with more global body patterns. The label dependency of these methods also limits their flexibility in learning more general skeleton representations. This paper proposes a generic unsupervised Hierarchical skeleton Meta-Prototype Contrastive learning (Hi-MPC) approach with Hard Skeleton Mining (HSM) for person re-ID with unlabeled 3D skeletons. Firstly, we construct hierarchical representations of skeletons to model coarse-to-fine body and motion features from the levels of body joints, components, and limbs. Then a hierarchical meta-prototype contrastive learning model is proposed to cluster and contrast the most typical skeleton features (\"prototypes\") from different-level skeletons. By converting original prototypes into meta-prototypes with multiple homogeneous transformations, we induce the model to learn the inherent consistency of prototypes to capture more effective skeleton features for person re-ID. Furthermore, we devise a hard skeleton mining mechanism to adaptively infer the informative importance of each skeleton, so as to focus on harder skeletons to learn more discriminative skeleton representations. Extensive evaluations on five datasets demonstrate that our approach outperforms a wide variety of state-of-the-art skeleton-based methods. We further show the general applicability of our method to cross-view person re-ID and RGB-based scenarios with estimated skeletons. ",
    "url": "https://arxiv.org/abs/2307.12917",
    "authors": [
      "Haocong Rao",
      "Cyril Leung",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.12935",
    "title": "Rule By Example: Harnessing Logical Rules for Explainable Hate Speech  Detection",
    "abstract": "Classic approaches to content moderation typically apply a rule-based heuristic approach to flag content. While rules are easily customizable and intuitive for humans to interpret, they are inherently fragile and lack the flexibility or robustness needed to moderate the vast amount of undesirable content found online today. Recent advances in deep learning have demonstrated the promise of using highly effective deep neural models to overcome these challenges. However, despite the improved performance, these data-driven models lack transparency and explainability, often leading to mistrust from everyday users and a lack of adoption by many platforms. In this paper, we present Rule By Example (RBE): a novel exemplar-based contrastive learning approach for learning from logical rules for the task of textual content moderation. RBE is capable of providing rule-grounded predictions, allowing for more explainable and customizable predictions compared to typical deep learning-based approaches. We demonstrate that our approach is capable of learning rich rule embedding representations using only a few data examples. Experimental results on 3 popular hate speech classification datasets show that RBE is able to outperform state-of-the-art deep learning classifiers as well as the use of rules in both supervised and unsupervised settings while providing explainable model predictions via rule-grounding. ",
    "url": "https://arxiv.org/abs/2307.12935",
    "authors": [
      "Christopher Clarke",
      "Matthew Hall",
      "Gaurav Mittal",
      "Ye Yu",
      "Sandra Sajeev",
      "Jason Mars",
      "Mei Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.12936",
    "title": "Timely Target Tracking: Distributed Updating in Cognitive Radar Networks",
    "abstract": "Cognitive radar networks are capable of optimizing operating parameters in order to provide actionable information to an operator or secondary system. CRNs have been proposed to answer the need for low-cost devices tracking potentially large numbers of targets in geographically diverse regions. Networks of small-scale devices have also been shown to outperform legacy, large scale, high price, single-device installations. In this work, we consider a CRN tracking multiple targets with a goal of providing information which is both fresh and accurate to a measurement fusion center. We show that under a constraint on the update rate of each radar node, the network is able to utilize Age of Information metrics to maximize the resource utilization and minimize error per track. Since information freshness is critical to decision-making, this structure enables a CRN to provide the highest-quality information possible to a downstream system or operator. We discuss centralized and distributed approaches to solving this problem, taking into account the quality of node observations, the maneuverability of each target, and a limit on the rate at which any node may provide updates to the FC. We present a centralized AoI-inspired node selection metric, where a FC requests updates from specific nodes. We compare this against several alternative techniques. Further, we provide a distributed approach which utilizes the Age of Incorrect Information metric, allowing each independent node to provide updates according to the targets it can observe. We provide mathematical analysis of the rate limits defined for the centralized and distributed approaches, showing that they are equivalent. We conclude with numerical simulations demonstrating that the performance of the algorithms exceeds that of alternative approaches, both in resource utilization and in tracking performance. ",
    "url": "https://arxiv.org/abs/2307.12936",
    "authors": [
      "William W. Howard",
      "Anthony F. Martone",
      "R. Michael Buehrer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.12941",
    "title": "On Privileged and Convergent Bases in Neural Network Representations",
    "abstract": "In this study, we investigate whether the representations learned by neural networks possess a privileged and convergent basis. Specifically, we examine the significance of feature directions represented by individual neurons. First, we establish that arbitrary rotations of neural representations cannot be inverted (unlike linear networks), indicating that they do not exhibit complete rotational invariance. Subsequently, we explore the possibility of multiple bases achieving identical performance. To do this, we compare the bases of networks trained with the same parameters but with varying random initializations. Our study reveals two findings: (1) Even in wide networks such as WideResNets, neural networks do not converge to a unique basis; (2) Basis correlation increases significantly when a few early layers of the network are frozen identically. Furthermore, we analyze Linear Mode Connectivity, which has been studied as a measure of basis correlation. Our findings give evidence that while Linear Mode Connectivity improves with increased network width, this improvement is not due to an increase in basis correlation. ",
    "url": "https://arxiv.org/abs/2307.12941",
    "authors": [
      "Davis Brown",
      "Nikhil Vyas",
      "Yamini Bansal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.11792",
    "title": "Quantum Convolutional Neural Networks with Interaction Layers for  Classification of Classical Data",
    "abstract": "Quantum Machine Learning (QML) has come into the limelight due to the exceptional computational abilities of quantum computers. With the promises of near error-free quantum computers in the not-so-distant future, it is important that the effect of multi-qubit interactions on quantum neural networks is studied extensively. This paper introduces a Quantum Convolutional Network with novel Interaction layers exploiting three-qubit interactions increasing the network's expressibility and entangling capability, for classifying both image and one-dimensional data. The proposed approach is tested on three publicly available datasets namely MNIST, Fashion MNIST, and Iris datasets, to perform binary and multiclass classifications and is found to supersede the performance of the existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2307.11792",
    "authors": [
      "Jishnu Mahmud",
      "Raisa Mashtura",
      "Shaikh Anowarul Fattah"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.11794",
    "title": "Artificial Intelligence-Generated Terahertz Multi-Resonant Metasurfaces  via Improved Transformer and CGAN Neural Networks",
    "abstract": "It is well known that the inverse design of terahertz (THz) multi-resonant graphene metasurfaces by using traditional deep neural networks (DNNs) has limited generalization ability. In this paper, we propose improved Transformer and conditional generative adversarial neural networks (CGAN) for the inverse design of graphene metasurfaces based upon THz multi-resonant absorption spectra. The improved Transformer can obtain higher accuracy and generalization performance in the StoV (Spectrum to Vector) design compared to traditional multilayer perceptron (MLP) neural networks, while the StoI (Spectrum to Image) design achieved through CGAN can provide more comprehensive information and higher accuracy than the StoV design obtained by MLP. Moreover, the improved CGAN can achieve the inverse design of graphene metasurface images directly from the desired multi-resonant absorption spectra. It is turned out that this work can finish facilitating the design process of artificial intelligence-generated metasurfaces (AIGM), and even provide a useful guide for developing complex THz metasurfaces based on 2D materials using generative neural networks. ",
    "url": "https://arxiv.org/abs/2307.11794",
    "authors": [
      "Yangpeng Huang",
      "Naixing Feng",
      "Yijun Cai"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ]
  },
  {
    "id": "arXiv:2307.11842",
    "title": "A high-order finite volume method for Maxwell's equations in  heterogeneous and time-varying media",
    "abstract": "We develop a finite volume method for Maxwell's equations in materials whose electromagnetic properties vary in space and time. We investigate both conservative and non-conservative numerical formulations. High-order methods accurately resolve fine structures that develop due to the varying material properties. Numerical examples demonstrate the effectiveness of the proposed method in handling temporal variation and its efficiency relative to traditional 2nd-order FDTD. ",
    "url": "https://arxiv.org/abs/2307.11842",
    "authors": [
      "Damian P. San Roman Alerigi",
      "David I. Ketcheson",
      "Boon S. Ooi"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2307.11960",
    "title": "DHC: Dual-debiased Heterogeneous Co-training Framework for  Class-imbalanced Semi-supervised Medical Image Segmentation",
    "abstract": "The volume-wise labeling of 3D medical images is expertise-demanded and time-consuming; hence semi-supervised learning (SSL) is highly desirable for training with limited labeled data. Imbalanced class distribution is a severe problem that bottlenecks the real-world application of these methods but was not addressed much. Aiming to solve this issue, we present a novel Dual-debiased Heterogeneous Co-training (DHC) framework for semi-supervised 3D medical image segmentation. Specifically, we propose two loss weighting strategies, namely Distribution-aware Debiased Weighting (DistDW) and Difficulty-aware Debiased Weighting (DiffDW), which leverage the pseudo labels dynamically to guide the model to solve data and learning biases. The framework improves significantly by co-training these two diverse and accurate sub-models. We also introduce more representative benchmarks for class-imbalanced semi-supervised medical image segmentation, which can fully demonstrate the efficacy of the class-imbalance designs. Experiments show that our proposed framework brings significant improvements by using pseudo labels for debiasing and alleviating the class imbalance problem. More importantly, our method outperforms the state-of-the-art SSL methods, demonstrating the potential of our framework for the more challenging SSL setting. Code and models are available at: https://github.com/xmed-lab/DHC. ",
    "url": "https://arxiv.org/abs/2307.11960",
    "authors": [
      "Haonan Wang",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12014",
    "title": "NLCUnet: Single-Image Super-Resolution Network with Hairline Details",
    "abstract": "Pursuing the precise details of super-resolution images is challenging for single-image super-resolution tasks. This paper presents a single-image super-resolution network with hairline details (termed NLCUnet), including three core designs. Specifically, a non-local attention mechanism is first introduced to restore local pieces by learning from the whole image region. Then, we find that the blur kernel trained by the existing work is unnecessary. Based on this finding, we create a new network architecture by integrating depth-wise convolution with channel attention without the blur kernel estimation, resulting in a performance improvement instead. Finally, to make the cropped region contain as much semantic information as possible, we propose a random 64$\\times$64 crop inside the central 512$\\times$512 crop instead of a direct random crop inside the whole image of 2K size. Numerous experiments conducted on the benchmark DF2K dataset demonstrate that our NLCUnet performs better than the state-of-the-art in terms of the PSNR and SSIM metrics and yields visually favorable hairline details. ",
    "url": "https://arxiv.org/abs/2307.12014",
    "authors": [
      "Jiancong Feng",
      "Yuan-Gen Wang",
      "Fengchuang Xing"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12138",
    "title": "SCPAT-GAN: Structural Constrained and Pathology Aware Convolutional  Transformer-GAN for Virtual Histology Staining of Human Coronary OCT images",
    "abstract": "There is a significant need for the generation of virtual histological information from coronary optical coherence tomography (OCT) images to better guide the treatment of coronary artery disease. However, existing methods either require a large pixel-wisely paired training dataset or have limited capability to map pathological regions. To address these issues, we proposed a structural constrained, pathology aware, transformer generative adversarial network, namely SCPAT-GAN, to generate virtual stained H&E histology from OCT images. The proposed SCPAT-GAN advances existing methods via a novel design to impose pathological guidance on structural layers using transformer-based network. ",
    "url": "https://arxiv.org/abs/2307.12138",
    "authors": [
      "Xueshen Li",
      "Hongshan Liu",
      "Xiaoyu Song",
      "Brigitta C. Brott",
      "Silvio H. Litovsky",
      "Yu Gan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12327",
    "title": "ES2Net: An Efficient Spectral-Spatial Network for Hyperspectral Image  Change Detection",
    "abstract": "Hyperspectral image change detection (HSI-CD) aims to identify the differences in bitemporal HSIs. To mitigate spectral redundancy and improve the discriminativeness of changing features, some methods introduced band selection technology to select bands conducive for CD. However, these methods are limited by the inability to end-to-end training with the deep learning-based feature extractor and lack considering the complex nonlinear relationship among bands. In this paper, we propose an end-to-end efficient spectral-spatial change detection network (ES2Net) to address these issues. Specifically, we devised a learnable band selection module to automatically select bands conducive to CD. It can be jointly optimized with a feature extraction network and capture the complex nonlinear relationships among bands. Moreover, considering the large spatial feature distribution differences among different bands, we design the cluster-wise spatial attention mechanism that assigns a spatial attention factor to each individual band to individually improve the feature discriminativeness for each band. Experiments on three widely used HSI-CD datasets demonstrate the effectiveness and superiority of this method compared with other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2307.12327",
    "authors": [
      "Qingren Yao",
      "Yuan Zhou",
      "Wei Xiang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12360",
    "title": "Unravelling the Mechanics of Knitted Fabrics Through Hierarchical  Geometric Representation",
    "abstract": "Knitting interloops one-dimensional yarns into three-dimensional fabrics that exhibit behaviours beyond their constitutive materials. How extensibility and anisotropy emerge from the hierarchical organization of yarns into knitted fabrics has long been unresolved. We sought to unravel the mechanical roles of tensile mechanics, assembly and dynamics arising from the yarn level on fabric nonlinearity by developing a yarn-based dynamical model. This physically validated model captures the fundamental mechanical response of knitted fabrics, analogous to flexible metamaterials and biological fiber networks due to geometric nonlinearity within such hierarchical systems. We identify the dictating factors of the mechanics of knitted fabrics, highlighting the previously overlooked but critical effect of pre-tension. Fabric anisotropy originates from observed yarn--yarn rearrangements during alignment dynamics and is topology-dependent. This yarn-based model also provides design flexibility of knitted fabrics to embed functionalities by allowing variation in both geometric configuration and material property. Our hierarchical approach to build up a knitted fabrics computationally modernizes an ancient craft and represents a first step towards mechanical programmability of knitted fabrics in wide engineering applications. ",
    "url": "https://arxiv.org/abs/2307.12360",
    "authors": [
      "Xiaoxiao Ding",
      "Vanessa Sanchez",
      "Katia Bertoldi",
      "Chris H. Rycroft"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.12449",
    "title": "WEPRO: Weight Prediction for Efficient Optimization of Hybrid  Quantum-Classical Algorithms",
    "abstract": "The exponential run time of quantum simulators on classical machines and long queue depths and high costs of real quantum devices present significant challenges in the effective training of Variational Quantum Algorithms (VQAs) like Quantum Neural Networks (QNNs), Variational Quantum Eigensolver (VQE) and Quantum Approximate Optimization Algorithm (QAOA). To address these limitations, we propose a new approach, WEPRO (Weight Prediction), which accelerates the convergence of VQAs by exploiting regular trends in the parameter weights. We introduce two techniques for optimal prediction performance namely, Naive Prediction (NaP) and Adaptive Prediction (AdaP). Through extensive experimentation and training of multiple QNN models on various datasets, we demonstrate that WEPRO offers a speedup of approximately $2.25\\times$ compared to standard training methods, while also providing improved accuracy (up to $2.3\\%$ higher) and loss (up to $6.1\\%$ lower) with low storage and computational overheads. We also evaluate WEPRO's effectiveness in VQE for molecular ground-state energy estimation and in QAOA for graph MaxCut. Our results show that WEPRO leads to speed improvements of up to $3.1\\times$ for VQE and $2.91\\times$ for QAOA, compared to traditional optimization techniques, while using up to $3.3\\times$ less number of shots (i.e., repeated circuit executions) per training iteration. ",
    "url": "https://arxiv.org/abs/2307.12449",
    "authors": [
      "Satwik Kundu",
      "Debarshi Kundu",
      "Swaroop Ghosh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12468",
    "title": "Robust iterative method for symmetric quantum signal processing in all  parameter regimes",
    "abstract": "This paper addresses the problem of solving nonlinear systems in the context of symmetric quantum signal processing (QSP), a powerful technique for implementing matrix functions on quantum computers. Symmetric QSP focuses on representing target polynomials as products of matrices in SU(2) that possess symmetry properties. We present a novel Newton's method tailored for efficiently solving the nonlinear system involved in determining the phase factors within the symmetric QSP framework. Our method demonstrates rapid and robust convergence in all parameter regimes, including the challenging scenario with ill-conditioned Jacobian matrices, using standard double precision arithmetic operations. For instance, solving symmetric QSP for a highly oscillatory target function $\\alpha \\cos(1000 x)$ (polynomial degree $\\approx 1433$) takes $6$ iterations to converge to machine precision when $\\alpha=0.9$, and the number of iterations only increases to $18$ iterations when $\\alpha=1-10^{-9}$ with a highly ill-conditioned Jacobian matrix. Leveraging the matrix product states the structure of symmetric QSP, the computation of the Jacobian matrix incurs a computational cost comparable to a single function evaluation. Moreover, we introduce a reformulation of symmetric QSP using real-number arithmetics, further enhancing the method's efficiency. Extensive numerical tests validate the effectiveness and robustness of our approach, which has been implemented in the QSPPACK software package. ",
    "url": "https://arxiv.org/abs/2307.12468",
    "authors": [
      "Yulong Dong",
      "Lin Lin",
      "Hongkang Ni",
      "Jiasu Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.12500",
    "title": "Photoemission Orbital Tomography Using Robust Sparse PhaseLift",
    "abstract": "Photoemission orbital tomography (POT) from photoelectron momentum maps (PMMs) has enabled detailed analysis of the shape and energy of molecular orbitals in the adsorbed state. This study proposes a new POT method based on the PhaseLift. Molecular orbitals, including three-dimensional phases, can be identified from a single PMM by actively providing atomic positions and basis. Moreover, our method is robust to noise and can perfectly discriminate adsorption-induced molecular deformations with an accuracy of 0.05 [angstrom]. Our new method enables simultaneous analysis of the three-dimensional shapes of molecules and molecular orbitals and thus paves the way for advanced quantum-mechanical interpretation of adsorption-induced electronic state changes and photo-excited inter-molecular interactions. ",
    "url": "https://arxiv.org/abs/2307.12500",
    "authors": [
      "Kaori Niki",
      "Rena Asano",
      "Ryuji Sakanoue",
      "Manabu Hagiwara",
      "Kazushi Mimura"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Chemical Physics (physics.chem-ph)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2307.12556",
    "title": "On the information-theoretic formulation of network participation",
    "abstract": "The participation coefficient is a widely used metric of the diversity of a node's connections with respect to a modular partition of a network. An information-theoretic formulation of this concept of connection diversity, referred to here as participation entropy, has been introduced as the Shannon entropy of the distribution of module labels across a node's connected neighbors. While diversity metrics have been studied theoretically in other literatures, including to index species diversity in ecology, many of these results have not previously been applied to networks. Here we show that the participation coefficient is a first-order approximation to participation entropy and use the desirable additive properties of entropy to develop new metrics of connection diversity with respect to multiple labelings of nodes in a network, as joint and conditional participation entropies. The information-theoretic formalism developed here allows new and more subtle types of nodal connection patterns in complex networks to be studied. ",
    "url": "https://arxiv.org/abs/2307.12556",
    "authors": [
      "Pavle Cajic",
      "Dominic Agius",
      "Oliver M. Cliff",
      "James M. Shine",
      "Joseph T. Lizier",
      "Ben D. Fulcher"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2307.12751",
    "title": "ICF-SRSR: Invertible scale-Conditional Function for Self-Supervised  Real-world Single Image Super-Resolution",
    "abstract": "Single image super-resolution (SISR) is a challenging ill-posed problem that aims to up-sample a given low-resolution (LR) image to a high-resolution (HR) counterpart. Due to the difficulty in obtaining real LR-HR training pairs, recent approaches are trained on simulated LR images degraded by simplified down-sampling operators, e.g., bicubic. Such an approach can be problematic in practice because of the large gap between the synthesized and real-world LR images. To alleviate the issue, we propose a novel Invertible scale-Conditional Function (ICF), which can scale an input image and then restore the original input with different scale conditions. By leveraging the proposed ICF, we construct a novel self-supervised SISR framework (ICF-SRSR) to handle the real-world SR task without using any paired/unpaired training data. Furthermore, our ICF-SRSR can generate realistic and feasible LR-HR pairs, which can make existing supervised SISR networks more robust. Extensive experiments demonstrate the effectiveness of the proposed method in handling SISR in a fully self-supervised manner. Our ICF-SRSR demonstrates superior performance compared to the existing methods trained on synthetic paired images in real-world scenarios and exhibits comparable performance compared to state-of-the-art supervised/unsupervised methods on public benchmark datasets. ",
    "url": "https://arxiv.org/abs/2307.12751",
    "authors": [
      "Reyhaneh Neshatavar",
      "Mohsen Yavartanoo",
      "Sanghyun Son",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12790",
    "title": "Compact & Capable: Harnessing Graph Neural Networks and Edge Convolution  for Medical Image Classification",
    "abstract": "Graph-based neural network models are gaining traction in the field of representation learning due to their ability to uncover latent topological relationships between entities that are otherwise challenging to identify. These models have been employed across a diverse range of domains, encompassing drug discovery, protein interactions, semantic segmentation, and fluid dynamics research. In this study, we investigate the potential of Graph Neural Networks (GNNs) for medical image classification. We introduce a novel model that combines GNNs and edge convolution, leveraging the interconnectedness of RGB channel feature values to strongly represent connections between crucial graph nodes. Our proposed model not only performs on par with state-of-the-art Deep Neural Networks (DNNs) but does so with 1000 times fewer parameters, resulting in reduced training time and data requirements. We compare our Graph Convolutional Neural Network (GCNN) to pre-trained DNNs for classifying MedMNIST dataset classes, revealing promising prospects for GNNs in medical image analysis. Our results also encourage further exploration of advanced graph-based models such as Graph Attention Networks (GAT) and Graph Auto-Encoders in the medical imaging domain. The proposed model yields more reliable, interpretable, and accurate outcomes for tasks like semantic segmentation and image classification compared to simpler GCNNs ",
    "url": "https://arxiv.org/abs/2307.12790",
    "authors": [
      "Aryan Singh",
      "Pepijn Van de Ven",
      "Ciar\u00e1n Eising",
      "Patrick Denny"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12904",
    "title": "Universal Approximation Theorem and error bounds for quantum neural  networks and quantum reservoirs",
    "abstract": "Universal approximation theorems are the foundations of classical neural networks, providing theoretical guarantees that the latter are able to approximate maps of interest. Recent results have shown that this can also be achieved in a quantum setting, whereby classical functions can be approximated by parameterised quantum circuits. We provide here precise error bounds for specific classes of functions and extend these results to the interesting new setup of randomised quantum circuits, mimicking classical reservoir neural networks. Our results show in particular that a quantum neural network with $\\mathcal{O}(\\varepsilon^{-2})$ weights and $\\mathcal{O} (\\lceil \\log_2(\\varepsilon^{-1}) \\rceil)$ qubits suffices to achieve accuracy $\\varepsilon>0$ when approximating functions with integrable Fourier transform. ",
    "url": "https://arxiv.org/abs/2307.12904",
    "authors": [
      "Lukas Gonon",
      "Antoine Jacquier"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2007.15393",
    "title": "Towards a new Social Choice Theory",
    "abstract": " Title: Towards a new Social Choice Theory ",
    "url": "https://arxiv.org/abs/2007.15393",
    "authors": [
      "Andr\u00e9s Garc\u00eda-Camino"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2009.04639",
    "title": "Improving Coreference Resolution by Leveraging Entity-Centric Features  with Graph Neural Networks and Second-order Inference",
    "abstract": " Title: Improving Coreference Resolution by Leveraging Entity-Centric Features  with Graph Neural Networks and Second-order Inference ",
    "url": "https://arxiv.org/abs/2009.04639",
    "authors": [
      "Lu Liu",
      "Zhenqiao Song",
      "Xiaoqing Zheng",
      "Jun He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2011.09094",
    "title": "UP-DETR: Unsupervised Pre-training for Object Detection with  Transformers",
    "abstract": " Comments: Accepted by TPAMI 2022 and CVPR 2021 ",
    "url": "https://arxiv.org/abs/2011.09094",
    "authors": [
      "Zhigang Dai",
      "Bolun Cai",
      "Yugeng Lin",
      "Junying Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.11060",
    "title": "Adversarial Patch Generation for Automated Program Repair",
    "abstract": " Title: Adversarial Patch Generation for Automated Program Repair ",
    "url": "https://arxiv.org/abs/2012.11060",
    "authors": [
      "Abdulaziz Alhefdhi",
      "Hoa Khanh Dam",
      "Xuan-Bach D. Le",
      "Thanh Le-Cong",
      "Aditya Ghose"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2102.13008",
    "title": "Imitation Learning with Human Eye Gaze via Multi-Objective Prediction",
    "abstract": " Comments: Paper accepted and selected as an oral presentation at Interactive Learning with Implicit Human Feedback Workshop at ICML 2023 ",
    "url": "https://arxiv.org/abs/2102.13008",
    "authors": [
      "Ravi Kumar Thakur",
      "MD-Nazmus Samin Sunbeam",
      "Vinicius G. Goecks",
      "Ellen Novoseller",
      "Ritwik Bera",
      "Vernon J. Lawhern",
      "Gregory M. Gremillion",
      "John Valasek",
      "Nicholas R. Waytowich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2103.11578",
    "title": "SparseGAN: Sparse Generative Adversarial Network for Text Generation",
    "abstract": " Title: SparseGAN: Sparse Generative Adversarial Network for Text Generation ",
    "url": "https://arxiv.org/abs/2103.11578",
    "authors": [
      "Liping Yuan",
      "Jiehang Zeng",
      "Xiaoqing Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.08693",
    "title": "Elastic Representation and Generative Shape Models for Tree-like 3D  Objects",
    "abstract": " Title: Elastic Representation and Generative Shape Models for Tree-like 3D  Objects ",
    "url": "https://arxiv.org/abs/2110.08693",
    "authors": [
      "Guan Wang",
      "Hamid Laga",
      "Anuj Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.09564",
    "title": "LAnoBERT: System Log Anomaly Detection based on BERT Masked Language  Model",
    "abstract": " Title: LAnoBERT: System Log Anomaly Detection based on BERT Masked Language  Model ",
    "url": "https://arxiv.org/abs/2111.09564",
    "authors": [
      "Yukyung Lee",
      "Jina Kim",
      "Pilsung Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.00543",
    "title": "Deterministic Generation of Multipartite Entanglement via Causal  Activation in the Quantum Internet",
    "abstract": " Title: Deterministic Generation of Multipartite Entanglement via Causal  Activation in the Quantum Internet ",
    "url": "https://arxiv.org/abs/2112.00543",
    "authors": [
      "Seid Koudia",
      "Angela Sara Cacciapuoti",
      "Marcello Caleffi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2201.11619",
    "title": "Positive First-order Logic on Words and Graphs",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2101.01968 ",
    "url": "https://arxiv.org/abs/2201.11619",
    "authors": [
      "Denis Kuperberg"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2205.09801",
    "title": "Representation Power of Graph Neural Networks: Improved Expressivity via  Algebraic Analysis",
    "abstract": " Title: Representation Power of Graph Neural Networks: Improved Expressivity via  Algebraic Analysis ",
    "url": "https://arxiv.org/abs/2205.09801",
    "authors": [
      "Charilaos I. Kanatsoulis",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.12583",
    "title": "MUG: Multi-human Graph Network for 3D Mesh Reconstruction from 2D Pose",
    "abstract": " Title: MUG: Multi-human Graph Network for 3D Mesh Reconstruction from 2D Pose ",
    "url": "https://arxiv.org/abs/2205.12583",
    "authors": [
      "Chenyan Wu",
      "Yandong Li",
      "Xianfeng Tang",
      "James Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.15425",
    "title": "Edge coloring of graphs of signed class 1 and 2",
    "abstract": " Title: Edge coloring of graphs of signed class 1 and 2 ",
    "url": "https://arxiv.org/abs/2205.15425",
    "authors": [
      "Robert Janczewski",
      "Krzysztof Turowski",
      "Bart\u0142omiej Wr\u00f3blewski"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2206.02058",
    "title": "When Personalization Harms: Reconsidering the Use of Group Attributes in  Prediction",
    "abstract": " Comments: ICML 2023 Oral ",
    "url": "https://arxiv.org/abs/2206.02058",
    "authors": [
      "Vinith M. Suriyakumar",
      "Marzyeh Ghassemi",
      "Berk Ustun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02909",
    "title": "Self-supervised Learning for Human Activity Recognition Using 700,000  Person-days of Wearable Data",
    "abstract": " Title: Self-supervised Learning for Human Activity Recognition Using 700,000  Person-days of Wearable Data ",
    "url": "https://arxiv.org/abs/2206.02909",
    "authors": [
      "Hang Yuan",
      "Shing Chan",
      "Andrew P. Creagh",
      "Catherine Tong",
      "David A. Clifton",
      "Aiden Doherty"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10381",
    "title": "TabText: A Flexible and Contextual Approach to Tabular Data  Representation",
    "abstract": " Title: TabText: A Flexible and Contextual Approach to Tabular Data  Representation ",
    "url": "https://arxiv.org/abs/2206.10381",
    "authors": [
      "Kimberly Villalobos Carballo",
      "Liangyuan Na",
      "Yu Ma",
      "L\u00e9onard Boussioux",
      "Cynthia Zeng",
      "Luis R. Soenksen",
      "Dimitris Bertsimas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.03522",
    "title": "TF-GNN: Graph Neural Networks in TensorFlow",
    "abstract": " Title: TF-GNN: Graph Neural Networks in TensorFlow ",
    "url": "https://arxiv.org/abs/2207.03522",
    "authors": [
      "Oleksandr Ferludin",
      "Arno Eigenwillig",
      "Martin Blais",
      "Dustin Zelle",
      "Jan Pfeifer",
      "Alvaro Sanchez-Gonzalez",
      "Wai Lok Sibon Li",
      "Sami Abu-El-Haija",
      "Peter Battaglia",
      "Neslihan Bulut",
      "Jonathan Halcrow",
      "Filipe Miguel Gon\u00e7alves de Almeida",
      "Pedro Gonnet",
      "Liangze Jiang",
      "Parth Kothari",
      "Silvio Lattanzi",
      "Andr\u00e9 Linhares",
      "Brandon Mayer",
      "Vahab Mirrokni",
      "John Palowitch",
      "Mihir Paradkar",
      "Jennifer She",
      "Anton Tsitsulin",
      "Kevin Villela",
      "Lisa Wang",
      "David Wong",
      "Bryan Perozzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.08548",
    "title": "GANDALF: Gated Adaptive Network for Deep Automated Learning of Features",
    "abstract": " Comments: 7 pages + Reference & Appendix ",
    "url": "https://arxiv.org/abs/2207.08548",
    "authors": [
      "Manu Joseph",
      "Harsh Raj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.13352",
    "title": "COVID-19 and social media: Beyond polarization",
    "abstract": " Title: COVID-19 and social media: Beyond polarization ",
    "url": "https://arxiv.org/abs/2207.13352",
    "authors": [
      "Giacomo De Nicola",
      "Victor H. Tuekam Mambou",
      "G\u00f6ran Kauermann"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2208.06868",
    "title": "Frouros: A Python library for drift detection in machine learning  systems",
    "abstract": " Comments: 11 pages, 1 table ",
    "url": "https://arxiv.org/abs/2208.06868",
    "authors": [
      "Jaime C\u00e9spedes-Sisniega",
      "\u00c1lvaro L\u00f3pez-Garc\u00eda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.09417",
    "title": "Target-oriented Sentiment Classification with Sequential Cross-modal  Semantic Graph",
    "abstract": " Comments: ICANN 2023, this https URL ",
    "url": "https://arxiv.org/abs/2208.09417",
    "authors": [
      "Yufeng Huang",
      "Zhuo Chen",
      "Jiaoyan Chen",
      "Jeff Z. Pan",
      "Zhen Yao",
      "Wen Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.11389",
    "title": "Approximate blocked Gibbs sampling for Bayesian neural networks",
    "abstract": " Title: Approximate blocked Gibbs sampling for Bayesian neural networks ",
    "url": "https://arxiv.org/abs/2208.11389",
    "authors": [
      "Theodore Papamarkou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2208.14003",
    "title": "EchoGNN: Explainable Ejection Fraction Estimation with Graph Neural  Networks",
    "abstract": " Comments: Published in MICCAI 2022 ",
    "url": "https://arxiv.org/abs/2208.14003",
    "authors": [
      "Masoud Mokhtari",
      "Teresa Tsang",
      "Purang Abolmaesumi",
      "Renjie Liao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.00511",
    "title": "DRL Enabled Coverage and Capacity Optimization in STAR-RIS Assisted  Networks",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2204.06390 ",
    "url": "https://arxiv.org/abs/2209.00511",
    "authors": [
      "Xinyu Gao",
      "Wenqiang Yi",
      "Yuanwei Liu",
      "Jianhua Zhang",
      "Ping Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.06346",
    "title": "Prediction of the outcome of a Twenty-20 Cricket Match : A Machine  Learning Approach",
    "abstract": " Comments: Machine Learning Applications, Sports, Cricket Outcome Prediction ",
    "url": "https://arxiv.org/abs/2209.06346",
    "authors": [
      "Ashish V Shenoy",
      "Arjun Singhvi",
      "Shruthi Racha",
      "Srinivas Tunuguntla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.09554",
    "title": "Towards Robust Referring Image Segmentation",
    "abstract": " Comments: update more results ",
    "url": "https://arxiv.org/abs/2209.09554",
    "authors": [
      "Jianzong Wu",
      "Xiangtai Li",
      "Xia Li",
      "Henghui Ding",
      "Yunhai Tong",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.10168",
    "title": "Improving Generalizability of Graph Anomaly Detection Models via Data  Augmentation",
    "abstract": " Comments: The updated version is accepted by TKDE 2023. Please refer to arXiv:2306.10534v1 ",
    "url": "https://arxiv.org/abs/2209.10168",
    "authors": [
      "Shuang Zhou",
      "Xiao Huang",
      "Ninghao Liu",
      "Fu-Lai Chung",
      "Long-Kai Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.11531",
    "title": "Deep Learning-based Anonymization of Chest Radiographs: A  Utility-preserving Measure for Patient Privacy",
    "abstract": " Comments: Accepted at MICCAI 2023 ",
    "url": "https://arxiv.org/abs/2209.11531",
    "authors": [
      "Kai Packh\u00e4user",
      "Sebastian G\u00fcndel",
      "Florian Thamm",
      "Felix Denzinger",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.10495",
    "title": "ADPS: Asymmetric Distillation Post-Segmentation for Image Anomaly  Detection",
    "abstract": " Comments: 11pages,9 figures ",
    "url": "https://arxiv.org/abs/2210.10495",
    "authors": [
      "Peng Xing",
      "Hao Tang",
      "Jinhui Tang",
      "Zechao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.15401",
    "title": "Facial Video-based Remote Physiological Measurement via Self-supervised  Learning",
    "abstract": " Comments: IEEE Transactions on Pattern Analysis and Machine Intelligence ",
    "url": "https://arxiv.org/abs/2210.15401",
    "authors": [
      "Zijie Yue",
      "Miaojing Shi",
      "Shuai Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.16392",
    "title": "Physics-aware Graph Neural Network for Accurate RNA 3D Structure  Prediction",
    "abstract": " Comments: Accepted by the Machine Learning for Structural Biology Workshop (MLSB) at the 36th Conference on Neural Information Processing Systems (NeurIPS 2022) ",
    "url": "https://arxiv.org/abs/2210.16392",
    "authors": [
      "Shuo Zhang",
      "Yang Liu",
      "Lei Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2211.00928",
    "title": "Neural Active Learning on Heteroskedastic Distributions",
    "abstract": " Title: Neural Active Learning on Heteroskedastic Distributions ",
    "url": "https://arxiv.org/abs/2211.00928",
    "authors": [
      "Savya Khosla",
      "Chew Kin Whye",
      "Jordan T. Ash",
      "Cyril Zhang",
      "Kenji Kawaguchi",
      "Alex Lamb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.09710",
    "title": "Style Classification of Rabbinic Literature for Detection of Lost  Midrash Tanhuma Material",
    "abstract": " Title: Style Classification of Rabbinic Literature for Detection of Lost  Midrash Tanhuma Material ",
    "url": "https://arxiv.org/abs/2211.09710",
    "authors": [
      "Shlomo Tannor",
      "Nachum Dershowitz",
      "Moshe Lavee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10890",
    "title": "Single-Pass Contrastive Learning Can Work for Both Homophilic and  Heterophilic Graph",
    "abstract": " Comments: Section 4.1 explains our graph model and 4.2 compares it with other methods. 4.3 discusses our theoretical analysis. Empirical evidence in 6.2 and Appendix B.1 integrates our method with neural networks. Our graph learning method was validated using recent research. Note: text overlaps with arXiv:2204.04874 ",
    "url": "https://arxiv.org/abs/2211.10890",
    "authors": [
      "Haonan Wang",
      "Jieyu Zhang",
      "Qi Zhu",
      "Wei Huang",
      "Kenji Kawaguchi",
      "Xiaokui Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.15104",
    "title": "Approximate Predictive Control Barrier Functions using Neural Networks:  A Computationally Cheap and Permissive Safety Filter",
    "abstract": " Comments: Accepted at ECC23 ",
    "url": "https://arxiv.org/abs/2211.15104",
    "authors": [
      "Alexandre Didier",
      "Robin C. Jacobs",
      "Jerome Sieber",
      "Kim P. Wabersich",
      "Melanie N. Zeilinger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2212.01771",
    "title": "Can Evolutionary Clustering Have Theoretical Guarantees?",
    "abstract": " Comments: 16 pages ",
    "url": "https://arxiv.org/abs/2212.01771",
    "authors": [
      "Chao Qian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.02230",
    "title": "A Hybrid Evolutionary Approach to Solve University Course Allocation  Problem",
    "abstract": " Title: A Hybrid Evolutionary Approach to Solve University Course Allocation  Problem ",
    "url": "https://arxiv.org/abs/2212.02230",
    "authors": [
      "Dibyo Fabian Dofadar",
      "Riyo Hayat Khan",
      "Shafqat Hasan",
      "Towshik Anam Taj",
      "Arif Shakil",
      "Mahbub Majumdar"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.06532",
    "title": "Validation of Neural Network Controllers for Uncertain Systems Through  Keep-Close Approach: Robustness Analysis and Safety Verification",
    "abstract": " Comments: 25 pages, 16 figures, Journal Paper submitted to IEEE Transactions on Control Systems Technology ",
    "url": "https://arxiv.org/abs/2212.06532",
    "authors": [
      "Abdelhafid Zenati",
      "Nabil Aouf",
      "David Sanchez de la Llana",
      "Samir Bannani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2301.11305",
    "title": "DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability  Curvature",
    "abstract": " Comments: ICML 2023 ",
    "url": "https://arxiv.org/abs/2301.11305",
    "authors": [
      "Eric Mitchell",
      "Yoonho Lee",
      "Alexander Khazatsky",
      "Christopher D. Manning",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.11513",
    "title": "CellMix: A General Instance Relationship based Method for Data  Augmentation Towards Pathology Image Classification",
    "abstract": " Title: CellMix: A General Instance Relationship based Method for Data  Augmentation Towards Pathology Image Classification ",
    "url": "https://arxiv.org/abs/2301.11513",
    "authors": [
      "Tianyi Zhang",
      "Zhiling Yan",
      "Chunhui Li",
      "Nan Ying",
      "Yanli Lei",
      "Yunlu Feng",
      "Yu Zhao",
      "Guanglei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.05400",
    "title": "DNArch: Learning Convolutional Neural Architectures by Backpropagation",
    "abstract": " Title: DNArch: Learning Convolutional Neural Architectures by Backpropagation ",
    "url": "https://arxiv.org/abs/2302.05400",
    "authors": [
      "David W. Romero",
      "Neil Zeghidour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.07989",
    "title": "From Graph Generation to Graph Classification",
    "abstract": " Comments: I welcome suggestions, comments, and proposals for collaboration to develop further the ideas in this paper. Please email oschulte@cs.sfu.ca. I am grateful to Renjie Liao for helpful comments ",
    "url": "https://arxiv.org/abs/2302.07989",
    "authors": [
      "Oliver Schulte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.08544",
    "title": "Knowledge-based Intent Modeling for Next Generation Cellular Networks",
    "abstract": " Comments: Accepted at MeditCom 2023 ",
    "url": "https://arxiv.org/abs/2302.08544",
    "authors": [
      "Kashif Mehmood",
      "Katina Kralevska",
      "David Palma"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2302.13687",
    "title": "FRoGGeR: Fast Robust Grasp Generation via the Min-Weight Metric",
    "abstract": " Comments: Accepted at IROS 2023. The arXiv version contains the appendix, which does not appear in the conference version ",
    "url": "https://arxiv.org/abs/2302.13687",
    "authors": [
      "Albert H. Li",
      "Preston Culbertson",
      "Joel W. Burdick",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2302.14349",
    "title": "Advantages of Asynchronous Measurement-Device-Independent Quantum Key  Distribution in Intercity Networks",
    "abstract": " Comments: 15 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2302.14349",
    "authors": [
      "Yuan-Mei Xie",
      "Jun-Lin Bai",
      "Yu-Shuo Lu",
      "Chen-Xun Weng",
      "Hua-Lei Yin",
      "Zeng-Bing Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.01284",
    "title": "NeU-NBV: Next Best View Planning Using Uncertainty Estimation in  Image-Based Neural Rendering",
    "abstract": " Comments: Accepted to IEEE/RSJ International Conference on Robotics and Intelligent Systems (IROS) 2023 ",
    "url": "https://arxiv.org/abs/2303.01284",
    "authors": [
      "Liren Jin",
      "Xieyuanli Chen",
      "Julius R\u00fcckin",
      "Marija Popovi\u0107"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.02401",
    "title": "Open-Vocabulary Affordance Detection in 3D Point Clouds",
    "abstract": " Comments: Accepted at The 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023) ",
    "url": "https://arxiv.org/abs/2303.02401",
    "authors": [
      "Toan Nguyen",
      "Minh Nhat Vu",
      "An Vuong",
      "Dzung Nguyen",
      "Thieu Vo",
      "Ngan Le",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06147",
    "title": "Exphormer: Sparse Transformers for Graphs",
    "abstract": " Title: Exphormer: Sparse Transformers for Graphs ",
    "url": "https://arxiv.org/abs/2303.06147",
    "authors": [
      "Hamed Shirzad",
      "Ameya Velingker",
      "Balaji Venkatachalam",
      "Danica J. Sutherland",
      "Ali Kemal Sinop"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06516",
    "title": "Efficient Computation of Shap Explanation Scores for Neural Network  Classifiers via Knowledge Compilation",
    "abstract": " Comments: Substantial revision of previous version with the same title. To appear in conference proceedings. It replaces the previously uploaded paper \"Opening Up the Neural Network Classifier for Shap Score Computation\", by the same authors ",
    "url": "https://arxiv.org/abs/2303.06516",
    "authors": [
      "Leopoldo Bertossi",
      "Jorge E. Leon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09340",
    "title": "Improving Automated Hemorrhage Detection in Sparse-view Computed  Tomography via Deep Convolutional Neural Network based Artifact Reduction",
    "abstract": " Comments: 11 pages, 6 figures, 1 table ",
    "url": "https://arxiv.org/abs/2303.09340",
    "authors": [
      "Johannes Thalhammer",
      "Manuel Schultheiss",
      "Tina Dorosti",
      "Tobias Lasser",
      "Franz Pfeiffer",
      "Daniela Pfeiffer",
      "Florian Schaff"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2303.10081",
    "title": "Verification and Synthesis of Robust Control Barrier Functions:  Multilevel Polynomial Optimization and Semidefinite Relaxation",
    "abstract": " Comments: Accepted to IEEE Conference on Decision and Control (CDC) 2023 ",
    "url": "https://arxiv.org/abs/2303.10081",
    "authors": [
      "Shucheng Kang",
      "Yuxiao Chen",
      "Heng Yang",
      "Marco Pavone"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.00429",
    "title": "Information Recovery-Driven Deep Incomplete Multiview Clustering Network",
    "abstract": " Comments: Accepted by TNNLS 2023. Please contact me if you have any questions: liucl1996@163.com. The code is available at: this https URL ",
    "url": "https://arxiv.org/abs/2304.00429",
    "authors": [
      "Chengliang Liu",
      "Jie Wen",
      "Zhihao Wu",
      "Xiaoling Luo",
      "Chao Huang",
      "Yong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.07378",
    "title": "A Reconfigurable Linear RF Analog Processor for Realizing Microwave  Artificial Neural Network",
    "abstract": " Comments: 11 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2304.07378",
    "authors": [
      "Minning Zhu",
      "Tzu-Wei Kuo",
      "Chung-Tse Michael Wu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2304.12073",
    "title": "The Game Chromatic Number of Complete Multipartite Graphs with No  Singletons",
    "abstract": " Title: The Game Chromatic Number of Complete Multipartite Graphs with No  Singletons ",
    "url": "https://arxiv.org/abs/2304.12073",
    "authors": [
      "Pawe\u0142 Obszarski",
      "Krzysztof Turowski",
      "Hubert Zi\u0119ba"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2304.12887",
    "title": "Data-Driven Robust Optimization for Energy-Aware and Safe Navigation of  Electric Vehicles",
    "abstract": " Title: Data-Driven Robust Optimization for Energy-Aware and Safe Navigation of  Electric Vehicles ",
    "url": "https://arxiv.org/abs/2304.12887",
    "authors": [
      "Simran Kumari",
      "Ashish R. Hota",
      "Siddhartha Mukhopadhyay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2304.13871",
    "title": "Typical and atypical solutions in non-convex neural networks with  discrete and continuous weights",
    "abstract": " Comments: 34 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2304.13871",
    "authors": [
      "Carlo Baldassi",
      "Enrico M. Malatesta",
      "Gabriele Perugini",
      "Riccardo Zecchina"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2305.03701",
    "title": "LMEye: An Interactive Perception Network for Large Language Models",
    "abstract": " Comments: working in progress,under review ",
    "url": "https://arxiv.org/abs/2305.03701",
    "authors": [
      "Yunxin Li",
      "Baotian Hu",
      "Xinyu Chen",
      "Lin Ma",
      "Min Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.06869",
    "title": "An Adaptive Graduated Nonconvexity Loss Function for Robust Nonlinear  Least Squares Solutions",
    "abstract": " Title: An Adaptive Graduated Nonconvexity Loss Function for Robust Nonlinear  Least Squares Solutions ",
    "url": "https://arxiv.org/abs/2305.06869",
    "authors": [
      "Kyungmin Jung",
      "Thomas Hitchcox",
      "James Richard Forbes"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.11435",
    "title": "Syllable Discovery and Cross-Lingual Generalization in a Visually  Grounded, Self-Supervised Speech Model",
    "abstract": " Comments: Interspeech 2023. Code & Model: this https URL ",
    "url": "https://arxiv.org/abs/2305.11435",
    "authors": [
      "Puyuan Peng",
      "Shang-Wen Li",
      "Okko R\u00e4s\u00e4nen",
      "Abdelrahman Mohamed",
      "David Harwath"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.15729",
    "title": "Accelerated K-Serial Stable Coalition for Dynamic Capture and Resource  Defense",
    "abstract": " Comments: 8 pages, 10 figures, 1 table ",
    "url": "https://arxiv.org/abs/2305.15729",
    "authors": [
      "Junfeng Chen",
      "Zili Tang",
      "Meng Guo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.16259",
    "title": "Neural Natural Language Processing for Long Texts: A Survey of the  State-of-the-Art",
    "abstract": " Comments: 58 pages, 11 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2305.16259",
    "authors": [
      "Dimitrios Tsirmpas",
      "Ioannis Gkionis",
      "Ioannis Mademlis",
      "Georgios Papadopoulos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.10125",
    "title": "Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress,  and Prospects",
    "abstract": " Comments: 20 pages, 230 references. The first work to comprehensively and systematically summarize self-supervised learning for time series analysis (SSL4TS). The GitHub repository is this https URL ",
    "url": "https://arxiv.org/abs/2306.10125",
    "authors": [
      "Kexin Zhang",
      "Qingsong Wen",
      "Chaoli Zhang",
      "Rongyao Cai",
      "Ming Jin",
      "Yong Liu",
      "James Zhang",
      "Yuxuan Liang",
      "Guansong Pang",
      "Dongjin Song",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2306.12231",
    "title": "Predicting protein variants with equivariant graph neural networks",
    "abstract": " Comments: 4 pages, 2 figures, accepted to the 2023 ICML Workshop on Computational Biology ",
    "url": "https://arxiv.org/abs/2306.12231",
    "authors": [
      "Antonia Boca",
      "Simon Mathis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2306.13385",
    "title": "Solving a class of multi-scale elliptic PDEs by means of Fourier-based  mixed physics informed neural networks",
    "abstract": " Title: Solving a class of multi-scale elliptic PDEs by means of Fourier-based  mixed physics informed neural networks ",
    "url": "https://arxiv.org/abs/2306.13385",
    "authors": [
      "Xi'an Li",
      "Jinran Wu",
      "You-Gan Wang",
      "Xin Tai",
      "Jianhua Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.15599",
    "title": "Coupling a Recurrent Neural Network to SPAD TCSPC Systems for Real-time  Fluorescence Lifetime Imaging",
    "abstract": " Title: Coupling a Recurrent Neural Network to SPAD TCSPC Systems for Real-time  Fluorescence Lifetime Imaging ",
    "url": "https://arxiv.org/abs/2306.15599",
    "authors": [
      "Yang Lin",
      "Paul Mos",
      "Andrei Ardelean",
      "Claudio Bruschini",
      "Edoardo Charbon"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2306.16264",
    "title": "Deep Unfolded Simulated Bifurcation for Massive MIMO Signal Detection",
    "abstract": " Comments: 5pages, 4 figures; codes are available at this https URL ",
    "url": "https://arxiv.org/abs/2306.16264",
    "authors": [
      "Satoshi Takabe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.17727",
    "title": "Improved NL2SQL based on Multi-layer Expert Network",
    "abstract": " Comments: the paper's figure has something wrong ",
    "url": "https://arxiv.org/abs/2306.17727",
    "authors": [
      "Chenduo Hao",
      "Xu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.01482",
    "title": "Nexus sine qua non: Essentially Connected Networks for Traffic  Forecasting",
    "abstract": " Title: Nexus sine qua non: Essentially Connected Networks for Traffic  Forecasting ",
    "url": "https://arxiv.org/abs/2307.01482",
    "authors": [
      "Tong Nie",
      "Guoyang Qin",
      "Yunpeng Wang",
      "Jian Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.02148",
    "title": "Compound Attention and Neighbor Matching Network for Multi-contrast MRI  Super-resolution",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2307.02148",
    "authors": [
      "Wenxuan Chen",
      "Sirui Wu",
      "Shuai Wang",
      "Zhongsen Li",
      "Jia Yang",
      "Huifeng Yao",
      "Xiaomeng Li",
      "Xiaolei Song"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.02591",
    "title": "ODD: A Benchmark Dataset for the NLP-based Opioid Related Aberrant  Behavior Detection",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2307.02591",
    "authors": [
      "Sunjae Kwon",
      "Xun Wang",
      "Weisong Liu",
      "Emily Druhl",
      "Minhee L. Sung",
      "Joel I. Reisman",
      "Wenjun Li",
      "Robert D. Kerns",
      "William Becker",
      "Hong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.02813",
    "title": "CPDG: A Contrastive Pre-Training Method for Dynamic Graph Neural  Networks",
    "abstract": " Comments: 13 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2307.02813",
    "authors": [
      "Yuanchen Bei",
      "Hao Xu",
      "Sheng Zhou",
      "Huixuan Chi",
      "Haishuai Wang",
      "Mengdi Zhang",
      "Zhao Li",
      "Jiajun Bu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2307.05182",
    "title": "CAT-ViL: Co-Attention Gated Vision-Language Embedding for Visual  Question Localized-Answering in Robotic Surgery",
    "abstract": " Comments: To appear in MICCAI 2023. Code availability: this https URL ",
    "url": "https://arxiv.org/abs/2307.05182",
    "authors": [
      "Long Bai",
      "Mobarakol Islam",
      "Hongliang Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2307.05811",
    "title": "Twin-width of graphs on surfaces",
    "abstract": " Title: Twin-width of graphs on surfaces ",
    "url": "https://arxiv.org/abs/2307.05811",
    "authors": [
      "Daniel Kr\u00e1\u013e",
      "Krist\u00fdna Pek\u00e1rkov\u00e1",
      "Kenny \u0160torgel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2307.05853",
    "title": "GLA-GCN: Global-local Adaptive Graph Convolutional Network for 3D Human  Pose Estimation from Monocular Video",
    "abstract": " Comments: 12 pages, Accepted to ICCV 2023, GitHub code: this https URL ",
    "url": "https://arxiv.org/abs/2307.05853",
    "authors": [
      "Bruce X.B. Yu",
      "Zhi Zhang",
      "Yongxu Liu",
      "Sheng-hua Zhong",
      "Yan Liu",
      "Chang Wen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.06148",
    "title": "NetGPT: A Native-AI Network Architecture Beyond Provisioning  Personalized Generative Services",
    "abstract": " Title: NetGPT: A Native-AI Network Architecture Beyond Provisioning  Personalized Generative Services ",
    "url": "https://arxiv.org/abs/2307.06148",
    "authors": [
      "Yuxuan Chen",
      "Rongpeng Li",
      "Zhifeng Zhao",
      "Chenghui Peng",
      "Jianjun Wu",
      "Ekram Hossain",
      "Honggang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.06207",
    "title": "Local Conditional Neural Fields for Versatile and Generalizable  Large-Scale Reconstructions in Computational Imaging",
    "abstract": " Title: Local Conditional Neural Fields for Versatile and Generalizable  Large-Scale Reconstructions in Computational Imaging ",
    "url": "https://arxiv.org/abs/2307.06207",
    "authors": [
      "Hao Wang",
      "Jiabei Zhu",
      "Yunzhe Li",
      "QianWan Yang",
      "Lei Tian"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2307.07847",
    "title": "Neural Video Recovery for Cloud Gaming",
    "abstract": " Title: Neural Video Recovery for Cloud Gaming ",
    "url": "https://arxiv.org/abs/2307.07847",
    "authors": [
      "Zhaoyuan He",
      "Yifan Yang",
      "Shuozhe Li",
      "Diyuan Dai",
      "Lili Qiu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2307.08044",
    "title": "Towards Flexible Time-to-event Modeling: Optimizing Neural Networks via  Rank Regression",
    "abstract": " Comments: Accepted at ECAI 2023 ",
    "url": "https://arxiv.org/abs/2307.08044",
    "authors": [
      "Hyunjun Lee",
      "Junhyun Lee",
      "Taehwa Choi",
      "Jaewoo Kang",
      "Sangbum Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.08572",
    "title": "Revisiting the Robustness of the Minimum Error Entropy Criterion: A  Transfer Learning Case Study",
    "abstract": " Comments: Manuscript accepted at ECAI-23. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2307.08572",
    "authors": [
      "Luis Pedro Silvestrin",
      "Shujian Yu",
      "Mark Hoogendoorn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08930",
    "title": "Unsupervised Deep Graph Matching Based on Cycle Consistency",
    "abstract": " Comments: 12 pages, 5 figures, 3 papers ",
    "url": "https://arxiv.org/abs/2307.08930",
    "authors": [
      "Siddharth Tourani",
      "Carsten Rother",
      "Muhammad Haris Khan",
      "Bogdan Savchynskyy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09339",
    "title": "Trajectory Data Collection with Local Differential Privacy",
    "abstract": " Comments: Accepted by VLDB 2023 ",
    "url": "https://arxiv.org/abs/2307.09339",
    "authors": [
      "Yuemin Zhang",
      "Qingqing Ye",
      "Rui Chen",
      "Haibo Hu",
      "Qilong Han"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.09624",
    "title": "Transformer-based Dual-domain Network for Few-view Dedicated Cardiac  SPECT Image Reconstructions",
    "abstract": " Comments: Early accepted by MICCAI 2023 in Vancouver, Canada ",
    "url": "https://arxiv.org/abs/2307.09624",
    "authors": [
      "Huidong Xie",
      "Bo Zhou",
      "Xiongchao Chen",
      "Xueqi Guo",
      "Stephanie Thorn",
      "Yi-Hwa Liu",
      "Ge Wang",
      "Albert Sinusas",
      "Chi Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.10443",
    "title": "Integrating a Heterogeneous Graph with Entity-aware Self-attention using  Relative Position Labels for Reading Comprehension Model",
    "abstract": " Comments: submitted for Knowledge-Based Systems Journal ",
    "url": "https://arxiv.org/abs/2307.10443",
    "authors": [
      "Shima Foolad",
      "Kourosh Kiani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.10479",
    "title": "Fast Approximate Nearest Neighbor Search with a Dynamic Exploration  Graph using Continuous Refinement",
    "abstract": " Title: Fast Approximate Nearest Neighbor Search with a Dynamic Exploration  Graph using Continuous Refinement ",
    "url": "https://arxiv.org/abs/2307.10479",
    "authors": [
      "Nico Hezel",
      "Kai Uwe Barthel",
      "Konstantin Schall",
      "Klaus Jung"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2307.10559",
    "title": "Air Traffic Controller Workload Level Prediction using Conformalized  Dynamical Graph Learning",
    "abstract": " Title: Air Traffic Controller Workload Level Prediction using Conformalized  Dynamical Graph Learning ",
    "url": "https://arxiv.org/abs/2307.10559",
    "authors": [
      "Yutian Pang",
      "Jueming Hu",
      "Christopher S. Lieber",
      "Nancy J. Cooke",
      "Yongming Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2307.10583",
    "title": "Deep fused flow and topology features for botnet detection basing on  pretrained GCN",
    "abstract": " Title: Deep fused flow and topology features for botnet detection basing on  pretrained GCN ",
    "url": "https://arxiv.org/abs/2307.10583",
    "authors": [
      "Meng Xiaoyuan",
      "Lang bo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.10853",
    "title": "Exploring Effective Priors and Efficient Models for Weakly-Supervised  Change Detection",
    "abstract": " Title: Exploring Effective Priors and Efficient Models for Weakly-Supervised  Change Detection ",
    "url": "https://arxiv.org/abs/2307.10853",
    "authors": [
      "Zhenghui Zhao",
      "Lixiang Ru",
      "Chen Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.11019",
    "title": "Investigating the Factual Knowledge Boundary of Large Language Models  with Retrieval Augmentation",
    "abstract": " Title: Investigating the Factual Knowledge Boundary of Large Language Models  with Retrieval Augmentation ",
    "url": "https://arxiv.org/abs/2307.11019",
    "authors": [
      "Ruiyang Ren",
      "Yuhao Wang",
      "Yingqi Qu",
      "Wayne Xin Zhao",
      "Jing Liu",
      "Hao Tian",
      "Hua Wu",
      "Ji-Rong Wen",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2307.11411",
    "title": "Deep Directly-Trained Spiking Neural Networks for Object Detection",
    "abstract": " Comments: Accepted by ICCV2023 ",
    "url": "https://arxiv.org/abs/2307.11411",
    "authors": [
      "Qiaoyi Su",
      "Yuhong Chou",
      "Yifan Hu",
      "Jianing Li",
      "Shijie Mei",
      "Ziyang Zhang",
      "Guoqi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.11466",
    "title": "MatSpectNet: Material Segmentation Network with Domain-Aware and  Physically-Constrained Hyperspectral Reconstruction",
    "abstract": " Comments: 7 pages main paper ",
    "url": "https://arxiv.org/abs/2307.11466",
    "authors": [
      "Yuwen Heng",
      "Yihong Wu",
      "Jiawen Chen",
      "Srinandan Dasmahapatra",
      "Hansung Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2307.11610",
    "title": "CausE: Towards Causal Knowledge Graph Embedding",
    "abstract": " Comments: Accepted by CCKS 2023 as a research paper ",
    "url": "https://arxiv.org/abs/2307.11610",
    "authors": [
      "Yichi Zhang",
      "Wen Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.11643",
    "title": "Morphological Image Analysis and Feature Extraction for Reasoning with  AI-based Defect Detection and Classification Models",
    "abstract": " Comments: 8 pages, 3 figures, 5 tables; submitted to 2023 IEEE symposium series on computational intelligence (SSCI) ",
    "url": "https://arxiv.org/abs/2307.11643",
    "authors": [
      "Jiajun Zhang",
      "Georgina Cosma",
      "Sarah Bugby",
      "Axel Finke",
      "Jason Watkins"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]